{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from train_RNA_ResNet import ResNet\n",
    "from keras import callbacks as cb\n",
    "from Calibration_Util import FileIO as io\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnaNet = ResNet()\n",
    "\n",
    "# GTEX as source and TCGA as target\n",
    "# source_file = 'unnorm-log-20PC-GTEX-breast.csv'\n",
    "# target_file = 'unnorm-log-20PC-TCGA-breast.csv'\n",
    "# source_path = os.path.join(io.DeepLearningRoot(), 'data/unnorm/breast/' + source_file)\n",
    "# target_path = os.path.join(io.DeepLearningRoot(), 'data/unnorm/breast/' + target_file)\n",
    "\n",
    "# Make GTEX target and TCGA source\n",
    "source_file = 'unnorm-log-20PC-TCGA-breast.csv'\n",
    "target_file = 'unnorm-log-20PC-GTEX-breast.csv'\n",
    "source_path = os.path.join(io.DeepLearningRoot(), 'data/unnorm/breast/' + source_file)\n",
    "target_path = os.path.join(io.DeepLearningRoot(), 'data/unnorm/breast/' + target_file)\n",
    "\n",
    "\n",
    "rnaNet.load_data(source_path=source_path,\n",
    "                target_path=target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1067.14365714   103.1033644 ]\n",
      " [-1022.31171832   -94.6254463 ]\n",
      " [-1066.99297093   107.32705825]\n",
      " [-1040.41299606   106.28553413]]\n",
      "[[-1050.32294685    23.69936908]\n",
      " [-1002.63295612  -119.89820325]\n",
      " [-1048.38625088    -9.52969781]\n",
      " [-1062.33591471    67.23195916]]\n",
      "\n",
      "gtex = source shape = (110, 20)\n",
      "tcga = target shape = (212, 20)\n"
     ]
    }
   ],
   "source": [
    "print(rnaNet.source[0:4, 0:2])\n",
    "print(rnaNet.target[0:4, 0:2])\n",
    "print(\"\\ngtex = source shape = \" + str(rnaNet.source.shape))\n",
    "print(\"tcga = target shape = \" + str(rnaNet.target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "Index(['TCGA.breast', 'TCGA.breast.1', 'TCGA.breast.2', 'TCGA.breast.3',\n",
      "       'TCGA.breast.4', 'TCGA.breast.5', 'TCGA.breast.6', 'TCGA.breast.7',\n",
      "       'TCGA.breast.8', 'TCGA.breast.9',\n",
      "       ...\n",
      "       'TCGA.breast.100', 'TCGA.breast.101', 'TCGA.breast.102',\n",
      "       'TCGA.breast.103', 'TCGA.breast.104', 'TCGA.breast.105',\n",
      "       'TCGA.breast.106', 'TCGA.breast.107', 'TCGA.breast.108',\n",
      "       'TCGA.breast.109'],\n",
      "      dtype='object', length=110)\n"
     ]
    }
   ],
   "source": [
    "breast = re.compile(r'.*breast.*')\n",
    "ind = rnaNet.source_df.index\n",
    "\n",
    "print(ind.str.match(breast))\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting scales using KNN\n",
      "[34.549049364350182, 69.098098728700364, 138.19619745740073]\n",
      "setting all scale weights to 1\n",
      "(110, 20)\n"
     ]
    }
   ],
   "source": [
    "rnaNet.init_res_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99 samples, validate on 11 samples\n",
      "Epoch 1/1000\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 1.5925 - val_loss: 1.7773\n",
      "Epoch 2/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.6012 - val_loss: 1.7774\n",
      "Epoch 3/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.6029 - val_loss: 1.7776\n",
      "Epoch 4/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.5894 - val_loss: 1.7779\n",
      "Epoch 5/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.5968 - val_loss: 1.7781\n",
      "Epoch 6/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.5998 - val_loss: 1.7784\n",
      "Epoch 7/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.5911 - val_loss: 1.7787\n",
      "Epoch 8/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.5923 - val_loss: 1.7790\n",
      "Epoch 9/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.5875 - val_loss: 1.7793\n",
      "Epoch 10/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.5967 - val_loss: 1.7796\n",
      "Epoch 11/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.5930 - val_loss: 1.7798\n",
      "Epoch 12/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.5862 - val_loss: 1.7800\n",
      "Epoch 13/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.5997 - val_loss: 1.7802\n",
      "Epoch 14/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.5928 - val_loss: 1.7804\n",
      "Epoch 15/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.6082 - val_loss: 1.7805\n",
      "Epoch 16/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.5899 - val_loss: 1.7807\n",
      "Epoch 17/1000\n",
      "99/99 [==============================] - 0s 484us/step - loss: 1.5926 - val_loss: 1.7810\n",
      "Epoch 18/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.5949 - val_loss: 1.7812\n",
      "Epoch 19/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.5989 - val_loss: 1.7814\n",
      "Epoch 20/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.5972 - val_loss: 1.7815\n",
      "Epoch 21/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.5934 - val_loss: 1.7817\n",
      "Epoch 22/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.5960 - val_loss: 1.7819\n",
      "Epoch 23/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.6008 - val_loss: 1.7821\n",
      "Epoch 24/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.5842 - val_loss: 1.7823\n",
      "Epoch 25/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.5797 - val_loss: 1.7826\n",
      "Epoch 26/1000\n",
      "99/99 [==============================] - 0s 496us/step - loss: 1.5856 - val_loss: 1.7829\n",
      "Epoch 27/1000\n",
      "99/99 [==============================] - 0s 489us/step - loss: 1.5897 - val_loss: 1.7831\n",
      "Epoch 28/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.5857 - val_loss: 1.7833\n",
      "Epoch 29/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.5958 - val_loss: 1.7834\n",
      "Epoch 30/1000\n",
      "99/99 [==============================] - 0s 489us/step - loss: 1.5878 - val_loss: 1.7834\n",
      "Epoch 31/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.5780 - val_loss: 1.7837\n",
      "Epoch 32/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.5745 - val_loss: 1.7839\n",
      "Epoch 33/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.5848 - val_loss: 1.7844\n",
      "Epoch 34/1000\n",
      "99/99 [==============================] - 0s 493us/step - loss: 1.5796 - val_loss: 1.7846\n",
      "Epoch 35/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.5970 - val_loss: 1.7848\n",
      "Epoch 36/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.5790 - val_loss: 1.7848\n",
      "Epoch 37/1000\n",
      "99/99 [==============================] - 0s 540us/step - loss: 1.5850 - val_loss: 1.7847\n",
      "Epoch 38/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.5799 - val_loss: 1.7847\n",
      "Epoch 39/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.5792 - val_loss: 1.7849\n",
      "Epoch 40/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.5809 - val_loss: 1.7855\n",
      "Epoch 41/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.5713 - val_loss: 1.7856\n",
      "Epoch 42/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.5842 - val_loss: 1.7859\n",
      "Epoch 43/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.5705 - val_loss: 1.7860\n",
      "Epoch 44/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.5732 - val_loss: 1.7863\n",
      "Epoch 45/1000\n",
      "99/99 [==============================] - 0s 528us/step - loss: 1.5826 - val_loss: 1.7867\n",
      "Epoch 46/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.5756 - val_loss: 1.7869\n",
      "Epoch 47/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.5704 - val_loss: 1.7869\n",
      "Epoch 48/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.5743 - val_loss: 1.7870\n",
      "Epoch 49/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.5976 - val_loss: 1.7875\n",
      "Epoch 50/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.5620 - val_loss: 1.7877\n",
      "Epoch 51/1000\n",
      "99/99 [==============================] - 0s 524us/step - loss: 1.5848 - val_loss: 1.7880\n",
      "Epoch 52/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.5832 - val_loss: 1.7884\n",
      "Epoch 53/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.5806 - val_loss: 1.7885\n",
      "Epoch 54/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.5722 - val_loss: 1.7883\n",
      "Epoch 55/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.5707 - val_loss: 1.7880\n",
      "Epoch 56/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.5737 - val_loss: 1.7879\n",
      "Epoch 57/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.5722 - val_loss: 1.7875\n",
      "Epoch 58/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.5731 - val_loss: 1.7871\n",
      "Epoch 59/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.5750 - val_loss: 1.7873\n",
      "Epoch 60/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.5670 - val_loss: 1.7871\n",
      "Epoch 61/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.5648 - val_loss: 1.7868\n",
      "Epoch 62/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.5540 - val_loss: 1.7868\n",
      "Epoch 63/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.5484 - val_loss: 1.7865\n",
      "Epoch 64/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.5705 - val_loss: 1.7867\n",
      "Epoch 65/1000\n",
      "99/99 [==============================] - 0s 524us/step - loss: 1.5653 - val_loss: 1.7869\n",
      "Epoch 66/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.5723 - val_loss: 1.7867\n",
      "Epoch 67/1000\n",
      "99/99 [==============================] - 0s 530us/step - loss: 1.5717 - val_loss: 1.7867\n",
      "Epoch 68/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.5605 - val_loss: 1.7866\n",
      "Epoch 69/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.5531 - val_loss: 1.7872\n",
      "Epoch 70/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.5548 - val_loss: 1.7876\n",
      "Epoch 71/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.5587 - val_loss: 1.7879\n",
      "Epoch 72/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.5560 - val_loss: 1.7873\n",
      "Epoch 73/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.5476 - val_loss: 1.7866\n",
      "Epoch 74/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.5713 - val_loss: 1.7856\n",
      "Epoch 75/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.5440 - val_loss: 1.7847\n",
      "Epoch 76/1000\n",
      "99/99 [==============================] - 0s 524us/step - loss: 1.5490 - val_loss: 1.7834\n",
      "Epoch 77/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.5487 - val_loss: 1.7828\n",
      "Epoch 78/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.5610 - val_loss: 1.7825\n",
      "Epoch 79/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.5565 - val_loss: 1.7821\n",
      "Epoch 80/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.5364 - val_loss: 1.7797\n",
      "Epoch 81/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.5415 - val_loss: 1.7786\n",
      "Epoch 82/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.5429 - val_loss: 1.7784\n",
      "Epoch 83/1000\n",
      "99/99 [==============================] - 0s 528us/step - loss: 1.5508 - val_loss: 1.7775\n",
      "Epoch 84/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.5382 - val_loss: 1.7769\n",
      "Epoch 85/1000\n",
      "99/99 [==============================] - 0s 487us/step - loss: 1.5422 - val_loss: 1.7760\n",
      "Epoch 86/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.5432 - val_loss: 1.7743\n",
      "Epoch 87/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.5383 - val_loss: 1.7728\n",
      "Epoch 88/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 1.5289 - val_loss: 1.7732\n",
      "Epoch 89/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.5297 - val_loss: 1.7756\n",
      "Epoch 90/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.5379 - val_loss: 1.7759\n",
      "Epoch 91/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.5204 - val_loss: 1.7779\n",
      "Epoch 92/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.5326 - val_loss: 1.7793\n",
      "Epoch 93/1000\n",
      "99/99 [==============================] - 0s 491us/step - loss: 1.5185 - val_loss: 1.7792\n",
      "Epoch 94/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 1.5274 - val_loss: 1.7771\n",
      "Epoch 95/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.5367 - val_loss: 1.7747\n",
      "Epoch 96/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.5159 - val_loss: 1.7704\n",
      "Epoch 97/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.5219 - val_loss: 1.7662\n",
      "Epoch 98/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.5104 - val_loss: 1.7651\n",
      "Epoch 99/1000\n",
      "99/99 [==============================] - 0s 544us/step - loss: 1.5154 - val_loss: 1.7660\n",
      "Epoch 100/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.5340 - val_loss: 1.7639\n",
      "Epoch 101/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.5199 - val_loss: 1.7647\n",
      "Epoch 102/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.5099 - val_loss: 1.7666\n",
      "Epoch 103/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.5280 - val_loss: 1.7650\n",
      "Epoch 104/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.4993 - val_loss: 1.7627\n",
      "Epoch 105/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.5039 - val_loss: 1.7613\n",
      "Epoch 106/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.5375 - val_loss: 1.7612\n",
      "Epoch 107/1000\n",
      "99/99 [==============================] - 0s 529us/step - loss: 1.4905 - val_loss: 1.7624\n",
      "Epoch 108/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.5069 - val_loss: 1.7571\n",
      "Epoch 109/1000\n",
      "99/99 [==============================] - 0s 490us/step - loss: 1.5100 - val_loss: 1.7521\n",
      "Epoch 110/1000\n",
      "99/99 [==============================] - 0s 496us/step - loss: 1.5016 - val_loss: 1.7524\n",
      "Epoch 111/1000\n",
      "99/99 [==============================] - 0s 527us/step - loss: 1.4941 - val_loss: 1.7547\n",
      "Epoch 112/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.4891 - val_loss: 1.7537\n",
      "Epoch 113/1000\n",
      "99/99 [==============================] - 0s 539us/step - loss: 1.4865 - val_loss: 1.7556\n",
      "Epoch 114/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.4828 - val_loss: 1.7561\n",
      "Epoch 115/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.4917 - val_loss: 1.7534\n",
      "Epoch 116/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.4703 - val_loss: 1.7487\n",
      "Epoch 117/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.4708 - val_loss: 1.7457\n",
      "Epoch 118/1000\n",
      "99/99 [==============================] - 0s 492us/step - loss: 1.4963 - val_loss: 1.7475\n",
      "Epoch 119/1000\n",
      "99/99 [==============================] - 0s 495us/step - loss: 1.4689 - val_loss: 1.7488\n",
      "Epoch 120/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.4714 - val_loss: 1.7501\n",
      "Epoch 121/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.4699 - val_loss: 1.7529\n",
      "Epoch 122/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.4725 - val_loss: 1.7545\n",
      "Epoch 123/1000\n",
      "99/99 [==============================] - 0s 484us/step - loss: 1.4639 - val_loss: 1.7546\n",
      "Epoch 124/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.4761 - val_loss: 1.7589\n",
      "Epoch 125/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.4578 - val_loss: 1.7650\n",
      "Epoch 126/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.4578 - val_loss: 1.7692\n",
      "Epoch 127/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.4850 - val_loss: 1.7741\n",
      "Epoch 128/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.4560 - val_loss: 1.7769\n",
      "Epoch 129/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.4598 - val_loss: 1.7754\n",
      "Epoch 130/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.4472 - val_loss: 1.7687\n",
      "Epoch 131/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.4725 - val_loss: 1.7711\n",
      "Epoch 132/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.4636 - val_loss: 1.7740\n",
      "Epoch 133/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.4608 - val_loss: 1.7708\n",
      "Epoch 134/1000\n",
      "99/99 [==============================] - 0s 529us/step - loss: 1.4626 - val_loss: 1.7664\n",
      "Epoch 135/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.4620 - val_loss: 1.7657\n",
      "Epoch 136/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.4634 - val_loss: 1.7649\n",
      "Epoch 137/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.4305 - val_loss: 1.7636\n",
      "Epoch 138/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.4245 - val_loss: 1.7612\n",
      "Epoch 139/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.4354 - val_loss: 1.7640\n",
      "Epoch 140/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.4287 - val_loss: 1.7679\n",
      "Epoch 141/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.4294 - val_loss: 1.7696\n",
      "Epoch 142/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.4103 - val_loss: 1.7749\n",
      "Epoch 143/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.4411 - val_loss: 1.7763\n",
      "Epoch 144/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.4200 - val_loss: 1.7732\n",
      "Epoch 145/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.4188 - val_loss: 1.7667\n",
      "Epoch 146/1000\n",
      "99/99 [==============================] - 0s 531us/step - loss: 1.4094 - val_loss: 1.7639\n",
      "Epoch 147/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.4237 - val_loss: 1.7628\n",
      "Epoch 148/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.4140 - val_loss: 1.7629\n",
      "Epoch 149/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.4123 - val_loss: 1.7699\n",
      "Epoch 150/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.4025 - val_loss: 1.7805\n",
      "Epoch 151/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.4014 - val_loss: 1.7794\n",
      "Epoch 152/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.4213 - val_loss: 1.7754\n",
      "Epoch 153/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.4030 - val_loss: 1.7713\n",
      "Epoch 154/1000\n",
      "99/99 [==============================] - 0s 535us/step - loss: 1.3934 - val_loss: 1.7685\n",
      "Epoch 155/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.4195 - val_loss: 1.7815\n",
      "Epoch 156/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.4163 - val_loss: 1.7784\n",
      "Epoch 157/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.3931 - val_loss: 1.7773\n",
      "Epoch 158/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.3844 - val_loss: 1.7714\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 528us/step - loss: 1.4047 - val_loss: 1.7773\n",
      "Epoch 160/1000\n",
      "99/99 [==============================] - 0s 495us/step - loss: 1.3918 - val_loss: 1.7878\n",
      "Epoch 161/1000\n",
      "99/99 [==============================] - 0s 491us/step - loss: 1.3872 - val_loss: 1.7929\n",
      "Epoch 162/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.3715 - val_loss: 1.7926\n",
      "Epoch 163/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.4065 - val_loss: 1.7889\n",
      "Epoch 164/1000\n",
      "99/99 [==============================] - 0s 495us/step - loss: 1.3940 - val_loss: 1.7866\n",
      "Epoch 165/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 1.3893 - val_loss: 1.7927\n",
      "Epoch 166/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.3842 - val_loss: 1.7955\n",
      "Epoch 167/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.3740 - val_loss: 1.7933\n",
      "Epoch 168/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.3937 - val_loss: 1.7953\n",
      "Epoch 169/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.3750 - val_loss: 1.7969\n",
      "Epoch 170/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.3670 - val_loss: 1.7987\n",
      "Epoch 171/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.3725 - val_loss: 1.7997\n",
      "Epoch 172/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.3635 - val_loss: 1.7985\n",
      "Epoch 173/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.3795 - val_loss: 1.8017\n",
      "Epoch 174/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.3671 - val_loss: 1.7910\n",
      "Epoch 175/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.3610 - val_loss: 1.7786\n",
      "Epoch 176/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.3573 - val_loss: 1.7787\n",
      "Epoch 177/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.3863 - val_loss: 1.7930\n",
      "Epoch 178/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.3662 - val_loss: 1.8061\n",
      "Epoch 179/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.3455 - val_loss: 1.8090\n",
      "Epoch 180/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.3690 - val_loss: 1.8113\n",
      "Epoch 181/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.3577 - val_loss: 1.8017\n",
      "Epoch 182/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.3521 - val_loss: 1.7931\n",
      "Epoch 183/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.3738 - val_loss: 1.7830\n",
      "Epoch 184/1000\n",
      "99/99 [==============================] - 0s 483us/step - loss: 1.3500 - val_loss: 1.7780\n",
      "Epoch 185/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.3602 - val_loss: 1.7728\n",
      "Epoch 186/1000\n",
      "99/99 [==============================] - 0s 525us/step - loss: 1.3507 - val_loss: 1.7608\n",
      "Epoch 187/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.3444 - val_loss: 1.7506\n",
      "Epoch 188/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.3451 - val_loss: 1.7482\n",
      "Epoch 189/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 1.3750 - val_loss: 1.7453\n",
      "Epoch 190/1000\n",
      "99/99 [==============================] - 0s 523us/step - loss: 1.3639 - val_loss: 1.7435\n",
      "Epoch 191/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.3264 - val_loss: 1.7424\n",
      "Epoch 192/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.3222 - val_loss: 1.7405\n",
      "Epoch 193/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.3504 - val_loss: 1.7430\n",
      "Epoch 194/1000\n",
      "99/99 [==============================] - 0s 524us/step - loss: 1.3304 - val_loss: 1.7435\n",
      "Epoch 195/1000\n",
      "99/99 [==============================] - 0s 523us/step - loss: 1.3166 - val_loss: 1.7434\n",
      "Epoch 196/1000\n",
      "99/99 [==============================] - 0s 526us/step - loss: 1.3300 - val_loss: 1.7418\n",
      "Epoch 197/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.3286 - val_loss: 1.7396\n",
      "Epoch 198/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.3400 - val_loss: 1.7394\n",
      "Epoch 199/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.3118 - val_loss: 1.7366\n",
      "Epoch 200/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.3323 - val_loss: 1.7360\n",
      "Epoch 201/1000\n",
      "99/99 [==============================] - 0s 535us/step - loss: 1.3183 - val_loss: 1.7410\n",
      "Epoch 202/1000\n",
      "99/99 [==============================] - 0s 491us/step - loss: 1.3176 - val_loss: 1.7341\n",
      "Epoch 203/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.3268 - val_loss: 1.7330\n",
      "Epoch 204/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.3049 - val_loss: 1.7332\n",
      "Epoch 205/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.3339 - val_loss: 1.7455\n",
      "Epoch 206/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.3249 - val_loss: 1.7565\n",
      "Epoch 207/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.3178 - val_loss: 1.7657\n",
      "Epoch 208/1000\n",
      "99/99 [==============================] - 0s 529us/step - loss: 1.3353 - val_loss: 1.7689\n",
      "Epoch 209/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.2995 - val_loss: 1.7724\n",
      "Epoch 210/1000\n",
      "99/99 [==============================] - 0s 526us/step - loss: 1.3173 - val_loss: 1.7706\n",
      "Epoch 211/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.3048 - val_loss: 1.7720\n",
      "Epoch 212/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.3013 - val_loss: 1.7706\n",
      "Epoch 213/1000\n",
      "99/99 [==============================] - 0s 496us/step - loss: 1.3324 - val_loss: 1.7645\n",
      "Epoch 214/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.2920 - val_loss: 1.7551\n",
      "Epoch 215/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.3242 - val_loss: 1.7426\n",
      "Epoch 216/1000\n",
      "99/99 [==============================] - 0s 491us/step - loss: 1.2906 - val_loss: 1.7349\n",
      "Epoch 217/1000\n",
      "99/99 [==============================] - 0s 523us/step - loss: 1.3054 - val_loss: 1.7232\n",
      "Epoch 218/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 1.3087 - val_loss: 1.7168\n",
      "Epoch 219/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.2945 - val_loss: 1.7169\n",
      "Epoch 220/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.2949 - val_loss: 1.7201\n",
      "Epoch 221/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.2858 - val_loss: 1.7169\n",
      "Epoch 222/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.3080 - val_loss: 1.7174\n",
      "Epoch 223/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.2988 - val_loss: 1.7207\n",
      "Epoch 224/1000\n",
      "99/99 [==============================] - 0s 496us/step - loss: 1.2770 - val_loss: 1.7223\n",
      "Epoch 225/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.3096 - val_loss: 1.7270\n",
      "Epoch 226/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.3071 - val_loss: 1.7251\n",
      "Epoch 227/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.2836 - val_loss: 1.7210\n",
      "Epoch 228/1000\n",
      "99/99 [==============================] - 0s 490us/step - loss: 1.2989 - val_loss: 1.7263\n",
      "Epoch 229/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.3160 - val_loss: 1.7360\n",
      "Epoch 230/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.2796 - val_loss: 1.7456\n",
      "Epoch 231/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.2701 - val_loss: 1.7603\n",
      "Epoch 232/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.2674 - val_loss: 1.7739\n",
      "Epoch 233/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.2763 - val_loss: 1.7751\n",
      "Epoch 234/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.2869 - val_loss: 1.7719\n",
      "Epoch 235/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.2830 - val_loss: 1.7693\n",
      "Epoch 236/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.2727 - val_loss: 1.7643\n",
      "Epoch 237/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.2894 - val_loss: 1.7573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.2604 - val_loss: 1.7586\n",
      "Epoch 239/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.2732 - val_loss: 1.7527\n",
      "Epoch 240/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.2641 - val_loss: 1.7530\n",
      "Epoch 241/1000\n",
      "99/99 [==============================] - 0s 525us/step - loss: 1.2804 - val_loss: 1.7509\n",
      "Epoch 242/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.2886 - val_loss: 1.7461\n",
      "Epoch 243/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 1.2701 - val_loss: 1.7444\n",
      "Epoch 244/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.2770 - val_loss: 1.7415\n",
      "Epoch 245/1000\n",
      "99/99 [==============================] - 0s 527us/step - loss: 1.2465 - val_loss: 1.7497\n",
      "Epoch 246/1000\n",
      "99/99 [==============================] - 0s 530us/step - loss: 1.2693 - val_loss: 1.7604\n",
      "Epoch 247/1000\n",
      "99/99 [==============================] - 0s 556us/step - loss: 1.2591 - val_loss: 1.7636\n",
      "Epoch 248/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.2675 - val_loss: 1.7608\n",
      "Epoch 249/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.2481 - val_loss: 1.7570\n",
      "Epoch 250/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.2643 - val_loss: 1.7492\n",
      "Epoch 251/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.2710 - val_loss: 1.7362\n",
      "Epoch 252/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.2600 - val_loss: 1.7286\n",
      "Epoch 253/1000\n",
      "99/99 [==============================] - 0s 526us/step - loss: 1.2715 - val_loss: 1.7360\n",
      "Epoch 254/1000\n",
      "99/99 [==============================] - 0s 524us/step - loss: 1.2653 - val_loss: 1.7482\n",
      "Epoch 255/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.2599 - val_loss: 1.7456\n",
      "Epoch 256/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.2596 - val_loss: 1.7363\n",
      "Epoch 257/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.2566 - val_loss: 1.7265\n",
      "Epoch 258/1000\n",
      "99/99 [==============================] - 0s 524us/step - loss: 1.2604 - val_loss: 1.7253\n",
      "Epoch 259/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.2548 - val_loss: 1.7290\n",
      "Epoch 260/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.2389 - val_loss: 1.7248\n",
      "Epoch 261/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.2532 - val_loss: 1.7181\n",
      "Epoch 262/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.2323 - val_loss: 1.7154\n",
      "Epoch 263/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 1.2435 - val_loss: 1.7112\n",
      "Epoch 264/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.2467 - val_loss: 1.7089\n",
      "Epoch 265/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.2418 - val_loss: 1.7116\n",
      "Epoch 266/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.2385 - val_loss: 1.7120\n",
      "Epoch 267/1000\n",
      "99/99 [==============================] - 0s 492us/step - loss: 1.2425 - val_loss: 1.7147\n",
      "Epoch 268/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.2457 - val_loss: 1.7160\n",
      "Epoch 269/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.2375 - val_loss: 1.7168\n",
      "Epoch 270/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.2480 - val_loss: 1.7165\n",
      "Epoch 271/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.2312 - val_loss: 1.7094\n",
      "Epoch 272/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.2273 - val_loss: 1.6963\n",
      "Epoch 273/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.2269 - val_loss: 1.6904\n",
      "Epoch 274/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.2321 - val_loss: 1.6996\n",
      "Epoch 275/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.2461 - val_loss: 1.7072\n",
      "Epoch 276/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.2312 - val_loss: 1.6962\n",
      "Epoch 277/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.2218 - val_loss: 1.6883\n",
      "Epoch 278/1000\n",
      "99/99 [==============================] - 0s 526us/step - loss: 1.2270 - val_loss: 1.6758\n",
      "Epoch 279/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.2363 - val_loss: 1.6612\n",
      "Epoch 280/1000\n",
      "99/99 [==============================] - 0s 524us/step - loss: 1.2181 - val_loss: 1.6564\n",
      "Epoch 281/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.2497 - val_loss: 1.6549\n",
      "Epoch 282/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.2320 - val_loss: 1.6548\n",
      "Epoch 283/1000\n",
      "99/99 [==============================] - 0s 527us/step - loss: 1.2312 - val_loss: 1.6530\n",
      "Epoch 284/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.2395 - val_loss: 1.6544\n",
      "Epoch 285/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.2235 - val_loss: 1.6506\n",
      "Epoch 286/1000\n",
      "99/99 [==============================] - 0s 530us/step - loss: 1.2603 - val_loss: 1.6505\n",
      "Epoch 287/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.2277 - val_loss: 1.6575\n",
      "Epoch 288/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.2217 - val_loss: 1.6640\n",
      "Epoch 289/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.2295 - val_loss: 1.6672\n",
      "Epoch 290/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.2201 - val_loss: 1.6704\n",
      "Epoch 291/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.2327 - val_loss: 1.6783\n",
      "Epoch 292/1000\n",
      "99/99 [==============================] - 0s 525us/step - loss: 1.2077 - val_loss: 1.6768\n",
      "Epoch 293/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.2213 - val_loss: 1.6672\n",
      "Epoch 294/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.2256 - val_loss: 1.6669\n",
      "Epoch 295/1000\n",
      "99/99 [==============================] - 0s 495us/step - loss: 1.2220 - val_loss: 1.6476\n",
      "Epoch 296/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.2199 - val_loss: 1.6485\n",
      "Epoch 297/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.2248 - val_loss: 1.6519\n",
      "Epoch 298/1000\n",
      "99/99 [==============================] - 0s 492us/step - loss: 1.2260 - val_loss: 1.6614\n",
      "Epoch 299/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.2109 - val_loss: 1.6616\n",
      "Epoch 300/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.2210 - val_loss: 1.6615\n",
      "Epoch 301/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.2102 - val_loss: 1.6585\n",
      "Epoch 302/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.2199 - val_loss: 1.6505\n",
      "Epoch 303/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.2150 - val_loss: 1.6449\n",
      "Epoch 304/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.2080 - val_loss: 1.6383\n",
      "Epoch 305/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.2262 - val_loss: 1.6383\n",
      "Epoch 306/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.2244 - val_loss: 1.6273\n",
      "Epoch 307/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.2217 - val_loss: 1.6207\n",
      "Epoch 308/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.2100 - val_loss: 1.6082\n",
      "Epoch 309/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.2179 - val_loss: 1.6109\n",
      "Epoch 310/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.2024 - val_loss: 1.6135\n",
      "Epoch 311/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.2056 - val_loss: 1.6283\n",
      "Epoch 312/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.2318 - val_loss: 1.6401\n",
      "Epoch 313/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.2264 - val_loss: 1.6447\n",
      "Epoch 314/1000\n",
      "99/99 [==============================] - 0s 494us/step - loss: 1.2036 - val_loss: 1.6389\n",
      "Epoch 315/1000\n",
      "99/99 [==============================] - 0s 493us/step - loss: 1.2012 - val_loss: 1.6370\n",
      "Epoch 316/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.1924 - val_loss: 1.6291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.2146 - val_loss: 1.6363\n",
      "Epoch 318/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.2060 - val_loss: 1.6395\n",
      "Epoch 319/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.2084 - val_loss: 1.6440\n",
      "Epoch 320/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.2085 - val_loss: 1.6489\n",
      "Epoch 321/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.2067 - val_loss: 1.6441\n",
      "Epoch 322/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.2028 - val_loss: 1.6538\n",
      "Epoch 323/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.2187 - val_loss: 1.6577\n",
      "Epoch 324/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.2014 - val_loss: 1.6432\n",
      "Epoch 325/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.1924 - val_loss: 1.6326\n",
      "Epoch 326/1000\n",
      "99/99 [==============================] - 0s 531us/step - loss: 1.1858 - val_loss: 1.6247\n",
      "Epoch 327/1000\n",
      "99/99 [==============================] - 0s 534us/step - loss: 1.2150 - val_loss: 1.6080\n",
      "Epoch 328/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.2035 - val_loss: 1.6065\n",
      "Epoch 329/1000\n",
      "99/99 [==============================] - 0s 537us/step - loss: 1.1908 - val_loss: 1.6132\n",
      "Epoch 330/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.1907 - val_loss: 1.6133\n",
      "Epoch 331/1000\n",
      "99/99 [==============================] - 0s 530us/step - loss: 1.1983 - val_loss: 1.6144\n",
      "Epoch 332/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.1930 - val_loss: 1.6091\n",
      "Epoch 333/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.1882 - val_loss: 1.6113\n",
      "Epoch 334/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.1768 - val_loss: 1.6066\n",
      "Epoch 335/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.1859 - val_loss: 1.6127\n",
      "Epoch 336/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.1733 - val_loss: 1.6160\n",
      "Epoch 337/1000\n",
      "99/99 [==============================] - 0s 538us/step - loss: 1.2023 - val_loss: 1.6165\n",
      "Epoch 338/1000\n",
      "99/99 [==============================] - 0s 534us/step - loss: 1.1896 - val_loss: 1.6123\n",
      "Epoch 339/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.1795 - val_loss: 1.6141\n",
      "Epoch 340/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.1862 - val_loss: 1.6112\n",
      "Epoch 341/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.1796 - val_loss: 1.6103\n",
      "Epoch 342/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.1764 - val_loss: 1.6092\n",
      "Epoch 343/1000\n",
      "99/99 [==============================] - 0s 530us/step - loss: 1.1692 - val_loss: 1.6091\n",
      "Epoch 344/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.1848 - val_loss: 1.6139\n",
      "Epoch 345/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.1796 - val_loss: 1.6069\n",
      "Epoch 346/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.2052 - val_loss: 1.6052\n",
      "Epoch 347/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.1672 - val_loss: 1.6060\n",
      "Epoch 348/1000\n",
      "99/99 [==============================] - 0s 525us/step - loss: 1.1986 - val_loss: 1.6022\n",
      "Epoch 349/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.1864 - val_loss: 1.6039\n",
      "Epoch 350/1000\n",
      "99/99 [==============================] - 0s 524us/step - loss: 1.1720 - val_loss: 1.6083\n",
      "Epoch 351/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.1847 - val_loss: 1.6072\n",
      "Epoch 352/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.1872 - val_loss: 1.5991\n",
      "Epoch 353/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.1968 - val_loss: 1.5974\n",
      "Epoch 354/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.1972 - val_loss: 1.6086\n",
      "Epoch 355/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.1765 - val_loss: 1.6390\n",
      "Epoch 356/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.1809 - val_loss: 1.6520\n",
      "Epoch 357/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.1670 - val_loss: 1.6549\n",
      "Epoch 358/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.1675 - val_loss: 1.6471\n",
      "Epoch 359/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.2073 - val_loss: 1.6391\n",
      "Epoch 360/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.1782 - val_loss: 1.6346\n",
      "Epoch 361/1000\n",
      "99/99 [==============================] - 0s 543us/step - loss: 1.1870 - val_loss: 1.6330\n",
      "Epoch 362/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.1759 - val_loss: 1.6249\n",
      "Epoch 363/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.1776 - val_loss: 1.6200\n",
      "Epoch 364/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.1775 - val_loss: 1.6303\n",
      "Epoch 365/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.1749 - val_loss: 1.6397\n",
      "Epoch 366/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.1782 - val_loss: 1.6221\n",
      "Epoch 367/1000\n",
      "99/99 [==============================] - 0s 533us/step - loss: 1.1725 - val_loss: 1.6165\n",
      "Epoch 368/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.1578 - val_loss: 1.6129\n",
      "Epoch 369/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.1616 - val_loss: 1.6171\n",
      "Epoch 370/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.1653 - val_loss: 1.6204\n",
      "Epoch 371/1000\n",
      "99/99 [==============================] - 0s 523us/step - loss: 1.1914 - val_loss: 1.6309\n",
      "Epoch 372/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.1477 - val_loss: 1.6389\n",
      "Epoch 373/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.1597 - val_loss: 1.6403\n",
      "Epoch 374/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.1736 - val_loss: 1.6289\n",
      "Epoch 375/1000\n",
      "99/99 [==============================] - 0s 523us/step - loss: 1.1613 - val_loss: 1.6199\n",
      "Epoch 376/1000\n",
      "99/99 [==============================] - 0s 496us/step - loss: 1.1510 - val_loss: 1.6090\n",
      "Epoch 377/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.1444 - val_loss: 1.6000\n",
      "Epoch 378/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.1467 - val_loss: 1.5951\n",
      "Epoch 379/1000\n",
      "99/99 [==============================] - 0s 535us/step - loss: 1.1683 - val_loss: 1.5870\n",
      "Epoch 380/1000\n",
      "99/99 [==============================] - 0s 528us/step - loss: 1.1632 - val_loss: 1.5759\n",
      "Epoch 381/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.1621 - val_loss: 1.5648\n",
      "Epoch 382/1000\n",
      "99/99 [==============================] - 0s 495us/step - loss: 1.1529 - val_loss: 1.5578\n",
      "Epoch 383/1000\n",
      "99/99 [==============================] - 0s 526us/step - loss: 1.1569 - val_loss: 1.5607\n",
      "Epoch 384/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.1618 - val_loss: 1.5559\n",
      "Epoch 385/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.1546 - val_loss: 1.5629\n",
      "Epoch 386/1000\n",
      "99/99 [==============================] - 0s 539us/step - loss: 1.1458 - val_loss: 1.5722\n",
      "Epoch 387/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.1645 - val_loss: 1.5821\n",
      "Epoch 388/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.1533 - val_loss: 1.5859\n",
      "Epoch 389/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.1671 - val_loss: 1.5921\n",
      "Epoch 390/1000\n",
      "99/99 [==============================] - 0s 523us/step - loss: 1.1709 - val_loss: 1.6002\n",
      "Epoch 391/1000\n",
      "99/99 [==============================] - 0s 535us/step - loss: 1.1575 - val_loss: 1.6047\n",
      "Epoch 392/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.1500 - val_loss: 1.6054\n",
      "Epoch 393/1000\n",
      "99/99 [==============================] - 0s 531us/step - loss: 1.1652 - val_loss: 1.5989\n",
      "Epoch 394/1000\n",
      "99/99 [==============================] - 0s 545us/step - loss: 1.1669 - val_loss: 1.5972\n",
      "Epoch 395/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.1632 - val_loss: 1.5959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.1582 - val_loss: 1.5941\n",
      "Epoch 397/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.1586 - val_loss: 1.5948\n",
      "Epoch 398/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.1626 - val_loss: 1.6055\n",
      "Epoch 399/1000\n",
      "99/99 [==============================] - 0s 540us/step - loss: 1.1424 - val_loss: 1.6149\n",
      "Epoch 400/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.1392 - val_loss: 1.6097\n",
      "Epoch 401/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.1493 - val_loss: 1.5888\n",
      "Epoch 402/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.1599 - val_loss: 1.5795\n",
      "Epoch 403/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.1520 - val_loss: 1.5828\n",
      "Epoch 404/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.1573 - val_loss: 1.5895\n",
      "Epoch 405/1000\n",
      "99/99 [==============================] - 0s 532us/step - loss: 1.1337 - val_loss: 1.5895\n",
      "Epoch 406/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.1374 - val_loss: 1.5810\n",
      "Epoch 407/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.1584 - val_loss: 1.5635\n",
      "Epoch 408/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.1525 - val_loss: 1.5592\n",
      "Epoch 409/1000\n",
      "99/99 [==============================] - 0s 527us/step - loss: 1.1507 - val_loss: 1.5470\n",
      "Epoch 410/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.1516 - val_loss: 1.5387\n",
      "Epoch 411/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.1432 - val_loss: 1.5362\n",
      "Epoch 412/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.1569 - val_loss: 1.5365\n",
      "Epoch 413/1000\n",
      "99/99 [==============================] - 0s 524us/step - loss: 1.1376 - val_loss: 1.5346\n",
      "Epoch 414/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.1482 - val_loss: 1.5387\n",
      "Epoch 415/1000\n",
      "99/99 [==============================] - 0s 535us/step - loss: 1.1437 - val_loss: 1.5524\n",
      "Epoch 416/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.1591 - val_loss: 1.5583\n",
      "Epoch 417/1000\n",
      "99/99 [==============================] - 0s 524us/step - loss: 1.1532 - val_loss: 1.5671\n",
      "Epoch 418/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.1486 - val_loss: 1.5748\n",
      "Epoch 419/1000\n",
      "99/99 [==============================] - 0s 530us/step - loss: 1.1413 - val_loss: 1.5784\n",
      "Epoch 420/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.1797 - val_loss: 1.5847\n",
      "Epoch 421/1000\n",
      "99/99 [==============================] - 0s 531us/step - loss: 1.1420 - val_loss: 1.5846\n",
      "Epoch 422/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.1449 - val_loss: 1.5818\n",
      "Epoch 423/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.1405 - val_loss: 1.5931\n",
      "Epoch 424/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.1525 - val_loss: 1.6110\n",
      "Epoch 425/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.1267 - val_loss: 1.6136\n",
      "Epoch 426/1000\n",
      "99/99 [==============================] - 0s 541us/step - loss: 1.1250 - val_loss: 1.6095\n",
      "Epoch 427/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.1434 - val_loss: 1.5924\n",
      "Epoch 428/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.1472 - val_loss: 1.5849\n",
      "Epoch 429/1000\n",
      "99/99 [==============================] - 0s 529us/step - loss: 1.1539 - val_loss: 1.5844\n",
      "Epoch 430/1000\n",
      "99/99 [==============================] - 0s 528us/step - loss: 1.1244 - val_loss: 1.5865\n",
      "Epoch 431/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.1228 - val_loss: 1.5870\n",
      "Epoch 432/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.1535 - val_loss: 1.5816\n",
      "Epoch 433/1000\n",
      "99/99 [==============================] - 0s 538us/step - loss: 1.1356 - val_loss: 1.5697\n",
      "Epoch 434/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.1215 - val_loss: 1.5549\n",
      "Epoch 435/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.1415 - val_loss: 1.5465\n",
      "Epoch 436/1000\n",
      "99/99 [==============================] - 0s 524us/step - loss: 1.1174 - val_loss: 1.5456\n",
      "Epoch 437/1000\n",
      "99/99 [==============================] - 0s 494us/step - loss: 1.1505 - val_loss: 1.5577\n",
      "Epoch 438/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.1200 - val_loss: 1.5704\n",
      "Epoch 439/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.1350 - val_loss: 1.5763\n",
      "Epoch 440/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.1084 - val_loss: 1.5763\n",
      "Epoch 441/1000\n",
      "99/99 [==============================] - 0s 527us/step - loss: 1.1339 - val_loss: 1.5804\n",
      "Epoch 442/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.1152 - val_loss: 1.5887\n",
      "Epoch 443/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.1319 - val_loss: 1.5871\n",
      "Epoch 444/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.1170 - val_loss: 1.5943\n",
      "Epoch 445/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.1304 - val_loss: 1.6057\n",
      "Epoch 446/1000\n",
      "99/99 [==============================] - 0s 527us/step - loss: 1.1507 - val_loss: 1.6013\n",
      "Epoch 447/1000\n",
      "99/99 [==============================] - 0s 526us/step - loss: 1.1277 - val_loss: 1.5851\n",
      "Epoch 448/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.1313 - val_loss: 1.5864\n",
      "Epoch 449/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.1188 - val_loss: 1.5953\n",
      "Epoch 450/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.1379 - val_loss: 1.5954\n",
      "Epoch 451/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.1367 - val_loss: 1.5850\n",
      "Epoch 452/1000\n",
      "99/99 [==============================] - 0s 496us/step - loss: 1.1137 - val_loss: 1.5707\n",
      "Epoch 453/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.1119 - val_loss: 1.5675\n",
      "Epoch 454/1000\n",
      "99/99 [==============================] - 0s 528us/step - loss: 1.1239 - val_loss: 1.5658\n",
      "Epoch 455/1000\n",
      "99/99 [==============================] - 0s 527us/step - loss: 1.1144 - val_loss: 1.5667\n",
      "Epoch 456/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.1317 - val_loss: 1.5631\n",
      "Epoch 457/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.1194 - val_loss: 1.5505\n",
      "Epoch 458/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.1351 - val_loss: 1.5407\n",
      "Epoch 459/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.1174 - val_loss: 1.5452\n",
      "Epoch 460/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.1191 - val_loss: 1.5627\n",
      "Epoch 461/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.1197 - val_loss: 1.5799\n",
      "Epoch 462/1000\n",
      "99/99 [==============================] - 0s 523us/step - loss: 1.1098 - val_loss: 1.5796\n",
      "Epoch 463/1000\n",
      "99/99 [==============================] - 0s 496us/step - loss: 1.1313 - val_loss: 1.5707\n",
      "Epoch 464/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.1092 - val_loss: 1.5674\n",
      "Epoch 465/1000\n",
      "99/99 [==============================] - 0s 530us/step - loss: 1.1221 - val_loss: 1.5620\n",
      "Epoch 466/1000\n",
      "99/99 [==============================] - 0s 526us/step - loss: 1.1107 - val_loss: 1.5576\n",
      "Epoch 467/1000\n",
      "99/99 [==============================] - 0s 484us/step - loss: 1.1051 - val_loss: 1.5553\n",
      "Epoch 468/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.1379 - val_loss: 1.5573\n",
      "Epoch 469/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.1144 - val_loss: 1.5588\n",
      "Epoch 470/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.1200 - val_loss: 1.5591\n",
      "Epoch 471/1000\n",
      "99/99 [==============================] - 0s 528us/step - loss: 1.1335 - val_loss: 1.5629\n",
      "Epoch 472/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.1243 - val_loss: 1.5625\n",
      "Epoch 473/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.1188 - val_loss: 1.5514\n",
      "Epoch 474/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.1246 - val_loss: 1.5455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.1131 - val_loss: 1.5523\n",
      "Epoch 476/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.1105 - val_loss: 1.5586\n",
      "Epoch 477/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.1213 - val_loss: 1.5578\n",
      "Epoch 478/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.1369 - val_loss: 1.5635\n",
      "Epoch 479/1000\n",
      "99/99 [==============================] - 0s 555us/step - loss: 1.1086 - val_loss: 1.5597\n",
      "Epoch 480/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.1314 - val_loss: 1.5539\n",
      "Epoch 481/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.1276 - val_loss: 1.5455\n",
      "Epoch 482/1000\n",
      "99/99 [==============================] - 0s 531us/step - loss: 1.1561 - val_loss: 1.5443\n",
      "Epoch 483/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.0924 - val_loss: 1.5445\n",
      "Epoch 484/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.1196 - val_loss: 1.5420\n",
      "Epoch 485/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.1346 - val_loss: 1.5474\n",
      "Epoch 486/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.1039 - val_loss: 1.5560\n",
      "Epoch 487/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.1481 - val_loss: 1.5628\n",
      "Epoch 488/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.1125 - val_loss: 1.5619\n",
      "Epoch 489/1000\n",
      "99/99 [==============================] - 0s 531us/step - loss: 1.1114 - val_loss: 1.5426\n",
      "Epoch 490/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.1169 - val_loss: 1.5199\n",
      "Epoch 491/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0954 - val_loss: 1.5121\n",
      "Epoch 492/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.1288 - val_loss: 1.5170\n",
      "Epoch 493/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.1128 - val_loss: 1.5131\n",
      "Epoch 494/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.0959 - val_loss: 1.5048\n",
      "Epoch 495/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.0861 - val_loss: 1.5068\n",
      "Epoch 496/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.0955 - val_loss: 1.5052\n",
      "Epoch 497/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.1029 - val_loss: 1.5044\n",
      "Epoch 498/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.1017 - val_loss: 1.5122\n",
      "Epoch 499/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.1404 - val_loss: 1.5178\n",
      "Epoch 500/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.0875 - val_loss: 1.5190\n",
      "Epoch 501/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.0922 - val_loss: 1.5133\n",
      "Epoch 502/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.1290 - val_loss: 1.5118\n",
      "Epoch 503/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0980 - val_loss: 1.5104\n",
      "Epoch 504/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.1009 - val_loss: 1.5105\n",
      "Epoch 505/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.1103 - val_loss: 1.5107\n",
      "Epoch 506/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.1006 - val_loss: 1.5121\n",
      "Epoch 507/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.1161 - val_loss: 1.5136\n",
      "Epoch 508/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.0998 - val_loss: 1.5106\n",
      "Epoch 509/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.1169 - val_loss: 1.5044\n",
      "Epoch 510/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.0985 - val_loss: 1.5100\n",
      "Epoch 511/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.1149 - val_loss: 1.5118\n",
      "Epoch 512/1000\n",
      "99/99 [==============================] - 0s 489us/step - loss: 1.0911 - val_loss: 1.5114\n",
      "Epoch 513/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0918 - val_loss: 1.5070\n",
      "Epoch 514/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.0918 - val_loss: 1.5062\n",
      "Epoch 515/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.0827 - val_loss: 1.5078\n",
      "Epoch 516/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.1103 - val_loss: 1.5147\n",
      "Epoch 517/1000\n",
      "99/99 [==============================] - 0s 529us/step - loss: 1.0788 - val_loss: 1.5154\n",
      "Epoch 518/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.1151 - val_loss: 1.5140\n",
      "Epoch 519/1000\n",
      "99/99 [==============================] - 0s 493us/step - loss: 1.0841 - val_loss: 1.5117\n",
      "Epoch 520/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.1126 - val_loss: 1.5150\n",
      "Epoch 521/1000\n",
      "99/99 [==============================] - 0s 530us/step - loss: 1.0994 - val_loss: 1.5164\n",
      "Epoch 522/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 1.0876 - val_loss: 1.5214\n",
      "Epoch 523/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.0822 - val_loss: 1.5271\n",
      "Epoch 524/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0883 - val_loss: 1.5259\n",
      "Epoch 525/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.0874 - val_loss: 1.5216\n",
      "Epoch 526/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.1025 - val_loss: 1.5204\n",
      "Epoch 527/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.0950 - val_loss: 1.5101\n",
      "Epoch 528/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.0937 - val_loss: 1.5061\n",
      "Epoch 529/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.1043 - val_loss: 1.5089\n",
      "Epoch 530/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0707 - val_loss: 1.5114\n",
      "Epoch 531/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.1179 - val_loss: 1.5059\n",
      "Epoch 532/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.1087 - val_loss: 1.4980\n",
      "Epoch 533/1000\n",
      "99/99 [==============================] - 0s 533us/step - loss: 1.0834 - val_loss: 1.4909\n",
      "Epoch 534/1000\n",
      "99/99 [==============================] - 0s 533us/step - loss: 1.0878 - val_loss: 1.4898\n",
      "Epoch 535/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.1248 - val_loss: 1.4872\n",
      "Epoch 536/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.0878 - val_loss: 1.4821\n",
      "Epoch 537/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.1246 - val_loss: 1.4807\n",
      "Epoch 538/1000\n",
      "99/99 [==============================] - 0s 526us/step - loss: 1.1061 - val_loss: 1.4835\n",
      "Epoch 539/1000\n",
      "99/99 [==============================] - 0s 567us/step - loss: 1.0821 - val_loss: 1.4953\n",
      "Epoch 540/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.1231 - val_loss: 1.4978\n",
      "Epoch 541/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.1031 - val_loss: 1.4989\n",
      "Epoch 542/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.0928 - val_loss: 1.5092\n",
      "Epoch 543/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.1006 - val_loss: 1.5126\n",
      "Epoch 544/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0789 - val_loss: 1.5140\n",
      "Epoch 545/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.0979 - val_loss: 1.5171\n",
      "Epoch 546/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.0833 - val_loss: 1.5231\n",
      "Epoch 547/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.0867 - val_loss: 1.5221\n",
      "Epoch 548/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.0976 - val_loss: 1.5170\n",
      "Epoch 549/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.0933 - val_loss: 1.5197\n",
      "Epoch 550/1000\n",
      "99/99 [==============================] - 0s 493us/step - loss: 1.0986 - val_loss: 1.5167\n",
      "Epoch 551/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.1033 - val_loss: 1.5151\n",
      "Epoch 552/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.0883 - val_loss: 1.5169\n",
      "Epoch 553/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0857 - val_loss: 1.5183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0872 - val_loss: 1.5210\n",
      "Epoch 555/1000\n",
      "99/99 [==============================] - 0s 493us/step - loss: 1.0911 - val_loss: 1.5197\n",
      "Epoch 556/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0755 - val_loss: 1.5176\n",
      "Epoch 557/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0764 - val_loss: 1.5123\n",
      "Epoch 558/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.1151 - val_loss: 1.5147\n",
      "Epoch 559/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0947 - val_loss: 1.5183\n",
      "Epoch 560/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0692 - val_loss: 1.5252\n",
      "Epoch 561/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0788 - val_loss: 1.5184\n",
      "Epoch 562/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.1011 - val_loss: 1.5180\n",
      "Epoch 563/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.0670 - val_loss: 1.5165\n",
      "Epoch 564/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.0837 - val_loss: 1.5153\n",
      "Epoch 565/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0735 - val_loss: 1.5138\n",
      "Epoch 566/1000\n",
      "99/99 [==============================] - 0s 487us/step - loss: 1.0752 - val_loss: 1.5255\n",
      "Epoch 567/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0860 - val_loss: 1.5270\n",
      "Epoch 568/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.0989 - val_loss: 1.5394\n",
      "Epoch 569/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0872 - val_loss: 1.5406\n",
      "Epoch 570/1000\n",
      "99/99 [==============================] - 0s 491us/step - loss: 1.1057 - val_loss: 1.5364\n",
      "Epoch 571/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0696 - val_loss: 1.5251\n",
      "Epoch 572/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.0822 - val_loss: 1.5175\n",
      "Epoch 573/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.0678 - val_loss: 1.5062\n",
      "Epoch 574/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.1381 - val_loss: 1.5035\n",
      "Epoch 575/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.0877 - val_loss: 1.5056\n",
      "Epoch 576/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0946 - val_loss: 1.5050\n",
      "Epoch 577/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.0806 - val_loss: 1.5016\n",
      "Epoch 578/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.0851 - val_loss: 1.5036\n",
      "Epoch 579/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.0690 - val_loss: 1.5035\n",
      "Epoch 580/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.0701 - val_loss: 1.4964\n",
      "Epoch 581/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.0760 - val_loss: 1.4924\n",
      "Epoch 582/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0838 - val_loss: 1.4985\n",
      "Epoch 583/1000\n",
      "99/99 [==============================] - 0s 526us/step - loss: 1.0581 - val_loss: 1.4979\n",
      "Epoch 584/1000\n",
      "99/99 [==============================] - 0s 528us/step - loss: 1.0815 - val_loss: 1.4921\n",
      "Epoch 585/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.0730 - val_loss: 1.4912\n",
      "Epoch 586/1000\n",
      "99/99 [==============================] - 0s 523us/step - loss: 1.0905 - val_loss: 1.4931\n",
      "Epoch 587/1000\n",
      "99/99 [==============================] - 0s 553us/step - loss: 1.0777 - val_loss: 1.4968\n",
      "Epoch 588/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.0902 - val_loss: 1.4977\n",
      "Epoch 589/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.0490 - val_loss: 1.4940\n",
      "Epoch 590/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.0752 - val_loss: 1.4846\n",
      "Epoch 591/1000\n",
      "99/99 [==============================] - 0s 524us/step - loss: 1.0752 - val_loss: 1.4744\n",
      "Epoch 592/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.0691 - val_loss: 1.4611\n",
      "Epoch 593/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.0617 - val_loss: 1.4539\n",
      "Epoch 594/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.0747 - val_loss: 1.4545\n",
      "Epoch 595/1000\n",
      "99/99 [==============================] - 0s 491us/step - loss: 1.0613 - val_loss: 1.4572\n",
      "Epoch 596/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.0888 - val_loss: 1.4513\n",
      "Epoch 597/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.0690 - val_loss: 1.4456\n",
      "Epoch 598/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0809 - val_loss: 1.4428\n",
      "Epoch 599/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0812 - val_loss: 1.4467\n",
      "Epoch 600/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.0714 - val_loss: 1.4594\n",
      "Epoch 601/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.0596 - val_loss: 1.4662\n",
      "Epoch 602/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.1124 - val_loss: 1.4733\n",
      "Epoch 603/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0766 - val_loss: 1.4748\n",
      "Epoch 604/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.0680 - val_loss: 1.4768\n",
      "Epoch 605/1000\n",
      "99/99 [==============================] - 0s 530us/step - loss: 1.0766 - val_loss: 1.4766\n",
      "Epoch 606/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.1026 - val_loss: 1.4777\n",
      "Epoch 607/1000\n",
      "99/99 [==============================] - 0s 527us/step - loss: 1.0786 - val_loss: 1.4777\n",
      "Epoch 608/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0761 - val_loss: 1.4748\n",
      "Epoch 609/1000\n",
      "99/99 [==============================] - 0s 527us/step - loss: 1.0931 - val_loss: 1.4667\n",
      "Epoch 610/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.0702 - val_loss: 1.4582\n",
      "Epoch 611/1000\n",
      "99/99 [==============================] - 0s 523us/step - loss: 1.0809 - val_loss: 1.4604\n",
      "Epoch 612/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0622 - val_loss: 1.4578\n",
      "Epoch 613/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0682 - val_loss: 1.4590\n",
      "Epoch 614/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0689 - val_loss: 1.4553\n",
      "Epoch 615/1000\n",
      "99/99 [==============================] - 0s 527us/step - loss: 1.0755 - val_loss: 1.4563\n",
      "Epoch 616/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0752 - val_loss: 1.4585\n",
      "Epoch 617/1000\n",
      "99/99 [==============================] - 0s 525us/step - loss: 1.0834 - val_loss: 1.4574\n",
      "Epoch 618/1000\n",
      "99/99 [==============================] - 0s 489us/step - loss: 1.0603 - val_loss: 1.4581\n",
      "Epoch 619/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.0728 - val_loss: 1.4626\n",
      "Epoch 620/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0924 - val_loss: 1.4590\n",
      "Epoch 621/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0585 - val_loss: 1.4603\n",
      "Epoch 622/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0636 - val_loss: 1.4631\n",
      "Epoch 623/1000\n",
      "99/99 [==============================] - 0s 528us/step - loss: 1.0581 - val_loss: 1.4639\n",
      "Epoch 624/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.0477 - val_loss: 1.4640\n",
      "Epoch 625/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0377 - val_loss: 1.4674\n",
      "Epoch 626/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0708 - val_loss: 1.4721\n",
      "Epoch 627/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0570 - val_loss: 1.4757\n",
      "Epoch 628/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0775 - val_loss: 1.4752\n",
      "Epoch 629/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.0590 - val_loss: 1.4673\n",
      "Epoch 630/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0735 - val_loss: 1.4603\n",
      "Epoch 631/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0562 - val_loss: 1.4589\n",
      "Epoch 632/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.0698 - val_loss: 1.4679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0755 - val_loss: 1.4746\n",
      "Epoch 634/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.0636 - val_loss: 1.4734\n",
      "Epoch 635/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.0466 - val_loss: 1.4654\n",
      "Epoch 636/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.0743 - val_loss: 1.4559\n",
      "Epoch 637/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.0577 - val_loss: 1.4534\n",
      "Epoch 638/1000\n",
      "99/99 [==============================] - 0s 492us/step - loss: 1.0784 - val_loss: 1.4515\n",
      "Epoch 639/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.0769 - val_loss: 1.4536\n",
      "Epoch 640/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.0792 - val_loss: 1.4619\n",
      "Epoch 641/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.0577 - val_loss: 1.4650\n",
      "Epoch 642/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0792 - val_loss: 1.4679\n",
      "Epoch 643/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.0439 - val_loss: 1.4695\n",
      "Epoch 644/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0755 - val_loss: 1.4694\n",
      "Epoch 645/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.0579 - val_loss: 1.4694\n",
      "Epoch 646/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.0420 - val_loss: 1.4672\n",
      "Epoch 647/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0595 - val_loss: 1.4573\n",
      "Epoch 648/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.0418 - val_loss: 1.4452\n",
      "Epoch 649/1000\n",
      "99/99 [==============================] - 0s 546us/step - loss: 1.0495 - val_loss: 1.4415\n",
      "Epoch 650/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0746 - val_loss: 1.4382\n",
      "Epoch 651/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.0434 - val_loss: 1.4347\n",
      "Epoch 652/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.0598 - val_loss: 1.4309\n",
      "Epoch 653/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 1.0609 - val_loss: 1.4317\n",
      "Epoch 654/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.0625 - val_loss: 1.4347\n",
      "Epoch 655/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.0705 - val_loss: 1.4398\n",
      "Epoch 656/1000\n",
      "99/99 [==============================] - 0s 496us/step - loss: 1.0473 - val_loss: 1.4492\n",
      "Epoch 657/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.0386 - val_loss: 1.4563\n",
      "Epoch 658/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0472 - val_loss: 1.4620\n",
      "Epoch 659/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.0418 - val_loss: 1.4610\n",
      "Epoch 660/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 1.0517 - val_loss: 1.4515\n",
      "Epoch 661/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.0818 - val_loss: 1.4517\n",
      "Epoch 662/1000\n",
      "99/99 [==============================] - 0s 523us/step - loss: 1.0505 - val_loss: 1.4546\n",
      "Epoch 663/1000\n",
      "99/99 [==============================] - 0s 494us/step - loss: 1.0722 - val_loss: 1.4557\n",
      "Epoch 664/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.0535 - val_loss: 1.4463\n",
      "Epoch 665/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.0617 - val_loss: 1.4427\n",
      "Epoch 666/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0397 - val_loss: 1.4371\n",
      "Epoch 667/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.0535 - val_loss: 1.4300\n",
      "Epoch 668/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0611 - val_loss: 1.4273\n",
      "Epoch 669/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.0628 - val_loss: 1.4258\n",
      "Epoch 670/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.0518 - val_loss: 1.4309\n",
      "Epoch 671/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0779 - val_loss: 1.4375\n",
      "Epoch 672/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0888 - val_loss: 1.4491\n",
      "Epoch 673/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 1.0340 - val_loss: 1.4517\n",
      "Epoch 674/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0380 - val_loss: 1.4515\n",
      "Epoch 675/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.0542 - val_loss: 1.4502\n",
      "Epoch 676/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0621 - val_loss: 1.4511\n",
      "Epoch 677/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.0621 - val_loss: 1.4513\n",
      "Epoch 678/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.0754 - val_loss: 1.4424\n",
      "Epoch 679/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0552 - val_loss: 1.4417\n",
      "Epoch 680/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.0762 - val_loss: 1.4420\n",
      "Epoch 681/1000\n",
      "99/99 [==============================] - 0s 494us/step - loss: 1.0731 - val_loss: 1.4436\n",
      "Epoch 682/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.0667 - val_loss: 1.4438\n",
      "Epoch 683/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0547 - val_loss: 1.4393\n",
      "Epoch 684/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.0582 - val_loss: 1.4346\n",
      "Epoch 685/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.0403 - val_loss: 1.4333\n",
      "Epoch 686/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.0427 - val_loss: 1.4340\n",
      "Epoch 687/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.0477 - val_loss: 1.4360\n",
      "Epoch 688/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.0569 - val_loss: 1.4422\n",
      "Epoch 689/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0556 - val_loss: 1.4366\n",
      "Epoch 690/1000\n",
      "99/99 [==============================] - 0s 496us/step - loss: 1.0452 - val_loss: 1.4310\n",
      "Epoch 691/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0357 - val_loss: 1.4322\n",
      "Epoch 692/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.0626 - val_loss: 1.4426\n",
      "Epoch 693/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.0563 - val_loss: 1.4495\n",
      "Epoch 694/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0463 - val_loss: 1.4601\n",
      "Epoch 695/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.0436 - val_loss: 1.4659\n",
      "Epoch 696/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.0540 - val_loss: 1.4644\n",
      "Epoch 697/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0413 - val_loss: 1.4621\n",
      "Epoch 698/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0576 - val_loss: 1.4568\n",
      "Epoch 699/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0371 - val_loss: 1.4594\n",
      "Epoch 700/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0392 - val_loss: 1.4576\n",
      "Epoch 701/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0355 - val_loss: 1.4523\n",
      "Epoch 702/1000\n",
      "99/99 [==============================] - 0s 495us/step - loss: 1.0711 - val_loss: 1.4510\n",
      "Epoch 703/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0349 - val_loss: 1.4476\n",
      "Epoch 704/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0548 - val_loss: 1.4382\n",
      "Epoch 705/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.0282 - val_loss: 1.4245\n",
      "Epoch 706/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.0226 - val_loss: 1.4156\n",
      "Epoch 707/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0316 - val_loss: 1.4129\n",
      "Epoch 708/1000\n",
      "99/99 [==============================] - 0s 527us/step - loss: 1.0583 - val_loss: 1.4088\n",
      "Epoch 709/1000\n",
      "99/99 [==============================] - 0s 495us/step - loss: 1.0249 - val_loss: 1.4046\n",
      "Epoch 710/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0380 - val_loss: 1.4002\n",
      "Epoch 711/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0287 - val_loss: 1.3946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 712/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.0260 - val_loss: 1.3946\n",
      "Epoch 713/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.0705 - val_loss: 1.3954\n",
      "Epoch 714/1000\n",
      "99/99 [==============================] - 0s 523us/step - loss: 1.0485 - val_loss: 1.3963\n",
      "Epoch 715/1000\n",
      "99/99 [==============================] - 0s 533us/step - loss: 1.0275 - val_loss: 1.3951\n",
      "Epoch 716/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0532 - val_loss: 1.3946\n",
      "Epoch 717/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0398 - val_loss: 1.3958\n",
      "Epoch 718/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.0383 - val_loss: 1.4003\n",
      "Epoch 719/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.0361 - val_loss: 1.4039\n",
      "Epoch 720/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0490 - val_loss: 1.4050\n",
      "Epoch 721/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.0293 - val_loss: 1.4053\n",
      "Epoch 722/1000\n",
      "99/99 [==============================] - 0s 492us/step - loss: 1.0316 - val_loss: 1.4035\n",
      "Epoch 723/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0252 - val_loss: 1.4061\n",
      "Epoch 724/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0675 - val_loss: 1.4079\n",
      "Epoch 725/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0426 - val_loss: 1.4057\n",
      "Epoch 726/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.0311 - val_loss: 1.4094\n",
      "Epoch 727/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 1.0261 - val_loss: 1.4104\n",
      "Epoch 728/1000\n",
      "99/99 [==============================] - 0s 495us/step - loss: 1.0340 - val_loss: 1.4172\n",
      "Epoch 729/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.0506 - val_loss: 1.4173\n",
      "Epoch 730/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.0338 - val_loss: 1.4206\n",
      "Epoch 731/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.0329 - val_loss: 1.4295\n",
      "Epoch 732/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0290 - val_loss: 1.4454\n",
      "Epoch 733/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.0593 - val_loss: 1.4452\n",
      "Epoch 734/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.0355 - val_loss: 1.4404\n",
      "Epoch 735/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0454 - val_loss: 1.4253\n",
      "Epoch 736/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0585 - val_loss: 1.4200\n",
      "Epoch 737/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0232 - val_loss: 1.4202\n",
      "Epoch 738/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0561 - val_loss: 1.4229\n",
      "Epoch 739/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.0458 - val_loss: 1.4265\n",
      "Epoch 740/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0436 - val_loss: 1.4215\n",
      "Epoch 741/1000\n",
      "99/99 [==============================] - 0s 523us/step - loss: 1.0526 - val_loss: 1.4144\n",
      "Epoch 742/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.0513 - val_loss: 1.4053\n",
      "Epoch 743/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.0238 - val_loss: 1.3970\n",
      "Epoch 744/1000\n",
      "99/99 [==============================] - 0s 491us/step - loss: 1.0346 - val_loss: 1.3922\n",
      "Epoch 745/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0485 - val_loss: 1.3923\n",
      "Epoch 746/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.0419 - val_loss: 1.3918\n",
      "Epoch 747/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.0452 - val_loss: 1.3933\n",
      "Epoch 748/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.0271 - val_loss: 1.3982\n",
      "Epoch 749/1000\n",
      "99/99 [==============================] - 0s 534us/step - loss: 1.0266 - val_loss: 1.3978\n",
      "Epoch 750/1000\n",
      "99/99 [==============================] - 0s 534us/step - loss: 1.0215 - val_loss: 1.3985\n",
      "Epoch 751/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.0247 - val_loss: 1.3971\n",
      "Epoch 752/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.0341 - val_loss: 1.3993\n",
      "Epoch 753/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0252 - val_loss: 1.4037\n",
      "Epoch 754/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.0617 - val_loss: 1.4090\n",
      "Epoch 755/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 1.0335 - val_loss: 1.4087\n",
      "Epoch 756/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.0309 - val_loss: 1.4061\n",
      "Epoch 757/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.0199 - val_loss: 1.4095\n",
      "Epoch 758/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.0389 - val_loss: 1.4115\n",
      "Epoch 759/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.0194 - val_loss: 1.4153\n",
      "Epoch 760/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.0210 - val_loss: 1.4263\n",
      "Epoch 761/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0235 - val_loss: 1.4362\n",
      "Epoch 762/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0114 - val_loss: 1.4455\n",
      "Epoch 763/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0312 - val_loss: 1.4456\n",
      "Epoch 764/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.0318 - val_loss: 1.4480\n",
      "Epoch 765/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.0214 - val_loss: 1.4507\n",
      "Epoch 766/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 1.0372 - val_loss: 1.4475\n",
      "Epoch 767/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0335 - val_loss: 1.4489\n",
      "Epoch 768/1000\n",
      "99/99 [==============================] - 0s 494us/step - loss: 1.0134 - val_loss: 1.4519\n",
      "Epoch 769/1000\n",
      "99/99 [==============================] - 0s 494us/step - loss: 1.0239 - val_loss: 1.4547\n",
      "Epoch 770/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.0289 - val_loss: 1.4623\n",
      "Epoch 771/1000\n",
      "99/99 [==============================] - 0s 528us/step - loss: 1.0247 - val_loss: 1.4594\n",
      "Epoch 772/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0405 - val_loss: 1.4589\n",
      "Epoch 773/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.0407 - val_loss: 1.4586\n",
      "Epoch 774/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.0373 - val_loss: 1.4542\n",
      "Epoch 775/1000\n",
      "99/99 [==============================] - 0s 538us/step - loss: 1.0426 - val_loss: 1.4531\n",
      "Epoch 776/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 1.0429 - val_loss: 1.4490\n",
      "Epoch 777/1000\n",
      "99/99 [==============================] - 0s 540us/step - loss: 1.0238 - val_loss: 1.4453\n",
      "Epoch 778/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0322 - val_loss: 1.4399\n",
      "Epoch 779/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.0149 - val_loss: 1.4444\n",
      "Epoch 780/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0171 - val_loss: 1.4428\n",
      "Epoch 781/1000\n",
      "99/99 [==============================] - 0s 525us/step - loss: 1.0461 - val_loss: 1.4340\n",
      "Epoch 782/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.0140 - val_loss: 1.4257\n",
      "Epoch 783/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0208 - val_loss: 1.4161\n",
      "Epoch 784/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.0420 - val_loss: 1.4179\n",
      "Epoch 785/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.0310 - val_loss: 1.4190\n",
      "Epoch 786/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0252 - val_loss: 1.4183\n",
      "Epoch 787/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.0169 - val_loss: 1.4204\n",
      "Epoch 788/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.0331 - val_loss: 1.4225\n",
      "Epoch 789/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.0279 - val_loss: 1.4216\n",
      "Epoch 790/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.0067 - val_loss: 1.4227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 791/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 1.0331 - val_loss: 1.4193\n",
      "Epoch 792/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.0194 - val_loss: 1.4184\n",
      "Epoch 793/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.0174 - val_loss: 1.4169\n",
      "Epoch 794/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.0114 - val_loss: 1.4102\n",
      "Epoch 795/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.0303 - val_loss: 1.4051\n",
      "Epoch 796/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.0333 - val_loss: 1.4106\n",
      "Epoch 797/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.0128 - val_loss: 1.4144\n",
      "Epoch 798/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 1.0172 - val_loss: 1.4147\n",
      "Epoch 799/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.0217 - val_loss: 1.4062\n",
      "Epoch 800/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.0070 - val_loss: 1.3997\n",
      "Epoch 801/1000\n",
      "99/99 [==============================] - 0s 528us/step - loss: 1.0289 - val_loss: 1.3942\n",
      "Epoch 802/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 1.0311 - val_loss: 1.3894\n",
      "Epoch 803/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 1.0379 - val_loss: 1.3841\n",
      "Epoch 804/1000\n",
      "99/99 [==============================] - 0s 528us/step - loss: 1.0273 - val_loss: 1.3834\n",
      "Epoch 805/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 1.0212 - val_loss: 1.3911\n",
      "Epoch 806/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 1.0185 - val_loss: 1.3984\n",
      "Epoch 807/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0050 - val_loss: 1.4064\n",
      "Epoch 808/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 1.0218 - val_loss: 1.4112\n",
      "Epoch 809/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.0305 - val_loss: 1.4192\n",
      "Epoch 810/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 1.0350 - val_loss: 1.4256\n",
      "Epoch 811/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.0318 - val_loss: 1.4256\n",
      "Epoch 812/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0361 - val_loss: 1.4312\n",
      "Epoch 813/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 1.0297 - val_loss: 1.4333\n",
      "Epoch 814/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0204 - val_loss: 1.4339\n",
      "Epoch 815/1000\n",
      "99/99 [==============================] - 0s 523us/step - loss: 1.0411 - val_loss: 1.4345\n",
      "Epoch 816/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.0178 - val_loss: 1.4325\n",
      "Epoch 817/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0091 - val_loss: 1.4298\n",
      "Epoch 818/1000\n",
      "99/99 [==============================] - 0s 496us/step - loss: 1.0276 - val_loss: 1.4250\n",
      "Epoch 819/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.0165 - val_loss: 1.4223\n",
      "Epoch 820/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 1.0274 - val_loss: 1.4210\n",
      "Epoch 821/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.0200 - val_loss: 1.4197\n",
      "Epoch 822/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 1.0149 - val_loss: 1.4184\n",
      "Epoch 823/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0019 - val_loss: 1.4268\n",
      "Epoch 824/1000\n",
      "99/99 [==============================] - 0s 538us/step - loss: 1.0115 - val_loss: 1.4319\n",
      "Epoch 825/1000\n",
      "99/99 [==============================] - 0s 532us/step - loss: 1.0042 - val_loss: 1.4267\n",
      "Epoch 826/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 0.9997 - val_loss: 1.4257\n",
      "Epoch 827/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0228 - val_loss: 1.4231\n",
      "Epoch 828/1000\n",
      "99/99 [==============================] - 0s 493us/step - loss: 1.0239 - val_loss: 1.4154\n",
      "Epoch 829/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 1.0123 - val_loss: 1.4082\n",
      "Epoch 830/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0155 - val_loss: 1.4045\n",
      "Epoch 831/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0097 - val_loss: 1.4025\n",
      "Epoch 832/1000\n",
      "99/99 [==============================] - 0s 492us/step - loss: 1.0188 - val_loss: 1.4032\n",
      "Epoch 833/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 1.0057 - val_loss: 1.4019\n",
      "Epoch 834/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 1.0119 - val_loss: 1.4020\n",
      "Epoch 835/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 0.9876 - val_loss: 1.4017\n",
      "Epoch 836/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 1.0353 - val_loss: 1.4027\n",
      "Epoch 837/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 0.9995 - val_loss: 1.4026\n",
      "Epoch 838/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.0074 - val_loss: 1.4042\n",
      "Epoch 839/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0290 - val_loss: 1.4072\n",
      "Epoch 840/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 0.9980 - val_loss: 1.4133\n",
      "Epoch 841/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 1.0270 - val_loss: 1.4146\n",
      "Epoch 842/1000\n",
      "99/99 [==============================] - 0s 496us/step - loss: 1.0004 - val_loss: 1.4122\n",
      "Epoch 843/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0166 - val_loss: 1.4126\n",
      "Epoch 844/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 1.0108 - val_loss: 1.4119\n",
      "Epoch 845/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 0.9991 - val_loss: 1.4081\n",
      "Epoch 846/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 0.9920 - val_loss: 1.4063\n",
      "Epoch 847/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 0.9852 - val_loss: 1.4109\n",
      "Epoch 848/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 0.9998 - val_loss: 1.4148\n",
      "Epoch 849/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 0.9876 - val_loss: 1.4133\n",
      "Epoch 850/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 0.9998 - val_loss: 1.4105\n",
      "Epoch 851/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 1.0026 - val_loss: 1.4058\n",
      "Epoch 852/1000\n",
      "99/99 [==============================] - 0s 494us/step - loss: 1.0094 - val_loss: 1.4041\n",
      "Epoch 853/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 1.0125 - val_loss: 1.4021\n",
      "Epoch 854/1000\n",
      "99/99 [==============================] - 0s 550us/step - loss: 0.9963 - val_loss: 1.4016\n",
      "Epoch 855/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 1.0088 - val_loss: 1.3991\n",
      "Epoch 856/1000\n",
      "99/99 [==============================] - 0s 529us/step - loss: 0.9905 - val_loss: 1.3973\n",
      "Epoch 857/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 0.9912 - val_loss: 1.3984\n",
      "Epoch 858/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 0.9871 - val_loss: 1.3982\n",
      "Epoch 859/1000\n",
      "99/99 [==============================] - 0s 525us/step - loss: 0.9875 - val_loss: 1.3981\n",
      "Epoch 860/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 0.9994 - val_loss: 1.4047\n",
      "Epoch 861/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 0.9751 - val_loss: 1.4130\n",
      "Epoch 862/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 0.9751 - val_loss: 1.4194\n",
      "Epoch 863/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 1.0054 - val_loss: 1.4248\n",
      "Epoch 864/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 0.9837 - val_loss: 1.4235\n",
      "Epoch 865/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0090 - val_loss: 1.4233\n",
      "Epoch 866/1000\n",
      "99/99 [==============================] - 0s 489us/step - loss: 1.0203 - val_loss: 1.4280\n",
      "Epoch 867/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 0.9811 - val_loss: 1.4272\n",
      "Epoch 868/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 0.9943 - val_loss: 1.4206\n",
      "Epoch 869/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 0.9893 - val_loss: 1.4194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 870/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 0.9943 - val_loss: 1.4201\n",
      "Epoch 871/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 0.9831 - val_loss: 1.4210\n",
      "Epoch 872/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 0.9894 - val_loss: 1.4183\n",
      "Epoch 873/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 0.9815 - val_loss: 1.4204\n",
      "Epoch 874/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 0.9980 - val_loss: 1.4215\n",
      "Epoch 875/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 0.9767 - val_loss: 1.4185\n",
      "Epoch 876/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 0.9941 - val_loss: 1.4123\n",
      "Epoch 877/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 0.9746 - val_loss: 1.4077\n",
      "Epoch 878/1000\n",
      "99/99 [==============================] - 0s 494us/step - loss: 0.9758 - val_loss: 1.4033\n",
      "Epoch 879/1000\n",
      "99/99 [==============================] - 0s 485us/step - loss: 0.9768 - val_loss: 1.4054\n",
      "Epoch 880/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 0.9757 - val_loss: 1.4119\n",
      "Epoch 881/1000\n",
      "99/99 [==============================] - 0s 529us/step - loss: 0.9769 - val_loss: 1.4157\n",
      "Epoch 882/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 0.9858 - val_loss: 1.4132\n",
      "Epoch 883/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 0.9853 - val_loss: 1.4100\n",
      "Epoch 884/1000\n",
      "99/99 [==============================] - 0s 522us/step - loss: 0.9561 - val_loss: 1.4094\n",
      "Epoch 885/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 0.9770 - val_loss: 1.4059\n",
      "Epoch 886/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 0.9809 - val_loss: 1.4065\n",
      "Epoch 887/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 0.9810 - val_loss: 1.4044\n",
      "Epoch 888/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 0.9718 - val_loss: 1.4019\n",
      "Epoch 889/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 0.9757 - val_loss: 1.4024\n",
      "Epoch 890/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 0.9654 - val_loss: 1.4002\n",
      "Epoch 891/1000\n",
      "99/99 [==============================] - 0s 535us/step - loss: 0.9767 - val_loss: 1.3984\n",
      "Epoch 892/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 0.9906 - val_loss: 1.3924\n",
      "Epoch 893/1000\n",
      "99/99 [==============================] - 0s 531us/step - loss: 0.9747 - val_loss: 1.3894\n",
      "Epoch 894/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 1.0010 - val_loss: 1.3903\n",
      "Epoch 895/1000\n",
      "99/99 [==============================] - 0s 524us/step - loss: 0.9671 - val_loss: 1.3918\n",
      "Epoch 896/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 0.9623 - val_loss: 1.3897\n",
      "Epoch 897/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 0.9704 - val_loss: 1.3886\n",
      "Epoch 898/1000\n",
      "99/99 [==============================] - 0s 514us/step - loss: 0.9730 - val_loss: 1.3888\n",
      "Epoch 899/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 0.9677 - val_loss: 1.3895\n",
      "Epoch 900/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 0.9618 - val_loss: 1.3927\n",
      "Epoch 901/1000\n",
      "99/99 [==============================] - 0s 527us/step - loss: 1.0171 - val_loss: 1.3939\n",
      "Epoch 902/1000\n",
      "99/99 [==============================] - 0s 533us/step - loss: 0.9614 - val_loss: 1.3945\n",
      "Epoch 903/1000\n",
      "99/99 [==============================] - 0s 530us/step - loss: 0.9651 - val_loss: 1.3946\n",
      "Epoch 904/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 0.9600 - val_loss: 1.3935\n",
      "Epoch 905/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 0.9535 - val_loss: 1.3892\n",
      "Epoch 906/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 0.9776 - val_loss: 1.3840\n",
      "Epoch 907/1000\n",
      "99/99 [==============================] - 0s 492us/step - loss: 0.9819 - val_loss: 1.3845\n",
      "Epoch 908/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 0.9864 - val_loss: 1.3836\n",
      "Epoch 909/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 0.9777 - val_loss: 1.3828\n",
      "Epoch 910/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 0.9687 - val_loss: 1.3841\n",
      "Epoch 911/1000\n",
      "99/99 [==============================] - 0s 529us/step - loss: 0.9782 - val_loss: 1.3878\n",
      "Epoch 912/1000\n",
      "99/99 [==============================] - 0s 495us/step - loss: 0.9845 - val_loss: 1.3913\n",
      "Epoch 913/1000\n",
      "99/99 [==============================] - 0s 523us/step - loss: 0.9770 - val_loss: 1.3878\n",
      "Epoch 914/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 0.9875 - val_loss: 1.3839\n",
      "Epoch 915/1000\n",
      "99/99 [==============================] - 0s 528us/step - loss: 0.9533 - val_loss: 1.3809\n",
      "Epoch 916/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 0.9927 - val_loss: 1.3798\n",
      "Epoch 917/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 0.9578 - val_loss: 1.3799\n",
      "Epoch 918/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 0.9599 - val_loss: 1.3801\n",
      "Epoch 919/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 0.9850 - val_loss: 1.3848\n",
      "Epoch 920/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 0.9686 - val_loss: 1.3904\n",
      "Epoch 921/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 0.9676 - val_loss: 1.3937\n",
      "Epoch 922/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 0.9760 - val_loss: 1.3988\n",
      "Epoch 923/1000\n",
      "99/99 [==============================] - 0s 529us/step - loss: 0.9703 - val_loss: 1.4025\n",
      "Epoch 924/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 0.9464 - val_loss: 1.4005\n",
      "Epoch 925/1000\n",
      "99/99 [==============================] - 0s 532us/step - loss: 0.9734 - val_loss: 1.3986\n",
      "Epoch 926/1000\n",
      "99/99 [==============================] - 0s 526us/step - loss: 0.9481 - val_loss: 1.3987\n",
      "Epoch 927/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 0.9667 - val_loss: 1.3963\n",
      "Epoch 928/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 0.9562 - val_loss: 1.3945\n",
      "Epoch 929/1000\n",
      "99/99 [==============================] - 0s 515us/step - loss: 0.9666 - val_loss: 1.3952\n",
      "Epoch 930/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 0.9609 - val_loss: 1.3956\n",
      "Epoch 931/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 0.9768 - val_loss: 1.3973\n",
      "Epoch 932/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 0.9849 - val_loss: 1.3965\n",
      "Epoch 933/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 0.9790 - val_loss: 1.3902\n",
      "Epoch 934/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 1.0078 - val_loss: 1.3861\n",
      "Epoch 935/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 0.9559 - val_loss: 1.3889\n",
      "Epoch 936/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 0.9738 - val_loss: 1.3918\n",
      "Epoch 937/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 0.9487 - val_loss: 1.3972\n",
      "Epoch 938/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 0.9674 - val_loss: 1.3963\n",
      "Epoch 939/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 0.9635 - val_loss: 1.3949\n",
      "Epoch 940/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 0.9780 - val_loss: 1.3941\n",
      "Epoch 941/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 0.9550 - val_loss: 1.3985\n",
      "Epoch 942/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 0.9333 - val_loss: 1.3983\n",
      "Epoch 943/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 0.9446 - val_loss: 1.3961\n",
      "Epoch 944/1000\n",
      "99/99 [==============================] - 0s 501us/step - loss: 0.9668 - val_loss: 1.3920\n",
      "Epoch 945/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 0.9504 - val_loss: 1.3906\n",
      "Epoch 946/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 0.9777 - val_loss: 1.3827\n",
      "Epoch 947/1000\n",
      "99/99 [==============================] - 0s 519us/step - loss: 0.9325 - val_loss: 1.3839\n",
      "Epoch 948/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 0.9419 - val_loss: 1.3850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 949/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 0.9567 - val_loss: 1.3913\n",
      "Epoch 950/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 0.9510 - val_loss: 1.3936\n",
      "Epoch 951/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 0.9557 - val_loss: 1.3945\n",
      "Epoch 952/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 0.9454 - val_loss: 1.3928\n",
      "Epoch 953/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 0.9359 - val_loss: 1.3905\n",
      "Epoch 954/1000\n",
      "99/99 [==============================] - 0s 517us/step - loss: 0.9498 - val_loss: 1.3900\n",
      "Epoch 955/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 0.9331 - val_loss: 1.3875\n",
      "Epoch 956/1000\n",
      "99/99 [==============================] - 0s 505us/step - loss: 0.9674 - val_loss: 1.3807\n",
      "Epoch 957/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 0.9484 - val_loss: 1.3779\n",
      "Epoch 958/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 0.9497 - val_loss: 1.3716\n",
      "Epoch 959/1000\n",
      "99/99 [==============================] - 0s 540us/step - loss: 0.9734 - val_loss: 1.3663\n",
      "Epoch 960/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 0.9298 - val_loss: 1.3611\n",
      "Epoch 961/1000\n",
      "99/99 [==============================] - 0s 503us/step - loss: 0.9841 - val_loss: 1.3620\n",
      "Epoch 962/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 0.9342 - val_loss: 1.3638\n",
      "Epoch 963/1000\n",
      "99/99 [==============================] - 0s 513us/step - loss: 0.9234 - val_loss: 1.3698\n",
      "Epoch 964/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 0.9477 - val_loss: 1.3717\n",
      "Epoch 965/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 0.9638 - val_loss: 1.3688\n",
      "Epoch 966/1000\n",
      "99/99 [==============================] - 0s 504us/step - loss: 0.9555 - val_loss: 1.3673\n",
      "Epoch 967/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 0.9509 - val_loss: 1.3718\n",
      "Epoch 968/1000\n",
      "99/99 [==============================] - 0s 508us/step - loss: 0.9323 - val_loss: 1.3771\n",
      "Epoch 969/1000\n",
      "99/99 [==============================] - 0s 529us/step - loss: 0.9518 - val_loss: 1.3785\n",
      "Epoch 970/1000\n",
      "99/99 [==============================] - 0s 502us/step - loss: 0.9599 - val_loss: 1.3766\n",
      "Epoch 971/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 0.9530 - val_loss: 1.3771\n",
      "Epoch 972/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 0.9544 - val_loss: 1.3782\n",
      "Epoch 973/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 0.9545 - val_loss: 1.3783\n",
      "Epoch 974/1000\n",
      "99/99 [==============================] - 0s 538us/step - loss: 0.9356 - val_loss: 1.3726\n",
      "Epoch 975/1000\n",
      "99/99 [==============================] - 0s 538us/step - loss: 0.9287 - val_loss: 1.3668\n",
      "Epoch 976/1000\n",
      "99/99 [==============================] - 0s 500us/step - loss: 0.9292 - val_loss: 1.3703\n",
      "Epoch 977/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 0.9311 - val_loss: 1.3711\n",
      "Epoch 978/1000\n",
      "99/99 [==============================] - 0s 498us/step - loss: 0.9647 - val_loss: 1.3701\n",
      "Epoch 979/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 0.9394 - val_loss: 1.3657\n",
      "Epoch 980/1000\n",
      "99/99 [==============================] - 0s 516us/step - loss: 0.9312 - val_loss: 1.3601\n",
      "Epoch 981/1000\n",
      "99/99 [==============================] - 0s 510us/step - loss: 0.9714 - val_loss: 1.3547\n",
      "Epoch 982/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 0.9738 - val_loss: 1.3510\n",
      "Epoch 983/1000\n",
      "99/99 [==============================] - 0s 520us/step - loss: 0.9425 - val_loss: 1.3548\n",
      "Epoch 984/1000\n",
      "99/99 [==============================] - 0s 499us/step - loss: 0.9431 - val_loss: 1.3559\n",
      "Epoch 985/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 0.9260 - val_loss: 1.3558\n",
      "Epoch 986/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 0.9385 - val_loss: 1.3566\n",
      "Epoch 987/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 0.9354 - val_loss: 1.3554\n",
      "Epoch 988/1000\n",
      "99/99 [==============================] - 0s 565us/step - loss: 0.9574 - val_loss: 1.3543\n",
      "Epoch 989/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 0.9395 - val_loss: 1.3509\n",
      "Epoch 990/1000\n",
      "99/99 [==============================] - 0s 507us/step - loss: 0.9802 - val_loss: 1.3573\n",
      "Epoch 991/1000\n",
      "99/99 [==============================] - 0s 521us/step - loss: 0.9343 - val_loss: 1.3687\n",
      "Epoch 992/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 0.9291 - val_loss: 1.3755\n",
      "Epoch 993/1000\n",
      "99/99 [==============================] - 0s 525us/step - loss: 0.9422 - val_loss: 1.3825\n",
      "Epoch 994/1000\n",
      "99/99 [==============================] - 0s 511us/step - loss: 0.9192 - val_loss: 1.3862\n",
      "Epoch 995/1000\n",
      "99/99 [==============================] - 0s 518us/step - loss: 0.9477 - val_loss: 1.3866\n",
      "Epoch 996/1000\n",
      "99/99 [==============================] - 0s 495us/step - loss: 0.9143 - val_loss: 1.3810\n",
      "Epoch 997/1000\n",
      "99/99 [==============================] - 0s 497us/step - loss: 0.9368 - val_loss: 1.3779\n",
      "Epoch 998/1000\n",
      "99/99 [==============================] - 0s 506us/step - loss: 0.9384 - val_loss: 1.3802\n",
      "Epoch 999/1000\n",
      "99/99 [==============================] - 0s 509us/step - loss: 0.9094 - val_loss: 1.3879\n",
      "Epoch 1000/1000\n",
      "99/99 [==============================] - 0s 512us/step - loss: 0.9129 - val_loss: 1.3914\n"
     ]
    }
   ],
   "source": [
    "callbacks=[rnaNet.lrate, cb.EarlyStopping(monitor='val_loss', patience=100, mode='auto')]\n",
    "rnaNet.train(epochs=1000, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnaNet.pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a434775c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAIrCAYAAADr3EO5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XucHFWd///3J5OQC4HMkAuQmwkQRVCJZFBAQC7yBXQRkWUXdhMwaMJ9d13l9tMNEL/45aooq8iMRhQ1wMqiEQG5CQiikMgdAgkhkBuQkAsJ5jYzn98f1Z3pmfT0dPV0d1WfeT0fj35Md3VVnVNV3VPvPnWqytxdAAAAIeuTdAUAAAAqjcADAACCR+ABAADBI/AAAIDgEXgAAEDwCDwAACB4BB4AABA8Ag8AAAgegQcAAASPwAMAAILXN+kKJGHYsGE+bty4pKsBACiTefPmrXL34UnXA+nVKwPPuHHjNHfu3KSrAQAoEzN7I+k6IN04pAUAAIJH4AEAAMEj8ADl8qc/SatXJ10LAEAeBB6gHDZvlg47TLr22qRrAgDIg8ADlIN79Le1Ndl6AADy6jWBx8ymm9lcM5u7cuXKpKsDAACqqNcEHndvcvdGd28cPpxLNQAA0Jv0msADAAB6LwIPAAAIHoEHAAAEj8ADAACCR+ABAADBI/AAAIDgEXgAAEDwCDwAACB4BB4AABA8Ag8AAAgegQcAAASPwAMAAIJH4AEAAMEj8AAAgOAReAAAQPAIPAAAIHgEHgAAEDwCDwAACB6BBwAABI/AAwAAgkfgAQAAwSPwAACA4BF4AABA8Ag8AAAgeAQeAAAQPAIPAAAIHoEHAAAEj8ADAACCR+ABAADBI/AAAIDgEXgAAEDwCDwAACB4BB6k2513SscfX7n5r1kjHXyw9Pzz0etVq6QDD5Tmz88//te+Jl19dXHzfvhh6cgjpS1bylLVsmhpkY4+Wrr//vLO949/lI46Kl3LmjV/frRNV67s2Xwuv1z6xjfKUycAVUfgQbrdf790112Vm/+bb0pPPCE99VT0etEi6a9/lebNyz/+d75TfOB59NEoCKxfX566lsPGjdIDD0RhrJwefVR66CFpw4byzrcc5s2LtumiRT2bz2WXSd/+dlmqBKD6ek3gMbPpZjbXzOau7OkvPVSPWdI12F7//knXoOfSuF7Tbocdkq4BgB7oNYHH3ZvcvdHdG4cPH550dQAAQBX1msADAAB6LwIPAAAIHoEHAAAEj8ADAACCR+ABAADBI/AAAIDgEXgAAEDwCDwAACB4BB4AABA8Ag8AAAgegQcAAASPwAMAAIJH4AEAAMEj8AAAgOAReAAAQPAIPAAAIHgEHgAAEDwCDwAACB6BByiD+++v3Lz/9jfpwQel+fOlhx+W1q2T3KW775ZaWno276VLpXnzylJN1Jj77pM2biz/fB97THr33fLPF+gpAg/QQ6+8Ih3/+crNf9Ik6TOfkT78YemII6QbbpD+8hfpc5+T5szp2bynTZMaG8tTT9SO116TjjlGuvnm8s53yxbp0EOla64p73yBciDwAD3U2lr98rJl9rTsnrYQoTaV6/PT3fyBNCHwAACA4BF4AABA8Ag8AAAgeAQeAAAQPAIPAAAIHoEHAAAEj8ADAACCR+ABAADBI/AAAIDgEXgAAEDwCDwAACB4BB7Uhk2bpFdflf7+9+gW31kbNkjLl0fPV62SnntO2rxZevrp6LFmTfu4b78trV0rLVwotbVJb70lvfRS9N7ixdKiRduXu2pVNJ8VKzqWu3Gj9Oab215O0IL291avlp59NrqluRTdOvrdd6P5L17cPt5rr21/06HW1mi4JC1YkJmHa4Je1V5aoPFapD6tW7Xjwmc1Vm9owJoV7dOuWxfVNXeeCxdGZb72mvT889LKlR2KG9CyQRP1tLR1a1Retl5vvBGt63w6b4NcCxZI69dH9ci9UdemTe3ra+1a6Z13otebNkXD3n9fWrYsWs/r1+eftxSV21W98tXFvf3zIUXboNANxDZulJYs6Ths8eLoM9XZqlXRtu4sd7tml7UaXn89untnIUuWSBs3qt/rr2pP5XwP1q1rH8c9+q4Vq60t+pxVcllbWqLPVPazsXVrtLxAHO7e6x6TJk1y1Ihzz3WX3A88MPo7cWL0N+tf/7X99ac/7d6vn/vBB7vvtpv7nnu6H398+7iS+8iR0d+f/cx9772j59nHwIHu994bPf/FL6JpDjnEffx49w9+sH28kSPdL754W7mv/mFR+3sXXuh+7LFRPT760WhYnz7RvAcOdB80yP3vf3d/663ovR/9qOPy3nRTNPyxx6K/s2f7Z3VXh3q+MeZgb+3br31Y1qmnRuU2N0evFy/uuHyS+8c+Fv39xjfc3f2uUdN8szLrLLdcyf3f/z3/Njn77I7lurtfdln7dAceGNXje99rf/+b34zea2lxP+CA9nH/67+i97/ylfZhJ57Y9edBij4T3Zk/Pxr3f/6nfb733BP9vf76rqe78MKOy7ZxY/T6W99y32GHju81NLiPHdtx+uXLo3GamqLXkyZtv64qYcOGqJyrrio8ntRh/d//rz+Nnh9xRPs4d2U+b888U1zZs2ZF448Y4S655P71r5e8JPndcEP0mfrSl6LX114blblu3bZRJM31FOxfeKT30WtaeMxsupnNNbO5Kzv9ykWKmUnjx0etM1LUApAr95fphg3S6NHRL9Z/+zepqSkaliv7a3/Dhu3fGzw4+uWYa8MG6fvf337c999vr+KmjdtPM2ZM+zRtbVHLwU47RcvT2treYtB5vtnX2ZapDRs0WB3HGbzhLW0ZPlrbyS5/dh4bO9Wrb9/tyhvYskFLlVlnueVKXbe0FGqBkaJtlbv8Uof11aGVKTv8vffah+XWoZTypfZWoA0bpKFDpT32aN+2ndd5rs7vtbV1Pc2aNe3rLavzdl21qvu6lkO21arQsmXl1Lnf5sz4uS1V2XnkbrNCsuNXsiWr83cq+7dQax3QSa8JPO7e5O6N7t44fPjwpKuDMnjySWl1N/vGUj3xRHRk4t3V7fu8fG65Jf68t26VfvnL0uvW1TzffFNq89Km35Bn39baJs2alf9oThzPP9/h6F+PLXyt8DbpzF16b/32Rw9DsHFjtI2y+/0tW6Sf/jT/sha7DbLbOzvPe++VXnml6/Gffz7/8LY26eabo3x6333S/PnRtrj11uod5QNy9ZrAg/Aceqj0+OOVmfd//0A65phoJ1Goq8Bpp3XdnaUrTzwhffvbPatfZ48+Kj3z7PaNOsXKNqDlWrFC+vKXpQce6FndTjtN+vUdPZtHrscfj3aexdq8JWpUWriwfHVIi9//PtpGTz4ZvZ7/inTGGdK8eduP+73vRX+7y8TZaV9+Ofp73HHSBRd0PX5Tc/7hzz0nTZ0q/frX0Xfp/POjBq9TT40aX4FqI/AAXfASW0uK0bBL5eYNJGn8+KRrAORH4AEAAMEj8AAAgOAReAAAQPAIPAAAIHgEHgAAEDwCDwAACB6BBwAABI/AAwAAgkfgAQAAwSPwAACA4BF4AABA8Ag8AAAgeAQeAAAQPAIPAAAIXt+kKwBkPfaYtHSpdMop27+34X1pcM7r666T2tq2H88lrVsnrV8iPbZI+qc26TvXRPMck1vW49Ihecr4zS+kyZ2G/+530vSN0qDM6/fWS28vkCZkXj/1lHR45vkjj0jjVkgjWqSWrdJOnebfb4t0zTXS1i3RsMcfl94aJz37rLR1q3TIk9LnJD39tPRxSQ8+uP0yrl8fzXtA5vVPfiLdeqt0fub1n/8s+QHSvF9K/5YzXWubtHa1NFTS0mXSz66QPtFpHf7tb9L+uStT0r33SkuWSB/7mPTQQ9LFLdE/jksukf7hH6RPfUpavVraJTPZmrXSzkOkOknvvy8984w0ZfvF6GD1mvbp170nDck8v/lmad99pQMOkF5+WfpwzjTPPx+tvzPPjOq1bp20YoX09tvSbiukc7oo689PSAd5NG1Xn7fONm2S+rZu/w+zpVW67JtSnz7SF74gbV0gfVLRvA/+D8m6n/U2nZf1oYekc86RzKJl/dWvovX9hz90XAdStN0OlrRwQfT6hz+U5syJ6nX00dHncu3a6L21a6WGzPSPPSZ9WtFn6poZ0Wew7u5oXm1t0vXXd6zj/PnSz37W/rpfv/zL8uij0gc+ED3/9a+jv888I919d/T8vvukLVukQw6RRo+WZs+WdtxR+trXomWfPVs6/vhoHXz1q9KOmfm+9Zb01O+k43PKyldPIB8CD1Lj/POjf4r5dkDvvNMx8Hz96/nn0doqvfuu9L+3SveskY7+mHThhVLfvtJXc8b71a+kQ0Z3nHbjRunW2zoGnn79pPr6aGeaDTzr10v33NseeO6+W7og83zZMmngSqltq+RtHQPP++9H/7j/+HD7zv1/75S+c2f0/PTTpeXLo+dXXindJun226WPfkTSC+3zaWmJdsBZX/lK9DcbeG7/H+nOv0r79OkYeLJ1GCrpN3dK31wn3dbpP8AVV0h3ZJ63ZQLPL38prVkjjRsnLV4sffkoaXdJN90kLVwYBZ7nnmsPfWvWROttsKS//jWzDgdJWqcuzX852slK0muvtYeuqVOjnfzvfhcFgqtypmlulm64IQo8//Iv0Wcka6K6Djy//7300Q2FP2+dvb5Y2iNP4GltjdaZJC1YIK2aK90v6dd3RKEqTuCZOlX6/Oel3/5WmjVLuvbaaNv27x8t6y9+Id12WxRY1qyJpjn0UGnQIOmaa6XzJL3wonTppdKNN7avjx/+MPpOjB8fvd6c89lZ8Vb0d/Fi6VvfkhoapKMz896wQfrqhR3rePPNURg//PAo5F55ZVRurilTos/Fd74j1dVFwUaSjjxSuvzy6Pnw4VF5AwdGoe6666LhJ5wQLesvfxkt6+uvSwceKH0mM+/HHpNOfkzyy9rLe+edKCgB3eGQFlKjb8Lx23L2TiOGR3932in6pdmV8eOlHXZofz1yZLSDKsU//7M04YPR87q+7X+PPHL7cXPLzBo0qP25mTR2bMf36/rkn05qX/d1dR2Hjx8f7QSz88yVHd6dQw6R9tizm5Fy5t25nM51GjJk+/G6amkopNyftz59ej7PPpn/yJ3XgdS+vnPX+0EHSfvvL/XJjD9wQBTk9tln+3lm5fsMZMsrZpsecUTUundOJlEOG9rx/d12k046KXr+kY9In/509HxKpplv2LAoxErRdiu0rJ11XhYgDj4+AAAgeAQeAAAQPAIPAAAIHoEHAAAEj8ADAACCR+ABAADBI/AAAIDgEXgAAEDwCDwAACB4BB4AABA8Ag8AAAgegQcAAASPwAMAAIJH4AEAAMHrm3QFkrDhhcX604SpSVcDnZy7UHJJf5rQPmzPlX9RXVudRmiFJKntnZXqI2mWou13kJ6QJP1pwlR9fMnrWt9vF43QW1q/weQy2fyXNUtTNezbHcs6TT/X5hXvqn/uQDP9h66XJP3L+ps0ac0DGtrnDW2uq9OQtjXbRhul5Tpa90uSrl45Vf03rt323t6L7tYOG9/RqrYhGqnlHcp0RXX6kc5Sf22WJJ2iW/URvSBJ+uh3pb7zo+dnvBfVY0rLT7XnA/06zGeE3tF6223b6+y62HfL01rz3gD9i36lSUuf1V6b1naYTn37asjmdyRJh783R7O0TI0tf1Gr6jSi9S1J0vSN128bvd+f/qhr+k3Vxo3SVkl9l0gtkuoef2TbsrfdE22v3Zc+3aF+a9aP1LvX/VotAxbowjZp761PSpIe/9AZ+tTixdvGXTbrXi2as1oTlv1p27AJa5/a9v2cJWnAvVEZB62K3v/E3x/Wy8dN1eHrpImSHpsgfWtZx0UdqnclSa9e9GONe3+9WrWLNl0ZLdtJukNPT1yocxdt/3nb650/a3dpW/l1bS06WFL/B36v/toi5bx3qKT+2rJt/e/4G6nP39dLkk7VbD3+wed06BtvdJimkFmSBtzTvqyzJP11X8lMOnyl9Ok26e8bpUEDpfcy03z0bunTK6U1a6K6HbP5txp8/hJdNF86LTvjldGfvkuiv4M3rdxW5mT9QpL0kdZnNUtTtfNKaahej8a/6grN0ghJ0oD7onoduErac09Jr0jDNkR13H/DSx2W44hbpmrgAOnyJdLOO0vj/lcaJWni96JhfeukxlnRtHpPqv9x5rmk5cdKR6yTDs8sa4ukttOlxZuf04Ctddq/7SnN0lS9+b2nNVbSXxrP0ybvr2bVaVq3axi9nbl70nWoCjObLml65uWHJL3Sw1kOk7Sqh/NIs9CXT2IZQxH6Moa+fFJ5lvED7j68HJVBmHpN4Ck3M5vr7o1J16NSQl8+iWUMRejLGPrySb1jGZE8+vAAAIDgEXgAAEDwCDyla0q6AhUW+vJJLGMoQl/G0JdP6h3LiITRhwcAAASPFh4AABA8Ag8AAAgegQcAAASPwAMAAIJH4AEAAMHrlffSGjZsmI8bNy7pagAAymTevHmrir21RH3fAb7XxI9UukqokmK3fa8MPOPGjdPcuXOTrgYAoEzM7I1ix92rdTP7gIAUu+05pAUAAIJH4AEAAMEj8AAAgOAReAAAQPAIPAAAIHgEHgAAEDwCDwAACB6BBwAABI/AAwAAgkfgAQAAwSPwAACA4KUu8JjZLDN7x8xeyBl2mZktM7NnMo/P5rx3iZktNLNXzOyYZGoNAADSLHWBR9LNko7NM/y77j4x87hbksxsH0mnSNo3M80PzayuajUFAAA1IXWBx90flbS6yNFPkHSru29299clLZT0iYpVDgAA1KTUBZ4CzjOz5zKHvBoyw0ZJWpIzztLMMAAAgG1qJfDcKGlPSRMlrZB0XdwZmNl0M5trZnNXrlxZ7voBAFKswz4g6cogETUReNz9bXdvdfc2Sc1qP2y1TNKYnFFHZ4blm0eTuze6e+Pw4cMrW2EAQKp02AckXRkkoiYCj5ntnvPyREnZM7jmSDrFzPqb2XhJEyQ9We36AQCAdOubdAU6M7PZkg6XNMzMlkq6VNLhZjZRkktaLOlMSXL3F83sdkkvSWqRdK67tyZRbwAAkF6pCzzufmqewT8pMP4Vkq6oXI0AAECtq4lDWgAAAD1B4AEAAMEj8AAAgOAReAAAQPAIPAAAIHgEHgAAEDwCDwAACB6BBwAABI/AAwAAgkfgAQAAwSPwAACA4BF4AABA8Ag8AAAgeAQeAAAQPAIPAAAIHoEHAAAEj8ADAACCR+ABAADBI/AAAIDgEXgAAEDwCDwAACB4BB4AABA8Ag8AAAgegQcAAASPwAMAAIJH4AEAAMEj8AAAgOAReAAAQPAIPAAAIHgEHgAAEDwCDwAACB6BBwAABI/AAwAAgkfgAQAAwSPwAACA4BF4AABA8Ag8AAAgeAQeAAAQPAIPAAAIHoEHAAAEj8ADAACCR+ABAADBI/AAAIDgEXgAAEDwCDwAACB4BB4AABA8Ag8AAAgegQcAAAQvdYHHzGaZ2Ttm9kLOsF3M7H4zW5D525AZbmb2fTNbaGbPmdn+ydUcAACkVeoCj6SbJR3badjFkh509wmSHsy8lqTjJE3IPKZLurFKdQQAADUkdYHH3R+VtLrT4BMk/Szz/GeSvpAz/Oce+YukejPbvTo1BQAAtSJ1gacLu7r7iszztyTtmnk+StKSnPGWZoYBAABsUyuBZxt3d0kedzozm25mc81s7sqVKytQMwBAWnXYByRdGSSiVgLP29lDVZm/72SGL5M0Jme80Zlh23H3JndvdPfG4cOHV7SyAIB06bAPSLoySEStBJ45kk7PPD9d0m9zhp+WOVvrQEnrcg59AQAASJL6Jl2BzsxstqTDJQ0zs6WSLpV0paTbzezLkt6Q9E+Z0e+W9FlJCyX9XdLUqlcYAACkXuoCj7uf2sVbR+UZ1yWdW9kaAQCAWpe6wAMAQKUtWdL9OJ0NGiQNHVr+uqA6CDwAgJrW3CxJ+30szjRjx5ZW1urVUkNDadMiWQQeAEBNmzlTkvr2izPNNdfEL2fYMKm+Pv50SAcCDwCgps2YIU2f3rI1zjRf/3qlaoO0qpXT0gEAyGvaNEl69rmk64F0I/AAAIDgEXgAAEDwCDwAACB4BB4AABA8Ag8AAAgegQcAAASPwAMAAIJH4AEAAMEj8AAAgOAReAAAQPAIPAAAIHgEHgAAEDwCDwAACB6BBwAABI/AAwAAgkfgAQAAweubdAWA1GlulmbOlGbMkKZNS7o2ACphv/2SrkH5bd0qnXyydPnlSdcklQg8QGczZ0pLl0Z/CTxAmJ57LukaVMbcuUnXILUIPEBnM2a0t/AACNJ/3+Cxpxk2TPrnf5bMKlAhVJy5x9/ota6xsdHnkoIBIDV6eiTZzOa5e2Mx4zaa+TyVtu9bvVpqaChpUlRIsdueFh4AQOKqfST51VfjTzN4MGGnlhF4AACJq/aR5AkTqlMO0oPAAwBI3LRpnCOAyiLwAIVwijoQpjvvrF5Zxx0nDRhQvfKQF52WgULGjIk6FoweLS1ZknRtAHQhbqflqu4BfvpT6UtfqmaJvQqdloFyiNmxgAYhoDhJf1e+vMcfY0+zdKl0++3SkCExJzzkkNhlofxo4QE66ck/YhqEgOKU+7sSt4XnxP8bf9/3//6ftGCBtPvusSdFBdHCA5SoJ6fHcs1CpFXSLSqdJf1d+clP4k/z6U9Lu+5a/rqgOmjhATpJ244BKIfQWx+58GDvRQsPUCJOj0WIkm5RSZsnnog/TX09YaeWEXgAoBcgyHd04IFJ1wDV1ifpCgAAUIzm5ujQXHNzz+dlVtpj/fqel41k0MIDAKgJ5bzf1tCh8afZZx+uH1jLCDxIP3oRA6mQ9FexnP2Q7nq3hGNaf5LsIMXfc86aFaUlJIqztJBuzc3S2WdLra3hnl4C1Ig0n+mV6ist//zn0pQp1SyxVyl229OHB+k2c2YUdurqOL2kQsrZLwJhmzEjCjt8FWPaaaekawAReJB22f+wN94Y3uGslCSN3H4RQCHTpkUtO3G/inE/6in5apTPsGFJ1wDikBaQnJQcH0i6XwbCF/ejXspXI+4hrbv6jipuxjlaWqLbStTFbSq46y5p4sTY5aE4XHgQSLuUXAmO67OgnPIF6Lgf9Wp8NXZvWVrSdKtf5OKDtYoWHgBA2STVcBm3hee078Xf9w0bJp16anQ9HqQHLTwAgLLr7hBobutMmg+XXn99/GmGDZNOOEHaccfy1weVR+ABABQtzsX/ynmhwHJ74IH403zyk9J77xF4ahWBBwBQtO761+SGnHzjpqXV59szNsWeZuMayTZLij9p9fTrF13GA9upqT48ZrZY0npJrZJa3L3RzHaRdJukcZIWS/ond19TaD704QGArvUklHQ3baX6+MTpw/MRG1DyhQf795dideHZvLnEkko0fry0aFF1y0xYsdu+FgNPo7uvyhl2taTV7n6lmV0sqcHdLyo0HwIPAHSt3KEkNwRJxYWpuKErTuDZ2wb7gxpSzKg9NkrL9YQO1EfOOUw7Da5wYe7SAQdIJ59c4YLSpTcFnlckHe7uK8xsd0kPu/uHCs2HwAMAXSv3YadSAlTcaeKepTVy/9JOSy9Fy4iRuvU20847V63IXiXUs7Rc0n1m5pJucvcmSbu6+4rM+29J2jWx2gFAAMp9baZSrqtT6WvxzJkX/8KDqG211sIzyt2XmdkISfdLOl/SHHevzxlnjbtvd1koM5suabokjR07dtIbb7xRrWoDqZCWzqJAJXT3K7/DPkCa9OXLS7sOz1lnSX24KVOqBHlIK5eZXSZpg6Rp4pBWuNhLl01K7mQBVETcQ1p765aSyrnpRyWcln7iiZzLXkHBBR4z21FSH3dfn3l+v6SZko6S9G5Op+Vd3P3CQvMi8NQQ9tJlQ3ZEV0r9bKTpMxU38FR1D3DzzdLpp1ezxF4lxMCzh6Q7My/7SvqVu19hZkMl3S5prKQ3FJ2WvrrQvAg8NSRN/1HjquW6o1cp9XdFnOmK/TqU+rWJHXjmzCl+5hmnnSZdfrlUH+teWiY/9jjtMpxr41RK0dve3XvdY9KkSQ5U3OjR7lL0F0ixpqboY9rUVN7pct/Pfh0aGtzr66O/TU3bz6PUr42kuV7sPiA6gbtqj8n9bvUFC+ItD4pX7LavmRaecqKFJxypbkRJdeWA0hV7XZ3cFqDsWVcbNkhr10bvjx4d/c1tJapaC88VVxQ/84w33pBWrow9maY9OU0//u1wTZoUf1p0L7hDWuVE4AkHXXyAymluli68MLo7+FVXtQeQ3O+d1PV3MF94mTJF+uUvpYED22/gWY7fBbEDTwn7vp7cJX3RougiyCg/Ak8BBJ5wFPw1mOIWlhRXDdgmG2ykjoGmlCsnd55nkreWaDTzP39k/9hlvPBiFHriBp9vjvm5fj5vX+2yS+wiUQQCTwEEnl4ixc0/Ka4asE1XLTw9nWclwn6qz9J66CHpiCOqWWKvEuqVloHiVfpSrT3QuWq0+ASkxjdmvurPnBlv/ELKfRXnUj1y8n9XraxX5+2vLS9VrTiZSZMni1tZdEILD2pHje9ICqHFJyA1vjE7V7+7xUnL4qa5hWeqZulmTa1iidLs2dIpp1S1yMTQwoPwzJwZ/WedOTO4wFOoMSrgnBemFLcsFqNz9btbnNz3+azm9+/nu754dPXKM5MmTJBefTX+tHvsIfUNNRkUc+56aA+uw1OjSr1YSK2Wm8HlfBBHTz6uxU6bb7ymJnez9mvtlLNexVCKr8PzJc2qZnE9elx3XWW2TyUVu+05pAV0J+E2e341I47uPq6FPk/FftTzjZd7Rld9vbRmTWnzLlXsQ1o33BC7jGuuld58Q1LMs7Ru8ck688J6jRkTu8iq+8d/lHbbLelaxMOVlgs8aOGpYZ1/JlboZ2OH2SbcwgPE0d3HtVCLYU9aeCZPjlp4Bg7M//VMVQtPXZ372LGxH8v6jfUldfEeG2zH6jbRHHtsZVZwihW77WnhQWoU1ZIRt0dliQWnpSMmUG7NzdJFF0V7x6uvLl+rYfY709AQ3Rg827enWt+jOC08++xQ7w/UDY1dRlub1NoWb5oPtCySJD2tibHLk6QD/eglAAAgAElEQVS99pJ2GlzkyFu3Rk00l11WUlm1iuvwFEDgSaeiQkbncFKO4z15CuYwEkJWiUCf/c5kbx2RezuJanyP4h7S+v63HoxdRl2dtMMOsSfT2o8eKu/bL/Z0/fpJhxzSsys89wYc0uKQVs1J7MhRNwVXol4cJUOSKvn5S+qzrZidlgcN8tiP+nr3tWuru1zoXrHbnhYeoIDmZunss6XW1vL+GuaQGVBe1biX1u67S3/7W/QX6cF1eIAymDkzCjt1dT2/rEruYbIav1QLUq4ah2R762HfZ55pPxstrcyk/feX+vRJuiYpU0wzUGgPDmmFL9usPnlyz5rXy9k8n+T1dDiE1rtU47NWTBnV/Nwp7nV4Siqjdh6/+EVZVmtNKHbbc0gLNSHur8nsIaO6ujIejuqiEsXeYDHJX8QcQqustLV25KtPuetYaH75OjCn6SytRjOfW0Lz6nXXRf9T4rac/GKns7Wqb/UubmMmffGL0qBB1SnPXTrpJGm//apTXmd0Wi6U7mnhqTmxfrE2Nfn6htF+QX1Tj1t4iqnE6NHuX1GTv6mozDSihWd7obTeFSu3jk1NUQfchobKfCayZTU0pLOF52M7D/X3hu8R+7F80B6+uG+8R7Wbdv6sAxNpUbr44spv464Uu+1p4UFNiPXrtFLNGQVaeD575hiN8qXa0DBag1cXLrMWWgN6g3J+TJJah3HKzR03e30cqTKtL0msj7gtPLdrfKWrJEkyuV7Wh/Wpw/pWvsWltVUtRxytzWf/R4UL2t5OO0WtX0ngOjwFEHgClf0ve/jh0sMPV/e/bYz/8Gk7vJTvgnFpDT7l3JGGEPRK/SwVexi2lsQJPB8fMtQfHPXh2GW89HLsSbSnXtM1ukD/8cQpGjs2/vSxDRkSfZF7EQJPAQSeQKUtSWR12rNWsy9FnOmr2d+iVGndxNUWJ9tX4lqdBQuolG7KiRN4zBpdqs4+4Ctq1uW6VAMHVr4FZNDfV6lv21Y9fOBFapwkDS72Cs2l2mEH6YILouadBBF4CiDwhGG7/39l+MebOwupTP/Hu9hLx65uFxOUKwTUQotHsXWsyLJMmSLNni2deqp0yy1lmmlp4mzzStyNpeTKVLCc2J2Wy17BXuqss6SPf7w6ZR1yiLTPPtsNJvAUQOAJQ7n/z3a+yKCUZ/5d7EkfndKsvWbP1MJTZ+iwW7o4ZSVnmu4uaJivmA27jNHgNVE/odlXLSkqmNVCiKmEsn42sitx2bKof2ZdndTSUnDUpBo7ijk7K/ez+sph03oe8JNe6IxYgWfkSJ971FGxq/DyfOndVYp9t/Rq2XHLWn182V1JV6Nyjj9emjNnu8EEngIIPGHo8f/ZTs05y8+eqUtbZ+inddN0443RKNvNv4s96fK+YzSydamW143WyJbu97C5p83feOP29c/Xr2bBhc06f+1M3VA/Q7MHTytqh97bDgFVpBtXdiUOHCht2VKwhae77Vpp3W7vTkl7jJZsG1+q7c9KnMAzcWKj33lnlfYBW7eq71ulXanwnnukP/85uqdWMXZ9f5H+7dkzdPSWu7XDDtJHPxqvvNZWafHi2NXUli3R/UqPOSb+tLGMHZv38BmnpRd4cFo63L3jebqZ529qtE+eXGCaLs5lfmRyky+rG+2PTC7u/NvuTonOvl9f317F3GmKLa+oU68LjFRo+jSe6l6R08NjLGhTk3tdXQXqUKRuq5pdQXV17k1NHcZP4/aMQzFOS5cmVe107Zn6pq/SLr5I40p6vDtknG8YUfzjjaOm+pw57ps3J7Ulqq/YbU8LD4JSsNWnuVkbLpqpb2yaoVsGTNNvPteswx7ONAfcdZfWrjPN8c/pM3UPa+SN6TgG1OXylLPppsC8ChWTxtajNBzCK7UOVal7GlZQhcRp4dlrr0Y/77zq7AMmPXSNDv3dhVUpKxHPPit97GOJVoFDWgUQeMJVcCeceXOJRmuslrSPkxm+oWG03ntPGtmanr14l/un5mbpoouiH5FXX92znVeBnWAxV9OtZgfiinQq76FyLV93ATJtZ/dVfobxxOrDU+I+4KWXpNdfjzfN6Adu1uDrvxW7rFIM10rtrPX6b51blfK2qp8u16Vap/qS5/HNb0rf6uHqIfAUQOAJV3ctPMvOnKnLfIZ+YtN00015zu6S0rEXzci3E8xW9+X3o07MaQlnXalUY5SUjhamapwl110n91Jk631BfbOuHlyG+1Ak3OQXJ/Dst1+j33Zb/H3AkUdKH/6wNGBA8dOc9eJ5Ov6NH8Quq1S3DZmmGbs2Va28ntiyRbrkEmn69J7Nhz489OFBHlXpp1DGQvLNKtsN44L6ypZTLuWcdxr7nFSjHp263pRFtt7rG/J0fCqlM1Rmho9Mbkpku6hKfXhOO839rLOKf/xx33Or01ko+/jCF6q74lOg2G1PCw96n0o3vXf6pZv6QxFK/Md55dV435U4p6GXZeYlHuaUkvssxWnhGbvTnn52v7MqXSVJ0hnvfVe7tq6oSlmSpD32kF57rXrlpQAtPLTwoCuVvrNhp5/85TpzqFZaYVIpqbt7VnjFJrFY3ZWZ1GdJMVp4JiVxd81qPnqZYrc9LTzofap8L4VyXdo/+FaYSkqqhafMG62rz1I5rzvU3apKa2NZ3CstP2FFXtwmh3t0/7G4Xu3/MW3a0if+hDH101bN6fdFXTvgv/Tww9LEiRUvMhVo4SmU7mnhqWll+wXZkxkVOW2hPjjZX8jFVqPWromTlFStizJXpqvWlXK29CTVGBZbp3WrOC08Q4a477df7MfGvffztePjPTbvNNRP10+r3sjz178mslUSUey2p4UHNafgj+Yy/+Tt6XVwCp1llZ1nT+54nZ3PzJm0/mSF3BLWk1tK9LSM1Om0oatxWvrAgdKmTfGmuUHnab721g90XuzyJOkf/1Hab79405hJZ54pDRtWUpE1hxYeWniCVfBHc+7pLGX4mZrv125TU3SG1PqG0lp4Shmnu7qVevZSqlpDyiSEZSrHMlTizK5U6UkLT5WbW5Jo4bnjjkS2SiKK3fa08CAs2Z+no0ZJc+f2+M7W+X7tpqEFoblZuvDC6JfcVVd17M/x/vvSmjXF1a+hIerGVF8fTZN6lW5+SEnzRqHPWJwLPpb72j1pFquFZ8QInxu32UTSSy9Lb61QrJuHHtn6QOxyemLj5K/o/e8295rWHYkWnsLpnhae8PWgI0Kx97lK4lfz5MnRL/ZBg7ZfvOwi19dHzydP7r6eDQ3RNA0Nla97WfS0g0l3Gy/O/Cv4QSg065RUMXUUp4WnxH1AKS0tN6i61+H5/civ+NFHu7/6allWa00odtvTwoMw9eCXeqFf149OadZes2dq4akzdNgtJd5roQf69o1+sZtFjViF+mwU0xJVkSrnmWnZ+pP0tMLlvH9DQk19KWmE6iANdapGH56nnpIWLIg3TePN5+n1+xfoKR0Qu7xSzNMk/UYn6qGHpCOOqEqRiePWEgUQeFBIoX/ey/uO0cjWpVpeN1ojW6p/N80pU6TZs4s7Upddjl8enrlJarX2RnnWQ6mrpiyrtFK3DknDXj4l0nCYN07gMWt0qbR9wODB8cY/rOUh3bB5msaMkfr1LanI4m3ZEvWsfvXVCheULgSeAgg8KFVuC88rh00rb+tDMcpxj6OceTRrWm218JQiDXvjCkhT3kpDXWLdS6vvQH+2NebpVj3Q9oFx6nPE4dUp7JOflM6qzlWk04LAUwCBB+WQyH60lEIze6NHD5+hf314Woebjo7RknRlgUrsOdOwN66AYi550JvEvfBgNfcAP9/zcn1hzhnaeecqFFZfH78ZqsZVvdOypEmSZpVrfpV80Gk5DEl3yEyk/B4Umu+mo49MbvJlddENH5OsZ8EbWVa3KjVju+VqirblV9SU/osGVoDidFru06eqHYlXaqhv3W2U+6gKP0aMcD/wwKQ2QWKK3fblDDwnSWot1/wq+SDwhCGNV4TN7oSKOUOq2vLu+Cu1EmPOt5g7wJfjekVByyzoUhvtDQ3p+uxVQ6zAU+2L4ki+tU8/b6mr8KNPX1/yoSP9xhvd33svqS1RfWULPJIOK/Ixg8CDakrTL/dsXerro29Vma572GHepS5nwenLuRJLvfphkdUoNbj8+JNN/qZG+48/mYIPSiVlVuIF9U29I+B1kubAM10/8n7aXJVHH7W45D57dlJbovqK3fbd9uExszZJruIuteTuXlfEeImiDw/KLdufoqFB2nHH8t7Msad9heJOX3I/kAp3aiq1XgXPrAtQb+3Hk+Y+PJeM+Ik+/5sz1NBQnfLMpA9+sLQbndaisvXhkbRK0i8k7dvN46uihQe9VCVbm7qad7ENKtmLFU6eXFwhJR8CSlOTW46K9VNCqijFLTxf0ix/5ZWk1kz4it32xbTw3CWpwd0/1c14J0m63WnhAfLrwU/v7m5xIXXduFJUw0vOSM0zlmjBhc2aYTM1+Kpe1kyAmhW3hec27VFSObs0SH36xJtm0aemaL/D69WnGi0uEydGTcy9SNlOSzezcyRNcfeDuhlvkqTz3H1qrJomgMCDRBSRPLrKRN2dgix1naWKylnluoU7Ui2xi1FWQZzA86H6Md40/qTYZTz9TOxJdIZmaWetjz9hT3SzXw9Nr7oOj5kdK+l7kuok/djdryw0PoEHxSh7X4giZthVzujphfti9ymqZEeQGuxkUoNVziv7+VpWF/VrCinQxmrhGTaspJuHPvhQ7El0lEqYqCfq6qSWluqWmbBeE3jMrE7Sq5KOlrRU0lOSTnX3l7qahsCDYlS7kSPfHdBz3ysluGSXoa6uPHfNLmXH39ysjofIZs6sudajcgfRpNDCE2k087m/+13sMpYvl95ZGXsyzfmt9PpiaeCAeNOtXCldcom0777FT+Mf2lu+514aODBeWbWsnJ2Wd5d0h6RjCoxzTGacEcV0HCrnQ9JBkv6Q8/oSSZcUmoZOyyhGtfvgFuosnL2ruVm8DsXZDsuf/GT8Zcm3/KV0aB492v1N5UyYYOfmUovuarpec42fGrCrtNhT2mm5mo/XNN4l9zlzktoS1acyXofnOklPK9Ma1MU4Julvkq4qptByPiT9o6LDWNnXUyT9d6FpCDyohEpeLyd7fZ+BA+NdU6ekHXKB67l0WccClW9qii4ouL4h+TO4yh1QUnpiWq+0n7TFUxx4VtXvUfnHkPF+/6cu9Ysvdl++PKENkYByBp5XJJ1ZxHhnSppfTKHlfBQbeCRNV3R73Lljx44t02pGb9Z5Z3dBfXSBuwvqy7/3K2rHmmdvXtIOOTOf9Q2ji5+2Rpo6CCjh6q6FJ3cfMGCHMT6+/7LYj921zN99fpn7shiPk06qerjqbcoZeDZJOrSI8Q6TtKmYQsv54JAWktJ5H5+9D9T6hsyAau9dC5UXpy6ZcR+Z3FR89Yu62A9QOcXu9KJRJ5WcJRYtcl+zpvjHpjPOJvBUWDkDzxpJnytivM9KWlNMoeV8SOoraZGk8ZJ2kPSspH0LTUPgQSxdhIV8N2/sMKBcLS7FV6lrOXUpdtouG23yzGC7sBcXTS/ooWoFniFD4j2adjiHwFNhxW77Yq7D86Ckhe5+Zjfj3SRpL3c/quAMK8DMPivpekWnpc9y9ysKjc9ZWoili1N0uj1Dp/MIzc1afvZMXdo6Q/eOntajE5Rin0GWU5cxM6cVNW2Xy5en8AsbmnX+2pm6oX6Grl5Twlk/XPcHPZTmW0s8ZZ/Qnuceq112qXBB7lJjo/T5z1e4oHQp51laJ0lqkXR6gXFOk7RF0onFpKykH7TwIJYuWh9id1vJTLCsbnS5jjqV1CDS48aUPDMoaZ4l3GyUhqCOWB/tFKOFZy8N8dWqr8rDJT+vzw/8nXeSWjPhK3bbF3UdHjO7TtG9suZJulfSm5Jc0lhFp6Q3Svquu389djRLAC08KIfY12DpZoJe18hRwgL3unXUDdZHuzgtPJOsjzf1PzB2GZs3Z8qKOd3/Hf49/eylAzRsWOwiUYRit33fYmbm7l8zs4cl/Yekr0vqn3lrs6THJZ3g7neVWFegJk2bFvOabd1MMGNGx1tFVEwFr5YXa9YlLHDV1lGNYH2UxuR6csCnY083dJR08snx70L++/NHSYSdxBXbwjNQUafkcZLekvRA5q133b3mrmFNCw9qUdlySgWbBbq751cgF/VFCqW5D4/uuEP64herWWKvUuy27/aer2a2h6QXJf2PpGsk3SJpvqT9ajHsALUqe0eGmTMVpYgxY6K/cc2YESWSCjQL5Jt1h3pXSE9WB1Bxu+2WdA2g4u6W/mtJEyWdrqgPz3hJP5Q0zt3HV7yGFUALD2pRh5aSmbXTeaMaLTz0ZUHcFp4/9Il/jKmuThoyJH4fHt13n/Txj8cuD8UpZx+egyR9zd0fz7x+2czOzPzd3d1X9KSiAIrTsQtQdTtv9CS0xO7rVAL6siCuYW0l3AW0TVr9qtTQUP76oPKKaeFpk3Sguz+ZM6xO0lZJk9z96cpWsfxo4QHioQUFaRe3hedfruu+/2pnw4ZJU6bE77SMyirrWVqKTkEH0EvRgoLQ/Od/Jl0DVFuxgecPZpavg/KDnYe7+4ieVwtAVhrOcqrGYSmgmr5y6CslTXfBBVK/fvGm6d9fGjWqpOLiGzGCY25dKOaQ1qVxZujul/eoRlXAIS2kVp5006PDSQXSUk+CVKVCWBrCHWpTqk9Lr6bhw6V33km6FlVV7LYv6jo8oSHwILXypJvmZmnBhc2aYTM1+KqYSaBAWupJkKpUnx76CqFUcQPP7SrtJOOGBqlPtxd06ei1w6Zq4pG7qE81+v7st590yCFVKCg9ynYvrRAf3EsLqdXVzZFi37grmsUF9U3RHczz3Gwp0ftxVXm+CJ9i3EtrUrXvXv6rXyW1WnqFYrc9LTxALSj2WE8Xd0XP7XTMoSKEKNWHtObNk/bfv5ol9ioc0iqAwIOKS6ozSs4xoeYZS7ZVYcGFzTp/7UzdUD9DV68h8SA8qQ48o0dLBx9c+XLa2qQjjpDOOafyZaUIgacAAg8qLqnOKF0ErQ27jNHgNUu1oWG0Bq+mcwzCk+rAU02TJkm9bP9WtntpAShBOe5XVcoNoqZNiwJWp1alwVdF9Rl8VS+6kA432EJvtNNOSdcgtWjhAaR0ng/NKUs9w/rrVVLdwrPjjtIBB1S+nJYW6R/+QbroosqXlSLlvtIyELbcW3qnJfBweeOeYf0hLR56SPrEJ5KuRa9HCw8gpbOFB0DRYrfw9MJ9X6ho4QHi4N4JABA0Oi0DAIDgEXgAAEDwCDwAACB4BB4AABA8Ag8AAAgegQcAAASPwAMAAIJH4AEAAMEj8AAAgOAReAAAQPAIPAAAIHjcSwvoLbhBKtDu6qurV9aXvywNHVq98pAXd0sHeosxY6SlS6XRo6UlS5KuDVBWse+WXukK5Zo9WzrllGqW2Ktwt3QAHc2Y0d7CA/R2S5dWr6yRI6tXFrpE4AF6i2nTOJQFZI0alXQNUGV0WgYAAMEj8AAAgOAReAAAQPAIPAAAIHgEHgAAEDwCDwAACB6BBwAABI/AAwAAgkfgAQAAwSPwAACA4BF4AABA8Ag8AAAgeDUReMzsMjNbZmbPZB6fzXnvEjNbaGavmNkxSdYTAACkUy3dLf277n5t7gAz20fSKZL2lTRS0gNm9kF3b02iggAAIJ1qooWngBMk3erum939dUkLJX0i4ToBAICUqaXAc56ZPWdms8ysITNslKQlOeMszQwDAADYJjWBx8weMLMX8jxOkHSjpD0lTZS0QtJ1Jcx/upnNNbO5K1euLHPtAQBp1mEfkHRlkIjU9OFx988UM56ZNUu6K/NymaQxOW+PzgzLN/8mSU2S1NjY6KXXFABQazrsA8zYB/RCqWnhKcTMds95eaKkFzLP50g6xcz6m9l4SRMkPVnt+gEAgHRLTQtPN642s4mSXNJiSWdKkru/aGa3S3pJUoukczlDCwAAdFYTgcfdpxR47wpJV1SxOgAAoMbUxCEtAACAniDwAACA4BF4AABA8Ag8AAAgeAQeAAAQPAIPAAAIHoEHAAAEj8ADAACCR+ABAADBI/AAAIDgEXgAAEDwCDwAACB4BB4AABA8Ag8AAAgegQcAAASPwAMAAIJH4AEAAMEj8AAAgOAReAAAQPAIPAAAIHgEHgAAEDwCDwAACB6BBwAABI/AAwAAgkfgAQAAwSPwAACA4BF4AABA8Ag8AAAgeAQeAAAQPAIPAAAIHoEHAAAEj8ADAACCR+ABAADBI/AAAIDgEXgAAEDwCDwAACB4BB4AABA8Ag8AAAgegQcAAASPwAMAAIJH4AEAAMEj8AAAgOAReAAAQPAIPAAAIHgEHgAAEDwCDwAACB6BBwAABI/AAwAAgpeawGNmJ5vZi2bWZmaNnd67xMwWmtkrZnZMzvBjM8MWmtnF1a81AACoBakJPJJekPRFSY/mDjSzfSSdImlfScdK+qGZ1ZlZnaQfSDpO0j6STs2MCwAA0EHfpCuQ5e4vS5KZdX7rBEm3uvtmSa+b2UJJn8i8t9DdF2WmuzUz7kvVqTEAAKgVaWrh6cooSUtyXi/NDOtqOAAAQAdVbeExswck7ZbnrW+4+28rXPZ0SdMlaezYsZUsCgCQMh32AQnXBcmoauBx98+UMNkySWNyXo/ODFOB4fnKbpLUJEmNjY1eQj0AADWqwz7AjH1AL1QLh7TmSDrFzPqb2XhJEyQ9KekpSRPMbLyZ7aCoY/OcBOsJAABSKjWdls3sREk3SBou6fdm9oy7H+PuL5rZ7Yo6I7dIOtfdWzPTnCfpD5LqJM1y9xcTqj4AAEix1AQed79T0p1dvHeFpCvyDL9b0t0VrhoAAKhxtXBICwAAoEcIPAAAIHgEHgAAEDwCDwAACB6BBwAABI/AAwAAgkfgAQAAwSPwAACA4BF4AABA8Ag8AAAgeAQeAAAQPAIPAAAIHoEHAAAEj8ADAACCR+ABAADBI/AAAIDgEXgAAEDwCDwAACB4BB4AABA8Ag8AAAgegQcAAASPwAMAAIJH4AEAAMEj8AAAgOAReAAAQPAIPAAAIHgEHgAAEDwCDwAACB6BBwAABI/AAwAAgkfgAQAAwSPwAACA4BF4AABA8Ag8AAAgeAQeAAAQPAIPAAAIHoEHAAAEj8ADAACCR+ABAADBI/AAAIDgEXgAAEDwCDwAACB4BB4AABA8Ag8AAAgegQcAAASPwAMAAIJH4AEAAMEj8AAAgOClJvCY2clm9qKZtZlZY87wcWa20cyeyTx+lPPeJDN73swWmtn3zcySqT0AAEiz1AQeSS9I+qKkR/O895q7T8w8zsoZfqOkaZImZB7HVr6aAACg1qQm8Lj7y+7+SrHjm9nuknZ297+4u0v6uaQvVKyCAACgZqUm8HRjvJk9bWaPmNmhmWGjJC3NGWdpZhgAAEAHfatZmJk9IGm3PG99w91/28VkKySNdfd3zWySpN+Y2b4llD1d0nRJGjt2bNzJAQA1rMM+IOG6IBlVDTzu/pkSptksaXPm+Twze03SByUtkzQ6Z9TRmWFdzadJUpMkNTY2etx6AABqV4d9gBn7gF4o9Ye0zGy4mdVlnu+hqHPyIndfIek9Mzswc3bWaZK6aiUCAAC9WGoCj5mdaGZLJR0k6fdm9ofMW4dJes7MnpH0a0lnufvqzHvnSPqxpIWSXpN0T5WrDQAAakBVD2kV4u53Srozz/A7JN3RxTRzJX2kwlUDAAA1LjUtPAAAAJVC4AEAAMEj8AAAgOAReAAAQPAIPAAAIHgEHgAAEDwCDwAACB6BBwAABI/AAwAAgkfgAQAAwSPwAACA4BF4AAC9yiYblHQVkABz96TrUHVmtlLSGz2czTBJq8pQnbQKffkkljEUoS9j6MsnlWcZP+Duw4sZ0czWS3qlh+X1FrXw+Stq2/fKwFMOZjbX3RuTrkelhL58EssYitCXMfTlk6q/jL1hnZZLSOuKQ1oAACB4BB4AABA8Ak/pmpKuQIWFvnwSyxiK0Jcx9OWTqr+MvWGdlksw64o+PAAAIHi08AAAgOAReLphZieb2Ytm1mZmjTnDx5nZRjN7JvP4Uc57k8zseTNbaGbfNzNLpvbF6WoZM+9dklmOV8zsmJzhx2aGLTSzi6tf69KZ2WVmtixn23025728y1trann7FGJmizPfrWfMbG5m2C5mdr+ZLcj8bUi6nnGY2Swze8fMXsgZlneZLPL9zHZ9zsz2T67mxetiGYP/HiJdCDzde0HSFyU9mue919x9YuZxVs7wGyVNkzQh8zi28tXskbzLaGb7SDpF0r6KluGHZlZnZnWSfiDpOEn7SDo1M24t+W7Otrtb6np5k6xkKQLZPoUckdlu2XB+saQH3X2CpAczr2vJzdr+f0RXy3Sc2v+vTFf0v6YW3Kz8/weD/R4ifQg83XD3l9296AtUmdnuknZ297941EHq55K+ULEKlkGBZTxB0q3uvtndX5e0UNInMo+F7r7I3bdIujUzbq3ranlrTajbpysnSPpZ5vnPlPLvW2fu/qik1Z0Gd7VMJ0j6uUf+Iqk+8z8n1bpYxq6E8j1EyhB4ema8mT1tZo+Y2aGZYaMkLc0ZZ2lmWC0aJWlJzuvssnQ1vJaclzkkMCvnEEgIyyWFsxz5uKT7zGyemU3PDNvV3Vdknr8laddkqlZWXS1TaNs25O8hUqZv0hVIAzN7QNJued76hrv/tovJVkga6+7vmtkkSb8xs30rVskeKnEZa1ah5VV0GOBbinae35J0naQzqlc79MAh7r7MzEZIut/M5ue+6e5uZkGdehriMmXwPURVEXgkuftnSphms6TNmefzzOw1SR+UtEzS6JxRR2eGJaqUZVRU7zE5r3OXpavhqVDs8ppZs6S7Mi8LLW8tCWU5tuPuyzJ/3zGzOxUd6njbzHZ39xWZwzvvJFrJ8rZgl84AAAPRSURBVOhqmYLZtu7+dvZ5oN9DpAyHtEpkZsOzHenMbA9FnQgXZZqh3zOzAzNnZ50mqVZbUOZIOsXM+pvZeEXL+KSkpyRNMLPxZraDog6GcxKsZyyd+jycqKjTttT18taamt4+XTGzHc1sp+xzSf9H0babI+n0zGinq3a/b7m6WqY5kk7LnK11oKR1OYe+akov+B4iZWjh6YaZnSjpBknDJf3ezJ5x92MkHSZpppltldQm6Sx3z3bKO0fRWQkDJd2TeaRWV8vo7i+a2e2SXpLUIulcd2/NTHOepD9IqpM0y91fTKj6pbjazCYqakpfLOlMSSq0vLXE3VtqfPt0ZVdJd0a/I9RX0q/c/V4ze0rS7Wb2ZUlvSPqnBOsYm5nNlnS4pGFmtlTSpZKuVP5lulvSZxV15P27pKlVr3AJuljGw0P+HiJ9uNIyAAAIHoe0AABA8Ag8AAAgeAQeAAAQPAIPAAAIHoEHAAAEj8AD1IjM3aU957HczO4wsz07jXeSmT1kZmvNbLOZvWpm3zGzkTnjmJn9f2a2xMw2mtmjmVOEASBIBB6gtqyTdFDm8XVJEyU9mLkQn8zsOkm3S1okaYqii/N9V9JRiu6gnnWxpP+SdJWk4yVtkPSAmeW7HQcA1DyuwwPUCDO7TNJ57j4sZ9ghkv6k6MJ0mxRdpfbL7j6r07R1kv6Pu99jZgMkvS3pOnefmXl/R0UXf7vJ3b9ZhcUBgKqihQeobfMyf8dJ+qqkv3UOO5Lk7q3unr3i98GSdlbUEpR9/31Jv5N0XEVrCwAJIfAAtW1c5u9bioLMvUVMs7ekVkkLOg1/OfMeAASHe2kBNcbMst/bPST9UNJ6SQ9I6i/pzSJm0SBpQ577E62RNMjMdnD3LeWqLwCkAYEHqC1DJW3Nef2mpH9WdANG5fwFAOQg8AC1ZZ2kzygKNm9JWu7ubmb9JG2WNLaIeayRNNjM6jq18jRI+jutOwBCRB8eoLa0uPtcd5/n7ss8c5qlu2+V9LikY4qYx3xJdZL26jR878x7ABAcAg8QjuslNZrZ6Z3fMLM+ZnZs5uWfJb0n6eSc9wcpuh7PPZ2nBYAQcEgLCIS7/87MviPpJ2b2KUm/VXRBwb0lnaXoOjv3uvsmM7tS0n+Z2RpFrTr/qegH0A2JVB4AKozAAwTE3b9mZn+WdJ6kX0kaqCjozJF0bc6oVyoKOJco6gg9V9LR7v52VSsMAFXClZYBAEDw6MMDAACCR+ABAADBI/AAAIDgEXgAAEDwCDwAACB4BB4AABA8Ag8AAAgegQcAAASPwAMAAIL3/wMLbDocTed0NAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a06a94f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "rnaNet.scatter_hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "def multiScatterHist(x1, x2, y1, y2, colors1, colors2, axis1='', axis2=''):\n",
    "    nullfmt = NullFormatter()         # no labels\n",
    "    \n",
    "    # sanity check\n",
    "    print(\"colors1 shape = \" + str(colors1.shape) + \" colors2 shape = \" + str(colors2.shape))\n",
    "    print(\"x1 shape = \" + str(x1.shape) + \" x2 shape = \" + str(x2.shape))\n",
    "    print(\"y1 shape = \" + str(y1.shape) + \" y2 shape = \" + str(y2.shape))\n",
    "    \n",
    "    # definitions for the axes\n",
    "    left, width = 0.1, 0.65\n",
    "    bottom, height = 0.1, 0.65\n",
    "    bottom_h = left_h = left + width + 0.02\n",
    "    \n",
    "    rect_scatter = [left, bottom, width, height]\n",
    "    rect_histx = [left, bottom_h, width, 0.2]\n",
    "    rect_histy = [left_h, bottom, 0.2, height]\n",
    "    \n",
    "    # start with a rectangular Figure\n",
    "    plt.figure(figsize=(12, 12))\n",
    "       \n",
    "    axScatter = plt.axes(rect_scatter)\n",
    "    axHistx = plt.axes(rect_histx)\n",
    "    axHisty = plt.axes(rect_histy)\n",
    "    \n",
    "    # no labels\n",
    "    axHistx.xaxis.set_major_formatter(nullfmt)\n",
    "    axHisty.yaxis.set_major_formatter(nullfmt)\n",
    "    \n",
    "    # the scatter plot:\n",
    "    axScatter.scatter(x1, x2, color=colors1, marker='o', s=20)\n",
    "    axScatter.scatter(y1, y2, color=colors2, marker='s', facecolors='none', s=20) \n",
    "\n",
    "\n",
    "    # now determine nice limits by hand:\n",
    "    binwidth = 0.5\n",
    "    xymax = np.max([np.max(np.fabs(x1)), np.max(np.fabs(x2))]) + 10\n",
    "    lim = (int(xymax/binwidth) + 1) * binwidth\n",
    "    \n",
    "    axScatter.set_xlim((-lim, lim))\n",
    "    axScatter.set_ylim((-lim, lim))\n",
    "    \n",
    "    bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "    axHistx.hist(x1, bins=bins, color = 'blue', normed=True, stacked = True, histtype='step' )\n",
    "    axHisty.hist(x2, bins=bins, orientation='horizontal', color = 'blue', normed=True, \n",
    "                 stacked = True, histtype='step')\n",
    "    axHistx.hist(y1, bins=bins, color = 'red', normed=True, stacked = True, histtype='step')\n",
    "    axHisty.hist(y2, bins=bins, orientation='horizontal', color = 'red', normed=True, \n",
    "                 stacked = True, histtype='step')\n",
    "    \n",
    "    axHistx.set_xlim(axScatter.get_xlim())\n",
    "    axHisty.set_ylim(axScatter.get_ylim())\n",
    "    \n",
    "    axHistx.set_xticklabels([])\n",
    "    axHistx.set_yticklabels([])\n",
    "    axHisty.set_xticklabels([])\n",
    "    axHisty.set_yticklabels([])\n",
    "    axScatter.set_xlabel(axis1, fontsize=15)\n",
    "    axScatter.set_ylabel(axis2, fontsize=15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
