{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMD ResNet for RNA data - Log transformed\n",
    "\n",
    "Use GTEX as source and TCGA as target since there are 2445 GTEX samples and only 683 TCGA samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import keras.optimizers\n",
    "from Calibration_Util import DataHandler as dh \n",
    "from Calibration_Util import FileIO as io\n",
    "from keras.layers import Input, Dense, merge, Activation, add\n",
    "from keras.models import Model\n",
    "from keras import callbacks as cb\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "#detect display\n",
    "import os\n",
    "havedisplay = \"DISPLAY\" in os.environ\n",
    "#if we have a display use a plotting backend\n",
    "if havedisplay:\n",
    "    matplotlib.use('TkAgg')\n",
    "else:\n",
    "    matplotlib.use('Agg')\n",
    "\n",
    "import CostFunctions as cf\n",
    "import Monitoring as mn\n",
    "from keras.regularizers import l2\n",
    "from sklearn import decomposition\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "import ScatterHist as sh\n",
    "from keras import initializers\n",
    "from numpy import genfromtxt\n",
    "import sklearn.preprocessing as prep\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmdNetLayerSizes = [20, 20]\n",
    "l2_penalty = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sourcePath = os.path.join(io.DeepLearningRoot(), 'data/rnaBatch1-gtex-20PCs.csv')\n",
    "# targetPath = os.path.join(io.DeepLearningRoot(), 'data/rnaBatch2-tcga-20PCs.csv')\n",
    "\n",
    "sourceFileName = 'unnorm-log-20PC-GTEX-breast-prostate-thyroid.csv'\n",
    "targetFileName = 'unnorm-log-20PC-TCGA-breast-prostate-thyroid.csv'\n",
    "\n",
    "sourcePath = os.path.join(io.DeepLearningRoot(), 'data/unnorm/' + sourceFileName)\n",
    "targetPath = os.path.join(io.DeepLearningRoot(), 'data/unnorm/' + targetFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# source = genfromtxt(sourcePath, delimiter=',', skip_header=1)\n",
    "# target = genfromtxt(targetPath, delimiter=',', skip_header=1)\n",
    "\n",
    "source = pd.read_csv(sourcePath, sep=',', header=0, index_col=0)\n",
    "target = pd.read_csv(targetPath, sep=',', header=0, index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GTEX.breast</th>\n",
       "      <td>-1047.593614</td>\n",
       "      <td>-69.125751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX.breast.1</th>\n",
       "      <td>-999.462901</td>\n",
       "      <td>-48.396654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX.breast.2</th>\n",
       "      <td>-1044.107343</td>\n",
       "      <td>-78.821058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX.breast.3</th>\n",
       "      <td>-1060.326254</td>\n",
       "      <td>-69.966899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       PC1        PC2\n",
       "GTEX.breast   -1047.593614 -69.125751\n",
       "GTEX.breast.1  -999.462901 -48.396654\n",
       "GTEX.breast.2 -1044.107343 -78.821058\n",
       "GTEX.breast.3 -1060.326254 -69.966899"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source[[\"PC1\", \"PC2\"]][0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA.breast</th>\n",
       "      <td>-1063.886554</td>\n",
       "      <td>-92.713602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.breast.1</th>\n",
       "      <td>-1016.555391</td>\n",
       "      <td>-76.951760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.breast.2</th>\n",
       "      <td>-1064.027776</td>\n",
       "      <td>-84.894844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.breast.3</th>\n",
       "      <td>-1037.386398</td>\n",
       "      <td>-88.541704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       PC1        PC2\n",
       "TCGA.breast   -1063.886554 -92.713602\n",
       "TCGA.breast.1 -1016.555391 -76.951760\n",
       "TCGA.breast.2 -1064.027776 -84.894844\n",
       "TCGA.breast.3 -1037.386398 -88.541704"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[[\"PC1\", \"PC2\"]][0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = source.values\n",
    "target = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1047.59361381   -69.12575067]\n",
      " [ -999.46290114   -48.39665354]\n",
      " [-1044.10734269   -78.82105825]\n",
      " [-1060.32625385   -69.96689896]]\n",
      "[[-1063.88655395   -92.71360174]\n",
      " [-1016.55539065   -76.95176009]\n",
      " [-1064.02777643   -84.89484393]\n",
      " [-1037.38639806   -88.54170399]]\n",
      "inputDim = 20\n"
     ]
    }
   ],
   "source": [
    "print(source[0:4, 0:2])\n",
    "print(target[0:4, 0:2])\n",
    "\n",
    "inputDim = target.shape[1]\n",
    "print(\"inputDim = \" + str(inputDim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtex = source shape = (636, 20)\n",
      "tcga = target shape = (211, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"gtex = source shape = \" + str(source.shape))\n",
    "print(\"tcga = target shape = \" + str(target.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build MMD Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "calibInput = Input(shape=(inputDim, ))\n",
    "\n",
    "# block 1\n",
    "block1_bn1 = BatchNormalization()(calibInput)\n",
    "block1_a1 = Activation('relu')(block1_bn1)\n",
    "block1_w1 = Dense(mmdNetLayerSizes[1], activation='linear', kernel_regularizer=l2(l2_penalty), \n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block1_a1)\n",
    "block1_bn2 = BatchNormalization()(block1_w1)\n",
    "block1_a2 = Activation('relu')(block1_bn2)\n",
    "block1_w2 = Dense(mmdNetLayerSizes[0], activation='linear', kernel_regularizer=l2(l2_penalty), \n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block1_a2)\n",
    "block1_output = add([block1_w2, calibInput])\n",
    "\n",
    "# block 2\n",
    "block2_bn1 = BatchNormalization()(block1_output)\n",
    "block2_a1 = Activation('relu')(block2_bn1)\n",
    "block2_w1 = Dense(mmdNetLayerSizes[1], activation='linear', kernel_regularizer=l2(l2_penalty), \n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block2_a1)\n",
    "block2_bn2 = BatchNormalization()(block1_w1)\n",
    "block2_a2 = Activation('relu')(block2_bn2)\n",
    "block2_w2 = Dense(mmdNetLayerSizes[0], activation='linear', kernel_regularizer=l2(l2_penalty), \n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block2_a2)\n",
    "block2_output = add([block2_w2, calibInput])\n",
    "\n",
    "# block 3\n",
    "block3_bn1 = BatchNormalization()(block2_output)\n",
    "block3_a1 = Activation('relu')(block3_bn1)\n",
    "block3_w1 = Dense(mmdNetLayerSizes[1], activation='linear', kernel_regularizer=l2(l2_penalty), \n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block3_a1)\n",
    "block3_bn2 = BatchNormalization()(block3_w1)\n",
    "block3_a2 = Activation('relu')(block3_bn2)\n",
    "block3_w2 = Dense(mmdNetLayerSizes[0], activation='linear', kernel_regularizer=l2(l2_penalty), \n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block3_a2)\n",
    "block3_output = add([block3_w2, calibInput])\n",
    "\n",
    "calibMMDNet = Model(inputs=calibInput, outputs=block3_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting scales using KNN\n",
      "[24.283234066309433, 48.566468132618866, 97.132936265237731]\n",
      "setting all scale weights to 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(636, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.1\n",
    "    epochs_drop = 250.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "# optimizer = keras.optimizers.rmsprop(lr=0.0)\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "calibMMDNet.compile(optimizer=optimizer, \n",
    "                    loss=lambda y_true,y_pred: \n",
    "                       cf.MMD(block3_output, target, MMDTargetValidation_split=0.1,\n",
    "                             MMDTargetSampleSize=100, n_neighbors=10).KerasCost(y_true,y_pred)\n",
    "                   )\n",
    "\n",
    "K.get_session().run(tf.global_variables_initializer())\n",
    "\n",
    "sourceLabels = np.zeros(source.shape)\n",
    "sourceLabels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 572 samples, validate on 64 samples\n",
      "Epoch 1/5000\n",
      "572/572 [==============================] - 1s 1ms/step - loss: 1.2691 - val_loss: 1.8092\n",
      "Epoch 2/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 1.2625 - val_loss: 1.8094\n",
      "Epoch 3/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.2604 - val_loss: 1.8095\n",
      "Epoch 4/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.2665 - val_loss: 1.8094\n",
      "Epoch 5/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.2676 - val_loss: 1.8093\n",
      "Epoch 6/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 1.2679 - val_loss: 1.8092\n",
      "Epoch 7/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 1.2672 - val_loss: 1.8091\n",
      "Epoch 8/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.2583 - val_loss: 1.8090\n",
      "Epoch 9/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.2583 - val_loss: 1.8088\n",
      "Epoch 10/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.2594 - val_loss: 1.8087\n",
      "Epoch 11/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.2706 - val_loss: 1.8079\n",
      "Epoch 12/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.2592 - val_loss: 1.8084\n",
      "Epoch 13/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.2545 - val_loss: 1.8082\n",
      "Epoch 14/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.2572 - val_loss: 1.8086\n",
      "Epoch 15/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 1.2585 - val_loss: 1.8069\n",
      "Epoch 16/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.2663 - val_loss: 1.8047\n",
      "Epoch 17/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.2591 - val_loss: 1.8051\n",
      "Epoch 18/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 1.2528 - val_loss: 1.8032\n",
      "Epoch 19/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.2527 - val_loss: 1.8021\n",
      "Epoch 20/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.2598 - val_loss: 1.8018\n",
      "Epoch 21/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.2476 - val_loss: 1.8038\n",
      "Epoch 22/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 1.2497 - val_loss: 1.7972\n",
      "Epoch 23/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.2470 - val_loss: 1.7870\n",
      "Epoch 24/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.2422 - val_loss: 1.7962\n",
      "Epoch 25/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.2417 - val_loss: 1.7909\n",
      "Epoch 26/5000\n",
      "572/572 [==============================] - 0s 506us/step - loss: 1.2356 - val_loss: 1.8046\n",
      "Epoch 27/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.2274 - val_loss: 1.8014\n",
      "Epoch 28/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.2403 - val_loss: 1.7921\n",
      "Epoch 29/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 1.2330 - val_loss: 1.7861\n",
      "Epoch 30/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.2289 - val_loss: 1.7788\n",
      "Epoch 31/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.2193 - val_loss: 1.7963\n",
      "Epoch 32/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.2241 - val_loss: 1.7739\n",
      "Epoch 33/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.2074 - val_loss: 1.7643\n",
      "Epoch 34/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.2176 - val_loss: 1.7734\n",
      "Epoch 35/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 1.2123 - val_loss: 1.7529\n",
      "Epoch 36/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.2097 - val_loss: 1.7460\n",
      "Epoch 37/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 1.2062 - val_loss: 1.7435\n",
      "Epoch 38/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 1.1970 - val_loss: 1.7510\n",
      "Epoch 39/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.1957 - val_loss: 1.7490\n",
      "Epoch 40/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 1.1884 - val_loss: 1.7461\n",
      "Epoch 41/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.1892 - val_loss: 1.7329\n",
      "Epoch 42/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.1899 - val_loss: 1.7230\n",
      "Epoch 43/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 1.1837 - val_loss: 1.7240\n",
      "Epoch 44/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.1868 - val_loss: 1.7164\n",
      "Epoch 45/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 1.1885 - val_loss: 1.7070\n",
      "Epoch 46/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.1780 - val_loss: 1.7042\n",
      "Epoch 47/5000\n",
      "572/572 [==============================] - 0s 502us/step - loss: 1.1854 - val_loss: 1.7115\n",
      "Epoch 48/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.1870 - val_loss: 1.6955\n",
      "Epoch 49/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.1786 - val_loss: 1.6890\n",
      "Epoch 50/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 1.1794 - val_loss: 1.7020\n",
      "Epoch 51/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.1732 - val_loss: 1.6780\n",
      "Epoch 52/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.1619 - val_loss: 1.6744\n",
      "Epoch 53/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.1689 - val_loss: 1.6755\n",
      "Epoch 54/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.1698 - val_loss: 1.6801\n",
      "Epoch 55/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.1657 - val_loss: 1.6797\n",
      "Epoch 56/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.1626 - val_loss: 1.6810\n",
      "Epoch 57/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 1.1660 - val_loss: 1.6778\n",
      "Epoch 58/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.1535 - val_loss: 1.6740\n",
      "Epoch 59/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 1.1548 - val_loss: 1.6658\n",
      "Epoch 60/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 1.1502 - val_loss: 1.6565\n",
      "Epoch 61/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 1.1551 - val_loss: 1.6623\n",
      "Epoch 62/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.1460 - val_loss: 1.6456\n",
      "Epoch 63/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.1531 - val_loss: 1.6513\n",
      "Epoch 64/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.1494 - val_loss: 1.6535\n",
      "Epoch 65/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.1455 - val_loss: 1.6509\n",
      "Epoch 66/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 1.1484 - val_loss: 1.6406\n",
      "Epoch 67/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.1416 - val_loss: 1.6375\n",
      "Epoch 68/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.1388 - val_loss: 1.6261\n",
      "Epoch 69/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.1408 - val_loss: 1.6410\n",
      "Epoch 70/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.1434 - val_loss: 1.6366\n",
      "Epoch 71/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.1365 - val_loss: 1.6299\n",
      "Epoch 72/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.1351 - val_loss: 1.6366\n",
      "Epoch 73/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.1287 - val_loss: 1.6390\n",
      "Epoch 74/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.1368 - val_loss: 1.6317\n",
      "Epoch 75/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.1382 - val_loss: 1.6319\n",
      "Epoch 76/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.1314 - val_loss: 1.6248\n",
      "Epoch 77/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.1353 - val_loss: 1.6245\n",
      "Epoch 78/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.1371 - val_loss: 1.6224\n",
      "Epoch 79/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.1357 - val_loss: 1.6201\n",
      "Epoch 80/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.1270 - val_loss: 1.6248\n",
      "Epoch 81/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.1243 - val_loss: 1.6142\n",
      "Epoch 82/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 1.1250 - val_loss: 1.6057\n",
      "Epoch 83/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 1.1198 - val_loss: 1.6130\n",
      "Epoch 84/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 1.1378 - val_loss: 1.6192\n",
      "Epoch 85/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.1291 - val_loss: 1.6093\n",
      "Epoch 86/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.1221 - val_loss: 1.6153\n",
      "Epoch 87/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.1277 - val_loss: 1.6119\n",
      "Epoch 88/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.1217 - val_loss: 1.6166\n",
      "Epoch 89/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 1.1198 - val_loss: 1.6142\n",
      "Epoch 90/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.1173 - val_loss: 1.6044\n",
      "Epoch 91/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.1181 - val_loss: 1.6108\n",
      "Epoch 92/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.1229 - val_loss: 1.6025\n",
      "Epoch 93/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.1232 - val_loss: 1.5965\n",
      "Epoch 94/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.1128 - val_loss: 1.5989\n",
      "Epoch 95/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.1049 - val_loss: 1.5957\n",
      "Epoch 96/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.1127 - val_loss: 1.6070\n",
      "Epoch 97/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.1163 - val_loss: 1.6058\n",
      "Epoch 98/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 1.1129 - val_loss: 1.5929\n",
      "Epoch 99/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.1076 - val_loss: 1.5994\n",
      "Epoch 100/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.1119 - val_loss: 1.5925\n",
      "Epoch 101/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 1.1055 - val_loss: 1.6012\n",
      "Epoch 102/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.0975 - val_loss: 1.5883\n",
      "Epoch 103/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.1055 - val_loss: 1.5952\n",
      "Epoch 104/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.1052 - val_loss: 1.5915\n",
      "Epoch 105/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.1039 - val_loss: 1.5947\n",
      "Epoch 106/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.1092 - val_loss: 1.5909\n",
      "Epoch 107/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.1016 - val_loss: 1.5922\n",
      "Epoch 108/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.1080 - val_loss: 1.5837\n",
      "Epoch 109/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.1000 - val_loss: 1.5897\n",
      "Epoch 110/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 1.1043 - val_loss: 1.5871\n",
      "Epoch 111/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.1044 - val_loss: 1.5780\n",
      "Epoch 112/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.1024 - val_loss: 1.5695\n",
      "Epoch 113/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.0994 - val_loss: 1.5646\n",
      "Epoch 114/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 1.0933 - val_loss: 1.5492\n",
      "Epoch 115/5000\n",
      "572/572 [==============================] - 0s 501us/step - loss: 1.0927 - val_loss: 1.5328\n",
      "Epoch 116/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.0865 - val_loss: 1.5241\n",
      "Epoch 117/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.0767 - val_loss: 1.5023\n",
      "Epoch 118/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 1.0772 - val_loss: 1.4900\n",
      "Epoch 119/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 1.0741 - val_loss: 1.4855\n",
      "Epoch 120/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 1.0682 - val_loss: 1.4819\n",
      "Epoch 121/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.0734 - val_loss: 1.4877\n",
      "Epoch 122/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.0687 - val_loss: 1.4810\n",
      "Epoch 123/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 1.0730 - val_loss: 1.4823\n",
      "Epoch 124/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.0651 - val_loss: 1.4890\n",
      "Epoch 125/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.0633 - val_loss: 1.4852\n",
      "Epoch 126/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.0604 - val_loss: 1.4852\n",
      "Epoch 127/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.0641 - val_loss: 1.4846\n",
      "Epoch 128/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.0598 - val_loss: 1.4821\n",
      "Epoch 129/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.0544 - val_loss: 1.4867\n",
      "Epoch 130/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.0650 - val_loss: 1.4884\n",
      "Epoch 131/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.0487 - val_loss: 1.4849\n",
      "Epoch 132/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 1.0409 - val_loss: 1.4864\n",
      "Epoch 133/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.0455 - val_loss: 1.4922\n",
      "Epoch 134/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.0499 - val_loss: 1.4956\n",
      "Epoch 135/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.0459 - val_loss: 1.4890\n",
      "Epoch 136/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 1.0616 - val_loss: 1.4894\n",
      "Epoch 137/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.0360 - val_loss: 1.4842\n",
      "Epoch 138/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 1.0448 - val_loss: 1.4834\n",
      "Epoch 139/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.0403 - val_loss: 1.4869\n",
      "Epoch 140/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.0376 - val_loss: 1.4822\n",
      "Epoch 141/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.0486 - val_loss: 1.4847\n",
      "Epoch 142/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.0433 - val_loss: 1.4861\n",
      "Epoch 143/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 1.0416 - val_loss: 1.4854\n",
      "Epoch 144/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 1.0412 - val_loss: 1.4891\n",
      "Epoch 145/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.0406 - val_loss: 1.4874\n",
      "Epoch 146/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.0347 - val_loss: 1.4792\n",
      "Epoch 147/5000\n",
      "572/572 [==============================] - 0s 505us/step - loss: 1.0327 - val_loss: 1.4776\n",
      "Epoch 148/5000\n",
      "572/572 [==============================] - 0s 571us/step - loss: 1.0307 - val_loss: 1.4841\n",
      "Epoch 149/5000\n",
      "572/572 [==============================] - 0s 576us/step - loss: 1.0310 - val_loss: 1.4787\n",
      "Epoch 150/5000\n",
      "572/572 [==============================] - 0s 554us/step - loss: 1.0353 - val_loss: 1.4782\n",
      "Epoch 151/5000\n",
      "572/572 [==============================] - 0s 572us/step - loss: 1.0338 - val_loss: 1.4791\n",
      "Epoch 152/5000\n",
      "572/572 [==============================] - 0s 566us/step - loss: 1.0290 - val_loss: 1.4814\n",
      "Epoch 153/5000\n",
      "572/572 [==============================] - 0s 575us/step - loss: 1.0315 - val_loss: 1.4756\n",
      "Epoch 154/5000\n",
      "572/572 [==============================] - 0s 545us/step - loss: 1.0370 - val_loss: 1.4785\n",
      "Epoch 155/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 568us/step - loss: 1.0259 - val_loss: 1.4770\n",
      "Epoch 156/5000\n",
      "572/572 [==============================] - 0s 568us/step - loss: 1.0288 - val_loss: 1.4780\n",
      "Epoch 157/5000\n",
      "572/572 [==============================] - 0s 501us/step - loss: 1.0327 - val_loss: 1.4779\n",
      "Epoch 158/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 1.0292 - val_loss: 1.4738\n",
      "Epoch 159/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 1.0360 - val_loss: 1.4731\n",
      "Epoch 160/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.0260 - val_loss: 1.4742\n",
      "Epoch 161/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.0248 - val_loss: 1.4766\n",
      "Epoch 162/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 1.0288 - val_loss: 1.4769\n",
      "Epoch 163/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 1.0248 - val_loss: 1.4749\n",
      "Epoch 164/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 1.0195 - val_loss: 1.4772\n",
      "Epoch 165/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 1.0215 - val_loss: 1.4758\n",
      "Epoch 166/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.0183 - val_loss: 1.4745\n",
      "Epoch 167/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.0149 - val_loss: 1.4737\n",
      "Epoch 168/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 1.0238 - val_loss: 1.4712\n",
      "Epoch 169/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 1.0152 - val_loss: 1.4735\n",
      "Epoch 170/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.0215 - val_loss: 1.4744\n",
      "Epoch 171/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.0218 - val_loss: 1.4738\n",
      "Epoch 172/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.0174 - val_loss: 1.4720\n",
      "Epoch 173/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.0183 - val_loss: 1.4723\n",
      "Epoch 174/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 1.0129 - val_loss: 1.4690\n",
      "Epoch 175/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 1.0056 - val_loss: 1.4691\n",
      "Epoch 176/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.0076 - val_loss: 1.4703\n",
      "Epoch 177/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 1.0182 - val_loss: 1.4662\n",
      "Epoch 178/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.0118 - val_loss: 1.4678\n",
      "Epoch 179/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.0091 - val_loss: 1.4651\n",
      "Epoch 180/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.0204 - val_loss: 1.4657\n",
      "Epoch 181/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.0060 - val_loss: 1.4692\n",
      "Epoch 182/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.0057 - val_loss: 1.4655\n",
      "Epoch 183/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 1.0150 - val_loss: 1.4656\n",
      "Epoch 184/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.0130 - val_loss: 1.4628\n",
      "Epoch 185/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 1.0014 - val_loss: 1.4643\n",
      "Epoch 186/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9956 - val_loss: 1.4683\n",
      "Epoch 187/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.0094 - val_loss: 1.4635\n",
      "Epoch 188/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 1.0136 - val_loss: 1.4661\n",
      "Epoch 189/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 1.0084 - val_loss: 1.4630\n",
      "Epoch 190/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 1.0006 - val_loss: 1.4694\n",
      "Epoch 191/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.0054 - val_loss: 1.4614\n",
      "Epoch 192/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.0031 - val_loss: 1.4613\n",
      "Epoch 193/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.0078 - val_loss: 1.4630\n",
      "Epoch 194/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 1.0128 - val_loss: 1.4615\n",
      "Epoch 195/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.0077 - val_loss: 1.4628\n",
      "Epoch 196/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9997 - val_loss: 1.4603\n",
      "Epoch 197/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 1.0047 - val_loss: 1.4589\n",
      "Epoch 198/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 1.0060 - val_loss: 1.4614\n",
      "Epoch 199/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9940 - val_loss: 1.4570\n",
      "Epoch 200/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.0019 - val_loss: 1.4554\n",
      "Epoch 201/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 1.0150 - val_loss: 1.4582\n",
      "Epoch 202/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9964 - val_loss: 1.4571\n",
      "Epoch 203/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9958 - val_loss: 1.4613\n",
      "Epoch 204/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9967 - val_loss: 1.4585\n",
      "Epoch 205/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9938 - val_loss: 1.4573\n",
      "Epoch 206/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 1.0028 - val_loss: 1.4576\n",
      "Epoch 207/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9982 - val_loss: 1.4597\n",
      "Epoch 208/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9986 - val_loss: 1.4584\n",
      "Epoch 209/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9937 - val_loss: 1.4606\n",
      "Epoch 210/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9931 - val_loss: 1.4600\n",
      "Epoch 211/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.9970 - val_loss: 1.4568\n",
      "Epoch 212/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9877 - val_loss: 1.4564\n",
      "Epoch 213/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9936 - val_loss: 1.4574\n",
      "Epoch 214/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9903 - val_loss: 1.4578\n",
      "Epoch 215/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.9866 - val_loss: 1.4556\n",
      "Epoch 216/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9933 - val_loss: 1.4567\n",
      "Epoch 217/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9948 - val_loss: 1.4553\n",
      "Epoch 218/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9855 - val_loss: 1.4511\n",
      "Epoch 219/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9886 - val_loss: 1.4535\n",
      "Epoch 220/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.9930 - val_loss: 1.4551\n",
      "Epoch 221/5000\n",
      "572/572 [==============================] - 0s 502us/step - loss: 0.9881 - val_loss: 1.4533\n",
      "Epoch 222/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9974 - val_loss: 1.4553\n",
      "Epoch 223/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9898 - val_loss: 1.4566\n",
      "Epoch 224/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9843 - val_loss: 1.4574\n",
      "Epoch 225/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9892 - val_loss: 1.4637\n",
      "Epoch 226/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9869 - val_loss: 1.4587\n",
      "Epoch 227/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9832 - val_loss: 1.4562\n",
      "Epoch 228/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9871 - val_loss: 1.4548\n",
      "Epoch 229/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9805 - val_loss: 1.4542\n",
      "Epoch 230/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9841 - val_loss: 1.4528\n",
      "Epoch 231/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9905 - val_loss: 1.4562\n",
      "Epoch 232/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9855 - val_loss: 1.4621\n",
      "Epoch 233/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9802 - val_loss: 1.4531\n",
      "Epoch 234/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9831 - val_loss: 1.4547\n",
      "Epoch 235/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9765 - val_loss: 1.4570\n",
      "Epoch 236/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.9926 - val_loss: 1.4552\n",
      "Epoch 237/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9837 - val_loss: 1.4555\n",
      "Epoch 238/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9917 - val_loss: 1.4517\n",
      "Epoch 239/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9723 - val_loss: 1.4565\n",
      "Epoch 240/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9862 - val_loss: 1.4548\n",
      "Epoch 241/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.9739 - val_loss: 1.4552\n",
      "Epoch 242/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9839 - val_loss: 1.4491\n",
      "Epoch 243/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9842 - val_loss: 1.4532\n",
      "Epoch 244/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9785 - val_loss: 1.4523\n",
      "Epoch 245/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.9688 - val_loss: 1.4555\n",
      "Epoch 246/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9907 - val_loss: 1.4519\n",
      "Epoch 247/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9710 - val_loss: 1.4525\n",
      "Epoch 248/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9809 - val_loss: 1.4531\n",
      "Epoch 249/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9728 - val_loss: 1.4517\n",
      "Epoch 250/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9643 - val_loss: 1.4529\n",
      "Epoch 251/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9723 - val_loss: 1.4545\n",
      "Epoch 252/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9682 - val_loss: 1.4601\n",
      "Epoch 253/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9787 - val_loss: 1.4575\n",
      "Epoch 254/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9824 - val_loss: 1.4533\n",
      "Epoch 255/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9725 - val_loss: 1.4513\n",
      "Epoch 256/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9676 - val_loss: 1.4555\n",
      "Epoch 257/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.9697 - val_loss: 1.4547\n",
      "Epoch 258/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9694 - val_loss: 1.4539\n",
      "Epoch 259/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9749 - val_loss: 1.4507\n",
      "Epoch 260/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9709 - val_loss: 1.4563\n",
      "Epoch 261/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.9742 - val_loss: 1.4512\n",
      "Epoch 262/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9692 - val_loss: 1.4555\n",
      "Epoch 263/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9884 - val_loss: 1.4497\n",
      "Epoch 264/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9642 - val_loss: 1.4490\n",
      "Epoch 265/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9722 - val_loss: 1.4484\n",
      "Epoch 266/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9699 - val_loss: 1.4515\n",
      "Epoch 267/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9609 - val_loss: 1.4622\n",
      "Epoch 268/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9745 - val_loss: 1.4572\n",
      "Epoch 269/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9674 - val_loss: 1.4501\n",
      "Epoch 270/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.9732 - val_loss: 1.4498\n",
      "Epoch 271/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.9673 - val_loss: 1.4479\n",
      "Epoch 272/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.9675 - val_loss: 1.4512\n",
      "Epoch 273/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9622 - val_loss: 1.4520\n",
      "Epoch 274/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9641 - val_loss: 1.4537\n",
      "Epoch 275/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9689 - val_loss: 1.4518\n",
      "Epoch 276/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9577 - val_loss: 1.4534\n",
      "Epoch 277/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9782 - val_loss: 1.4504\n",
      "Epoch 278/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9764 - val_loss: 1.4496\n",
      "Epoch 279/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9672 - val_loss: 1.4503\n",
      "Epoch 280/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9567 - val_loss: 1.4498\n",
      "Epoch 281/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9603 - val_loss: 1.4486\n",
      "Epoch 282/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9645 - val_loss: 1.4420\n",
      "Epoch 283/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9677 - val_loss: 1.4463\n",
      "Epoch 284/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9578 - val_loss: 1.4514\n",
      "Epoch 285/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9677 - val_loss: 1.4492\n",
      "Epoch 286/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9623 - val_loss: 1.4443\n",
      "Epoch 287/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9666 - val_loss: 1.4466\n",
      "Epoch 288/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9680 - val_loss: 1.4474\n",
      "Epoch 289/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9592 - val_loss: 1.4464\n",
      "Epoch 290/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9637 - val_loss: 1.4470\n",
      "Epoch 291/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9582 - val_loss: 1.4501\n",
      "Epoch 292/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9492 - val_loss: 1.4508\n",
      "Epoch 293/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9645 - val_loss: 1.4494\n",
      "Epoch 294/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9663 - val_loss: 1.4493\n",
      "Epoch 295/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9550 - val_loss: 1.4526\n",
      "Epoch 296/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9572 - val_loss: 1.4501\n",
      "Epoch 297/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9538 - val_loss: 1.4491\n",
      "Epoch 298/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9469 - val_loss: 1.4506\n",
      "Epoch 299/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.9520 - val_loss: 1.4560\n",
      "Epoch 300/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9624 - val_loss: 1.4492\n",
      "Epoch 301/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9611 - val_loss: 1.4550\n",
      "Epoch 302/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9529 - val_loss: 1.4550\n",
      "Epoch 303/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9514 - val_loss: 1.4549\n",
      "Epoch 304/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9551 - val_loss: 1.4537\n",
      "Epoch 305/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9517 - val_loss: 1.4567\n",
      "Epoch 306/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9534 - val_loss: 1.4535\n",
      "Epoch 307/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.9658 - val_loss: 1.4526\n",
      "Epoch 308/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.9581 - val_loss: 1.4539\n",
      "Epoch 309/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 491us/step - loss: 0.9526 - val_loss: 1.4550\n",
      "Epoch 310/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9611 - val_loss: 1.4549\n",
      "Epoch 311/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9472 - val_loss: 1.4537\n",
      "Epoch 312/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9619 - val_loss: 1.4490\n",
      "Epoch 313/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9487 - val_loss: 1.4519\n",
      "Epoch 314/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9532 - val_loss: 1.4537\n",
      "Epoch 315/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9410 - val_loss: 1.4542\n",
      "Epoch 316/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9519 - val_loss: 1.4525\n",
      "Epoch 317/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.9441 - val_loss: 1.4511\n",
      "Epoch 318/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9474 - val_loss: 1.4576\n",
      "Epoch 319/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9471 - val_loss: 1.4557\n",
      "Epoch 320/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9470 - val_loss: 1.4553\n",
      "Epoch 321/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9522 - val_loss: 1.4507\n",
      "Epoch 322/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9509 - val_loss: 1.4511\n",
      "Epoch 323/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9632 - val_loss: 1.4500\n",
      "Epoch 324/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9484 - val_loss: 1.4513\n",
      "Epoch 325/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9512 - val_loss: 1.4510\n",
      "Epoch 326/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9391 - val_loss: 1.4537\n",
      "Epoch 327/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9345 - val_loss: 1.4558\n",
      "Epoch 328/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9427 - val_loss: 1.4529\n",
      "Epoch 329/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9403 - val_loss: 1.4534\n",
      "Epoch 330/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9610 - val_loss: 1.4473\n",
      "Epoch 331/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9469 - val_loss: 1.4454\n",
      "Epoch 332/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.9501 - val_loss: 1.4484\n",
      "Epoch 333/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9465 - val_loss: 1.4549\n",
      "Epoch 334/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9442 - val_loss: 1.4561\n",
      "Epoch 335/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.9444 - val_loss: 1.4555\n",
      "Epoch 336/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.9381 - val_loss: 1.4534\n",
      "Epoch 337/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9337 - val_loss: 1.4573\n",
      "Epoch 338/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9410 - val_loss: 1.4572\n",
      "Epoch 339/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.9400 - val_loss: 1.4542\n",
      "Epoch 340/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9438 - val_loss: 1.4591\n",
      "Epoch 341/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9367 - val_loss: 1.4568\n",
      "Epoch 342/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.9466 - val_loss: 1.4542\n",
      "Epoch 343/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9567 - val_loss: 1.4520\n",
      "Epoch 344/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9430 - val_loss: 1.4554\n",
      "Epoch 345/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9440 - val_loss: 1.4516\n",
      "Epoch 346/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.9433 - val_loss: 1.4551\n",
      "Epoch 347/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9435 - val_loss: 1.4595\n",
      "Epoch 348/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.9353 - val_loss: 1.4570\n",
      "Epoch 349/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9417 - val_loss: 1.4521\n",
      "Epoch 350/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9389 - val_loss: 1.4531\n",
      "Epoch 351/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9619 - val_loss: 1.4483\n",
      "Epoch 352/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9311 - val_loss: 1.4550\n",
      "Epoch 353/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9402 - val_loss: 1.4558\n",
      "Epoch 354/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9424 - val_loss: 1.4566\n",
      "Epoch 355/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.9341 - val_loss: 1.4538\n",
      "Epoch 356/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9371 - val_loss: 1.4589\n",
      "Epoch 357/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.9415 - val_loss: 1.4514\n",
      "Epoch 358/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9388 - val_loss: 1.4548\n",
      "Epoch 359/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9316 - val_loss: 1.4515\n",
      "Epoch 360/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.9457 - val_loss: 1.4488\n",
      "Epoch 361/5000\n",
      "572/572 [==============================] - 0s 501us/step - loss: 0.9322 - val_loss: 1.4545\n",
      "Epoch 362/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.9285 - val_loss: 1.4562\n",
      "Epoch 363/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9296 - val_loss: 1.4540\n",
      "Epoch 364/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.9426 - val_loss: 1.4497\n",
      "Epoch 365/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9279 - val_loss: 1.4549\n",
      "Epoch 366/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9359 - val_loss: 1.4553\n",
      "Epoch 367/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9454 - val_loss: 1.4525\n",
      "Epoch 368/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9317 - val_loss: 1.4520\n",
      "Epoch 369/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9240 - val_loss: 1.4533\n",
      "Epoch 370/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9363 - val_loss: 1.4498\n",
      "Epoch 371/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9365 - val_loss: 1.4491\n",
      "Epoch 372/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.9253 - val_loss: 1.4511\n",
      "Epoch 373/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9282 - val_loss: 1.4565\n",
      "Epoch 374/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9259 - val_loss: 1.4543\n",
      "Epoch 375/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9344 - val_loss: 1.4520\n",
      "Epoch 376/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.9366 - val_loss: 1.4491\n",
      "Epoch 377/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9336 - val_loss: 1.4472\n",
      "Epoch 378/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9205 - val_loss: 1.4496\n",
      "Epoch 379/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.9359 - val_loss: 1.4607\n",
      "Epoch 380/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9306 - val_loss: 1.4519\n",
      "Epoch 381/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9321 - val_loss: 1.4536\n",
      "Epoch 382/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9213 - val_loss: 1.4622\n",
      "Epoch 383/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9247 - val_loss: 1.4581\n",
      "Epoch 384/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9308 - val_loss: 1.4586\n",
      "Epoch 385/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9329 - val_loss: 1.4557\n",
      "Epoch 386/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9225 - val_loss: 1.4535\n",
      "Epoch 387/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9356 - val_loss: 1.4520\n",
      "Epoch 388/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9271 - val_loss: 1.4613\n",
      "Epoch 389/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9279 - val_loss: 1.4604\n",
      "Epoch 390/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9279 - val_loss: 1.4578\n",
      "Epoch 391/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9230 - val_loss: 1.4530\n",
      "Epoch 392/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9202 - val_loss: 1.4544\n",
      "Epoch 393/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9250 - val_loss: 1.4561\n",
      "Epoch 394/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.9351 - val_loss: 1.4509\n",
      "Epoch 395/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9266 - val_loss: 1.4490\n",
      "Epoch 396/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.9273 - val_loss: 1.4519\n",
      "Epoch 397/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9308 - val_loss: 1.4562\n",
      "Epoch 398/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.9335 - val_loss: 1.4512\n",
      "Epoch 399/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9327 - val_loss: 1.4503\n",
      "Epoch 400/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9341 - val_loss: 1.4580\n",
      "Epoch 401/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9412 - val_loss: 1.4481\n",
      "Epoch 402/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9225 - val_loss: 1.4505\n",
      "Epoch 403/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9172 - val_loss: 1.4553\n",
      "Epoch 404/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9271 - val_loss: 1.4558\n",
      "Epoch 405/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.9272 - val_loss: 1.4532\n",
      "Epoch 406/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9232 - val_loss: 1.4560\n",
      "Epoch 407/5000\n",
      "572/572 [==============================] - 0s 501us/step - loss: 0.9295 - val_loss: 1.4534\n",
      "Epoch 408/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9280 - val_loss: 1.4496\n",
      "Epoch 409/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9172 - val_loss: 1.4637\n",
      "Epoch 410/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.9185 - val_loss: 1.4608\n",
      "Epoch 411/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.9315 - val_loss: 1.4532\n",
      "Epoch 412/5000\n",
      "572/572 [==============================] - 0s 503us/step - loss: 0.9293 - val_loss: 1.4526\n",
      "Epoch 413/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9316 - val_loss: 1.4483\n",
      "Epoch 414/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9218 - val_loss: 1.4491\n",
      "Epoch 415/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9121 - val_loss: 1.4555\n",
      "Epoch 416/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9198 - val_loss: 1.4595\n",
      "Epoch 417/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9115 - val_loss: 1.4599\n",
      "Epoch 418/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9105 - val_loss: 1.4584\n",
      "Epoch 419/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9140 - val_loss: 1.4553\n",
      "Epoch 420/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9233 - val_loss: 1.4535\n",
      "Epoch 421/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9171 - val_loss: 1.4519\n",
      "Epoch 422/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.9156 - val_loss: 1.4536\n",
      "Epoch 423/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9185 - val_loss: 1.4629\n",
      "Epoch 424/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9196 - val_loss: 1.4615\n",
      "Epoch 425/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.9142 - val_loss: 1.4569\n",
      "Epoch 426/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9085 - val_loss: 1.4508\n",
      "Epoch 427/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9232 - val_loss: 1.4514\n",
      "Epoch 428/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9076 - val_loss: 1.4527\n",
      "Epoch 429/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9155 - val_loss: 1.4562\n",
      "Epoch 430/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8996 - val_loss: 1.4622\n",
      "Epoch 431/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.9140 - val_loss: 1.4555\n",
      "Epoch 432/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9279 - val_loss: 1.4525\n",
      "Epoch 433/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9139 - val_loss: 1.4555\n",
      "Epoch 434/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9124 - val_loss: 1.4588\n",
      "Epoch 435/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9088 - val_loss: 1.4617\n",
      "Epoch 436/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9082 - val_loss: 1.4519\n",
      "Epoch 437/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9124 - val_loss: 1.4478\n",
      "Epoch 438/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9127 - val_loss: 1.4542\n",
      "Epoch 439/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9082 - val_loss: 1.4486\n",
      "Epoch 440/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9128 - val_loss: 1.4477\n",
      "Epoch 441/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.9156 - val_loss: 1.4476\n",
      "Epoch 442/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9113 - val_loss: 1.4480\n",
      "Epoch 443/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9103 - val_loss: 1.4509\n",
      "Epoch 444/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9038 - val_loss: 1.4566\n",
      "Epoch 445/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9056 - val_loss: 1.4585\n",
      "Epoch 446/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9023 - val_loss: 1.4578\n",
      "Epoch 447/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.9092 - val_loss: 1.4596\n",
      "Epoch 448/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8986 - val_loss: 1.4622\n",
      "Epoch 449/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9090 - val_loss: 1.4585\n",
      "Epoch 450/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9139 - val_loss: 1.4619\n",
      "Epoch 451/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9197 - val_loss: 1.4491\n",
      "Epoch 452/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9093 - val_loss: 1.4538\n",
      "Epoch 453/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9098 - val_loss: 1.4538\n",
      "Epoch 454/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9037 - val_loss: 1.4629\n",
      "Epoch 455/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9078 - val_loss: 1.4595\n",
      "Epoch 456/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9086 - val_loss: 1.4617\n",
      "Epoch 457/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.9116 - val_loss: 1.4564\n",
      "Epoch 458/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9109 - val_loss: 1.4555\n",
      "Epoch 459/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8952 - val_loss: 1.4663\n",
      "Epoch 460/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9012 - val_loss: 1.4681\n",
      "Epoch 461/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9091 - val_loss: 1.4708\n",
      "Epoch 462/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9058 - val_loss: 1.4637\n",
      "Epoch 463/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 491us/step - loss: 0.8979 - val_loss: 1.4731\n",
      "Epoch 464/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8983 - val_loss: 1.4659\n",
      "Epoch 465/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9122 - val_loss: 1.4591\n",
      "Epoch 466/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9034 - val_loss: 1.4677\n",
      "Epoch 467/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9054 - val_loss: 1.4600\n",
      "Epoch 468/5000\n",
      "572/572 [==============================] - 0s 502us/step - loss: 0.8957 - val_loss: 1.4566\n",
      "Epoch 469/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9070 - val_loss: 1.4516\n",
      "Epoch 470/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8924 - val_loss: 1.4617\n",
      "Epoch 471/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8907 - val_loss: 1.4691\n",
      "Epoch 472/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8985 - val_loss: 1.4569\n",
      "Epoch 473/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.9115 - val_loss: 1.4567\n",
      "Epoch 474/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8983 - val_loss: 1.4540\n",
      "Epoch 475/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8997 - val_loss: 1.4583\n",
      "Epoch 476/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9007 - val_loss: 1.4569\n",
      "Epoch 477/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8990 - val_loss: 1.4615\n",
      "Epoch 478/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9038 - val_loss: 1.4529\n",
      "Epoch 479/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9086 - val_loss: 1.4513\n",
      "Epoch 480/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9059 - val_loss: 1.4560\n",
      "Epoch 481/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8994 - val_loss: 1.4594\n",
      "Epoch 482/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8931 - val_loss: 1.4593\n",
      "Epoch 483/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8943 - val_loss: 1.4528\n",
      "Epoch 484/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.9104 - val_loss: 1.4547\n",
      "Epoch 485/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9211 - val_loss: 1.4506\n",
      "Epoch 486/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8931 - val_loss: 1.4467\n",
      "Epoch 487/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.9047 - val_loss: 1.4514\n",
      "Epoch 488/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8920 - val_loss: 1.4571\n",
      "Epoch 489/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9055 - val_loss: 1.4668\n",
      "Epoch 490/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.9113 - val_loss: 1.4587\n",
      "Epoch 491/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9033 - val_loss: 1.4612\n",
      "Epoch 492/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9123 - val_loss: 1.4679\n",
      "Epoch 493/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9046 - val_loss: 1.4526\n",
      "Epoch 494/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8959 - val_loss: 1.4548\n",
      "Epoch 495/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9098 - val_loss: 1.4591\n",
      "Epoch 496/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.9137 - val_loss: 1.4483\n",
      "Epoch 497/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9049 - val_loss: 1.4457\n",
      "Epoch 498/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.9144 - val_loss: 1.4501\n",
      "Epoch 499/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.9034 - val_loss: 1.4464\n",
      "Epoch 500/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.9088 - val_loss: 1.4498\n",
      "Epoch 501/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8961 - val_loss: 1.4560\n",
      "Epoch 502/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8973 - val_loss: 1.4592\n",
      "Epoch 503/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8989 - val_loss: 1.4496\n",
      "Epoch 504/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8926 - val_loss: 1.4567\n",
      "Epoch 505/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8856 - val_loss: 1.4730\n",
      "Epoch 506/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8923 - val_loss: 1.4716\n",
      "Epoch 507/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8979 - val_loss: 1.4632\n",
      "Epoch 508/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8986 - val_loss: 1.4557\n",
      "Epoch 509/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8884 - val_loss: 1.4598\n",
      "Epoch 510/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9113 - val_loss: 1.4522\n",
      "Epoch 511/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8979 - val_loss: 1.4502\n",
      "Epoch 512/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8931 - val_loss: 1.4592\n",
      "Epoch 513/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.8843 - val_loss: 1.4632\n",
      "Epoch 514/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8894 - val_loss: 1.4612\n",
      "Epoch 515/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8945 - val_loss: 1.4575\n",
      "Epoch 516/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8975 - val_loss: 1.4555\n",
      "Epoch 517/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8856 - val_loss: 1.4564\n",
      "Epoch 518/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8972 - val_loss: 1.4585\n",
      "Epoch 519/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8947 - val_loss: 1.4581\n",
      "Epoch 520/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8863 - val_loss: 1.4532\n",
      "Epoch 521/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8854 - val_loss: 1.4598\n",
      "Epoch 522/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9030 - val_loss: 1.4549\n",
      "Epoch 523/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8924 - val_loss: 1.4471\n",
      "Epoch 524/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.8824 - val_loss: 1.4488\n",
      "Epoch 525/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8944 - val_loss: 1.4550\n",
      "Epoch 526/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.9018 - val_loss: 1.4536\n",
      "Epoch 527/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8939 - val_loss: 1.4496\n",
      "Epoch 528/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8907 - val_loss: 1.4473\n",
      "Epoch 529/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8959 - val_loss: 1.4499\n",
      "Epoch 530/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8901 - val_loss: 1.4599\n",
      "Epoch 531/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8840 - val_loss: 1.4664\n",
      "Epoch 532/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8851 - val_loss: 1.4608\n",
      "Epoch 533/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8886 - val_loss: 1.4616\n",
      "Epoch 534/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.9027 - val_loss: 1.4488\n",
      "Epoch 535/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8880 - val_loss: 1.4519\n",
      "Epoch 536/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8984 - val_loss: 1.4607\n",
      "Epoch 537/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8804 - val_loss: 1.4576\n",
      "Epoch 538/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8940 - val_loss: 1.4559\n",
      "Epoch 539/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8891 - val_loss: 1.4557\n",
      "Epoch 540/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8991 - val_loss: 1.4578\n",
      "Epoch 541/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8835 - val_loss: 1.4555\n",
      "Epoch 542/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8927 - val_loss: 1.4500\n",
      "Epoch 543/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8900 - val_loss: 1.4665\n",
      "Epoch 544/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8819 - val_loss: 1.4555\n",
      "Epoch 545/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8926 - val_loss: 1.4569\n",
      "Epoch 546/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8865 - val_loss: 1.4610\n",
      "Epoch 547/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8906 - val_loss: 1.4585\n",
      "Epoch 548/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8875 - val_loss: 1.4523\n",
      "Epoch 549/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8885 - val_loss: 1.4514\n",
      "Epoch 550/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8931 - val_loss: 1.4529\n",
      "Epoch 551/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.9029 - val_loss: 1.4505\n",
      "Epoch 552/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8784 - val_loss: 1.4516\n",
      "Epoch 553/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8816 - val_loss: 1.4521\n",
      "Epoch 554/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8757 - val_loss: 1.4557\n",
      "Epoch 555/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8753 - val_loss: 1.4593\n",
      "Epoch 556/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8870 - val_loss: 1.4544\n",
      "Epoch 557/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8878 - val_loss: 1.4463\n",
      "Epoch 558/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.9057 - val_loss: 1.4514\n",
      "Epoch 559/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8874 - val_loss: 1.4369\n",
      "Epoch 560/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8933 - val_loss: 1.4499\n",
      "Epoch 561/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8779 - val_loss: 1.4596\n",
      "Epoch 562/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8890 - val_loss: 1.4488\n",
      "Epoch 563/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8752 - val_loss: 1.4609\n",
      "Epoch 564/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8887 - val_loss: 1.4696\n",
      "Epoch 565/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8819 - val_loss: 1.4674\n",
      "Epoch 566/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8876 - val_loss: 1.4541\n",
      "Epoch 567/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8813 - val_loss: 1.4623\n",
      "Epoch 568/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8867 - val_loss: 1.4697\n",
      "Epoch 569/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8882 - val_loss: 1.4657\n",
      "Epoch 570/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8774 - val_loss: 1.4586\n",
      "Epoch 571/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8716 - val_loss: 1.4566\n",
      "Epoch 572/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8796 - val_loss: 1.4596\n",
      "Epoch 573/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8910 - val_loss: 1.4476\n",
      "Epoch 574/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8893 - val_loss: 1.4513\n",
      "Epoch 575/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8696 - val_loss: 1.4588\n",
      "Epoch 576/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8850 - val_loss: 1.4559\n",
      "Epoch 577/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8844 - val_loss: 1.4595\n",
      "Epoch 578/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8786 - val_loss: 1.4574\n",
      "Epoch 579/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8718 - val_loss: 1.4557\n",
      "Epoch 580/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8793 - val_loss: 1.4587\n",
      "Epoch 581/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8778 - val_loss: 1.4575\n",
      "Epoch 582/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8677 - val_loss: 1.4578\n",
      "Epoch 583/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8795 - val_loss: 1.4686\n",
      "Epoch 584/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8710 - val_loss: 1.4626\n",
      "Epoch 585/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8890 - val_loss: 1.4493\n",
      "Epoch 586/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8875 - val_loss: 1.4393\n",
      "Epoch 587/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8949 - val_loss: 1.4412\n",
      "Epoch 588/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8741 - val_loss: 1.4480\n",
      "Epoch 589/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8783 - val_loss: 1.4438\n",
      "Epoch 590/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8891 - val_loss: 1.4563\n",
      "Epoch 591/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8904 - val_loss: 1.4534\n",
      "Epoch 592/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8802 - val_loss: 1.4658\n",
      "Epoch 593/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8986 - val_loss: 1.4499\n",
      "Epoch 594/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8970 - val_loss: 1.4494\n",
      "Epoch 595/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8694 - val_loss: 1.4484\n",
      "Epoch 596/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8818 - val_loss: 1.4438\n",
      "Epoch 597/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8685 - val_loss: 1.4525\n",
      "Epoch 598/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8848 - val_loss: 1.4505\n",
      "Epoch 599/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8744 - val_loss: 1.4569\n",
      "Epoch 600/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8799 - val_loss: 1.4436\n",
      "Epoch 601/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8741 - val_loss: 1.4518\n",
      "Epoch 602/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8720 - val_loss: 1.4459\n",
      "Epoch 603/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8816 - val_loss: 1.4440\n",
      "Epoch 604/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8767 - val_loss: 1.4317\n",
      "Epoch 605/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8770 - val_loss: 1.4358\n",
      "Epoch 606/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8811 - val_loss: 1.4356\n",
      "Epoch 607/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8847 - val_loss: 1.4390\n",
      "Epoch 608/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8718 - val_loss: 1.4410\n",
      "Epoch 609/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8739 - val_loss: 1.4541\n",
      "Epoch 610/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8717 - val_loss: 1.4532\n",
      "Epoch 611/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8858 - val_loss: 1.4670\n",
      "Epoch 612/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8918 - val_loss: 1.4440\n",
      "Epoch 613/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8742 - val_loss: 1.4498\n",
      "Epoch 614/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8681 - val_loss: 1.4518\n",
      "Epoch 615/5000\n",
      "572/572 [==============================] - 0s 506us/step - loss: 0.8779 - val_loss: 1.4697\n",
      "Epoch 616/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8902 - val_loss: 1.4606\n",
      "Epoch 617/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 499us/step - loss: 0.8745 - val_loss: 1.4412\n",
      "Epoch 618/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.8843 - val_loss: 1.4511\n",
      "Epoch 619/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8665 - val_loss: 1.4487\n",
      "Epoch 620/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8848 - val_loss: 1.4390\n",
      "Epoch 621/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8674 - val_loss: 1.4413\n",
      "Epoch 622/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8757 - val_loss: 1.4412\n",
      "Epoch 623/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8842 - val_loss: 1.4431\n",
      "Epoch 624/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8854 - val_loss: 1.4459\n",
      "Epoch 625/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8927 - val_loss: 1.4368\n",
      "Epoch 626/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8712 - val_loss: 1.4492\n",
      "Epoch 627/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8785 - val_loss: 1.4391\n",
      "Epoch 628/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8873 - val_loss: 1.4430\n",
      "Epoch 629/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8793 - val_loss: 1.4484\n",
      "Epoch 630/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.8682 - val_loss: 1.4428\n",
      "Epoch 631/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8693 - val_loss: 1.4443\n",
      "Epoch 632/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8830 - val_loss: 1.4419\n",
      "Epoch 633/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8684 - val_loss: 1.4436\n",
      "Epoch 634/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8785 - val_loss: 1.4375\n",
      "Epoch 635/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8820 - val_loss: 1.4416\n",
      "Epoch 636/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8807 - val_loss: 1.4472\n",
      "Epoch 637/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8672 - val_loss: 1.4505\n",
      "Epoch 638/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8638 - val_loss: 1.4578\n",
      "Epoch 639/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8734 - val_loss: 1.4417\n",
      "Epoch 640/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8745 - val_loss: 1.4495\n",
      "Epoch 641/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8856 - val_loss: 1.4474\n",
      "Epoch 642/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8761 - val_loss: 1.4515\n",
      "Epoch 643/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8743 - val_loss: 1.4432\n",
      "Epoch 644/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8751 - val_loss: 1.4413\n",
      "Epoch 645/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8783 - val_loss: 1.4380\n",
      "Epoch 646/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8668 - val_loss: 1.4524\n",
      "Epoch 647/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8764 - val_loss: 1.4415\n",
      "Epoch 648/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8671 - val_loss: 1.4385\n",
      "Epoch 649/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8647 - val_loss: 1.4428\n",
      "Epoch 650/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8739 - val_loss: 1.4562\n",
      "Epoch 651/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8693 - val_loss: 1.4588\n",
      "Epoch 652/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8741 - val_loss: 1.4600\n",
      "Epoch 653/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8741 - val_loss: 1.4503\n",
      "Epoch 654/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8791 - val_loss: 1.4362\n",
      "Epoch 655/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8676 - val_loss: 1.4384\n",
      "Epoch 656/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8621 - val_loss: 1.4406\n",
      "Epoch 657/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8726 - val_loss: 1.4417\n",
      "Epoch 658/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8651 - val_loss: 1.4474\n",
      "Epoch 659/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8666 - val_loss: 1.4405\n",
      "Epoch 660/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8760 - val_loss: 1.4387\n",
      "Epoch 661/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8679 - val_loss: 1.4456\n",
      "Epoch 662/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8752 - val_loss: 1.4577\n",
      "Epoch 663/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8786 - val_loss: 1.4541\n",
      "Epoch 664/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8811 - val_loss: 1.4457\n",
      "Epoch 665/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8749 - val_loss: 1.4439\n",
      "Epoch 666/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8661 - val_loss: 1.4465\n",
      "Epoch 667/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8546 - val_loss: 1.4515\n",
      "Epoch 668/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8789 - val_loss: 1.4536\n",
      "Epoch 669/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8751 - val_loss: 1.4530\n",
      "Epoch 670/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8690 - val_loss: 1.4546\n",
      "Epoch 671/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8685 - val_loss: 1.4517\n",
      "Epoch 672/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8535 - val_loss: 1.4514\n",
      "Epoch 673/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8537 - val_loss: 1.4596\n",
      "Epoch 674/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8790 - val_loss: 1.4479\n",
      "Epoch 675/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8620 - val_loss: 1.4511\n",
      "Epoch 676/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8686 - val_loss: 1.4443\n",
      "Epoch 677/5000\n",
      "572/572 [==============================] - 0s 502us/step - loss: 0.8804 - val_loss: 1.4422\n",
      "Epoch 678/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8628 - val_loss: 1.4448\n",
      "Epoch 679/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8741 - val_loss: 1.4425\n",
      "Epoch 680/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8901 - val_loss: 1.4449\n",
      "Epoch 681/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8722 - val_loss: 1.4409\n",
      "Epoch 682/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8622 - val_loss: 1.4367\n",
      "Epoch 683/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8710 - val_loss: 1.4375\n",
      "Epoch 684/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8653 - val_loss: 1.4330\n",
      "Epoch 685/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8623 - val_loss: 1.4365\n",
      "Epoch 686/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8668 - val_loss: 1.4425\n",
      "Epoch 687/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8653 - val_loss: 1.4423\n",
      "Epoch 688/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8763 - val_loss: 1.4496\n",
      "Epoch 689/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8772 - val_loss: 1.4464\n",
      "Epoch 690/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8630 - val_loss: 1.4333\n",
      "Epoch 691/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8604 - val_loss: 1.4390\n",
      "Epoch 692/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8483 - val_loss: 1.4406\n",
      "Epoch 693/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8777 - val_loss: 1.4323\n",
      "Epoch 694/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8632 - val_loss: 1.4352\n",
      "Epoch 695/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8530 - val_loss: 1.4468\n",
      "Epoch 696/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8646 - val_loss: 1.4609\n",
      "Epoch 697/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8614 - val_loss: 1.4555\n",
      "Epoch 698/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8754 - val_loss: 1.4630\n",
      "Epoch 699/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8627 - val_loss: 1.4598\n",
      "Epoch 700/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8638 - val_loss: 1.4568\n",
      "Epoch 701/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8570 - val_loss: 1.4475\n",
      "Epoch 702/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8537 - val_loss: 1.4553\n",
      "Epoch 703/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8722 - val_loss: 1.4433\n",
      "Epoch 704/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8660 - val_loss: 1.4334\n",
      "Epoch 705/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8553 - val_loss: 1.4451\n",
      "Epoch 706/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8670 - val_loss: 1.4424\n",
      "Epoch 707/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8626 - val_loss: 1.4644\n",
      "Epoch 708/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8649 - val_loss: 1.4480\n",
      "Epoch 709/5000\n",
      "572/572 [==============================] - 0s 501us/step - loss: 0.8609 - val_loss: 1.4440\n",
      "Epoch 710/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8641 - val_loss: 1.4444\n",
      "Epoch 711/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8669 - val_loss: 1.4517\n",
      "Epoch 712/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8656 - val_loss: 1.4434\n",
      "Epoch 713/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8475 - val_loss: 1.4382\n",
      "Epoch 714/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8639 - val_loss: 1.4411\n",
      "Epoch 715/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8561 - val_loss: 1.4327\n",
      "Epoch 716/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8559 - val_loss: 1.4380\n",
      "Epoch 717/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8541 - val_loss: 1.4393\n",
      "Epoch 718/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8710 - val_loss: 1.4522\n",
      "Epoch 719/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8503 - val_loss: 1.4462\n",
      "Epoch 720/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8657 - val_loss: 1.4401\n",
      "Epoch 721/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8533 - val_loss: 1.4469\n",
      "Epoch 722/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8580 - val_loss: 1.4511\n",
      "Epoch 723/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8466 - val_loss: 1.4364\n",
      "Epoch 724/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8629 - val_loss: 1.4316\n",
      "Epoch 725/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8739 - val_loss: 1.4307\n",
      "Epoch 726/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8598 - val_loss: 1.4307\n",
      "Epoch 727/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8647 - val_loss: 1.4368\n",
      "Epoch 728/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8619 - val_loss: 1.4416\n",
      "Epoch 729/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8602 - val_loss: 1.4377\n",
      "Epoch 730/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8715 - val_loss: 1.4376\n",
      "Epoch 731/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8875 - val_loss: 1.4414\n",
      "Epoch 732/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8579 - val_loss: 1.4423\n",
      "Epoch 733/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8590 - val_loss: 1.4368\n",
      "Epoch 734/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8493 - val_loss: 1.4283\n",
      "Epoch 735/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8520 - val_loss: 1.4345\n",
      "Epoch 736/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8709 - val_loss: 1.4404\n",
      "Epoch 737/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8711 - val_loss: 1.4339\n",
      "Epoch 738/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8616 - val_loss: 1.4412\n",
      "Epoch 739/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8573 - val_loss: 1.4437\n",
      "Epoch 740/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8601 - val_loss: 1.4441\n",
      "Epoch 741/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8516 - val_loss: 1.4428\n",
      "Epoch 742/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8486 - val_loss: 1.4461\n",
      "Epoch 743/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8667 - val_loss: 1.4283\n",
      "Epoch 744/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8638 - val_loss: 1.4336\n",
      "Epoch 745/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8682 - val_loss: 1.4259\n",
      "Epoch 746/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8535 - val_loss: 1.4578\n",
      "Epoch 747/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8617 - val_loss: 1.4474\n",
      "Epoch 748/5000\n",
      "572/572 [==============================] - 0s 504us/step - loss: 0.8568 - val_loss: 1.4302\n",
      "Epoch 749/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8723 - val_loss: 1.4206\n",
      "Epoch 750/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8560 - val_loss: 1.4227\n",
      "Epoch 751/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8595 - val_loss: 1.4312\n",
      "Epoch 752/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8725 - val_loss: 1.4399\n",
      "Epoch 753/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8723 - val_loss: 1.4380\n",
      "Epoch 754/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8529 - val_loss: 1.4293\n",
      "Epoch 755/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8539 - val_loss: 1.4338\n",
      "Epoch 756/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8674 - val_loss: 1.4592\n",
      "Epoch 757/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8532 - val_loss: 1.4497\n",
      "Epoch 758/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8606 - val_loss: 1.4441\n",
      "Epoch 759/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8645 - val_loss: 1.4370\n",
      "Epoch 760/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8545 - val_loss: 1.4321\n",
      "Epoch 761/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8505 - val_loss: 1.4338\n",
      "Epoch 762/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8525 - val_loss: 1.4317\n",
      "Epoch 763/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8630 - val_loss: 1.4490\n",
      "Epoch 764/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8542 - val_loss: 1.4442\n",
      "Epoch 765/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8382 - val_loss: 1.4479\n",
      "Epoch 766/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8687 - val_loss: 1.4247\n",
      "Epoch 767/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8561 - val_loss: 1.4333\n",
      "Epoch 768/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8755 - val_loss: 1.4214\n",
      "Epoch 769/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8576 - val_loss: 1.4280\n",
      "Epoch 770/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8631 - val_loss: 1.4291\n",
      "Epoch 771/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 494us/step - loss: 0.8616 - val_loss: 1.4161\n",
      "Epoch 772/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8530 - val_loss: 1.4316\n",
      "Epoch 773/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8630 - val_loss: 1.4194\n",
      "Epoch 774/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8574 - val_loss: 1.4219\n",
      "Epoch 775/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8450 - val_loss: 1.4233\n",
      "Epoch 776/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8630 - val_loss: 1.4352\n",
      "Epoch 777/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8617 - val_loss: 1.4179\n",
      "Epoch 778/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8745 - val_loss: 1.4249\n",
      "Epoch 779/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8591 - val_loss: 1.4224\n",
      "Epoch 780/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8636 - val_loss: 1.4274\n",
      "Epoch 781/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8482 - val_loss: 1.4230\n",
      "Epoch 782/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8558 - val_loss: 1.4513\n",
      "Epoch 783/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8640 - val_loss: 1.4378\n",
      "Epoch 784/5000\n",
      "572/572 [==============================] - 0s 536us/step - loss: 0.8639 - val_loss: 1.4304\n",
      "Epoch 785/5000\n",
      "572/572 [==============================] - 0s 570us/step - loss: 0.8475 - val_loss: 1.4316\n",
      "Epoch 786/5000\n",
      "572/572 [==============================] - 0s 567us/step - loss: 0.8516 - val_loss: 1.4239\n",
      "Epoch 787/5000\n",
      "572/572 [==============================] - 0s 572us/step - loss: 0.8538 - val_loss: 1.4288\n",
      "Epoch 788/5000\n",
      "572/572 [==============================] - 0s 562us/step - loss: 0.8559 - val_loss: 1.4238\n",
      "Epoch 789/5000\n",
      "572/572 [==============================] - 0s 560us/step - loss: 0.8575 - val_loss: 1.4224\n",
      "Epoch 790/5000\n",
      "572/572 [==============================] - 0s 575us/step - loss: 0.8608 - val_loss: 1.4233\n",
      "Epoch 791/5000\n",
      "572/572 [==============================] - 0s 582us/step - loss: 0.8667 - val_loss: 1.4226\n",
      "Epoch 792/5000\n",
      "572/572 [==============================] - 0s 560us/step - loss: 0.8561 - val_loss: 1.4175\n",
      "Epoch 793/5000\n",
      "572/572 [==============================] - 0s 550us/step - loss: 0.8527 - val_loss: 1.4245\n",
      "Epoch 794/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8693 - val_loss: 1.4264\n",
      "Epoch 795/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8652 - val_loss: 1.4269\n",
      "Epoch 796/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8677 - val_loss: 1.4083\n",
      "Epoch 797/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8671 - val_loss: 1.4262\n",
      "Epoch 798/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8713 - val_loss: 1.4149\n",
      "Epoch 799/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8567 - val_loss: 1.4064\n",
      "Epoch 800/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8514 - val_loss: 1.4176\n",
      "Epoch 801/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8512 - val_loss: 1.4239\n",
      "Epoch 802/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8525 - val_loss: 1.4155\n",
      "Epoch 803/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8518 - val_loss: 1.4144\n",
      "Epoch 804/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8476 - val_loss: 1.4175\n",
      "Epoch 805/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8653 - val_loss: 1.4223\n",
      "Epoch 806/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8545 - val_loss: 1.4167\n",
      "Epoch 807/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8480 - val_loss: 1.4398\n",
      "Epoch 808/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8493 - val_loss: 1.4420\n",
      "Epoch 809/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8445 - val_loss: 1.4356\n",
      "Epoch 810/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8450 - val_loss: 1.4254\n",
      "Epoch 811/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8588 - val_loss: 1.4335\n",
      "Epoch 812/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8530 - val_loss: 1.4241\n",
      "Epoch 813/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8408 - val_loss: 1.4342\n",
      "Epoch 814/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8680 - val_loss: 1.4277\n",
      "Epoch 815/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8570 - val_loss: 1.4186\n",
      "Epoch 816/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8664 - val_loss: 1.4263\n",
      "Epoch 817/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8520 - val_loss: 1.4098\n",
      "Epoch 818/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8471 - val_loss: 1.4056\n",
      "Epoch 819/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8518 - val_loss: 1.4121\n",
      "Epoch 820/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8540 - val_loss: 1.4245\n",
      "Epoch 821/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8424 - val_loss: 1.4213\n",
      "Epoch 822/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8557 - val_loss: 1.4181\n",
      "Epoch 823/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8586 - val_loss: 1.4262\n",
      "Epoch 824/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8451 - val_loss: 1.4159\n",
      "Epoch 825/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8549 - val_loss: 1.4044\n",
      "Epoch 826/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8434 - val_loss: 1.4207\n",
      "Epoch 827/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8685 - val_loss: 1.4270\n",
      "Epoch 828/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8458 - val_loss: 1.4116\n",
      "Epoch 829/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8595 - val_loss: 1.4130\n",
      "Epoch 830/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8414 - val_loss: 1.4138\n",
      "Epoch 831/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8511 - val_loss: 1.4119\n",
      "Epoch 832/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8440 - val_loss: 1.4190\n",
      "Epoch 833/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8576 - val_loss: 1.4270\n",
      "Epoch 834/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8609 - val_loss: 1.4163\n",
      "Epoch 835/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8434 - val_loss: 1.4132\n",
      "Epoch 836/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8655 - val_loss: 1.4112\n",
      "Epoch 837/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8653 - val_loss: 1.4077\n",
      "Epoch 838/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8556 - val_loss: 1.4155\n",
      "Epoch 839/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8548 - val_loss: 1.4124\n",
      "Epoch 840/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8548 - val_loss: 1.4115\n",
      "Epoch 841/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8513 - val_loss: 1.4112\n",
      "Epoch 842/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8436 - val_loss: 1.4199\n",
      "Epoch 843/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8516 - val_loss: 1.4223\n",
      "Epoch 844/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8478 - val_loss: 1.4220\n",
      "Epoch 845/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8527 - val_loss: 1.4354\n",
      "Epoch 846/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8468 - val_loss: 1.4326\n",
      "Epoch 847/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8595 - val_loss: 1.4280\n",
      "Epoch 848/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8676 - val_loss: 1.4351\n",
      "Epoch 849/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8496 - val_loss: 1.4262\n",
      "Epoch 850/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8523 - val_loss: 1.4246\n",
      "Epoch 851/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8594 - val_loss: 1.4208\n",
      "Epoch 852/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8558 - val_loss: 1.4249\n",
      "Epoch 853/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8525 - val_loss: 1.4177\n",
      "Epoch 854/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8438 - val_loss: 1.4287\n",
      "Epoch 855/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8348 - val_loss: 1.4291\n",
      "Epoch 856/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8467 - val_loss: 1.4245\n",
      "Epoch 857/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8369 - val_loss: 1.4164\n",
      "Epoch 858/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8371 - val_loss: 1.4314\n",
      "Epoch 859/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8561 - val_loss: 1.4349\n",
      "Epoch 860/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8607 - val_loss: 1.4150\n",
      "Epoch 861/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8513 - val_loss: 1.4180\n",
      "Epoch 862/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8390 - val_loss: 1.4135\n",
      "Epoch 863/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8434 - val_loss: 1.4264\n",
      "Epoch 864/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8621 - val_loss: 1.4160\n",
      "Epoch 865/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8506 - val_loss: 1.4194\n",
      "Epoch 866/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8386 - val_loss: 1.4082\n",
      "Epoch 867/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8567 - val_loss: 1.4029\n",
      "Epoch 868/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8664 - val_loss: 1.4003\n",
      "Epoch 869/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8567 - val_loss: 1.4091\n",
      "Epoch 870/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8494 - val_loss: 1.4140\n",
      "Epoch 871/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8469 - val_loss: 1.4219\n",
      "Epoch 872/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8484 - val_loss: 1.4215\n",
      "Epoch 873/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8405 - val_loss: 1.4214\n",
      "Epoch 874/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8491 - val_loss: 1.4174\n",
      "Epoch 875/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8529 - val_loss: 1.4237\n",
      "Epoch 876/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8440 - val_loss: 1.4233\n",
      "Epoch 877/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8380 - val_loss: 1.4065\n",
      "Epoch 878/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8590 - val_loss: 1.4065\n",
      "Epoch 879/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8457 - val_loss: 1.4175\n",
      "Epoch 880/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8545 - val_loss: 1.4128\n",
      "Epoch 881/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8397 - val_loss: 1.4308\n",
      "Epoch 882/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8338 - val_loss: 1.4254\n",
      "Epoch 883/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8646 - val_loss: 1.4166\n",
      "Epoch 884/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8371 - val_loss: 1.4237\n",
      "Epoch 885/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8428 - val_loss: 1.4202\n",
      "Epoch 886/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8474 - val_loss: 1.4097\n",
      "Epoch 887/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8549 - val_loss: 1.4125\n",
      "Epoch 888/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8486 - val_loss: 1.4065\n",
      "Epoch 889/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.8427 - val_loss: 1.4142\n",
      "Epoch 890/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8427 - val_loss: 1.4141\n",
      "Epoch 891/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8479 - val_loss: 1.4053\n",
      "Epoch 892/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8500 - val_loss: 1.4112\n",
      "Epoch 893/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8528 - val_loss: 1.4126\n",
      "Epoch 894/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8375 - val_loss: 1.4120\n",
      "Epoch 895/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8407 - val_loss: 1.4107\n",
      "Epoch 896/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8447 - val_loss: 1.4124\n",
      "Epoch 897/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8349 - val_loss: 1.4139\n",
      "Epoch 898/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8411 - val_loss: 1.4122\n",
      "Epoch 899/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8449 - val_loss: 1.4265\n",
      "Epoch 900/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8497 - val_loss: 1.4203\n",
      "Epoch 901/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8577 - val_loss: 1.4182\n",
      "Epoch 902/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8406 - val_loss: 1.4128\n",
      "Epoch 903/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8532 - val_loss: 1.4109\n",
      "Epoch 904/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8440 - val_loss: 1.4185\n",
      "Epoch 905/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8333 - val_loss: 1.4174\n",
      "Epoch 906/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8360 - val_loss: 1.4286\n",
      "Epoch 907/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8473 - val_loss: 1.4279\n",
      "Epoch 908/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8520 - val_loss: 1.4222\n",
      "Epoch 909/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8440 - val_loss: 1.4208\n",
      "Epoch 910/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8507 - val_loss: 1.4180\n",
      "Epoch 911/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8463 - val_loss: 1.4079\n",
      "Epoch 912/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8388 - val_loss: 1.4059\n",
      "Epoch 913/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8462 - val_loss: 1.4146\n",
      "Epoch 914/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8390 - val_loss: 1.4066\n",
      "Epoch 915/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8452 - val_loss: 1.4071\n",
      "Epoch 916/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8601 - val_loss: 1.4005\n",
      "Epoch 917/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8348 - val_loss: 1.3983\n",
      "Epoch 918/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8365 - val_loss: 1.4094\n",
      "Epoch 919/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8456 - val_loss: 1.4217\n",
      "Epoch 920/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8473 - val_loss: 1.3983\n",
      "Epoch 921/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8344 - val_loss: 1.4170\n",
      "Epoch 922/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8318 - val_loss: 1.4053\n",
      "Epoch 923/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8542 - val_loss: 1.4019\n",
      "Epoch 924/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8401 - val_loss: 1.4077\n",
      "Epoch 925/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 490us/step - loss: 0.8367 - val_loss: 1.4117\n",
      "Epoch 926/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8490 - val_loss: 1.4085\n",
      "Epoch 927/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8390 - val_loss: 1.4103\n",
      "Epoch 928/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8471 - val_loss: 1.4151\n",
      "Epoch 929/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8398 - val_loss: 1.4149\n",
      "Epoch 930/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8326 - val_loss: 1.4139\n",
      "Epoch 931/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8290 - val_loss: 1.4154\n",
      "Epoch 932/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8307 - val_loss: 1.4257\n",
      "Epoch 933/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8353 - val_loss: 1.4238\n",
      "Epoch 934/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8447 - val_loss: 1.4296\n",
      "Epoch 935/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8390 - val_loss: 1.4321\n",
      "Epoch 936/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8476 - val_loss: 1.4303\n",
      "Epoch 937/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8336 - val_loss: 1.4337\n",
      "Epoch 938/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8484 - val_loss: 1.4075\n",
      "Epoch 939/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8426 - val_loss: 1.4076\n",
      "Epoch 940/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8406 - val_loss: 1.4077\n",
      "Epoch 941/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8569 - val_loss: 1.4133\n",
      "Epoch 942/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8395 - val_loss: 1.4196\n",
      "Epoch 943/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8544 - val_loss: 1.4063\n",
      "Epoch 944/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8523 - val_loss: 1.3960\n",
      "Epoch 945/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8395 - val_loss: 1.3909\n",
      "Epoch 946/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8307 - val_loss: 1.3978\n",
      "Epoch 947/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8417 - val_loss: 1.3963\n",
      "Epoch 948/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8287 - val_loss: 1.4144\n",
      "Epoch 949/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8511 - val_loss: 1.4065\n",
      "Epoch 950/5000\n",
      "572/572 [==============================] - 0s 509us/step - loss: 0.8394 - val_loss: 1.4130\n",
      "Epoch 951/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8478 - val_loss: 1.4162\n",
      "Epoch 952/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8434 - val_loss: 1.4117\n",
      "Epoch 953/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8469 - val_loss: 1.4094\n",
      "Epoch 954/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8356 - val_loss: 1.4099\n",
      "Epoch 955/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8469 - val_loss: 1.4145\n",
      "Epoch 956/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8532 - val_loss: 1.4093\n",
      "Epoch 957/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8474 - val_loss: 1.4228\n",
      "Epoch 958/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8451 - val_loss: 1.4010\n",
      "Epoch 959/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8436 - val_loss: 1.3969\n",
      "Epoch 960/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8499 - val_loss: 1.3987\n",
      "Epoch 961/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8299 - val_loss: 1.3998\n",
      "Epoch 962/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8301 - val_loss: 1.4149\n",
      "Epoch 963/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.8422 - val_loss: 1.4138\n",
      "Epoch 964/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8411 - val_loss: 1.4186\n",
      "Epoch 965/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8361 - val_loss: 1.4179\n",
      "Epoch 966/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8539 - val_loss: 1.4197\n",
      "Epoch 967/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8589 - val_loss: 1.4248\n",
      "Epoch 968/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8314 - val_loss: 1.4028\n",
      "Epoch 969/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8336 - val_loss: 1.4102\n",
      "Epoch 970/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8404 - val_loss: 1.4112\n",
      "Epoch 971/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8402 - val_loss: 1.4075\n",
      "Epoch 972/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8495 - val_loss: 1.4148\n",
      "Epoch 973/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8393 - val_loss: 1.4090\n",
      "Epoch 974/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8389 - val_loss: 1.4203\n",
      "Epoch 975/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8498 - val_loss: 1.4098\n",
      "Epoch 976/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8442 - val_loss: 1.4100\n",
      "Epoch 977/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8427 - val_loss: 1.4242\n",
      "Epoch 978/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8508 - val_loss: 1.4120\n",
      "Epoch 979/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8374 - val_loss: 1.4164\n",
      "Epoch 980/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.8426 - val_loss: 1.4146\n",
      "Epoch 981/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8344 - val_loss: 1.4263\n",
      "Epoch 982/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8304 - val_loss: 1.4212\n",
      "Epoch 983/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8416 - val_loss: 1.4304\n",
      "Epoch 984/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8295 - val_loss: 1.4225\n",
      "Epoch 985/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8328 - val_loss: 1.4164\n",
      "Epoch 986/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8590 - val_loss: 1.4070\n",
      "Epoch 987/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8417 - val_loss: 1.4040\n",
      "Epoch 988/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8387 - val_loss: 1.4040\n",
      "Epoch 989/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8430 - val_loss: 1.4079\n",
      "Epoch 990/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8391 - val_loss: 1.4151\n",
      "Epoch 991/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8515 - val_loss: 1.4088\n",
      "Epoch 992/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8443 - val_loss: 1.3942\n",
      "Epoch 993/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8348 - val_loss: 1.4049\n",
      "Epoch 994/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8416 - val_loss: 1.4035\n",
      "Epoch 995/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8427 - val_loss: 1.3992\n",
      "Epoch 996/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8398 - val_loss: 1.4139\n",
      "Epoch 997/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8380 - val_loss: 1.4068\n",
      "Epoch 998/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8426 - val_loss: 1.4131\n",
      "Epoch 999/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8429 - val_loss: 1.3996\n",
      "Epoch 1000/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8375 - val_loss: 1.4241\n",
      "Epoch 1001/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8424 - val_loss: 1.4103\n",
      "Epoch 1002/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8360 - val_loss: 1.4053\n",
      "Epoch 1003/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8288 - val_loss: 1.4062\n",
      "Epoch 1004/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8351 - val_loss: 1.3992\n",
      "Epoch 1005/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8370 - val_loss: 1.4158\n",
      "Epoch 1006/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8376 - val_loss: 1.4159\n",
      "Epoch 1007/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8525 - val_loss: 1.4234\n",
      "Epoch 1008/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8409 - val_loss: 1.4213\n",
      "Epoch 1009/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8343 - val_loss: 1.4003\n",
      "Epoch 1010/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8296 - val_loss: 1.4200\n",
      "Epoch 1011/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8322 - val_loss: 1.4113\n",
      "Epoch 1012/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8334 - val_loss: 1.3990\n",
      "Epoch 1013/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8250 - val_loss: 1.3976\n",
      "Epoch 1014/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8460 - val_loss: 1.3956\n",
      "Epoch 1015/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8289 - val_loss: 1.4036\n",
      "Epoch 1016/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8303 - val_loss: 1.3995\n",
      "Epoch 1017/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8255 - val_loss: 1.4229\n",
      "Epoch 1018/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8482 - val_loss: 1.4155\n",
      "Epoch 1019/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8315 - val_loss: 1.4127\n",
      "Epoch 1020/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8399 - val_loss: 1.4109\n",
      "Epoch 1021/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8292 - val_loss: 1.4087\n",
      "Epoch 1022/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8553 - val_loss: 1.4011\n",
      "Epoch 1023/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.8493 - val_loss: 1.3946\n",
      "Epoch 1024/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8446 - val_loss: 1.4091\n",
      "Epoch 1025/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8347 - val_loss: 1.4079\n",
      "Epoch 1026/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8314 - val_loss: 1.3998\n",
      "Epoch 1027/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8347 - val_loss: 1.4089\n",
      "Epoch 1028/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8337 - val_loss: 1.4087\n",
      "Epoch 1029/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8487 - val_loss: 1.4117\n",
      "Epoch 1030/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8383 - val_loss: 1.4011\n",
      "Epoch 1031/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8456 - val_loss: 1.3949\n",
      "Epoch 1032/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8253 - val_loss: 1.3989\n",
      "Epoch 1033/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8315 - val_loss: 1.3963\n",
      "Epoch 1034/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8263 - val_loss: 1.3907\n",
      "Epoch 1035/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8423 - val_loss: 1.3995\n",
      "Epoch 1036/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8434 - val_loss: 1.4011\n",
      "Epoch 1037/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8335 - val_loss: 1.3934\n",
      "Epoch 1038/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8311 - val_loss: 1.4218\n",
      "Epoch 1039/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8398 - val_loss: 1.4117\n",
      "Epoch 1040/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8348 - val_loss: 1.4056\n",
      "Epoch 1041/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8469 - val_loss: 1.4008\n",
      "Epoch 1042/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8311 - val_loss: 1.3945\n",
      "Epoch 1043/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8400 - val_loss: 1.4008\n",
      "Epoch 1044/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8414 - val_loss: 1.3994\n",
      "Epoch 1045/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8247 - val_loss: 1.3967\n",
      "Epoch 1046/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8409 - val_loss: 1.4034\n",
      "Epoch 1047/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8371 - val_loss: 1.4100\n",
      "Epoch 1048/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8371 - val_loss: 1.3934\n",
      "Epoch 1049/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8412 - val_loss: 1.4051\n",
      "Epoch 1050/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8368 - val_loss: 1.4195\n",
      "Epoch 1051/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8260 - val_loss: 1.4145\n",
      "Epoch 1052/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8323 - val_loss: 1.4085\n",
      "Epoch 1053/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8272 - val_loss: 1.4047\n",
      "Epoch 1054/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8338 - val_loss: 1.4240\n",
      "Epoch 1055/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8316 - val_loss: 1.4134\n",
      "Epoch 1056/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8324 - val_loss: 1.4104\n",
      "Epoch 1057/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8271 - val_loss: 1.4083\n",
      "Epoch 1058/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8572 - val_loss: 1.3961\n",
      "Epoch 1059/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8347 - val_loss: 1.3934\n",
      "Epoch 1060/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8294 - val_loss: 1.3945\n",
      "Epoch 1061/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8350 - val_loss: 1.4037\n",
      "Epoch 1062/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8323 - val_loss: 1.3866\n",
      "Epoch 1063/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8176 - val_loss: 1.4088\n",
      "Epoch 1064/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8265 - val_loss: 1.4109\n",
      "Epoch 1065/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8236 - val_loss: 1.4167\n",
      "Epoch 1066/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8305 - val_loss: 1.4091\n",
      "Epoch 1067/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.8492 - val_loss: 1.3986\n",
      "Epoch 1068/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8260 - val_loss: 1.4085\n",
      "Epoch 1069/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8294 - val_loss: 1.3946\n",
      "Epoch 1070/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8400 - val_loss: 1.3957\n",
      "Epoch 1071/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8562 - val_loss: 1.3895\n",
      "Epoch 1072/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8424 - val_loss: 1.3869\n",
      "Epoch 1073/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8429 - val_loss: 1.3834\n",
      "Epoch 1074/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8391 - val_loss: 1.3929\n",
      "Epoch 1075/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8281 - val_loss: 1.4047\n",
      "Epoch 1076/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8341 - val_loss: 1.4047\n",
      "Epoch 1077/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8426 - val_loss: 1.3990\n",
      "Epoch 1078/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 492us/step - loss: 0.8387 - val_loss: 1.4043\n",
      "Epoch 1079/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8371 - val_loss: 1.4166\n",
      "Epoch 1080/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8271 - val_loss: 1.4089\n",
      "Epoch 1081/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8361 - val_loss: 1.3961\n",
      "Epoch 1082/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8191 - val_loss: 1.3986\n",
      "Epoch 1083/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8444 - val_loss: 1.4074\n",
      "Epoch 1084/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8461 - val_loss: 1.4030\n",
      "Epoch 1085/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8254 - val_loss: 1.4085\n",
      "Epoch 1086/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8276 - val_loss: 1.4031\n",
      "Epoch 1087/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8392 - val_loss: 1.3886\n",
      "Epoch 1088/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8260 - val_loss: 1.3952\n",
      "Epoch 1089/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8297 - val_loss: 1.4008\n",
      "Epoch 1090/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8349 - val_loss: 1.4060\n",
      "Epoch 1091/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8622 - val_loss: 1.4060\n",
      "Epoch 1092/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8168 - val_loss: 1.4064\n",
      "Epoch 1093/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8316 - val_loss: 1.4080\n",
      "Epoch 1094/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8326 - val_loss: 1.3993\n",
      "Epoch 1095/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8185 - val_loss: 1.3995\n",
      "Epoch 1096/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8363 - val_loss: 1.3925\n",
      "Epoch 1097/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8321 - val_loss: 1.3878\n",
      "Epoch 1098/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8258 - val_loss: 1.4004\n",
      "Epoch 1099/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8362 - val_loss: 1.3952\n",
      "Epoch 1100/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8370 - val_loss: 1.4119\n",
      "Epoch 1101/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8153 - val_loss: 1.4130\n",
      "Epoch 1102/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8294 - val_loss: 1.4013\n",
      "Epoch 1103/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8280 - val_loss: 1.4021\n",
      "Epoch 1104/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8408 - val_loss: 1.4037\n",
      "Epoch 1105/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8148 - val_loss: 1.3999\n",
      "Epoch 1106/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8275 - val_loss: 1.4092\n",
      "Epoch 1107/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8427 - val_loss: 1.4094\n",
      "Epoch 1108/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8455 - val_loss: 1.3928\n",
      "Epoch 1109/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8219 - val_loss: 1.3989\n",
      "Epoch 1110/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8489 - val_loss: 1.4052\n",
      "Epoch 1111/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8337 - val_loss: 1.4054\n",
      "Epoch 1112/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8293 - val_loss: 1.4030\n",
      "Epoch 1113/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8360 - val_loss: 1.3884\n",
      "Epoch 1114/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8481 - val_loss: 1.3998\n",
      "Epoch 1115/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8375 - val_loss: 1.3866\n",
      "Epoch 1116/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8207 - val_loss: 1.3919\n",
      "Epoch 1117/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8436 - val_loss: 1.4135\n",
      "Epoch 1118/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8375 - val_loss: 1.3969\n",
      "Epoch 1119/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8328 - val_loss: 1.3942\n",
      "Epoch 1120/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8284 - val_loss: 1.3943\n",
      "Epoch 1121/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8246 - val_loss: 1.3991\n",
      "Epoch 1122/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8196 - val_loss: 1.4046\n",
      "Epoch 1123/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8287 - val_loss: 1.4087\n",
      "Epoch 1124/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8435 - val_loss: 1.4135\n",
      "Epoch 1125/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8287 - val_loss: 1.4106\n",
      "Epoch 1126/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8355 - val_loss: 1.4137\n",
      "Epoch 1127/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8347 - val_loss: 1.3904\n",
      "Epoch 1128/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8258 - val_loss: 1.3988\n",
      "Epoch 1129/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8395 - val_loss: 1.3979\n",
      "Epoch 1130/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8120 - val_loss: 1.3962\n",
      "Epoch 1131/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.8221 - val_loss: 1.3921\n",
      "Epoch 1132/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8321 - val_loss: 1.3918\n",
      "Epoch 1133/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8352 - val_loss: 1.3871\n",
      "Epoch 1134/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8311 - val_loss: 1.3925\n",
      "Epoch 1135/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8346 - val_loss: 1.3912\n",
      "Epoch 1136/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8277 - val_loss: 1.4075\n",
      "Epoch 1137/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8449 - val_loss: 1.3990\n",
      "Epoch 1138/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8212 - val_loss: 1.4049\n",
      "Epoch 1139/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8227 - val_loss: 1.4142\n",
      "Epoch 1140/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8287 - val_loss: 1.4059\n",
      "Epoch 1141/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8352 - val_loss: 1.4057\n",
      "Epoch 1142/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8386 - val_loss: 1.3949\n",
      "Epoch 1143/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8362 - val_loss: 1.4037\n",
      "Epoch 1144/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8366 - val_loss: 1.3934\n",
      "Epoch 1145/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8344 - val_loss: 1.3897\n",
      "Epoch 1146/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8225 - val_loss: 1.3951\n",
      "Epoch 1147/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8489 - val_loss: 1.3828\n",
      "Epoch 1148/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8361 - val_loss: 1.3938\n",
      "Epoch 1149/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8187 - val_loss: 1.3947\n",
      "Epoch 1150/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8251 - val_loss: 1.3968\n",
      "Epoch 1151/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8281 - val_loss: 1.4072\n",
      "Epoch 1152/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8310 - val_loss: 1.3959\n",
      "Epoch 1153/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8303 - val_loss: 1.4014\n",
      "Epoch 1154/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8187 - val_loss: 1.3974\n",
      "Epoch 1155/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8301 - val_loss: 1.4022\n",
      "Epoch 1156/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8306 - val_loss: 1.3960\n",
      "Epoch 1157/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8223 - val_loss: 1.3942\n",
      "Epoch 1158/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8381 - val_loss: 1.3842\n",
      "Epoch 1159/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8241 - val_loss: 1.3873\n",
      "Epoch 1160/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8451 - val_loss: 1.3869\n",
      "Epoch 1161/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8307 - val_loss: 1.3900\n",
      "Epoch 1162/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8209 - val_loss: 1.3877\n",
      "Epoch 1163/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8385 - val_loss: 1.4060\n",
      "Epoch 1164/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8125 - val_loss: 1.3990\n",
      "Epoch 1165/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8366 - val_loss: 1.4024\n",
      "Epoch 1166/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8417 - val_loss: 1.3948\n",
      "Epoch 1167/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8340 - val_loss: 1.3986\n",
      "Epoch 1168/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8450 - val_loss: 1.3963\n",
      "Epoch 1169/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8277 - val_loss: 1.4100\n",
      "Epoch 1170/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8390 - val_loss: 1.4143\n",
      "Epoch 1171/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8378 - val_loss: 1.4227\n",
      "Epoch 1172/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8192 - val_loss: 1.4312\n",
      "Epoch 1173/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.8360 - val_loss: 1.3887\n",
      "Epoch 1174/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8357 - val_loss: 1.3797\n",
      "Epoch 1175/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8203 - val_loss: 1.3827\n",
      "Epoch 1176/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8295 - val_loss: 1.3836\n",
      "Epoch 1177/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8351 - val_loss: 1.3817\n",
      "Epoch 1178/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8295 - val_loss: 1.3875\n",
      "Epoch 1179/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8223 - val_loss: 1.4004\n",
      "Epoch 1180/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8413 - val_loss: 1.3737\n",
      "Epoch 1181/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8417 - val_loss: 1.3893\n",
      "Epoch 1182/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8348 - val_loss: 1.4069\n",
      "Epoch 1183/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8276 - val_loss: 1.3977\n",
      "Epoch 1184/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8408 - val_loss: 1.4120\n",
      "Epoch 1185/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8076 - val_loss: 1.4058\n",
      "Epoch 1186/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8378 - val_loss: 1.3984\n",
      "Epoch 1187/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8221 - val_loss: 1.3950\n",
      "Epoch 1188/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8308 - val_loss: 1.3994\n",
      "Epoch 1189/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8253 - val_loss: 1.4067\n",
      "Epoch 1190/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8267 - val_loss: 1.3979\n",
      "Epoch 1191/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8290 - val_loss: 1.4158\n",
      "Epoch 1192/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8282 - val_loss: 1.3926\n",
      "Epoch 1193/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8301 - val_loss: 1.3979\n",
      "Epoch 1194/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8307 - val_loss: 1.3942\n",
      "Epoch 1195/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8202 - val_loss: 1.3786\n",
      "Epoch 1196/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8158 - val_loss: 1.3780\n",
      "Epoch 1197/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8482 - val_loss: 1.3818\n",
      "Epoch 1198/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8209 - val_loss: 1.3865\n",
      "Epoch 1199/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8248 - val_loss: 1.3994\n",
      "Epoch 1200/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8119 - val_loss: 1.4021\n",
      "Epoch 1201/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8389 - val_loss: 1.3988\n",
      "Epoch 1202/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8468 - val_loss: 1.3950\n",
      "Epoch 1203/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8316 - val_loss: 1.3903\n",
      "Epoch 1204/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8326 - val_loss: 1.3899\n",
      "Epoch 1205/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8248 - val_loss: 1.3800\n",
      "Epoch 1206/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8526 - val_loss: 1.3813\n",
      "Epoch 1207/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8298 - val_loss: 1.3841\n",
      "Epoch 1208/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8216 - val_loss: 1.3867\n",
      "Epoch 1209/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8261 - val_loss: 1.3927\n",
      "Epoch 1210/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8294 - val_loss: 1.3973\n",
      "Epoch 1211/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8202 - val_loss: 1.4133\n",
      "Epoch 1212/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8238 - val_loss: 1.3979\n",
      "Epoch 1213/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8226 - val_loss: 1.3990\n",
      "Epoch 1214/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8258 - val_loss: 1.3776\n",
      "Epoch 1215/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8342 - val_loss: 1.3765\n",
      "Epoch 1216/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8403 - val_loss: 1.4098\n",
      "Epoch 1217/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8123 - val_loss: 1.3913\n",
      "Epoch 1218/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8208 - val_loss: 1.3887\n",
      "Epoch 1219/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8131 - val_loss: 1.3912\n",
      "Epoch 1220/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8415 - val_loss: 1.4010\n",
      "Epoch 1221/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8429 - val_loss: 1.3897\n",
      "Epoch 1222/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8281 - val_loss: 1.3908\n",
      "Epoch 1223/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8253 - val_loss: 1.3778\n",
      "Epoch 1224/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8251 - val_loss: 1.3779\n",
      "Epoch 1225/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8396 - val_loss: 1.3782\n",
      "Epoch 1226/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8220 - val_loss: 1.3803\n",
      "Epoch 1227/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8288 - val_loss: 1.3732\n",
      "Epoch 1228/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8333 - val_loss: 1.3732\n",
      "Epoch 1229/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8386 - val_loss: 1.3781\n",
      "Epoch 1230/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 490us/step - loss: 0.8432 - val_loss: 1.3951\n",
      "Epoch 1231/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8133 - val_loss: 1.4110\n",
      "Epoch 1232/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8234 - val_loss: 1.4183\n",
      "Epoch 1233/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8205 - val_loss: 1.3843\n",
      "Epoch 1234/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8368 - val_loss: 1.3834\n",
      "Epoch 1235/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8303 - val_loss: 1.3869\n",
      "Epoch 1236/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8276 - val_loss: 1.3851\n",
      "Epoch 1237/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8188 - val_loss: 1.3826\n",
      "Epoch 1238/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8308 - val_loss: 1.3855\n",
      "Epoch 1239/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8310 - val_loss: 1.3869\n",
      "Epoch 1240/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8300 - val_loss: 1.3963\n",
      "Epoch 1241/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8320 - val_loss: 1.4026\n",
      "Epoch 1242/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8339 - val_loss: 1.4035\n",
      "Epoch 1243/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8291 - val_loss: 1.4026\n",
      "Epoch 1244/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8255 - val_loss: 1.3926\n",
      "Epoch 1245/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8311 - val_loss: 1.3944\n",
      "Epoch 1246/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8187 - val_loss: 1.4043\n",
      "Epoch 1247/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8361 - val_loss: 1.3896\n",
      "Epoch 1248/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8184 - val_loss: 1.3832\n",
      "Epoch 1249/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8282 - val_loss: 1.3830\n",
      "Epoch 1250/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8149 - val_loss: 1.3949\n",
      "Epoch 1251/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8306 - val_loss: 1.3891\n",
      "Epoch 1252/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8266 - val_loss: 1.3811\n",
      "Epoch 1253/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8447 - val_loss: 1.3816\n",
      "Epoch 1254/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8304 - val_loss: 1.3763\n",
      "Epoch 1255/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8265 - val_loss: 1.3911\n",
      "Epoch 1256/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8396 - val_loss: 1.3900\n",
      "Epoch 1257/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8135 - val_loss: 1.3934\n",
      "Epoch 1258/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8204 - val_loss: 1.3952\n",
      "Epoch 1259/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8254 - val_loss: 1.3829\n",
      "Epoch 1260/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8252 - val_loss: 1.3736\n",
      "Epoch 1261/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8189 - val_loss: 1.4066\n",
      "Epoch 1262/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8234 - val_loss: 1.4032\n",
      "Epoch 1263/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8250 - val_loss: 1.3981\n",
      "Epoch 1264/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8282 - val_loss: 1.3842\n",
      "Epoch 1265/5000\n",
      "572/572 [==============================] - 0s 478us/step - loss: 0.8392 - val_loss: 1.3839\n",
      "Epoch 1266/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.8251 - val_loss: 1.3795\n",
      "Epoch 1267/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8390 - val_loss: 1.3794\n",
      "Epoch 1268/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8271 - val_loss: 1.3905\n",
      "Epoch 1269/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8211 - val_loss: 1.3973\n",
      "Epoch 1270/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8166 - val_loss: 1.4167\n",
      "Epoch 1271/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8137 - val_loss: 1.3924\n",
      "Epoch 1272/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8190 - val_loss: 1.3810\n",
      "Epoch 1273/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8221 - val_loss: 1.3985\n",
      "Epoch 1274/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8240 - val_loss: 1.4025\n",
      "Epoch 1275/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8311 - val_loss: 1.3905\n",
      "Epoch 1276/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8184 - val_loss: 1.3844\n",
      "Epoch 1277/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8170 - val_loss: 1.3842\n",
      "Epoch 1278/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8303 - val_loss: 1.3928\n",
      "Epoch 1279/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8153 - val_loss: 1.3827\n",
      "Epoch 1280/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8351 - val_loss: 1.3815\n",
      "Epoch 1281/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8459 - val_loss: 1.3800\n",
      "Epoch 1282/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8206 - val_loss: 1.3815\n",
      "Epoch 1283/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8246 - val_loss: 1.3976\n",
      "Epoch 1284/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8157 - val_loss: 1.4050\n",
      "Epoch 1285/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8278 - val_loss: 1.3977\n",
      "Epoch 1286/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7989 - val_loss: 1.3864\n",
      "Epoch 1287/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8150 - val_loss: 1.3826\n",
      "Epoch 1288/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8279 - val_loss: 1.3751\n",
      "Epoch 1289/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8173 - val_loss: 1.3824\n",
      "Epoch 1290/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8452 - val_loss: 1.3863\n",
      "Epoch 1291/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8247 - val_loss: 1.3865\n",
      "Epoch 1292/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8230 - val_loss: 1.4052\n",
      "Epoch 1293/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8273 - val_loss: 1.4111\n",
      "Epoch 1294/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8249 - val_loss: 1.3982\n",
      "Epoch 1295/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8392 - val_loss: 1.3845\n",
      "Epoch 1296/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8157 - val_loss: 1.3999\n",
      "Epoch 1297/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8310 - val_loss: 1.3766\n",
      "Epoch 1298/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8254 - val_loss: 1.3761\n",
      "Epoch 1299/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8204 - val_loss: 1.3776\n",
      "Epoch 1300/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8297 - val_loss: 1.3758\n",
      "Epoch 1301/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8133 - val_loss: 1.3881\n",
      "Epoch 1302/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.8119 - val_loss: 1.3864\n",
      "Epoch 1303/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8329 - val_loss: 1.3861\n",
      "Epoch 1304/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8207 - val_loss: 1.4107\n",
      "Epoch 1305/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8378 - val_loss: 1.4094\n",
      "Epoch 1306/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8215 - val_loss: 1.3968\n",
      "Epoch 1307/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8185 - val_loss: 1.3892\n",
      "Epoch 1308/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8378 - val_loss: 1.3963\n",
      "Epoch 1309/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8120 - val_loss: 1.3798\n",
      "Epoch 1310/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8298 - val_loss: 1.3711\n",
      "Epoch 1311/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8333 - val_loss: 1.3745\n",
      "Epoch 1312/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8209 - val_loss: 1.3847\n",
      "Epoch 1313/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8281 - val_loss: 1.3864\n",
      "Epoch 1314/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8103 - val_loss: 1.3858\n",
      "Epoch 1315/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8286 - val_loss: 1.3850\n",
      "Epoch 1316/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8170 - val_loss: 1.3828\n",
      "Epoch 1317/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8421 - val_loss: 1.3838\n",
      "Epoch 1318/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8198 - val_loss: 1.3824\n",
      "Epoch 1319/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8272 - val_loss: 1.3823\n",
      "Epoch 1320/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8264 - val_loss: 1.3710\n",
      "Epoch 1321/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8166 - val_loss: 1.3744\n",
      "Epoch 1322/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8296 - val_loss: 1.3736\n",
      "Epoch 1323/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8211 - val_loss: 1.3949\n",
      "Epoch 1324/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8274 - val_loss: 1.3877\n",
      "Epoch 1325/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8290 - val_loss: 1.3822\n",
      "Epoch 1326/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8199 - val_loss: 1.3899\n",
      "Epoch 1327/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8376 - val_loss: 1.3770\n",
      "Epoch 1328/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8272 - val_loss: 1.3649\n",
      "Epoch 1329/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8104 - val_loss: 1.3824\n",
      "Epoch 1330/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8272 - val_loss: 1.3890\n",
      "Epoch 1331/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.8133 - val_loss: 1.3980\n",
      "Epoch 1332/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8222 - val_loss: 1.3881\n",
      "Epoch 1333/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8276 - val_loss: 1.3860\n",
      "Epoch 1334/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8188 - val_loss: 1.3764\n",
      "Epoch 1335/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8242 - val_loss: 1.3767\n",
      "Epoch 1336/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8147 - val_loss: 1.3728\n",
      "Epoch 1337/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8251 - val_loss: 1.3792\n",
      "Epoch 1338/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8082 - val_loss: 1.3978\n",
      "Epoch 1339/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8109 - val_loss: 1.4138\n",
      "Epoch 1340/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8222 - val_loss: 1.4062\n",
      "Epoch 1341/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8316 - val_loss: 1.3924\n",
      "Epoch 1342/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8556 - val_loss: 1.3970\n",
      "Epoch 1343/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8099 - val_loss: 1.3985\n",
      "Epoch 1344/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8242 - val_loss: 1.3976\n",
      "Epoch 1345/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8279 - val_loss: 1.3973\n",
      "Epoch 1346/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8177 - val_loss: 1.3941\n",
      "Epoch 1347/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8171 - val_loss: 1.4020\n",
      "Epoch 1348/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8249 - val_loss: 1.3808\n",
      "Epoch 1349/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8110 - val_loss: 1.3886\n",
      "Epoch 1350/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8363 - val_loss: 1.3758\n",
      "Epoch 1351/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8179 - val_loss: 1.3762\n",
      "Epoch 1352/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8236 - val_loss: 1.3840\n",
      "Epoch 1353/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8090 - val_loss: 1.3874\n",
      "Epoch 1354/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8109 - val_loss: 1.3851\n",
      "Epoch 1355/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8148 - val_loss: 1.3914\n",
      "Epoch 1356/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8070 - val_loss: 1.3894\n",
      "Epoch 1357/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8196 - val_loss: 1.3999\n",
      "Epoch 1358/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8186 - val_loss: 1.4038\n",
      "Epoch 1359/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8263 - val_loss: 1.3880\n",
      "Epoch 1360/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8161 - val_loss: 1.3802\n",
      "Epoch 1361/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8191 - val_loss: 1.3766\n",
      "Epoch 1362/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8183 - val_loss: 1.3839\n",
      "Epoch 1363/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8236 - val_loss: 1.3735\n",
      "Epoch 1364/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8166 - val_loss: 1.3812\n",
      "Epoch 1365/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8200 - val_loss: 1.3875\n",
      "Epoch 1366/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8282 - val_loss: 1.3899\n",
      "Epoch 1367/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8313 - val_loss: 1.4030\n",
      "Epoch 1368/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8258 - val_loss: 1.3786\n",
      "Epoch 1369/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8165 - val_loss: 1.3741\n",
      "Epoch 1370/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8215 - val_loss: 1.3986\n",
      "Epoch 1371/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8327 - val_loss: 1.3874\n",
      "Epoch 1372/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8225 - val_loss: 1.3768\n",
      "Epoch 1373/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8168 - val_loss: 1.3658\n",
      "Epoch 1374/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8111 - val_loss: 1.3804\n",
      "Epoch 1375/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8050 - val_loss: 1.3909\n",
      "Epoch 1376/5000\n",
      "572/572 [==============================] - 0s 505us/step - loss: 0.8222 - val_loss: 1.3971\n",
      "Epoch 1377/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8192 - val_loss: 1.4040\n",
      "Epoch 1378/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8075 - val_loss: 1.3881\n",
      "Epoch 1379/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8371 - val_loss: 1.3990\n",
      "Epoch 1380/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8218 - val_loss: 1.3881\n",
      "Epoch 1381/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8289 - val_loss: 1.3862\n",
      "Epoch 1382/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 484us/step - loss: 0.8118 - val_loss: 1.3841\n",
      "Epoch 1383/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8269 - val_loss: 1.3801\n",
      "Epoch 1384/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8297 - val_loss: 1.3827\n",
      "Epoch 1385/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8135 - val_loss: 1.3752\n",
      "Epoch 1386/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8292 - val_loss: 1.3774\n",
      "Epoch 1387/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8228 - val_loss: 1.3792\n",
      "Epoch 1388/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8095 - val_loss: 1.3890\n",
      "Epoch 1389/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8284 - val_loss: 1.3850\n",
      "Epoch 1390/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8278 - val_loss: 1.3846\n",
      "Epoch 1391/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8311 - val_loss: 1.3732\n",
      "Epoch 1392/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8116 - val_loss: 1.3808\n",
      "Epoch 1393/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8366 - val_loss: 1.3666\n",
      "Epoch 1394/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8214 - val_loss: 1.3791\n",
      "Epoch 1395/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8158 - val_loss: 1.3850\n",
      "Epoch 1396/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8128 - val_loss: 1.3771\n",
      "Epoch 1397/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8176 - val_loss: 1.3793\n",
      "Epoch 1398/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8242 - val_loss: 1.3766\n",
      "Epoch 1399/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.8086 - val_loss: 1.3782\n",
      "Epoch 1400/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8100 - val_loss: 1.3894\n",
      "Epoch 1401/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8067 - val_loss: 1.3884\n",
      "Epoch 1402/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8245 - val_loss: 1.3989\n",
      "Epoch 1403/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8364 - val_loss: 1.3955\n",
      "Epoch 1404/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8080 - val_loss: 1.3786\n",
      "Epoch 1405/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8172 - val_loss: 1.3711\n",
      "Epoch 1406/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8263 - val_loss: 1.3676\n",
      "Epoch 1407/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8237 - val_loss: 1.3796\n",
      "Epoch 1408/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8066 - val_loss: 1.3939\n",
      "Epoch 1409/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8139 - val_loss: 1.3915\n",
      "Epoch 1410/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8274 - val_loss: 1.3840\n",
      "Epoch 1411/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8253 - val_loss: 1.3784\n",
      "Epoch 1412/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8206 - val_loss: 1.3694\n",
      "Epoch 1413/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8184 - val_loss: 1.3819\n",
      "Epoch 1414/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8267 - val_loss: 1.3721\n",
      "Epoch 1415/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8143 - val_loss: 1.3782\n",
      "Epoch 1416/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8165 - val_loss: 1.3835\n",
      "Epoch 1417/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8196 - val_loss: 1.3764\n",
      "Epoch 1418/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8274 - val_loss: 1.3688\n",
      "Epoch 1419/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8062 - val_loss: 1.3727\n",
      "Epoch 1420/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8251 - val_loss: 1.3695\n",
      "Epoch 1421/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8191 - val_loss: 1.3711\n",
      "Epoch 1422/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8228 - val_loss: 1.3985\n",
      "Epoch 1423/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8187 - val_loss: 1.3806\n",
      "Epoch 1424/5000\n",
      "572/572 [==============================] - 0s 541us/step - loss: 0.8103 - val_loss: 1.3836\n",
      "Epoch 1425/5000\n",
      "572/572 [==============================] - 0s 572us/step - loss: 0.8224 - val_loss: 1.3887\n",
      "Epoch 1426/5000\n",
      "572/572 [==============================] - 0s 558us/step - loss: 0.8044 - val_loss: 1.3766\n",
      "Epoch 1427/5000\n",
      "572/572 [==============================] - 0s 569us/step - loss: 0.8122 - val_loss: 1.3886\n",
      "Epoch 1428/5000\n",
      "572/572 [==============================] - 0s 575us/step - loss: 0.8165 - val_loss: 1.3821\n",
      "Epoch 1429/5000\n",
      "572/572 [==============================] - 0s 587us/step - loss: 0.8296 - val_loss: 1.3930\n",
      "Epoch 1430/5000\n",
      "572/572 [==============================] - 0s 581us/step - loss: 0.8139 - val_loss: 1.3942\n",
      "Epoch 1431/5000\n",
      "572/572 [==============================] - 0s 555us/step - loss: 0.8179 - val_loss: 1.3931\n",
      "Epoch 1432/5000\n",
      "572/572 [==============================] - 0s 567us/step - loss: 0.8307 - val_loss: 1.3873\n",
      "Epoch 1433/5000\n",
      "572/572 [==============================] - 0s 573us/step - loss: 0.8164 - val_loss: 1.3777\n",
      "Epoch 1434/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8071 - val_loss: 1.3880\n",
      "Epoch 1435/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8192 - val_loss: 1.3873\n",
      "Epoch 1436/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8354 - val_loss: 1.3750\n",
      "Epoch 1437/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8172 - val_loss: 1.3816\n",
      "Epoch 1438/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8303 - val_loss: 1.3738\n",
      "Epoch 1439/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8255 - val_loss: 1.3885\n",
      "Epoch 1440/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8253 - val_loss: 1.3739\n",
      "Epoch 1441/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8146 - val_loss: 1.3751\n",
      "Epoch 1442/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8213 - val_loss: 1.3804\n",
      "Epoch 1443/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.8173 - val_loss: 1.3813\n",
      "Epoch 1444/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8120 - val_loss: 1.3791\n",
      "Epoch 1445/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8178 - val_loss: 1.3992\n",
      "Epoch 1446/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7988 - val_loss: 1.4027\n",
      "Epoch 1447/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8080 - val_loss: 1.3898\n",
      "Epoch 1448/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8070 - val_loss: 1.3796\n",
      "Epoch 1449/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8330 - val_loss: 1.3732\n",
      "Epoch 1450/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8146 - val_loss: 1.3761\n",
      "Epoch 1451/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8127 - val_loss: 1.3971\n",
      "Epoch 1452/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8271 - val_loss: 1.3887\n",
      "Epoch 1453/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8260 - val_loss: 1.3821\n",
      "Epoch 1454/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8244 - val_loss: 1.3775\n",
      "Epoch 1455/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8202 - val_loss: 1.3748\n",
      "Epoch 1456/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8262 - val_loss: 1.3697\n",
      "Epoch 1457/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8152 - val_loss: 1.3771\n",
      "Epoch 1458/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8359 - val_loss: 1.3725\n",
      "Epoch 1459/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8094 - val_loss: 1.3720\n",
      "Epoch 1460/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8185 - val_loss: 1.3640\n",
      "Epoch 1461/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8260 - val_loss: 1.3655\n",
      "Epoch 1462/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8150 - val_loss: 1.3753\n",
      "Epoch 1463/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8186 - val_loss: 1.3862\n",
      "Epoch 1464/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8159 - val_loss: 1.3887\n",
      "Epoch 1465/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8195 - val_loss: 1.3696\n",
      "Epoch 1466/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8219 - val_loss: 1.3866\n",
      "Epoch 1467/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7990 - val_loss: 1.3719\n",
      "Epoch 1468/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8107 - val_loss: 1.3731\n",
      "Epoch 1469/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8118 - val_loss: 1.3661\n",
      "Epoch 1470/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8273 - val_loss: 1.3723\n",
      "Epoch 1471/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8078 - val_loss: 1.3727\n",
      "Epoch 1472/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8125 - val_loss: 1.3772\n",
      "Epoch 1473/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8380 - val_loss: 1.3717\n",
      "Epoch 1474/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8401 - val_loss: 1.3671\n",
      "Epoch 1475/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8105 - val_loss: 1.3689\n",
      "Epoch 1476/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8175 - val_loss: 1.3942\n",
      "Epoch 1477/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.8109 - val_loss: 1.3920\n",
      "Epoch 1478/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8266 - val_loss: 1.4167\n",
      "Epoch 1479/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8145 - val_loss: 1.3851\n",
      "Epoch 1480/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8252 - val_loss: 1.3780\n",
      "Epoch 1481/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8164 - val_loss: 1.3649\n",
      "Epoch 1482/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8299 - val_loss: 1.3748\n",
      "Epoch 1483/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8114 - val_loss: 1.3853\n",
      "Epoch 1484/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8155 - val_loss: 1.3773\n",
      "Epoch 1485/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8408 - val_loss: 1.3883\n",
      "Epoch 1486/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8149 - val_loss: 1.3751\n",
      "Epoch 1487/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8215 - val_loss: 1.3699\n",
      "Epoch 1488/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8307 - val_loss: 1.3811\n",
      "Epoch 1489/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8211 - val_loss: 1.3964\n",
      "Epoch 1490/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8158 - val_loss: 1.3808\n",
      "Epoch 1491/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8124 - val_loss: 1.3930\n",
      "Epoch 1492/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8294 - val_loss: 1.3672\n",
      "Epoch 1493/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8186 - val_loss: 1.3799\n",
      "Epoch 1494/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8118 - val_loss: 1.3666\n",
      "Epoch 1495/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8120 - val_loss: 1.3684\n",
      "Epoch 1496/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8270 - val_loss: 1.3834\n",
      "Epoch 1497/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8122 - val_loss: 1.3688\n",
      "Epoch 1498/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8149 - val_loss: 1.3621\n",
      "Epoch 1499/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8213 - val_loss: 1.3635\n",
      "Epoch 1500/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8050 - val_loss: 1.3771\n",
      "Epoch 1501/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8177 - val_loss: 1.3829\n",
      "Epoch 1502/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8399 - val_loss: 1.4137\n",
      "Epoch 1503/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8212 - val_loss: 1.3966\n",
      "Epoch 1504/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8237 - val_loss: 1.3680\n",
      "Epoch 1505/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8247 - val_loss: 1.3707\n",
      "Epoch 1506/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8119 - val_loss: 1.3763\n",
      "Epoch 1507/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8198 - val_loss: 1.3937\n",
      "Epoch 1508/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8311 - val_loss: 1.3741\n",
      "Epoch 1509/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8123 - val_loss: 1.3823\n",
      "Epoch 1510/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8303 - val_loss: 1.3606\n",
      "Epoch 1511/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8324 - val_loss: 1.3792\n",
      "Epoch 1512/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8097 - val_loss: 1.3956\n",
      "Epoch 1513/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8309 - val_loss: 1.3954\n",
      "Epoch 1514/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8074 - val_loss: 1.3848\n",
      "Epoch 1515/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8266 - val_loss: 1.3753\n",
      "Epoch 1516/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8125 - val_loss: 1.3629\n",
      "Epoch 1517/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8177 - val_loss: 1.3704\n",
      "Epoch 1518/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8178 - val_loss: 1.3775\n",
      "Epoch 1519/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8010 - val_loss: 1.3776\n",
      "Epoch 1520/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8118 - val_loss: 1.3866\n",
      "Epoch 1521/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8095 - val_loss: 1.3777\n",
      "Epoch 1522/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8231 - val_loss: 1.3886\n",
      "Epoch 1523/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8179 - val_loss: 1.3731\n",
      "Epoch 1524/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8130 - val_loss: 1.3645\n",
      "Epoch 1525/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8228 - val_loss: 1.3779\n",
      "Epoch 1526/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8016 - val_loss: 1.3718\n",
      "Epoch 1527/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8236 - val_loss: 1.3741\n",
      "Epoch 1528/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8165 - val_loss: 1.3742\n",
      "Epoch 1529/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8155 - val_loss: 1.3897\n",
      "Epoch 1530/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8205 - val_loss: 1.3722\n",
      "Epoch 1531/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8222 - val_loss: 1.3601\n",
      "Epoch 1532/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.8263 - val_loss: 1.3719\n",
      "Epoch 1533/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8223 - val_loss: 1.3660\n",
      "Epoch 1534/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 490us/step - loss: 0.8186 - val_loss: 1.3746\n",
      "Epoch 1535/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8168 - val_loss: 1.3908\n",
      "Epoch 1536/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8131 - val_loss: 1.3725\n",
      "Epoch 1537/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8190 - val_loss: 1.3833\n",
      "Epoch 1538/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8131 - val_loss: 1.3678\n",
      "Epoch 1539/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8157 - val_loss: 1.3764\n",
      "Epoch 1540/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8182 - val_loss: 1.3754\n",
      "Epoch 1541/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8061 - val_loss: 1.3828\n",
      "Epoch 1542/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8259 - val_loss: 1.3875\n",
      "Epoch 1543/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8120 - val_loss: 1.3831\n",
      "Epoch 1544/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8181 - val_loss: 1.3829\n",
      "Epoch 1545/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7992 - val_loss: 1.3950\n",
      "Epoch 1546/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8169 - val_loss: 1.3868\n",
      "Epoch 1547/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8355 - val_loss: 1.3677\n",
      "Epoch 1548/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8040 - val_loss: 1.3805\n",
      "Epoch 1549/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8189 - val_loss: 1.3884\n",
      "Epoch 1550/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8264 - val_loss: 1.3746\n",
      "Epoch 1551/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8230 - val_loss: 1.3762\n",
      "Epoch 1552/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8064 - val_loss: 1.3710\n",
      "Epoch 1553/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8172 - val_loss: 1.3714\n",
      "Epoch 1554/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8233 - val_loss: 1.3720\n",
      "Epoch 1555/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8174 - val_loss: 1.3809\n",
      "Epoch 1556/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8087 - val_loss: 1.3798\n",
      "Epoch 1557/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8118 - val_loss: 1.3784\n",
      "Epoch 1558/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8310 - val_loss: 1.3744\n",
      "Epoch 1559/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7979 - val_loss: 1.3799\n",
      "Epoch 1560/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8121 - val_loss: 1.3767\n",
      "Epoch 1561/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8149 - val_loss: 1.3855\n",
      "Epoch 1562/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8152 - val_loss: 1.3863\n",
      "Epoch 1563/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8224 - val_loss: 1.3792\n",
      "Epoch 1564/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8074 - val_loss: 1.4025\n",
      "Epoch 1565/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8117 - val_loss: 1.4048\n",
      "Epoch 1566/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8320 - val_loss: 1.3820\n",
      "Epoch 1567/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8170 - val_loss: 1.3656\n",
      "Epoch 1568/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8031 - val_loss: 1.3628\n",
      "Epoch 1569/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8075 - val_loss: 1.3773\n",
      "Epoch 1570/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8180 - val_loss: 1.3972\n",
      "Epoch 1571/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8139 - val_loss: 1.3833\n",
      "Epoch 1572/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8297 - val_loss: 1.3727\n",
      "Epoch 1573/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8116 - val_loss: 1.3808\n",
      "Epoch 1574/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8241 - val_loss: 1.3643\n",
      "Epoch 1575/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8231 - val_loss: 1.3758\n",
      "Epoch 1576/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8160 - val_loss: 1.3695\n",
      "Epoch 1577/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7952 - val_loss: 1.3792\n",
      "Epoch 1578/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8160 - val_loss: 1.3797\n",
      "Epoch 1579/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8281 - val_loss: 1.3839\n",
      "Epoch 1580/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8228 - val_loss: 1.3731\n",
      "Epoch 1581/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8047 - val_loss: 1.3659\n",
      "Epoch 1582/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8179 - val_loss: 1.3611\n",
      "Epoch 1583/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8140 - val_loss: 1.3545\n",
      "Epoch 1584/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8228 - val_loss: 1.3721\n",
      "Epoch 1585/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8092 - val_loss: 1.3825\n",
      "Epoch 1586/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8095 - val_loss: 1.3735\n",
      "Epoch 1587/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8191 - val_loss: 1.3665\n",
      "Epoch 1588/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8067 - val_loss: 1.3861\n",
      "Epoch 1589/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8250 - val_loss: 1.3971\n",
      "Epoch 1590/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8231 - val_loss: 1.3969\n",
      "Epoch 1591/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8246 - val_loss: 1.3760\n",
      "Epoch 1592/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8059 - val_loss: 1.3850\n",
      "Epoch 1593/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8094 - val_loss: 1.3848\n",
      "Epoch 1594/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8120 - val_loss: 1.3712\n",
      "Epoch 1595/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8124 - val_loss: 1.3922\n",
      "Epoch 1596/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8114 - val_loss: 1.3669\n",
      "Epoch 1597/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8028 - val_loss: 1.3608\n",
      "Epoch 1598/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8061 - val_loss: 1.3681\n",
      "Epoch 1599/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8036 - val_loss: 1.3776\n",
      "Epoch 1600/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8207 - val_loss: 1.3996\n",
      "Epoch 1601/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8245 - val_loss: 1.3927\n",
      "Epoch 1602/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8164 - val_loss: 1.3960\n",
      "Epoch 1603/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8046 - val_loss: 1.3826\n",
      "Epoch 1604/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8147 - val_loss: 1.3912\n",
      "Epoch 1605/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8301 - val_loss: 1.3807\n",
      "Epoch 1606/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8047 - val_loss: 1.3680\n",
      "Epoch 1607/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8236 - val_loss: 1.3656\n",
      "Epoch 1608/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7984 - val_loss: 1.3637\n",
      "Epoch 1609/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8238 - val_loss: 1.3638\n",
      "Epoch 1610/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8331 - val_loss: 1.3824\n",
      "Epoch 1611/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8157 - val_loss: 1.3909\n",
      "Epoch 1612/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8129 - val_loss: 1.3779\n",
      "Epoch 1613/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8190 - val_loss: 1.3898\n",
      "Epoch 1614/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8093 - val_loss: 1.3812\n",
      "Epoch 1615/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8127 - val_loss: 1.3867\n",
      "Epoch 1616/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8222 - val_loss: 1.3763\n",
      "Epoch 1617/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8149 - val_loss: 1.3867\n",
      "Epoch 1618/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8153 - val_loss: 1.3687\n",
      "Epoch 1619/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8191 - val_loss: 1.3711\n",
      "Epoch 1620/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8025 - val_loss: 1.3778\n",
      "Epoch 1621/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8181 - val_loss: 1.3798\n",
      "Epoch 1622/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8058 - val_loss: 1.3839\n",
      "Epoch 1623/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8082 - val_loss: 1.3949\n",
      "Epoch 1624/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8034 - val_loss: 1.3946\n",
      "Epoch 1625/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8105 - val_loss: 1.3907\n",
      "Epoch 1626/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8260 - val_loss: 1.3885\n",
      "Epoch 1627/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8197 - val_loss: 1.3732\n",
      "Epoch 1628/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8185 - val_loss: 1.3596\n",
      "Epoch 1629/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8120 - val_loss: 1.3634\n",
      "Epoch 1630/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8083 - val_loss: 1.3703\n",
      "Epoch 1631/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8027 - val_loss: 1.3793\n",
      "Epoch 1632/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8089 - val_loss: 1.3772\n",
      "Epoch 1633/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8246 - val_loss: 1.3598\n",
      "Epoch 1634/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8131 - val_loss: 1.3778\n",
      "Epoch 1635/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8178 - val_loss: 1.3790\n",
      "Epoch 1636/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8245 - val_loss: 1.3706\n",
      "Epoch 1637/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8090 - val_loss: 1.3749\n",
      "Epoch 1638/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8099 - val_loss: 1.3756\n",
      "Epoch 1639/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8205 - val_loss: 1.3715\n",
      "Epoch 1640/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8090 - val_loss: 1.3625\n",
      "Epoch 1641/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8076 - val_loss: 1.3774\n",
      "Epoch 1642/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8005 - val_loss: 1.3868\n",
      "Epoch 1643/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8199 - val_loss: 1.3923\n",
      "Epoch 1644/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8123 - val_loss: 1.4024\n",
      "Epoch 1645/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8012 - val_loss: 1.3809\n",
      "Epoch 1646/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7976 - val_loss: 1.3738\n",
      "Epoch 1647/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8147 - val_loss: 1.3938\n",
      "Epoch 1648/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8087 - val_loss: 1.3794\n",
      "Epoch 1649/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8076 - val_loss: 1.3828\n",
      "Epoch 1650/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7936 - val_loss: 1.3788\n",
      "Epoch 1651/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8193 - val_loss: 1.3864\n",
      "Epoch 1652/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8395 - val_loss: 1.3921\n",
      "Epoch 1653/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8067 - val_loss: 1.3765\n",
      "Epoch 1654/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8268 - val_loss: 1.3734\n",
      "Epoch 1655/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8245 - val_loss: 1.3702\n",
      "Epoch 1656/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8180 - val_loss: 1.3736\n",
      "Epoch 1657/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8066 - val_loss: 1.3554\n",
      "Epoch 1658/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8037 - val_loss: 1.3559\n",
      "Epoch 1659/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8165 - val_loss: 1.3581\n",
      "Epoch 1660/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8086 - val_loss: 1.3659\n",
      "Epoch 1661/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8235 - val_loss: 1.3762\n",
      "Epoch 1662/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8133 - val_loss: 1.3822\n",
      "Epoch 1663/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8100 - val_loss: 1.3871\n",
      "Epoch 1664/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8355 - val_loss: 1.3876\n",
      "Epoch 1665/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8138 - val_loss: 1.3783\n",
      "Epoch 1666/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8119 - val_loss: 1.3781\n",
      "Epoch 1667/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8172 - val_loss: 1.3886\n",
      "Epoch 1668/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8133 - val_loss: 1.3870\n",
      "Epoch 1669/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8087 - val_loss: 1.3958\n",
      "Epoch 1670/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8037 - val_loss: 1.3813\n",
      "Epoch 1671/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8097 - val_loss: 1.3835\n",
      "Epoch 1672/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8143 - val_loss: 1.3691\n",
      "Epoch 1673/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8027 - val_loss: 1.3616\n",
      "Epoch 1674/5000\n",
      "572/572 [==============================] - 0s 503us/step - loss: 0.8178 - val_loss: 1.3789\n",
      "Epoch 1675/5000\n",
      "572/572 [==============================] - 0s 520us/step - loss: 0.8173 - val_loss: 1.3658\n",
      "Epoch 1676/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.7955 - val_loss: 1.3605\n",
      "Epoch 1677/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8170 - val_loss: 1.3614\n",
      "Epoch 1678/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7991 - val_loss: 1.3595\n",
      "Epoch 1679/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8058 - val_loss: 1.3793\n",
      "Epoch 1680/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8137 - val_loss: 1.3748\n",
      "Epoch 1681/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8117 - val_loss: 1.3774\n",
      "Epoch 1682/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8212 - val_loss: 1.3737\n",
      "Epoch 1683/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8271 - val_loss: 1.3662\n",
      "Epoch 1684/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8192 - val_loss: 1.3701\n",
      "Epoch 1685/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8200 - val_loss: 1.3628\n",
      "Epoch 1686/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 491us/step - loss: 0.8059 - val_loss: 1.3624\n",
      "Epoch 1687/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8159 - val_loss: 1.3704\n",
      "Epoch 1688/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8129 - val_loss: 1.3946\n",
      "Epoch 1689/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8149 - val_loss: 1.3797\n",
      "Epoch 1690/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8250 - val_loss: 1.3928\n",
      "Epoch 1691/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8107 - val_loss: 1.4075\n",
      "Epoch 1692/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8111 - val_loss: 1.3837\n",
      "Epoch 1693/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8074 - val_loss: 1.3775\n",
      "Epoch 1694/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8098 - val_loss: 1.3635\n",
      "Epoch 1695/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8125 - val_loss: 1.3743\n",
      "Epoch 1696/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8109 - val_loss: 1.3640\n",
      "Epoch 1697/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8089 - val_loss: 1.3751\n",
      "Epoch 1698/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8218 - val_loss: 1.3667\n",
      "Epoch 1699/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8218 - val_loss: 1.3803\n",
      "Epoch 1700/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8019 - val_loss: 1.3800\n",
      "Epoch 1701/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8059 - val_loss: 1.3889\n",
      "Epoch 1702/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8168 - val_loss: 1.3885\n",
      "Epoch 1703/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8025 - val_loss: 1.3816\n",
      "Epoch 1704/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8151 - val_loss: 1.3684\n",
      "Epoch 1705/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8108 - val_loss: 1.3672\n",
      "Epoch 1706/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8144 - val_loss: 1.3635\n",
      "Epoch 1707/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8235 - val_loss: 1.3694\n",
      "Epoch 1708/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8295 - val_loss: 1.3679\n",
      "Epoch 1709/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8128 - val_loss: 1.3744\n",
      "Epoch 1710/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8153 - val_loss: 1.3922\n",
      "Epoch 1711/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8249 - val_loss: 1.3718\n",
      "Epoch 1712/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8125 - val_loss: 1.3839\n",
      "Epoch 1713/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8279 - val_loss: 1.3812\n",
      "Epoch 1714/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7921 - val_loss: 1.3915\n",
      "Epoch 1715/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8100 - val_loss: 1.3702\n",
      "Epoch 1716/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8064 - val_loss: 1.3557\n",
      "Epoch 1717/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7978 - val_loss: 1.3591\n",
      "Epoch 1718/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8073 - val_loss: 1.3623\n",
      "Epoch 1719/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8187 - val_loss: 1.3651\n",
      "Epoch 1720/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8103 - val_loss: 1.3704\n",
      "Epoch 1721/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8010 - val_loss: 1.3717\n",
      "Epoch 1722/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8105 - val_loss: 1.3610\n",
      "Epoch 1723/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8005 - val_loss: 1.3634\n",
      "Epoch 1724/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7989 - val_loss: 1.3761\n",
      "Epoch 1725/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8107 - val_loss: 1.3747\n",
      "Epoch 1726/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8043 - val_loss: 1.3667\n",
      "Epoch 1727/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8174 - val_loss: 1.3665\n",
      "Epoch 1728/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8012 - val_loss: 1.3595\n",
      "Epoch 1729/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8209 - val_loss: 1.3683\n",
      "Epoch 1730/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8085 - val_loss: 1.3715\n",
      "Epoch 1731/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8061 - val_loss: 1.3687\n",
      "Epoch 1732/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8163 - val_loss: 1.3889\n",
      "Epoch 1733/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8068 - val_loss: 1.3690\n",
      "Epoch 1734/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8138 - val_loss: 1.3728\n",
      "Epoch 1735/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8109 - val_loss: 1.3764\n",
      "Epoch 1736/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8170 - val_loss: 1.3779\n",
      "Epoch 1737/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8177 - val_loss: 1.3820\n",
      "Epoch 1738/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8216 - val_loss: 1.3779\n",
      "Epoch 1739/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8165 - val_loss: 1.3784\n",
      "Epoch 1740/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8029 - val_loss: 1.3819\n",
      "Epoch 1741/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8043 - val_loss: 1.3773\n",
      "Epoch 1742/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8062 - val_loss: 1.3850\n",
      "Epoch 1743/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8201 - val_loss: 1.3708\n",
      "Epoch 1744/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8057 - val_loss: 1.3770\n",
      "Epoch 1745/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8201 - val_loss: 1.3728\n",
      "Epoch 1746/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8115 - val_loss: 1.3632\n",
      "Epoch 1747/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8107 - val_loss: 1.3697\n",
      "Epoch 1748/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8075 - val_loss: 1.3595\n",
      "Epoch 1749/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8018 - val_loss: 1.3579\n",
      "Epoch 1750/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8049 - val_loss: 1.3617\n",
      "Epoch 1751/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8239 - val_loss: 1.3535\n",
      "Epoch 1752/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8276 - val_loss: 1.3750\n",
      "Epoch 1753/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8258 - val_loss: 1.3685\n",
      "Epoch 1754/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8071 - val_loss: 1.3630\n",
      "Epoch 1755/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8101 - val_loss: 1.3642\n",
      "Epoch 1756/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8088 - val_loss: 1.3934\n",
      "Epoch 1757/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8284 - val_loss: 1.3583\n",
      "Epoch 1758/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8130 - val_loss: 1.3720\n",
      "Epoch 1759/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8183 - val_loss: 1.3712\n",
      "Epoch 1760/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8070 - val_loss: 1.3651\n",
      "Epoch 1761/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8213 - val_loss: 1.3691\n",
      "Epoch 1762/5000\n",
      "572/572 [==============================] - 0s 478us/step - loss: 0.8204 - val_loss: 1.3972\n",
      "Epoch 1763/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8152 - val_loss: 1.3811\n",
      "Epoch 1764/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8045 - val_loss: 1.3797\n",
      "Epoch 1765/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8339 - val_loss: 1.3681\n",
      "Epoch 1766/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8115 - val_loss: 1.3755\n",
      "Epoch 1767/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7991 - val_loss: 1.3966\n",
      "Epoch 1768/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8070 - val_loss: 1.3743\n",
      "Epoch 1769/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8044 - val_loss: 1.3791\n",
      "Epoch 1770/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8154 - val_loss: 1.3658\n",
      "Epoch 1771/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8252 - val_loss: 1.3679\n",
      "Epoch 1772/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8010 - val_loss: 1.3584\n",
      "Epoch 1773/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8175 - val_loss: 1.3800\n",
      "Epoch 1774/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8052 - val_loss: 1.3720\n",
      "Epoch 1775/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8037 - val_loss: 1.3715\n",
      "Epoch 1776/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7997 - val_loss: 1.3721\n",
      "Epoch 1777/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8044 - val_loss: 1.3812\n",
      "Epoch 1778/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8061 - val_loss: 1.3880\n",
      "Epoch 1779/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8055 - val_loss: 1.3702\n",
      "Epoch 1780/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.8231 - val_loss: 1.3567\n",
      "Epoch 1781/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8101 - val_loss: 1.3786\n",
      "Epoch 1782/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8112 - val_loss: 1.3681\n",
      "Epoch 1783/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.8186 - val_loss: 1.3657\n",
      "Epoch 1784/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8139 - val_loss: 1.3691\n",
      "Epoch 1785/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8030 - val_loss: 1.3792\n",
      "Epoch 1786/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8073 - val_loss: 1.3647\n",
      "Epoch 1787/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8113 - val_loss: 1.3583\n",
      "Epoch 1788/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8178 - val_loss: 1.3697\n",
      "Epoch 1789/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8107 - val_loss: 1.3857\n",
      "Epoch 1790/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8083 - val_loss: 1.3694\n",
      "Epoch 1791/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8166 - val_loss: 1.3548\n",
      "Epoch 1792/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7986 - val_loss: 1.3705\n",
      "Epoch 1793/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8172 - val_loss: 1.3865\n",
      "Epoch 1794/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8111 - val_loss: 1.3774\n",
      "Epoch 1795/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7982 - val_loss: 1.3838\n",
      "Epoch 1796/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8274 - val_loss: 1.3738\n",
      "Epoch 1797/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8067 - val_loss: 1.3722\n",
      "Epoch 1798/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8111 - val_loss: 1.3671\n",
      "Epoch 1799/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8026 - val_loss: 1.3667\n",
      "Epoch 1800/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8162 - val_loss: 1.3646\n",
      "Epoch 1801/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8160 - val_loss: 1.3657\n",
      "Epoch 1802/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7979 - val_loss: 1.3765\n",
      "Epoch 1803/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8026 - val_loss: 1.3703\n",
      "Epoch 1804/5000\n",
      "572/572 [==============================] - 0s 502us/step - loss: 0.8045 - val_loss: 1.3699\n",
      "Epoch 1805/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8170 - val_loss: 1.3522\n",
      "Epoch 1806/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8084 - val_loss: 1.3559\n",
      "Epoch 1807/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8181 - val_loss: 1.3707\n",
      "Epoch 1808/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7969 - val_loss: 1.3714\n",
      "Epoch 1809/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8072 - val_loss: 1.3883\n",
      "Epoch 1810/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8085 - val_loss: 1.3806\n",
      "Epoch 1811/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8199 - val_loss: 1.3771\n",
      "Epoch 1812/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7891 - val_loss: 1.3879\n",
      "Epoch 1813/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.8004 - val_loss: 1.3764\n",
      "Epoch 1814/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8062 - val_loss: 1.3740\n",
      "Epoch 1815/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8102 - val_loss: 1.3715\n",
      "Epoch 1816/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8118 - val_loss: 1.3606\n",
      "Epoch 1817/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8122 - val_loss: 1.3578\n",
      "Epoch 1818/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8096 - val_loss: 1.3675\n",
      "Epoch 1819/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8176 - val_loss: 1.3630\n",
      "Epoch 1820/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8079 - val_loss: 1.3641\n",
      "Epoch 1821/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8090 - val_loss: 1.3635\n",
      "Epoch 1822/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8044 - val_loss: 1.3639\n",
      "Epoch 1823/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8104 - val_loss: 1.3629\n",
      "Epoch 1824/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8139 - val_loss: 1.3796\n",
      "Epoch 1825/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8187 - val_loss: 1.3826\n",
      "Epoch 1826/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8145 - val_loss: 1.3957\n",
      "Epoch 1827/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8152 - val_loss: 1.3777\n",
      "Epoch 1828/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8127 - val_loss: 1.3693\n",
      "Epoch 1829/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8004 - val_loss: 1.3616\n",
      "Epoch 1830/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8049 - val_loss: 1.3701\n",
      "Epoch 1831/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8081 - val_loss: 1.3496\n",
      "Epoch 1832/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8031 - val_loss: 1.3433\n",
      "Epoch 1833/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8099 - val_loss: 1.3515\n",
      "Epoch 1834/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8071 - val_loss: 1.3432\n",
      "Epoch 1835/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8051 - val_loss: 1.3599\n",
      "Epoch 1836/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8257 - val_loss: 1.3785\n",
      "Epoch 1837/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7977 - val_loss: 1.3969\n",
      "Epoch 1838/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 480us/step - loss: 0.8151 - val_loss: 1.3832\n",
      "Epoch 1839/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8161 - val_loss: 1.3685\n",
      "Epoch 1840/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8000 - val_loss: 1.3748\n",
      "Epoch 1841/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8192 - val_loss: 1.3661\n",
      "Epoch 1842/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7999 - val_loss: 1.3600\n",
      "Epoch 1843/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8123 - val_loss: 1.3706\n",
      "Epoch 1844/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8056 - val_loss: 1.3700\n",
      "Epoch 1845/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8057 - val_loss: 1.3891\n",
      "Epoch 1846/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8127 - val_loss: 1.3838\n",
      "Epoch 1847/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8109 - val_loss: 1.3622\n",
      "Epoch 1848/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8060 - val_loss: 1.3701\n",
      "Epoch 1849/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8087 - val_loss: 1.3849\n",
      "Epoch 1850/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8125 - val_loss: 1.3895\n",
      "Epoch 1851/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8052 - val_loss: 1.3833\n",
      "Epoch 1852/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8084 - val_loss: 1.3531\n",
      "Epoch 1853/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7961 - val_loss: 1.3567\n",
      "Epoch 1854/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8093 - val_loss: 1.3719\n",
      "Epoch 1855/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8171 - val_loss: 1.3872\n",
      "Epoch 1856/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8182 - val_loss: 1.3808\n",
      "Epoch 1857/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8055 - val_loss: 1.3783\n",
      "Epoch 1858/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8106 - val_loss: 1.3864\n",
      "Epoch 1859/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7982 - val_loss: 1.3641\n",
      "Epoch 1860/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8129 - val_loss: 1.3585\n",
      "Epoch 1861/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8077 - val_loss: 1.3695\n",
      "Epoch 1862/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8021 - val_loss: 1.3875\n",
      "Epoch 1863/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8155 - val_loss: 1.4100\n",
      "Epoch 1864/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8085 - val_loss: 1.3649\n",
      "Epoch 1865/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8158 - val_loss: 1.3589\n",
      "Epoch 1866/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8145 - val_loss: 1.3499\n",
      "Epoch 1867/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8126 - val_loss: 1.3715\n",
      "Epoch 1868/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8030 - val_loss: 1.3598\n",
      "Epoch 1869/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7996 - val_loss: 1.3515\n",
      "Epoch 1870/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7981 - val_loss: 1.3602\n",
      "Epoch 1871/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8150 - val_loss: 1.3566\n",
      "Epoch 1872/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8203 - val_loss: 1.3533\n",
      "Epoch 1873/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8079 - val_loss: 1.3700\n",
      "Epoch 1874/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8245 - val_loss: 1.3795\n",
      "Epoch 1875/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8194 - val_loss: 1.3874\n",
      "Epoch 1876/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8116 - val_loss: 1.3680\n",
      "Epoch 1877/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8114 - val_loss: 1.3662\n",
      "Epoch 1878/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8232 - val_loss: 1.3592\n",
      "Epoch 1879/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8097 - val_loss: 1.3529\n",
      "Epoch 1880/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8045 - val_loss: 1.3548\n",
      "Epoch 1881/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7997 - val_loss: 1.3650\n",
      "Epoch 1882/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7948 - val_loss: 1.3684\n",
      "Epoch 1883/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.8075 - val_loss: 1.3579\n",
      "Epoch 1884/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8109 - val_loss: 1.3776\n",
      "Epoch 1885/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7993 - val_loss: 1.3753\n",
      "Epoch 1886/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8066 - val_loss: 1.3751\n",
      "Epoch 1887/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8091 - val_loss: 1.3635\n",
      "Epoch 1888/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8219 - val_loss: 1.3580\n",
      "Epoch 1889/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7944 - val_loss: 1.3646\n",
      "Epoch 1890/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8028 - val_loss: 1.3857\n",
      "Epoch 1891/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8210 - val_loss: 1.3870\n",
      "Epoch 1892/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8202 - val_loss: 1.3600\n",
      "Epoch 1893/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8108 - val_loss: 1.3451\n",
      "Epoch 1894/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8135 - val_loss: 1.3521\n",
      "Epoch 1895/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8110 - val_loss: 1.3514\n",
      "Epoch 1896/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7922 - val_loss: 1.3645\n",
      "Epoch 1897/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8043 - val_loss: 1.3586\n",
      "Epoch 1898/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7960 - val_loss: 1.3437\n",
      "Epoch 1899/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8026 - val_loss: 1.3681\n",
      "Epoch 1900/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8168 - val_loss: 1.3650\n",
      "Epoch 1901/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7999 - val_loss: 1.3573\n",
      "Epoch 1902/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8080 - val_loss: 1.3638\n",
      "Epoch 1903/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8040 - val_loss: 1.3657\n",
      "Epoch 1904/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.8045 - val_loss: 1.3458\n",
      "Epoch 1905/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8012 - val_loss: 1.3678\n",
      "Epoch 1906/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8084 - val_loss: 1.3840\n",
      "Epoch 1907/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8133 - val_loss: 1.3682\n",
      "Epoch 1908/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8066 - val_loss: 1.3785\n",
      "Epoch 1909/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8207 - val_loss: 1.3720\n",
      "Epoch 1910/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8225 - val_loss: 1.3812\n",
      "Epoch 1911/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7989 - val_loss: 1.3738\n",
      "Epoch 1912/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8061 - val_loss: 1.3704\n",
      "Epoch 1913/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8163 - val_loss: 1.3668\n",
      "Epoch 1914/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.8111 - val_loss: 1.3705\n",
      "Epoch 1915/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.8061 - val_loss: 1.3677\n",
      "Epoch 1916/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8043 - val_loss: 1.3564\n",
      "Epoch 1917/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8152 - val_loss: 1.3506\n",
      "Epoch 1918/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7998 - val_loss: 1.3517\n",
      "Epoch 1919/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8028 - val_loss: 1.3790\n",
      "Epoch 1920/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8157 - val_loss: 1.3637\n",
      "Epoch 1921/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8105 - val_loss: 1.3680\n",
      "Epoch 1922/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7984 - val_loss: 1.3755\n",
      "Epoch 1923/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8058 - val_loss: 1.3736\n",
      "Epoch 1924/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8162 - val_loss: 1.3610\n",
      "Epoch 1925/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8020 - val_loss: 1.3668\n",
      "Epoch 1926/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8117 - val_loss: 1.3570\n",
      "Epoch 1927/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8130 - val_loss: 1.3661\n",
      "Epoch 1928/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8157 - val_loss: 1.3707\n",
      "Epoch 1929/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8156 - val_loss: 1.3723\n",
      "Epoch 1930/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8003 - val_loss: 1.3797\n",
      "Epoch 1931/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8131 - val_loss: 1.3913\n",
      "Epoch 1932/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7920 - val_loss: 1.3920\n",
      "Epoch 1933/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8108 - val_loss: 1.3797\n",
      "Epoch 1934/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8156 - val_loss: 1.3706\n",
      "Epoch 1935/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8057 - val_loss: 1.3655\n",
      "Epoch 1936/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8096 - val_loss: 1.3765\n",
      "Epoch 1937/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8003 - val_loss: 1.3650\n",
      "Epoch 1938/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8194 - val_loss: 1.3441\n",
      "Epoch 1939/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8231 - val_loss: 1.3589\n",
      "Epoch 1940/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8096 - val_loss: 1.3507\n",
      "Epoch 1941/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8192 - val_loss: 1.3563\n",
      "Epoch 1942/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8017 - val_loss: 1.3571\n",
      "Epoch 1943/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8113 - val_loss: 1.3624\n",
      "Epoch 1944/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8105 - val_loss: 1.3720\n",
      "Epoch 1945/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8100 - val_loss: 1.3743\n",
      "Epoch 1946/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8137 - val_loss: 1.3656\n",
      "Epoch 1947/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8049 - val_loss: 1.3648\n",
      "Epoch 1948/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8173 - val_loss: 1.3747\n",
      "Epoch 1949/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8176 - val_loss: 1.3854\n",
      "Epoch 1950/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8109 - val_loss: 1.3823\n",
      "Epoch 1951/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8024 - val_loss: 1.3792\n",
      "Epoch 1952/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8029 - val_loss: 1.3622\n",
      "Epoch 1953/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8065 - val_loss: 1.3670\n",
      "Epoch 1954/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8160 - val_loss: 1.3636\n",
      "Epoch 1955/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8082 - val_loss: 1.3482\n",
      "Epoch 1956/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8212 - val_loss: 1.3677\n",
      "Epoch 1957/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8003 - val_loss: 1.3614\n",
      "Epoch 1958/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7880 - val_loss: 1.3569\n",
      "Epoch 1959/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7977 - val_loss: 1.3734\n",
      "Epoch 1960/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8069 - val_loss: 1.3644\n",
      "Epoch 1961/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7951 - val_loss: 1.3478\n",
      "Epoch 1962/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8129 - val_loss: 1.3533\n",
      "Epoch 1963/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8103 - val_loss: 1.3573\n",
      "Epoch 1964/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8165 - val_loss: 1.3477\n",
      "Epoch 1965/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8085 - val_loss: 1.3527\n",
      "Epoch 1966/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7994 - val_loss: 1.3553\n",
      "Epoch 1967/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8048 - val_loss: 1.3536\n",
      "Epoch 1968/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8258 - val_loss: 1.3560\n",
      "Epoch 1969/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8179 - val_loss: 1.3650\n",
      "Epoch 1970/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8172 - val_loss: 1.3617\n",
      "Epoch 1971/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7966 - val_loss: 1.3474\n",
      "Epoch 1972/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8213 - val_loss: 1.3532\n",
      "Epoch 1973/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8031 - val_loss: 1.3584\n",
      "Epoch 1974/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8003 - val_loss: 1.3592\n",
      "Epoch 1975/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8181 - val_loss: 1.3452\n",
      "Epoch 1976/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8441 - val_loss: 1.3525\n",
      "Epoch 1977/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7923 - val_loss: 1.3783\n",
      "Epoch 1978/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8032 - val_loss: 1.3720\n",
      "Epoch 1979/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8115 - val_loss: 1.3835\n",
      "Epoch 1980/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8047 - val_loss: 1.3861\n",
      "Epoch 1981/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8030 - val_loss: 1.3880\n",
      "Epoch 1982/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8114 - val_loss: 1.3505\n",
      "Epoch 1983/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8032 - val_loss: 1.3783\n",
      "Epoch 1984/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8012 - val_loss: 1.3776\n",
      "Epoch 1985/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8008 - val_loss: 1.3717\n",
      "Epoch 1986/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8112 - val_loss: 1.3749\n",
      "Epoch 1987/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8163 - val_loss: 1.3814\n",
      "Epoch 1988/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8125 - val_loss: 1.3630\n",
      "Epoch 1989/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8035 - val_loss: 1.3626\n",
      "Epoch 1990/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 490us/step - loss: 0.8138 - val_loss: 1.3638\n",
      "Epoch 1991/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8098 - val_loss: 1.3523\n",
      "Epoch 1992/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8072 - val_loss: 1.3594\n",
      "Epoch 1993/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8072 - val_loss: 1.3586\n",
      "Epoch 1994/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7866 - val_loss: 1.3575\n",
      "Epoch 1995/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.8149 - val_loss: 1.3465\n",
      "Epoch 1996/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8174 - val_loss: 1.3606\n",
      "Epoch 1997/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8225 - val_loss: 1.3644\n",
      "Epoch 1998/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8031 - val_loss: 1.3676\n",
      "Epoch 1999/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8145 - val_loss: 1.3515\n",
      "Epoch 2000/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7919 - val_loss: 1.3545\n",
      "Epoch 2001/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8151 - val_loss: 1.3652\n",
      "Epoch 2002/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8174 - val_loss: 1.3430\n",
      "Epoch 2003/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8105 - val_loss: 1.3448\n",
      "Epoch 2004/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8158 - val_loss: 1.3645\n",
      "Epoch 2005/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8029 - val_loss: 1.3614\n",
      "Epoch 2006/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8007 - val_loss: 1.3632\n",
      "Epoch 2007/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8198 - val_loss: 1.3369\n",
      "Epoch 2008/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8015 - val_loss: 1.3499\n",
      "Epoch 2009/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8015 - val_loss: 1.3466\n",
      "Epoch 2010/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8090 - val_loss: 1.3366\n",
      "Epoch 2011/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8206 - val_loss: 1.3374\n",
      "Epoch 2012/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8092 - val_loss: 1.3559\n",
      "Epoch 2013/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8125 - val_loss: 1.3645\n",
      "Epoch 2014/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8041 - val_loss: 1.3530\n",
      "Epoch 2015/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8091 - val_loss: 1.3832\n",
      "Epoch 2016/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8054 - val_loss: 1.3483\n",
      "Epoch 2017/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8061 - val_loss: 1.3571\n",
      "Epoch 2018/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8058 - val_loss: 1.3716\n",
      "Epoch 2019/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8144 - val_loss: 1.3514\n",
      "Epoch 2020/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8191 - val_loss: 1.3354\n",
      "Epoch 2021/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8065 - val_loss: 1.3398\n",
      "Epoch 2022/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8009 - val_loss: 1.3467\n",
      "Epoch 2023/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8108 - val_loss: 1.3504\n",
      "Epoch 2024/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8021 - val_loss: 1.3701\n",
      "Epoch 2025/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8038 - val_loss: 1.3572\n",
      "Epoch 2026/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8106 - val_loss: 1.3583\n",
      "Epoch 2027/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7955 - val_loss: 1.3621\n",
      "Epoch 2028/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8070 - val_loss: 1.3754\n",
      "Epoch 2029/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7963 - val_loss: 1.3812\n",
      "Epoch 2030/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8055 - val_loss: 1.3686\n",
      "Epoch 2031/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8141 - val_loss: 1.3472\n",
      "Epoch 2032/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7991 - val_loss: 1.3520\n",
      "Epoch 2033/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8048 - val_loss: 1.3521\n",
      "Epoch 2034/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7933 - val_loss: 1.3591\n",
      "Epoch 2035/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7920 - val_loss: 1.3743\n",
      "Epoch 2036/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8105 - val_loss: 1.3829\n",
      "Epoch 2037/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8028 - val_loss: 1.3805\n",
      "Epoch 2038/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8134 - val_loss: 1.3715\n",
      "Epoch 2039/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8096 - val_loss: 1.3699\n",
      "Epoch 2040/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7986 - val_loss: 1.3762\n",
      "Epoch 2041/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7960 - val_loss: 1.3733\n",
      "Epoch 2042/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8049 - val_loss: 1.3593\n",
      "Epoch 2043/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8055 - val_loss: 1.3597\n",
      "Epoch 2044/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8078 - val_loss: 1.3677\n",
      "Epoch 2045/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8126 - val_loss: 1.3702\n",
      "Epoch 2046/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8114 - val_loss: 1.3796\n",
      "Epoch 2047/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8160 - val_loss: 1.3798\n",
      "Epoch 2048/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8067 - val_loss: 1.3689\n",
      "Epoch 2049/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8099 - val_loss: 1.3716\n",
      "Epoch 2050/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8039 - val_loss: 1.3606\n",
      "Epoch 2051/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8026 - val_loss: 1.3657\n",
      "Epoch 2052/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8035 - val_loss: 1.3924\n",
      "Epoch 2053/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8102 - val_loss: 1.3744\n",
      "Epoch 2054/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8109 - val_loss: 1.3804\n",
      "Epoch 2055/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7979 - val_loss: 1.3770\n",
      "Epoch 2056/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8068 - val_loss: 1.3955\n",
      "Epoch 2057/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8043 - val_loss: 1.3642\n",
      "Epoch 2058/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8390 - val_loss: 1.3692\n",
      "Epoch 2059/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8118 - val_loss: 1.3655\n",
      "Epoch 2060/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8112 - val_loss: 1.3443\n",
      "Epoch 2061/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7925 - val_loss: 1.3496\n",
      "Epoch 2062/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8172 - val_loss: 1.3378\n",
      "Epoch 2063/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7895 - val_loss: 1.3555\n",
      "Epoch 2064/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8121 - val_loss: 1.3640\n",
      "Epoch 2065/5000\n",
      "572/572 [==============================] - 0s 565us/step - loss: 0.8258 - val_loss: 1.3559\n",
      "Epoch 2066/5000\n",
      "572/572 [==============================] - 0s 582us/step - loss: 0.8030 - val_loss: 1.3581\n",
      "Epoch 2067/5000\n",
      "572/572 [==============================] - 0s 563us/step - loss: 0.8089 - val_loss: 1.3542\n",
      "Epoch 2068/5000\n",
      "572/572 [==============================] - 0s 563us/step - loss: 0.8147 - val_loss: 1.3403\n",
      "Epoch 2069/5000\n",
      "572/572 [==============================] - 0s 547us/step - loss: 0.8114 - val_loss: 1.3534\n",
      "Epoch 2070/5000\n",
      "572/572 [==============================] - 0s 553us/step - loss: 0.8068 - val_loss: 1.3640\n",
      "Epoch 2071/5000\n",
      "572/572 [==============================] - 0s 565us/step - loss: 0.8050 - val_loss: 1.3490\n",
      "Epoch 2072/5000\n",
      "572/572 [==============================] - 0s 568us/step - loss: 0.8128 - val_loss: 1.3529\n",
      "Epoch 2073/5000\n",
      "572/572 [==============================] - 0s 576us/step - loss: 0.8010 - val_loss: 1.3601\n",
      "Epoch 2074/5000\n",
      "572/572 [==============================] - 0s 531us/step - loss: 0.7969 - val_loss: 1.3590\n",
      "Epoch 2075/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8152 - val_loss: 1.3596\n",
      "Epoch 2076/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8116 - val_loss: 1.3510\n",
      "Epoch 2077/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8022 - val_loss: 1.3495\n",
      "Epoch 2078/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8146 - val_loss: 1.3700\n",
      "Epoch 2079/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8078 - val_loss: 1.3784\n",
      "Epoch 2080/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8058 - val_loss: 1.3848\n",
      "Epoch 2081/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8071 - val_loss: 1.3676\n",
      "Epoch 2082/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7998 - val_loss: 1.3712\n",
      "Epoch 2083/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8132 - val_loss: 1.3797\n",
      "Epoch 2084/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8061 - val_loss: 1.3665\n",
      "Epoch 2085/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8041 - val_loss: 1.3541\n",
      "Epoch 2086/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8055 - val_loss: 1.3394\n",
      "Epoch 2087/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8015 - val_loss: 1.3520\n",
      "Epoch 2088/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7972 - val_loss: 1.3407\n",
      "Epoch 2089/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7991 - val_loss: 1.3430\n",
      "Epoch 2090/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7973 - val_loss: 1.3463\n",
      "Epoch 2091/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7993 - val_loss: 1.3552\n",
      "Epoch 2092/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8117 - val_loss: 1.3497\n",
      "Epoch 2093/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8036 - val_loss: 1.3469\n",
      "Epoch 2094/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7940 - val_loss: 1.3363\n",
      "Epoch 2095/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8110 - val_loss: 1.3562\n",
      "Epoch 2096/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7913 - val_loss: 1.3605\n",
      "Epoch 2097/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7991 - val_loss: 1.3546\n",
      "Epoch 2098/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7991 - val_loss: 1.3819\n",
      "Epoch 2099/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8172 - val_loss: 1.3708\n",
      "Epoch 2100/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8147 - val_loss: 1.3648\n",
      "Epoch 2101/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8168 - val_loss: 1.3616\n",
      "Epoch 2102/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8092 - val_loss: 1.3662\n",
      "Epoch 2103/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7913 - val_loss: 1.3674\n",
      "Epoch 2104/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8033 - val_loss: 1.3568\n",
      "Epoch 2105/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8001 - val_loss: 1.3416\n",
      "Epoch 2106/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8086 - val_loss: 1.3478\n",
      "Epoch 2107/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8254 - val_loss: 1.3523\n",
      "Epoch 2108/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8031 - val_loss: 1.3534\n",
      "Epoch 2109/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8038 - val_loss: 1.3612\n",
      "Epoch 2110/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8134 - val_loss: 1.3458\n",
      "Epoch 2111/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8040 - val_loss: 1.3442\n",
      "Epoch 2112/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8029 - val_loss: 1.3545\n",
      "Epoch 2113/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8095 - val_loss: 1.3551\n",
      "Epoch 2114/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8073 - val_loss: 1.3691\n",
      "Epoch 2115/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8037 - val_loss: 1.3760\n",
      "Epoch 2116/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8014 - val_loss: 1.3751\n",
      "Epoch 2117/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8105 - val_loss: 1.3714\n",
      "Epoch 2118/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7920 - val_loss: 1.3834\n",
      "Epoch 2119/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7945 - val_loss: 1.3737\n",
      "Epoch 2120/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8032 - val_loss: 1.3617\n",
      "Epoch 2121/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7975 - val_loss: 1.3756\n",
      "Epoch 2122/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8066 - val_loss: 1.3582\n",
      "Epoch 2123/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8044 - val_loss: 1.3621\n",
      "Epoch 2124/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7905 - val_loss: 1.3608\n",
      "Epoch 2125/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8157 - val_loss: 1.3625\n",
      "Epoch 2126/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8166 - val_loss: 1.3632\n",
      "Epoch 2127/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8299 - val_loss: 1.3606\n",
      "Epoch 2128/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8036 - val_loss: 1.3699\n",
      "Epoch 2129/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7983 - val_loss: 1.3712\n",
      "Epoch 2130/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8011 - val_loss: 1.3481\n",
      "Epoch 2131/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.8016 - val_loss: 1.3473\n",
      "Epoch 2132/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8068 - val_loss: 1.3552\n",
      "Epoch 2133/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8009 - val_loss: 1.3647\n",
      "Epoch 2134/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8052 - val_loss: 1.3617\n",
      "Epoch 2135/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8103 - val_loss: 1.3651\n",
      "Epoch 2136/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7959 - val_loss: 1.3510\n",
      "Epoch 2137/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7804 - val_loss: 1.3571\n",
      "Epoch 2138/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7882 - val_loss: 1.3702\n",
      "Epoch 2139/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8126 - val_loss: 1.3558\n",
      "Epoch 2140/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8181 - val_loss: 1.3703\n",
      "Epoch 2141/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8123 - val_loss: 1.3725\n",
      "Epoch 2142/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 489us/step - loss: 0.7970 - val_loss: 1.3594\n",
      "Epoch 2143/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8227 - val_loss: 1.3535\n",
      "Epoch 2144/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7858 - val_loss: 1.3535\n",
      "Epoch 2145/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8097 - val_loss: 1.3534\n",
      "Epoch 2146/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8010 - val_loss: 1.3513\n",
      "Epoch 2147/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8188 - val_loss: 1.3449\n",
      "Epoch 2148/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8122 - val_loss: 1.3574\n",
      "Epoch 2149/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8133 - val_loss: 1.3627\n",
      "Epoch 2150/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7985 - val_loss: 1.3569\n",
      "Epoch 2151/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8243 - val_loss: 1.3629\n",
      "Epoch 2152/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8076 - val_loss: 1.3733\n",
      "Epoch 2153/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8066 - val_loss: 1.3760\n",
      "Epoch 2154/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7985 - val_loss: 1.3655\n",
      "Epoch 2155/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8129 - val_loss: 1.3754\n",
      "Epoch 2156/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8025 - val_loss: 1.3802\n",
      "Epoch 2157/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8094 - val_loss: 1.3638\n",
      "Epoch 2158/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8059 - val_loss: 1.3540\n",
      "Epoch 2159/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8053 - val_loss: 1.3531\n",
      "Epoch 2160/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7962 - val_loss: 1.3530\n",
      "Epoch 2161/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8098 - val_loss: 1.3678\n",
      "Epoch 2162/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7912 - val_loss: 1.3697\n",
      "Epoch 2163/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7936 - val_loss: 1.3717\n",
      "Epoch 2164/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7987 - val_loss: 1.3576\n",
      "Epoch 2165/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7848 - val_loss: 1.3563\n",
      "Epoch 2166/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7908 - val_loss: 1.3674\n",
      "Epoch 2167/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8013 - val_loss: 1.3725\n",
      "Epoch 2168/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8020 - val_loss: 1.3591\n",
      "Epoch 2169/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8112 - val_loss: 1.3652\n",
      "Epoch 2170/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8015 - val_loss: 1.3465\n",
      "Epoch 2171/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8146 - val_loss: 1.3369\n",
      "Epoch 2172/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8024 - val_loss: 1.3532\n",
      "Epoch 2173/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8099 - val_loss: 1.3656\n",
      "Epoch 2174/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8033 - val_loss: 1.3548\n",
      "Epoch 2175/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8181 - val_loss: 1.3607\n",
      "Epoch 2176/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8035 - val_loss: 1.3534\n",
      "Epoch 2177/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8236 - val_loss: 1.3811\n",
      "Epoch 2178/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7979 - val_loss: 1.3891\n",
      "Epoch 2179/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8036 - val_loss: 1.3780\n",
      "Epoch 2180/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8051 - val_loss: 1.3664\n",
      "Epoch 2181/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8164 - val_loss: 1.3466\n",
      "Epoch 2182/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7951 - val_loss: 1.3511\n",
      "Epoch 2183/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8058 - val_loss: 1.3409\n",
      "Epoch 2184/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.8170 - val_loss: 1.3434\n",
      "Epoch 2185/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8135 - val_loss: 1.3400\n",
      "Epoch 2186/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8116 - val_loss: 1.3459\n",
      "Epoch 2187/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7978 - val_loss: 1.3521\n",
      "Epoch 2188/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8118 - val_loss: 1.3873\n",
      "Epoch 2189/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8118 - val_loss: 1.3576\n",
      "Epoch 2190/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8058 - val_loss: 1.3531\n",
      "Epoch 2191/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.8130 - val_loss: 1.3494\n",
      "Epoch 2192/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7950 - val_loss: 1.3505\n",
      "Epoch 2193/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8104 - val_loss: 1.3413\n",
      "Epoch 2194/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8044 - val_loss: 1.3572\n",
      "Epoch 2195/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8124 - val_loss: 1.3512\n",
      "Epoch 2196/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8030 - val_loss: 1.3719\n",
      "Epoch 2197/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7943 - val_loss: 1.3706\n",
      "Epoch 2198/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8090 - val_loss: 1.3633\n",
      "Epoch 2199/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7916 - val_loss: 1.3485\n",
      "Epoch 2200/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7936 - val_loss: 1.3517\n",
      "Epoch 2201/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7934 - val_loss: 1.3663\n",
      "Epoch 2202/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8070 - val_loss: 1.3652\n",
      "Epoch 2203/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8083 - val_loss: 1.3576\n",
      "Epoch 2204/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8074 - val_loss: 1.3390\n",
      "Epoch 2205/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8053 - val_loss: 1.3395\n",
      "Epoch 2206/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8067 - val_loss: 1.3289\n",
      "Epoch 2207/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8124 - val_loss: 1.3402\n",
      "Epoch 2208/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8044 - val_loss: 1.3542\n",
      "Epoch 2209/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7947 - val_loss: 1.3536\n",
      "Epoch 2210/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8210 - val_loss: 1.3635\n",
      "Epoch 2211/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.8149 - val_loss: 1.3619\n",
      "Epoch 2212/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7979 - val_loss: 1.3546\n",
      "Epoch 2213/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8174 - val_loss: 1.3464\n",
      "Epoch 2214/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7963 - val_loss: 1.3755\n",
      "Epoch 2215/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8052 - val_loss: 1.3687\n",
      "Epoch 2216/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8047 - val_loss: 1.3609\n",
      "Epoch 2217/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8032 - val_loss: 1.3675\n",
      "Epoch 2218/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7941 - val_loss: 1.3435\n",
      "Epoch 2219/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7999 - val_loss: 1.3474\n",
      "Epoch 2220/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7839 - val_loss: 1.3516\n",
      "Epoch 2221/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7892 - val_loss: 1.3548\n",
      "Epoch 2222/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7965 - val_loss: 1.3680\n",
      "Epoch 2223/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8026 - val_loss: 1.3630\n",
      "Epoch 2224/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7961 - val_loss: 1.3629\n",
      "Epoch 2225/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8118 - val_loss: 1.3735\n",
      "Epoch 2226/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8069 - val_loss: 1.3677\n",
      "Epoch 2227/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8094 - val_loss: 1.3584\n",
      "Epoch 2228/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7943 - val_loss: 1.3583\n",
      "Epoch 2229/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7987 - val_loss: 1.3554\n",
      "Epoch 2230/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7989 - val_loss: 1.3492\n",
      "Epoch 2231/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8200 - val_loss: 1.3394\n",
      "Epoch 2232/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8024 - val_loss: 1.3396\n",
      "Epoch 2233/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8000 - val_loss: 1.3424\n",
      "Epoch 2234/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7976 - val_loss: 1.3457\n",
      "Epoch 2235/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7964 - val_loss: 1.3575\n",
      "Epoch 2236/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7962 - val_loss: 1.3567\n",
      "Epoch 2237/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8045 - val_loss: 1.3544\n",
      "Epoch 2238/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7951 - val_loss: 1.3552\n",
      "Epoch 2239/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8065 - val_loss: 1.3413\n",
      "Epoch 2240/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8004 - val_loss: 1.3489\n",
      "Epoch 2241/5000\n",
      "572/572 [==============================] - 0s 509us/step - loss: 0.8064 - val_loss: 1.3384\n",
      "Epoch 2242/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8028 - val_loss: 1.3633\n",
      "Epoch 2243/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7894 - val_loss: 1.3663\n",
      "Epoch 2244/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7883 - val_loss: 1.3670\n",
      "Epoch 2245/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7997 - val_loss: 1.3685\n",
      "Epoch 2246/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8083 - val_loss: 1.3774\n",
      "Epoch 2247/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8092 - val_loss: 1.3587\n",
      "Epoch 2248/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7970 - val_loss: 1.3420\n",
      "Epoch 2249/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8161 - val_loss: 1.3374\n",
      "Epoch 2250/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8141 - val_loss: 1.3579\n",
      "Epoch 2251/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7972 - val_loss: 1.3657\n",
      "Epoch 2252/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8199 - val_loss: 1.3442\n",
      "Epoch 2253/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7921 - val_loss: 1.3629\n",
      "Epoch 2254/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8007 - val_loss: 1.3756\n",
      "Epoch 2255/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8023 - val_loss: 1.3855\n",
      "Epoch 2256/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8171 - val_loss: 1.3807\n",
      "Epoch 2257/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8024 - val_loss: 1.3507\n",
      "Epoch 2258/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8048 - val_loss: 1.3619\n",
      "Epoch 2259/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8070 - val_loss: 1.3634\n",
      "Epoch 2260/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8095 - val_loss: 1.3519\n",
      "Epoch 2261/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8091 - val_loss: 1.3432\n",
      "Epoch 2262/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8099 - val_loss: 1.3453\n",
      "Epoch 2263/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8145 - val_loss: 1.3716\n",
      "Epoch 2264/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8139 - val_loss: 1.3646\n",
      "Epoch 2265/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8045 - val_loss: 1.3651\n",
      "Epoch 2266/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8003 - val_loss: 1.3452\n",
      "Epoch 2267/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8015 - val_loss: 1.3539\n",
      "Epoch 2268/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8085 - val_loss: 1.3479\n",
      "Epoch 2269/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8101 - val_loss: 1.3446\n",
      "Epoch 2270/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7997 - val_loss: 1.3592\n",
      "Epoch 2271/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7961 - val_loss: 1.3510\n",
      "Epoch 2272/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8153 - val_loss: 1.3536\n",
      "Epoch 2273/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7981 - val_loss: 1.3492\n",
      "Epoch 2274/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8128 - val_loss: 1.3550\n",
      "Epoch 2275/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8013 - val_loss: 1.3673\n",
      "Epoch 2276/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8070 - val_loss: 1.3665\n",
      "Epoch 2277/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7915 - val_loss: 1.3804\n",
      "Epoch 2278/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8001 - val_loss: 1.3737\n",
      "Epoch 2279/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7943 - val_loss: 1.3592\n",
      "Epoch 2280/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7902 - val_loss: 1.3551\n",
      "Epoch 2281/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7937 - val_loss: 1.3643\n",
      "Epoch 2282/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7984 - val_loss: 1.3444\n",
      "Epoch 2283/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8029 - val_loss: 1.3413\n",
      "Epoch 2284/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7806 - val_loss: 1.3528\n",
      "Epoch 2285/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7921 - val_loss: 1.3700\n",
      "Epoch 2286/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8192 - val_loss: 1.3544\n",
      "Epoch 2287/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7914 - val_loss: 1.3556\n",
      "Epoch 2288/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7966 - val_loss: 1.3484\n",
      "Epoch 2289/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.8154 - val_loss: 1.3455\n",
      "Epoch 2290/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8074 - val_loss: 1.3591\n",
      "Epoch 2291/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8052 - val_loss: 1.3486\n",
      "Epoch 2292/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7816 - val_loss: 1.3486\n",
      "Epoch 2293/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8140 - val_loss: 1.3634\n",
      "Epoch 2294/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 486us/step - loss: 0.8065 - val_loss: 1.3430\n",
      "Epoch 2295/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8108 - val_loss: 1.3579\n",
      "Epoch 2296/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8019 - val_loss: 1.3599\n",
      "Epoch 2297/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7967 - val_loss: 1.3598\n",
      "Epoch 2298/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7990 - val_loss: 1.3497\n",
      "Epoch 2299/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7928 - val_loss: 1.3422\n",
      "Epoch 2300/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7926 - val_loss: 1.3530\n",
      "Epoch 2301/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8022 - val_loss: 1.3530\n",
      "Epoch 2302/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8005 - val_loss: 1.3381\n",
      "Epoch 2303/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8071 - val_loss: 1.3616\n",
      "Epoch 2304/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8021 - val_loss: 1.3844\n",
      "Epoch 2305/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8143 - val_loss: 1.3696\n",
      "Epoch 2306/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7910 - val_loss: 1.3758\n",
      "Epoch 2307/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8054 - val_loss: 1.3573\n",
      "Epoch 2308/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8004 - val_loss: 1.3568\n",
      "Epoch 2309/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8034 - val_loss: 1.3597\n",
      "Epoch 2310/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8117 - val_loss: 1.3701\n",
      "Epoch 2311/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8050 - val_loss: 1.3577\n",
      "Epoch 2312/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8029 - val_loss: 1.3584\n",
      "Epoch 2313/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8005 - val_loss: 1.3581\n",
      "Epoch 2314/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7926 - val_loss: 1.3641\n",
      "Epoch 2315/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7988 - val_loss: 1.3800\n",
      "Epoch 2316/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7990 - val_loss: 1.3506\n",
      "Epoch 2317/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8148 - val_loss: 1.3671\n",
      "Epoch 2318/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8034 - val_loss: 1.3685\n",
      "Epoch 2319/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8066 - val_loss: 1.3429\n",
      "Epoch 2320/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8100 - val_loss: 1.3520\n",
      "Epoch 2321/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.7981 - val_loss: 1.3511\n",
      "Epoch 2322/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8027 - val_loss: 1.3788\n",
      "Epoch 2323/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8086 - val_loss: 1.3564\n",
      "Epoch 2324/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7903 - val_loss: 1.3759\n",
      "Epoch 2325/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8031 - val_loss: 1.3602\n",
      "Epoch 2326/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8043 - val_loss: 1.3489\n",
      "Epoch 2327/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8034 - val_loss: 1.3693\n",
      "Epoch 2328/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7939 - val_loss: 1.3453\n",
      "Epoch 2329/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8124 - val_loss: 1.3527\n",
      "Epoch 2330/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7964 - val_loss: 1.3488\n",
      "Epoch 2331/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8079 - val_loss: 1.3676\n",
      "Epoch 2332/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8016 - val_loss: 1.3630\n",
      "Epoch 2333/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8113 - val_loss: 1.3775\n",
      "Epoch 2334/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8135 - val_loss: 1.3553\n",
      "Epoch 2335/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7945 - val_loss: 1.3549\n",
      "Epoch 2336/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7941 - val_loss: 1.3474\n",
      "Epoch 2337/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7962 - val_loss: 1.3627\n",
      "Epoch 2338/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8117 - val_loss: 1.3557\n",
      "Epoch 2339/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7887 - val_loss: 1.3565\n",
      "Epoch 2340/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8055 - val_loss: 1.3645\n",
      "Epoch 2341/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7976 - val_loss: 1.3669\n",
      "Epoch 2342/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8070 - val_loss: 1.3605\n",
      "Epoch 2343/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8033 - val_loss: 1.3703\n",
      "Epoch 2344/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7988 - val_loss: 1.3590\n",
      "Epoch 2345/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7983 - val_loss: 1.3632\n",
      "Epoch 2346/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8171 - val_loss: 1.3714\n",
      "Epoch 2347/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7965 - val_loss: 1.3740\n",
      "Epoch 2348/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7947 - val_loss: 1.3574\n",
      "Epoch 2349/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8104 - val_loss: 1.3485\n",
      "Epoch 2350/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7999 - val_loss: 1.3651\n",
      "Epoch 2351/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7984 - val_loss: 1.3724\n",
      "Epoch 2352/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8036 - val_loss: 1.3819\n",
      "Epoch 2353/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8070 - val_loss: 1.3796\n",
      "Epoch 2354/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8100 - val_loss: 1.3832\n",
      "Epoch 2355/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7904 - val_loss: 1.3674\n",
      "Epoch 2356/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8002 - val_loss: 1.3609\n",
      "Epoch 2357/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7910 - val_loss: 1.3693\n",
      "Epoch 2358/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8162 - val_loss: 1.3638\n",
      "Epoch 2359/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7867 - val_loss: 1.3461\n",
      "Epoch 2360/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8086 - val_loss: 1.3474\n",
      "Epoch 2361/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7955 - val_loss: 1.3638\n",
      "Epoch 2362/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7928 - val_loss: 1.3694\n",
      "Epoch 2363/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8128 - val_loss: 1.3770\n",
      "Epoch 2364/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7961 - val_loss: 1.3709\n",
      "Epoch 2365/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7948 - val_loss: 1.3445\n",
      "Epoch 2366/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8027 - val_loss: 1.3453\n",
      "Epoch 2367/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7911 - val_loss: 1.3379\n",
      "Epoch 2368/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7866 - val_loss: 1.3530\n",
      "Epoch 2369/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8115 - val_loss: 1.3723\n",
      "Epoch 2370/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7972 - val_loss: 1.3608\n",
      "Epoch 2371/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7934 - val_loss: 1.3720\n",
      "Epoch 2372/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7993 - val_loss: 1.3528\n",
      "Epoch 2373/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7981 - val_loss: 1.3548\n",
      "Epoch 2374/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8040 - val_loss: 1.3555\n",
      "Epoch 2375/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7967 - val_loss: 1.3563\n",
      "Epoch 2376/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7978 - val_loss: 1.3563\n",
      "Epoch 2377/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7952 - val_loss: 1.3682\n",
      "Epoch 2378/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8100 - val_loss: 1.3661\n",
      "Epoch 2379/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7961 - val_loss: 1.3964\n",
      "Epoch 2380/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7884 - val_loss: 1.3827\n",
      "Epoch 2381/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7943 - val_loss: 1.3786\n",
      "Epoch 2382/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7969 - val_loss: 1.3672\n",
      "Epoch 2383/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7921 - val_loss: 1.3438\n",
      "Epoch 2384/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7955 - val_loss: 1.3487\n",
      "Epoch 2385/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8010 - val_loss: 1.3431\n",
      "Epoch 2386/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7989 - val_loss: 1.3485\n",
      "Epoch 2387/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8180 - val_loss: 1.3483\n",
      "Epoch 2388/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8196 - val_loss: 1.3641\n",
      "Epoch 2389/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.8192 - val_loss: 1.3483\n",
      "Epoch 2390/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7969 - val_loss: 1.3482\n",
      "Epoch 2391/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8068 - val_loss: 1.3371\n",
      "Epoch 2392/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7938 - val_loss: 1.3401\n",
      "Epoch 2393/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7945 - val_loss: 1.3444\n",
      "Epoch 2394/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8019 - val_loss: 1.3651\n",
      "Epoch 2395/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8106 - val_loss: 1.3693\n",
      "Epoch 2396/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7845 - val_loss: 1.3520\n",
      "Epoch 2397/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8007 - val_loss: 1.3470\n",
      "Epoch 2398/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7945 - val_loss: 1.3408\n",
      "Epoch 2399/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7907 - val_loss: 1.3596\n",
      "Epoch 2400/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7901 - val_loss: 1.3457\n",
      "Epoch 2401/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8024 - val_loss: 1.3622\n",
      "Epoch 2402/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8057 - val_loss: 1.3661\n",
      "Epoch 2403/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7974 - val_loss: 1.3515\n",
      "Epoch 2404/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7867 - val_loss: 1.3439\n",
      "Epoch 2405/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7993 - val_loss: 1.3485\n",
      "Epoch 2406/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8009 - val_loss: 1.3541\n",
      "Epoch 2407/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7930 - val_loss: 1.3435\n",
      "Epoch 2408/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8060 - val_loss: 1.3432\n",
      "Epoch 2409/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7897 - val_loss: 1.3693\n",
      "Epoch 2410/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7953 - val_loss: 1.3630\n",
      "Epoch 2411/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8389 - val_loss: 1.3643\n",
      "Epoch 2412/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7972 - val_loss: 1.3871\n",
      "Epoch 2413/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7893 - val_loss: 1.3636\n",
      "Epoch 2414/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7842 - val_loss: 1.3650\n",
      "Epoch 2415/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7924 - val_loss: 1.3429\n",
      "Epoch 2416/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.8084 - val_loss: 1.3391\n",
      "Epoch 2417/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7983 - val_loss: 1.3548\n",
      "Epoch 2418/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7959 - val_loss: 1.3456\n",
      "Epoch 2419/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7905 - val_loss: 1.3301\n",
      "Epoch 2420/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7855 - val_loss: 1.3403\n",
      "Epoch 2421/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8020 - val_loss: 1.3393\n",
      "Epoch 2422/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7989 - val_loss: 1.3474\n",
      "Epoch 2423/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7760 - val_loss: 1.3562\n",
      "Epoch 2424/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8099 - val_loss: 1.3640\n",
      "Epoch 2425/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7986 - val_loss: 1.3597\n",
      "Epoch 2426/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7979 - val_loss: 1.3634\n",
      "Epoch 2427/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8190 - val_loss: 1.3663\n",
      "Epoch 2428/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7864 - val_loss: 1.3825\n",
      "Epoch 2429/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7987 - val_loss: 1.3632\n",
      "Epoch 2430/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7903 - val_loss: 1.3768\n",
      "Epoch 2431/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8080 - val_loss: 1.3634\n",
      "Epoch 2432/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8038 - val_loss: 1.3693\n",
      "Epoch 2433/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8059 - val_loss: 1.3582\n",
      "Epoch 2434/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8002 - val_loss: 1.3449\n",
      "Epoch 2435/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7898 - val_loss: 1.3429\n",
      "Epoch 2436/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7825 - val_loss: 1.3486\n",
      "Epoch 2437/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7900 - val_loss: 1.3269\n",
      "Epoch 2438/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7796 - val_loss: 1.3488\n",
      "Epoch 2439/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8016 - val_loss: 1.3480\n",
      "Epoch 2440/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7972 - val_loss: 1.3617\n",
      "Epoch 2441/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8125 - val_loss: 1.3449\n",
      "Epoch 2442/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8047 - val_loss: 1.3627\n",
      "Epoch 2443/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8062 - val_loss: 1.3664\n",
      "Epoch 2444/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8002 - val_loss: 1.3669\n",
      "Epoch 2445/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7858 - val_loss: 1.3641\n",
      "Epoch 2446/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 483us/step - loss: 0.8107 - val_loss: 1.3493\n",
      "Epoch 2447/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.8024 - val_loss: 1.3643\n",
      "Epoch 2448/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7877 - val_loss: 1.3743\n",
      "Epoch 2449/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8026 - val_loss: 1.3446\n",
      "Epoch 2450/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7934 - val_loss: 1.3512\n",
      "Epoch 2451/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8011 - val_loss: 1.3472\n",
      "Epoch 2452/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8002 - val_loss: 1.3460\n",
      "Epoch 2453/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8031 - val_loss: 1.3538\n",
      "Epoch 2454/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8063 - val_loss: 1.3586\n",
      "Epoch 2455/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8036 - val_loss: 1.3454\n",
      "Epoch 2456/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7945 - val_loss: 1.3549\n",
      "Epoch 2457/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7984 - val_loss: 1.3400\n",
      "Epoch 2458/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7916 - val_loss: 1.3317\n",
      "Epoch 2459/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8013 - val_loss: 1.3530\n",
      "Epoch 2460/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8007 - val_loss: 1.3381\n",
      "Epoch 2461/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8074 - val_loss: 1.3497\n",
      "Epoch 2462/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8066 - val_loss: 1.3509\n",
      "Epoch 2463/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7960 - val_loss: 1.3454\n",
      "Epoch 2464/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8141 - val_loss: 1.3360\n",
      "Epoch 2465/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7924 - val_loss: 1.3373\n",
      "Epoch 2466/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7877 - val_loss: 1.3516\n",
      "Epoch 2467/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8061 - val_loss: 1.3772\n",
      "Epoch 2468/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8112 - val_loss: 1.3812\n",
      "Epoch 2469/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8008 - val_loss: 1.3434\n",
      "Epoch 2470/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8025 - val_loss: 1.3288\n",
      "Epoch 2471/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7852 - val_loss: 1.3472\n",
      "Epoch 2472/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7957 - val_loss: 1.3698\n",
      "Epoch 2473/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7950 - val_loss: 1.3546\n",
      "Epoch 2474/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8009 - val_loss: 1.3608\n",
      "Epoch 2475/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7858 - val_loss: 1.3719\n",
      "Epoch 2476/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8094 - val_loss: 1.3784\n",
      "Epoch 2477/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7899 - val_loss: 1.3840\n",
      "Epoch 2478/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8009 - val_loss: 1.3818\n",
      "Epoch 2479/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7966 - val_loss: 1.3761\n",
      "Epoch 2480/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7986 - val_loss: 1.3634\n",
      "Epoch 2481/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8066 - val_loss: 1.3675\n",
      "Epoch 2482/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7811 - val_loss: 1.3700\n",
      "Epoch 2483/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8174 - val_loss: 1.3577\n",
      "Epoch 2484/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7928 - val_loss: 1.3677\n",
      "Epoch 2485/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8023 - val_loss: 1.3445\n",
      "Epoch 2486/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7930 - val_loss: 1.3608\n",
      "Epoch 2487/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7933 - val_loss: 1.3684\n",
      "Epoch 2488/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7930 - val_loss: 1.3563\n",
      "Epoch 2489/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7997 - val_loss: 1.3586\n",
      "Epoch 2490/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7970 - val_loss: 1.3528\n",
      "Epoch 2491/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8058 - val_loss: 1.3649\n",
      "Epoch 2492/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8303 - val_loss: 1.3387\n",
      "Epoch 2493/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8019 - val_loss: 1.3468\n",
      "Epoch 2494/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7952 - val_loss: 1.3511\n",
      "Epoch 2495/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8042 - val_loss: 1.3495\n",
      "Epoch 2496/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7972 - val_loss: 1.3630\n",
      "Epoch 2497/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7893 - val_loss: 1.3485\n",
      "Epoch 2498/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7954 - val_loss: 1.3554\n",
      "Epoch 2499/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8065 - val_loss: 1.3519\n",
      "Epoch 2500/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7942 - val_loss: 1.3537\n",
      "Epoch 2501/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7906 - val_loss: 1.3496\n",
      "Epoch 2502/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7800 - val_loss: 1.3611\n",
      "Epoch 2503/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7895 - val_loss: 1.3616\n",
      "Epoch 2504/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7918 - val_loss: 1.3508\n",
      "Epoch 2505/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8019 - val_loss: 1.3415\n",
      "Epoch 2506/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7990 - val_loss: 1.3441\n",
      "Epoch 2507/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7944 - val_loss: 1.3408\n",
      "Epoch 2508/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.7805 - val_loss: 1.3485\n",
      "Epoch 2509/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8015 - val_loss: 1.3546\n",
      "Epoch 2510/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8008 - val_loss: 1.3499\n",
      "Epoch 2511/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8028 - val_loss: 1.3535\n",
      "Epoch 2512/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7759 - val_loss: 1.3559\n",
      "Epoch 2513/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8046 - val_loss: 1.3578\n",
      "Epoch 2514/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7954 - val_loss: 1.3648\n",
      "Epoch 2515/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7977 - val_loss: 1.3732\n",
      "Epoch 2516/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7910 - val_loss: 1.3730\n",
      "Epoch 2517/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7963 - val_loss: 1.3443\n",
      "Epoch 2518/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7956 - val_loss: 1.3571\n",
      "Epoch 2519/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8017 - val_loss: 1.3730\n",
      "Epoch 2520/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8044 - val_loss: 1.3841\n",
      "Epoch 2521/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7899 - val_loss: 1.3733\n",
      "Epoch 2522/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.7826 - val_loss: 1.3821\n",
      "Epoch 2523/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8196 - val_loss: 1.3569\n",
      "Epoch 2524/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7877 - val_loss: 1.3560\n",
      "Epoch 2525/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8088 - val_loss: 1.3541\n",
      "Epoch 2526/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7907 - val_loss: 1.3519\n",
      "Epoch 2527/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8034 - val_loss: 1.3546\n",
      "Epoch 2528/5000\n",
      "572/572 [==============================] - 0s 502us/step - loss: 0.7980 - val_loss: 1.3511\n",
      "Epoch 2529/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.7978 - val_loss: 1.3479\n",
      "Epoch 2530/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8047 - val_loss: 1.3544\n",
      "Epoch 2531/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8009 - val_loss: 1.3496\n",
      "Epoch 2532/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8282 - val_loss: 1.3645\n",
      "Epoch 2533/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7985 - val_loss: 1.3387\n",
      "Epoch 2534/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8019 - val_loss: 1.3689\n",
      "Epoch 2535/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8063 - val_loss: 1.3519\n",
      "Epoch 2536/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7989 - val_loss: 1.3338\n",
      "Epoch 2537/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7803 - val_loss: 1.3525\n",
      "Epoch 2538/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8018 - val_loss: 1.3568\n",
      "Epoch 2539/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8087 - val_loss: 1.3676\n",
      "Epoch 2540/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8045 - val_loss: 1.3519\n",
      "Epoch 2541/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7893 - val_loss: 1.3615\n",
      "Epoch 2542/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7907 - val_loss: 1.3504\n",
      "Epoch 2543/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7941 - val_loss: 1.3414\n",
      "Epoch 2544/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7855 - val_loss: 1.3339\n",
      "Epoch 2545/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7991 - val_loss: 1.3454\n",
      "Epoch 2546/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7858 - val_loss: 1.3536\n",
      "Epoch 2547/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.7983 - val_loss: 1.3674\n",
      "Epoch 2548/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7934 - val_loss: 1.3332\n",
      "Epoch 2549/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7985 - val_loss: 1.3420\n",
      "Epoch 2550/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8127 - val_loss: 1.3223\n",
      "Epoch 2551/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.8070 - val_loss: 1.3399\n",
      "Epoch 2552/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7905 - val_loss: 1.3513\n",
      "Epoch 2553/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8001 - val_loss: 1.3635\n",
      "Epoch 2554/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7927 - val_loss: 1.3678\n",
      "Epoch 2555/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7900 - val_loss: 1.3965\n",
      "Epoch 2556/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8117 - val_loss: 1.3964\n",
      "Epoch 2557/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7860 - val_loss: 1.3866\n",
      "Epoch 2558/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7970 - val_loss: 1.3631\n",
      "Epoch 2559/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8052 - val_loss: 1.3519\n",
      "Epoch 2560/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7958 - val_loss: 1.3427\n",
      "Epoch 2561/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.7907 - val_loss: 1.3644\n",
      "Epoch 2562/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7901 - val_loss: 1.3580\n",
      "Epoch 2563/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7950 - val_loss: 1.3491\n",
      "Epoch 2564/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8077 - val_loss: 1.3563\n",
      "Epoch 2565/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7934 - val_loss: 1.3379\n",
      "Epoch 2566/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8005 - val_loss: 1.3463\n",
      "Epoch 2567/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7945 - val_loss: 1.3704\n",
      "Epoch 2568/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7923 - val_loss: 1.3572\n",
      "Epoch 2569/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8036 - val_loss: 1.3638\n",
      "Epoch 2570/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7949 - val_loss: 1.3762\n",
      "Epoch 2571/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8027 - val_loss: 1.3755\n",
      "Epoch 2572/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7952 - val_loss: 1.3456\n",
      "Epoch 2573/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7867 - val_loss: 1.3380\n",
      "Epoch 2574/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8026 - val_loss: 1.3399\n",
      "Epoch 2575/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7964 - val_loss: 1.3455\n",
      "Epoch 2576/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8049 - val_loss: 1.3595\n",
      "Epoch 2577/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7955 - val_loss: 1.3496\n",
      "Epoch 2578/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7986 - val_loss: 1.3337\n",
      "Epoch 2579/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8096 - val_loss: 1.3416\n",
      "Epoch 2580/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7962 - val_loss: 1.3584\n",
      "Epoch 2581/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8004 - val_loss: 1.3666\n",
      "Epoch 2582/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7879 - val_loss: 1.3674\n",
      "Epoch 2583/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7862 - val_loss: 1.3540\n",
      "Epoch 2584/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7959 - val_loss: 1.3622\n",
      "Epoch 2585/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7950 - val_loss: 1.3599\n",
      "Epoch 2586/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.8025 - val_loss: 1.3629\n",
      "Epoch 2587/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7994 - val_loss: 1.3504\n",
      "Epoch 2588/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7826 - val_loss: 1.3555\n",
      "Epoch 2589/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8020 - val_loss: 1.3559\n",
      "Epoch 2590/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8024 - val_loss: 1.3447\n",
      "Epoch 2591/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8014 - val_loss: 1.3516\n",
      "Epoch 2592/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7936 - val_loss: 1.3366\n",
      "Epoch 2593/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7953 - val_loss: 1.3583\n",
      "Epoch 2594/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7985 - val_loss: 1.3576\n",
      "Epoch 2595/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7918 - val_loss: 1.3485\n",
      "Epoch 2596/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7922 - val_loss: 1.3629\n",
      "Epoch 2597/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8013 - val_loss: 1.3503\n",
      "Epoch 2598/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 487us/step - loss: 0.7983 - val_loss: 1.3455\n",
      "Epoch 2599/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7994 - val_loss: 1.3344\n",
      "Epoch 2600/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7745 - val_loss: 1.3498\n",
      "Epoch 2601/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8339 - val_loss: 1.3414\n",
      "Epoch 2602/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7894 - val_loss: 1.3374\n",
      "Epoch 2603/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8010 - val_loss: 1.3327\n",
      "Epoch 2604/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7999 - val_loss: 1.3570\n",
      "Epoch 2605/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8004 - val_loss: 1.3365\n",
      "Epoch 2606/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8059 - val_loss: 1.3391\n",
      "Epoch 2607/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8004 - val_loss: 1.3387\n",
      "Epoch 2608/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7874 - val_loss: 1.3378\n",
      "Epoch 2609/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8004 - val_loss: 1.3391\n",
      "Epoch 2610/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7909 - val_loss: 1.3698\n",
      "Epoch 2611/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7873 - val_loss: 1.3706\n",
      "Epoch 2612/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7907 - val_loss: 1.3630\n",
      "Epoch 2613/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7938 - val_loss: 1.3589\n",
      "Epoch 2614/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8131 - val_loss: 1.3600\n",
      "Epoch 2615/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7777 - val_loss: 1.3486\n",
      "Epoch 2616/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7854 - val_loss: 1.3508\n",
      "Epoch 2617/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7970 - val_loss: 1.3692\n",
      "Epoch 2618/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7944 - val_loss: 1.3750\n",
      "Epoch 2619/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8109 - val_loss: 1.3401\n",
      "Epoch 2620/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7927 - val_loss: 1.3443\n",
      "Epoch 2621/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7813 - val_loss: 1.3462\n",
      "Epoch 2622/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.7909 - val_loss: 1.3467\n",
      "Epoch 2623/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8174 - val_loss: 1.3547\n",
      "Epoch 2624/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8020 - val_loss: 1.3551\n",
      "Epoch 2625/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7965 - val_loss: 1.3661\n",
      "Epoch 2626/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8116 - val_loss: 1.3598\n",
      "Epoch 2627/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7997 - val_loss: 1.3454\n",
      "Epoch 2628/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7999 - val_loss: 1.3360\n",
      "Epoch 2629/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8122 - val_loss: 1.3320\n",
      "Epoch 2630/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7881 - val_loss: 1.3528\n",
      "Epoch 2631/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7962 - val_loss: 1.3600\n",
      "Epoch 2632/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7982 - val_loss: 1.3480\n",
      "Epoch 2633/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7967 - val_loss: 1.3596\n",
      "Epoch 2634/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7868 - val_loss: 1.3452\n",
      "Epoch 2635/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7993 - val_loss: 1.3502\n",
      "Epoch 2636/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7902 - val_loss: 1.3817\n",
      "Epoch 2637/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7995 - val_loss: 1.3664\n",
      "Epoch 2638/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7970 - val_loss: 1.3624\n",
      "Epoch 2639/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8052 - val_loss: 1.3573\n",
      "Epoch 2640/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7923 - val_loss: 1.3515\n",
      "Epoch 2641/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7897 - val_loss: 1.3497\n",
      "Epoch 2642/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7708 - val_loss: 1.3575\n",
      "Epoch 2643/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8061 - val_loss: 1.3396\n",
      "Epoch 2644/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8218 - val_loss: 1.3238\n",
      "Epoch 2645/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7956 - val_loss: 1.3319\n",
      "Epoch 2646/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7945 - val_loss: 1.3226\n",
      "Epoch 2647/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7872 - val_loss: 1.3430\n",
      "Epoch 2648/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8121 - val_loss: 1.3370\n",
      "Epoch 2649/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8048 - val_loss: 1.3438\n",
      "Epoch 2650/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8085 - val_loss: 1.3315\n",
      "Epoch 2651/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8010 - val_loss: 1.3429\n",
      "Epoch 2652/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7839 - val_loss: 1.3384\n",
      "Epoch 2653/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7895 - val_loss: 1.3536\n",
      "Epoch 2654/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7786 - val_loss: 1.3490\n",
      "Epoch 2655/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7926 - val_loss: 1.3696\n",
      "Epoch 2656/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7969 - val_loss: 1.3692\n",
      "Epoch 2657/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7977 - val_loss: 1.3616\n",
      "Epoch 2658/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7869 - val_loss: 1.3698\n",
      "Epoch 2659/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7940 - val_loss: 1.3935\n",
      "Epoch 2660/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7900 - val_loss: 1.3803\n",
      "Epoch 2661/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8016 - val_loss: 1.3899\n",
      "Epoch 2662/5000\n",
      "572/572 [==============================] - 0s 513us/step - loss: 0.8038 - val_loss: 1.3551\n",
      "Epoch 2663/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8046 - val_loss: 1.3575\n",
      "Epoch 2664/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7854 - val_loss: 1.3463\n",
      "Epoch 2665/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8021 - val_loss: 1.3547\n",
      "Epoch 2666/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7939 - val_loss: 1.3691\n",
      "Epoch 2667/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7927 - val_loss: 1.3575\n",
      "Epoch 2668/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7947 - val_loss: 1.3521\n",
      "Epoch 2669/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7933 - val_loss: 1.3471\n",
      "Epoch 2670/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7883 - val_loss: 1.3467\n",
      "Epoch 2671/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.8110 - val_loss: 1.3351\n",
      "Epoch 2672/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7833 - val_loss: 1.3657\n",
      "Epoch 2673/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7939 - val_loss: 1.3604\n",
      "Epoch 2674/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8051 - val_loss: 1.3635\n",
      "Epoch 2675/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7865 - val_loss: 1.3395\n",
      "Epoch 2676/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7981 - val_loss: 1.3444\n",
      "Epoch 2677/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7950 - val_loss: 1.3614\n",
      "Epoch 2678/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7973 - val_loss: 1.3659\n",
      "Epoch 2679/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7924 - val_loss: 1.3619\n",
      "Epoch 2680/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7929 - val_loss: 1.3565\n",
      "Epoch 2681/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8006 - val_loss: 1.3787\n",
      "Epoch 2682/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7890 - val_loss: 1.3570\n",
      "Epoch 2683/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7820 - val_loss: 1.3474\n",
      "Epoch 2684/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7874 - val_loss: 1.3418\n",
      "Epoch 2685/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7813 - val_loss: 1.3499\n",
      "Epoch 2686/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7843 - val_loss: 1.3554\n",
      "Epoch 2687/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7928 - val_loss: 1.3480\n",
      "Epoch 2688/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7984 - val_loss: 1.3595\n",
      "Epoch 2689/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8089 - val_loss: 1.3875\n",
      "Epoch 2690/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8086 - val_loss: 1.4012\n",
      "Epoch 2691/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7979 - val_loss: 1.3872\n",
      "Epoch 2692/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8071 - val_loss: 1.3623\n",
      "Epoch 2693/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7937 - val_loss: 1.3743\n",
      "Epoch 2694/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7921 - val_loss: 1.3728\n",
      "Epoch 2695/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8067 - val_loss: 1.3435\n",
      "Epoch 2696/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7887 - val_loss: 1.3455\n",
      "Epoch 2697/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7956 - val_loss: 1.3521\n",
      "Epoch 2698/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8093 - val_loss: 1.3437\n",
      "Epoch 2699/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8036 - val_loss: 1.3395\n",
      "Epoch 2700/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7973 - val_loss: 1.3278\n",
      "Epoch 2701/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7924 - val_loss: 1.3402\n",
      "Epoch 2702/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7998 - val_loss: 1.3369\n",
      "Epoch 2703/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7766 - val_loss: 1.3564\n",
      "Epoch 2704/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8011 - val_loss: 1.3752\n",
      "Epoch 2705/5000\n",
      "572/572 [==============================] - 0s 505us/step - loss: 0.7975 - val_loss: 1.3641\n",
      "Epoch 2706/5000\n",
      "572/572 [==============================] - 0s 564us/step - loss: 0.8041 - val_loss: 1.3606\n",
      "Epoch 2707/5000\n",
      "572/572 [==============================] - 0s 549us/step - loss: 0.7943 - val_loss: 1.3453\n",
      "Epoch 2708/5000\n",
      "572/572 [==============================] - 0s 573us/step - loss: 0.7886 - val_loss: 1.3445\n",
      "Epoch 2709/5000\n",
      "572/572 [==============================] - 0s 561us/step - loss: 0.8013 - val_loss: 1.3485\n",
      "Epoch 2710/5000\n",
      "572/572 [==============================] - 0s 538us/step - loss: 0.7918 - val_loss: 1.3449\n",
      "Epoch 2711/5000\n",
      "572/572 [==============================] - 0s 540us/step - loss: 0.7914 - val_loss: 1.3561\n",
      "Epoch 2712/5000\n",
      "572/572 [==============================] - 0s 531us/step - loss: 0.7860 - val_loss: 1.3485\n",
      "Epoch 2713/5000\n",
      "572/572 [==============================] - 0s 563us/step - loss: 0.7844 - val_loss: 1.3562\n",
      "Epoch 2714/5000\n",
      "572/572 [==============================] - 0s 570us/step - loss: 0.8021 - val_loss: 1.3397\n",
      "Epoch 2715/5000\n",
      "572/572 [==============================] - 0s 520us/step - loss: 0.7962 - val_loss: 1.3483\n",
      "Epoch 2716/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7969 - val_loss: 1.3446\n",
      "Epoch 2717/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7872 - val_loss: 1.3532\n",
      "Epoch 2718/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7946 - val_loss: 1.3470\n",
      "Epoch 2719/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7967 - val_loss: 1.3711\n",
      "Epoch 2720/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7974 - val_loss: 1.3557\n",
      "Epoch 2721/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7897 - val_loss: 1.3536\n",
      "Epoch 2722/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7971 - val_loss: 1.3365\n",
      "Epoch 2723/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7891 - val_loss: 1.3715\n",
      "Epoch 2724/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7932 - val_loss: 1.3515\n",
      "Epoch 2725/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7907 - val_loss: 1.3499\n",
      "Epoch 2726/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7903 - val_loss: 1.3579\n",
      "Epoch 2727/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8004 - val_loss: 1.3596\n",
      "Epoch 2728/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7930 - val_loss: 1.3727\n",
      "Epoch 2729/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7991 - val_loss: 1.3504\n",
      "Epoch 2730/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7888 - val_loss: 1.3531\n",
      "Epoch 2731/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7855 - val_loss: 1.3570\n",
      "Epoch 2732/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7934 - val_loss: 1.3700\n",
      "Epoch 2733/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8011 - val_loss: 1.3727\n",
      "Epoch 2734/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7977 - val_loss: 1.3724\n",
      "Epoch 2735/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8012 - val_loss: 1.3541\n",
      "Epoch 2736/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.7868 - val_loss: 1.3612\n",
      "Epoch 2737/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7988 - val_loss: 1.3400\n",
      "Epoch 2738/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7997 - val_loss: 1.3419\n",
      "Epoch 2739/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7923 - val_loss: 1.3766\n",
      "Epoch 2740/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8045 - val_loss: 1.3790\n",
      "Epoch 2741/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7961 - val_loss: 1.3539\n",
      "Epoch 2742/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.8060 - val_loss: 1.3515\n",
      "Epoch 2743/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7949 - val_loss: 1.3319\n",
      "Epoch 2744/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7998 - val_loss: 1.3237\n",
      "Epoch 2745/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7890 - val_loss: 1.3375\n",
      "Epoch 2746/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7985 - val_loss: 1.3497\n",
      "Epoch 2747/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7966 - val_loss: 1.3616\n",
      "Epoch 2748/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7907 - val_loss: 1.3426\n",
      "Epoch 2749/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7826 - val_loss: 1.3484\n",
      "Epoch 2750/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 487us/step - loss: 0.7902 - val_loss: 1.3383\n",
      "Epoch 2751/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8156 - val_loss: 1.3446\n",
      "Epoch 2752/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7941 - val_loss: 1.3561\n",
      "Epoch 2753/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8109 - val_loss: 1.3496\n",
      "Epoch 2754/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8000 - val_loss: 1.3648\n",
      "Epoch 2755/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7894 - val_loss: 1.3658\n",
      "Epoch 2756/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7815 - val_loss: 1.3586\n",
      "Epoch 2757/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7933 - val_loss: 1.3763\n",
      "Epoch 2758/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.7964 - val_loss: 1.3717\n",
      "Epoch 2759/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7897 - val_loss: 1.3773\n",
      "Epoch 2760/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7894 - val_loss: 1.3674\n",
      "Epoch 2761/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7981 - val_loss: 1.3599\n",
      "Epoch 2762/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7923 - val_loss: 1.3577\n",
      "Epoch 2763/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7942 - val_loss: 1.3467\n",
      "Epoch 2764/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7922 - val_loss: 1.3538\n",
      "Epoch 2765/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7994 - val_loss: 1.3506\n",
      "Epoch 2766/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7874 - val_loss: 1.3606\n",
      "Epoch 2767/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8091 - val_loss: 1.3632\n",
      "Epoch 2768/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7931 - val_loss: 1.3782\n",
      "Epoch 2769/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7986 - val_loss: 1.3709\n",
      "Epoch 2770/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7840 - val_loss: 1.3790\n",
      "Epoch 2771/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7912 - val_loss: 1.3559\n",
      "Epoch 2772/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8003 - val_loss: 1.3295\n",
      "Epoch 2773/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7948 - val_loss: 1.3518\n",
      "Epoch 2774/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8070 - val_loss: 1.3707\n",
      "Epoch 2775/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7964 - val_loss: 1.3479\n",
      "Epoch 2776/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8063 - val_loss: 1.3385\n",
      "Epoch 2777/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7984 - val_loss: 1.3288\n",
      "Epoch 2778/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7942 - val_loss: 1.3286\n",
      "Epoch 2779/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8008 - val_loss: 1.3365\n",
      "Epoch 2780/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7970 - val_loss: 1.3372\n",
      "Epoch 2781/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8022 - val_loss: 1.3740\n",
      "Epoch 2782/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7954 - val_loss: 1.3462\n",
      "Epoch 2783/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7841 - val_loss: 1.3680\n",
      "Epoch 2784/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8168 - val_loss: 1.3691\n",
      "Epoch 2785/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7883 - val_loss: 1.3395\n",
      "Epoch 2786/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8005 - val_loss: 1.3470\n",
      "Epoch 2787/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7948 - val_loss: 1.3481\n",
      "Epoch 2788/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8029 - val_loss: 1.3718\n",
      "Epoch 2789/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7995 - val_loss: 1.3576\n",
      "Epoch 2790/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7964 - val_loss: 1.3503\n",
      "Epoch 2791/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7940 - val_loss: 1.3449\n",
      "Epoch 2792/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7954 - val_loss: 1.3417\n",
      "Epoch 2793/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7836 - val_loss: 1.3441\n",
      "Epoch 2794/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8004 - val_loss: 1.3409\n",
      "Epoch 2795/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7999 - val_loss: 1.3482\n",
      "Epoch 2796/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7826 - val_loss: 1.3319\n",
      "Epoch 2797/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7896 - val_loss: 1.3205\n",
      "Epoch 2798/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8084 - val_loss: 1.3542\n",
      "Epoch 2799/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7910 - val_loss: 1.3657\n",
      "Epoch 2800/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7832 - val_loss: 1.3825\n",
      "Epoch 2801/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7891 - val_loss: 1.3638\n",
      "Epoch 2802/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7894 - val_loss: 1.3687\n",
      "Epoch 2803/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7763 - val_loss: 1.3696\n",
      "Epoch 2804/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8018 - val_loss: 1.3514\n",
      "Epoch 2805/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7893 - val_loss: 1.3783\n",
      "Epoch 2806/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8105 - val_loss: 1.3639\n",
      "Epoch 2807/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7931 - val_loss: 1.3709\n",
      "Epoch 2808/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7920 - val_loss: 1.3490\n",
      "Epoch 2809/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7987 - val_loss: 1.3542\n",
      "Epoch 2810/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8035 - val_loss: 1.3812\n",
      "Epoch 2811/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7973 - val_loss: 1.3604\n",
      "Epoch 2812/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7900 - val_loss: 1.3520\n",
      "Epoch 2813/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8101 - val_loss: 1.3381\n",
      "Epoch 2814/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7969 - val_loss: 1.3563\n",
      "Epoch 2815/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7945 - val_loss: 1.3680\n",
      "Epoch 2816/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7992 - val_loss: 1.3545\n",
      "Epoch 2817/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8062 - val_loss: 1.3375\n",
      "Epoch 2818/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8003 - val_loss: 1.3488\n",
      "Epoch 2819/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7883 - val_loss: 1.3629\n",
      "Epoch 2820/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8011 - val_loss: 1.3442\n",
      "Epoch 2821/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7816 - val_loss: 1.3436\n",
      "Epoch 2822/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8097 - val_loss: 1.3636\n",
      "Epoch 2823/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7908 - val_loss: 1.3578\n",
      "Epoch 2824/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7932 - val_loss: 1.3519\n",
      "Epoch 2825/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7957 - val_loss: 1.3419\n",
      "Epoch 2826/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8036 - val_loss: 1.3491\n",
      "Epoch 2827/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8036 - val_loss: 1.3360\n",
      "Epoch 2828/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8046 - val_loss: 1.3412\n",
      "Epoch 2829/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7919 - val_loss: 1.3388\n",
      "Epoch 2830/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7952 - val_loss: 1.3261\n",
      "Epoch 2831/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7893 - val_loss: 1.3282\n",
      "Epoch 2832/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8013 - val_loss: 1.3293\n",
      "Epoch 2833/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7951 - val_loss: 1.3499\n",
      "Epoch 2834/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8036 - val_loss: 1.3808\n",
      "Epoch 2835/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7851 - val_loss: 1.3684\n",
      "Epoch 2836/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8021 - val_loss: 1.3862\n",
      "Epoch 2837/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7926 - val_loss: 1.3990\n",
      "Epoch 2838/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7906 - val_loss: 1.3692\n",
      "Epoch 2839/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7984 - val_loss: 1.3744\n",
      "Epoch 2840/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7898 - val_loss: 1.3391\n",
      "Epoch 2841/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7949 - val_loss: 1.3510\n",
      "Epoch 2842/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7969 - val_loss: 1.3489\n",
      "Epoch 2843/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8091 - val_loss: 1.3492\n",
      "Epoch 2844/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7950 - val_loss: 1.3465\n",
      "Epoch 2845/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7892 - val_loss: 1.3267\n",
      "Epoch 2846/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7834 - val_loss: 1.3427\n",
      "Epoch 2847/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7938 - val_loss: 1.3543\n",
      "Epoch 2848/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7919 - val_loss: 1.3245\n",
      "Epoch 2849/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8065 - val_loss: 1.3428\n",
      "Epoch 2850/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8005 - val_loss: 1.3365\n",
      "Epoch 2851/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7989 - val_loss: 1.3431\n",
      "Epoch 2852/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7838 - val_loss: 1.3533\n",
      "Epoch 2853/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7977 - val_loss: 1.3613\n",
      "Epoch 2854/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7879 - val_loss: 1.3492\n",
      "Epoch 2855/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7848 - val_loss: 1.3774\n",
      "Epoch 2856/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7889 - val_loss: 1.3746\n",
      "Epoch 2857/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7934 - val_loss: 1.3653\n",
      "Epoch 2858/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7869 - val_loss: 1.3507\n",
      "Epoch 2859/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8041 - val_loss: 1.3483\n",
      "Epoch 2860/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7780 - val_loss: 1.3750\n",
      "Epoch 2861/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7959 - val_loss: 1.3611\n",
      "Epoch 2862/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7886 - val_loss: 1.3550\n",
      "Epoch 2863/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7956 - val_loss: 1.3367\n",
      "Epoch 2864/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8017 - val_loss: 1.3425\n",
      "Epoch 2865/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7964 - val_loss: 1.3300\n",
      "Epoch 2866/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7971 - val_loss: 1.3386\n",
      "Epoch 2867/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7793 - val_loss: 1.3638\n",
      "Epoch 2868/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.7970 - val_loss: 1.3506\n",
      "Epoch 2869/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7916 - val_loss: 1.3628\n",
      "Epoch 2870/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7828 - val_loss: 1.3822\n",
      "Epoch 2871/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8004 - val_loss: 1.3484\n",
      "Epoch 2872/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7813 - val_loss: 1.3315\n",
      "Epoch 2873/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8035 - val_loss: 1.3453\n",
      "Epoch 2874/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7847 - val_loss: 1.3402\n",
      "Epoch 2875/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8125 - val_loss: 1.3480\n",
      "Epoch 2876/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7783 - val_loss: 1.3449\n",
      "Epoch 2877/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7901 - val_loss: 1.3363\n",
      "Epoch 2878/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7895 - val_loss: 1.3550\n",
      "Epoch 2879/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8119 - val_loss: 1.3446\n",
      "Epoch 2880/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7818 - val_loss: 1.3507\n",
      "Epoch 2881/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7904 - val_loss: 1.3650\n",
      "Epoch 2882/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8035 - val_loss: 1.3894\n",
      "Epoch 2883/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7779 - val_loss: 1.3741\n",
      "Epoch 2884/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8002 - val_loss: 1.3722\n",
      "Epoch 2885/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7973 - val_loss: 1.3518\n",
      "Epoch 2886/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7840 - val_loss: 1.3403\n",
      "Epoch 2887/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7845 - val_loss: 1.3269\n",
      "Epoch 2888/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8026 - val_loss: 1.3463\n",
      "Epoch 2889/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8026 - val_loss: 1.3240\n",
      "Epoch 2890/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7850 - val_loss: 1.3586\n",
      "Epoch 2891/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7770 - val_loss: 1.3531\n",
      "Epoch 2892/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7896 - val_loss: 1.3514\n",
      "Epoch 2893/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7921 - val_loss: 1.3655\n",
      "Epoch 2894/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7909 - val_loss: 1.3757\n",
      "Epoch 2895/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7995 - val_loss: 1.3576\n",
      "Epoch 2896/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7875 - val_loss: 1.3429\n",
      "Epoch 2897/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7951 - val_loss: 1.3410\n",
      "Epoch 2898/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8078 - val_loss: 1.3479\n",
      "Epoch 2899/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7934 - val_loss: 1.3528\n",
      "Epoch 2900/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8062 - val_loss: 1.3667\n",
      "Epoch 2901/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7904 - val_loss: 1.3732\n",
      "Epoch 2902/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 488us/step - loss: 0.7896 - val_loss: 1.3697\n",
      "Epoch 2903/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7996 - val_loss: 1.3603\n",
      "Epoch 2904/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.8048 - val_loss: 1.3540\n",
      "Epoch 2905/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.8065 - val_loss: 1.3497\n",
      "Epoch 2906/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8005 - val_loss: 1.3314\n",
      "Epoch 2907/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7928 - val_loss: 1.3422\n",
      "Epoch 2908/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7921 - val_loss: 1.3351\n",
      "Epoch 2909/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7962 - val_loss: 1.3431\n",
      "Epoch 2910/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7985 - val_loss: 1.3243\n",
      "Epoch 2911/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7838 - val_loss: 1.3507\n",
      "Epoch 2912/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7885 - val_loss: 1.3467\n",
      "Epoch 2913/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7976 - val_loss: 1.3677\n",
      "Epoch 2914/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7820 - val_loss: 1.3594\n",
      "Epoch 2915/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7889 - val_loss: 1.3409\n",
      "Epoch 2916/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7786 - val_loss: 1.3472\n",
      "Epoch 2917/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7816 - val_loss: 1.3466\n",
      "Epoch 2918/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7813 - val_loss: 1.3502\n",
      "Epoch 2919/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7920 - val_loss: 1.3654\n",
      "Epoch 2920/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7826 - val_loss: 1.3597\n",
      "Epoch 2921/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7816 - val_loss: 1.3699\n",
      "Epoch 2922/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7942 - val_loss: 1.3825\n",
      "Epoch 2923/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7918 - val_loss: 1.3857\n",
      "Epoch 2924/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7784 - val_loss: 1.3803\n",
      "Epoch 2925/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7927 - val_loss: 1.3736\n",
      "Epoch 2926/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7954 - val_loss: 1.3600\n",
      "Epoch 2927/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7842 - val_loss: 1.3808\n",
      "Epoch 2928/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7817 - val_loss: 1.3792\n",
      "Epoch 2929/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7827 - val_loss: 1.3692\n",
      "Epoch 2930/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7892 - val_loss: 1.3742\n",
      "Epoch 2931/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8163 - val_loss: 1.3589\n",
      "Epoch 2932/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8029 - val_loss: 1.3470\n",
      "Epoch 2933/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8052 - val_loss: 1.3448\n",
      "Epoch 2934/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8076 - val_loss: 1.3323\n",
      "Epoch 2935/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7840 - val_loss: 1.3392\n",
      "Epoch 2936/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8091 - val_loss: 1.3461\n",
      "Epoch 2937/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7955 - val_loss: 1.3386\n",
      "Epoch 2938/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7804 - val_loss: 1.3381\n",
      "Epoch 2939/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7876 - val_loss: 1.3403\n",
      "Epoch 2940/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7862 - val_loss: 1.3638\n",
      "Epoch 2941/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8034 - val_loss: 1.3429\n",
      "Epoch 2942/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7802 - val_loss: 1.3383\n",
      "Epoch 2943/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8019 - val_loss: 1.3538\n",
      "Epoch 2944/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7932 - val_loss: 1.3389\n",
      "Epoch 2945/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7878 - val_loss: 1.3739\n",
      "Epoch 2946/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7984 - val_loss: 1.3554\n",
      "Epoch 2947/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.8015 - val_loss: 1.3425\n",
      "Epoch 2948/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8154 - val_loss: 1.3436\n",
      "Epoch 2949/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7808 - val_loss: 1.3388\n",
      "Epoch 2950/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8015 - val_loss: 1.3292\n",
      "Epoch 2951/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8109 - val_loss: 1.3359\n",
      "Epoch 2952/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7887 - val_loss: 1.3269\n",
      "Epoch 2953/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7897 - val_loss: 1.3485\n",
      "Epoch 2954/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8020 - val_loss: 1.3627\n",
      "Epoch 2955/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.7874 - val_loss: 1.3390\n",
      "Epoch 2956/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7764 - val_loss: 1.3412\n",
      "Epoch 2957/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7842 - val_loss: 1.3468\n",
      "Epoch 2958/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7919 - val_loss: 1.3394\n",
      "Epoch 2959/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7843 - val_loss: 1.3367\n",
      "Epoch 2960/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7888 - val_loss: 1.3648\n",
      "Epoch 2961/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8013 - val_loss: 1.3417\n",
      "Epoch 2962/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7738 - val_loss: 1.3433\n",
      "Epoch 2963/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.8090 - val_loss: 1.3534\n",
      "Epoch 2964/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8044 - val_loss: 1.3456\n",
      "Epoch 2965/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7922 - val_loss: 1.3565\n",
      "Epoch 2966/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7832 - val_loss: 1.3387\n",
      "Epoch 2967/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7897 - val_loss: 1.3501\n",
      "Epoch 2968/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8149 - val_loss: 1.3355\n",
      "Epoch 2969/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8014 - val_loss: 1.3270\n",
      "Epoch 2970/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7899 - val_loss: 1.3339\n",
      "Epoch 2971/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7985 - val_loss: 1.3413\n",
      "Epoch 2972/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7968 - val_loss: 1.3408\n",
      "Epoch 2973/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8216 - val_loss: 1.3628\n",
      "Epoch 2974/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7957 - val_loss: 1.3556\n",
      "Epoch 2975/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7973 - val_loss: 1.3478\n",
      "Epoch 2976/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7876 - val_loss: 1.3646\n",
      "Epoch 2977/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7863 - val_loss: 1.3538\n",
      "Epoch 2978/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7978 - val_loss: 1.3489\n",
      "Epoch 2979/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.8061 - val_loss: 1.3355\n",
      "Epoch 2980/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8082 - val_loss: 1.3169\n",
      "Epoch 2981/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7968 - val_loss: 1.3369\n",
      "Epoch 2982/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7843 - val_loss: 1.3361\n",
      "Epoch 2983/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8122 - val_loss: 1.3280\n",
      "Epoch 2984/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7946 - val_loss: 1.3417\n",
      "Epoch 2985/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.8007 - val_loss: 1.3547\n",
      "Epoch 2986/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7923 - val_loss: 1.3565\n",
      "Epoch 2987/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.7851 - val_loss: 1.3713\n",
      "Epoch 2988/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7952 - val_loss: 1.3521\n",
      "Epoch 2989/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7976 - val_loss: 1.3560\n",
      "Epoch 2990/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7902 - val_loss: 1.3404\n",
      "Epoch 2991/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7897 - val_loss: 1.3308\n",
      "Epoch 2992/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7818 - val_loss: 1.3299\n",
      "Epoch 2993/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7939 - val_loss: 1.3409\n",
      "Epoch 2994/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8007 - val_loss: 1.3237\n",
      "Epoch 2995/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7833 - val_loss: 1.3289\n",
      "Epoch 2996/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7809 - val_loss: 1.3474\n",
      "Epoch 2997/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7812 - val_loss: 1.3470\n",
      "Epoch 2998/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7868 - val_loss: 1.3351\n",
      "Epoch 2999/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.8131 - val_loss: 1.3393\n",
      "Epoch 3000/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7847 - val_loss: 1.3668\n",
      "Epoch 3001/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7794 - val_loss: 1.3625\n",
      "Epoch 3002/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7899 - val_loss: 1.3519\n",
      "Epoch 3003/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7881 - val_loss: 1.3559\n",
      "Epoch 3004/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7840 - val_loss: 1.3701\n",
      "Epoch 3005/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7763 - val_loss: 1.3605\n",
      "Epoch 3006/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8013 - val_loss: 1.3559\n",
      "Epoch 3007/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7936 - val_loss: 1.3387\n",
      "Epoch 3008/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8043 - val_loss: 1.3464\n",
      "Epoch 3009/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7940 - val_loss: 1.3254\n",
      "Epoch 3010/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7944 - val_loss: 1.3290\n",
      "Epoch 3011/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7825 - val_loss: 1.3349\n",
      "Epoch 3012/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7786 - val_loss: 1.3266\n",
      "Epoch 3013/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7843 - val_loss: 1.3425\n",
      "Epoch 3014/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7824 - val_loss: 1.3516\n",
      "Epoch 3015/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7890 - val_loss: 1.3664\n",
      "Epoch 3016/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7927 - val_loss: 1.3488\n",
      "Epoch 3017/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7917 - val_loss: 1.3517\n",
      "Epoch 3018/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7914 - val_loss: 1.3470\n",
      "Epoch 3019/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7964 - val_loss: 1.3669\n",
      "Epoch 3020/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7984 - val_loss: 1.3696\n",
      "Epoch 3021/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8053 - val_loss: 1.3683\n",
      "Epoch 3022/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7946 - val_loss: 1.3291\n",
      "Epoch 3023/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7792 - val_loss: 1.3304\n",
      "Epoch 3024/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8108 - val_loss: 1.3379\n",
      "Epoch 3025/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7874 - val_loss: 1.3497\n",
      "Epoch 3026/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7976 - val_loss: 1.3357\n",
      "Epoch 3027/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7903 - val_loss: 1.3224\n",
      "Epoch 3028/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8109 - val_loss: 1.3177\n",
      "Epoch 3029/5000\n",
      "572/572 [==============================] - 0s 478us/step - loss: 0.7905 - val_loss: 1.3175\n",
      "Epoch 3030/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8010 - val_loss: 1.3150\n",
      "Epoch 3031/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7982 - val_loss: 1.3094\n",
      "Epoch 3032/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7986 - val_loss: 1.3101\n",
      "Epoch 3033/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7814 - val_loss: 1.3319\n",
      "Epoch 3034/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8047 - val_loss: 1.3298\n",
      "Epoch 3035/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7949 - val_loss: 1.3356\n",
      "Epoch 3036/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8097 - val_loss: 1.3566\n",
      "Epoch 3037/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7987 - val_loss: 1.3622\n",
      "Epoch 3038/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7885 - val_loss: 1.3446\n",
      "Epoch 3039/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8002 - val_loss: 1.3534\n",
      "Epoch 3040/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7913 - val_loss: 1.3299\n",
      "Epoch 3041/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7855 - val_loss: 1.3720\n",
      "Epoch 3042/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7781 - val_loss: 1.3735\n",
      "Epoch 3043/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7852 - val_loss: 1.3730\n",
      "Epoch 3044/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7981 - val_loss: 1.3503\n",
      "Epoch 3045/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7861 - val_loss: 1.3376\n",
      "Epoch 3046/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7901 - val_loss: 1.3390\n",
      "Epoch 3047/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7916 - val_loss: 1.3403\n",
      "Epoch 3048/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8088 - val_loss: 1.3271\n",
      "Epoch 3049/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7906 - val_loss: 1.3330\n",
      "Epoch 3050/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7995 - val_loss: 1.3465\n",
      "Epoch 3051/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8096 - val_loss: 1.3710\n",
      "Epoch 3052/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7920 - val_loss: 1.3675\n",
      "Epoch 3053/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7902 - val_loss: 1.3928\n",
      "Epoch 3054/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 486us/step - loss: 0.8163 - val_loss: 1.3520\n",
      "Epoch 3055/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7921 - val_loss: 1.3493\n",
      "Epoch 3056/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7991 - val_loss: 1.3525\n",
      "Epoch 3057/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7993 - val_loss: 1.3362\n",
      "Epoch 3058/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7969 - val_loss: 1.3208\n",
      "Epoch 3059/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7825 - val_loss: 1.3142\n",
      "Epoch 3060/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7827 - val_loss: 1.3225\n",
      "Epoch 3061/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7963 - val_loss: 1.3471\n",
      "Epoch 3062/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7806 - val_loss: 1.3813\n",
      "Epoch 3063/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7910 - val_loss: 1.3813\n",
      "Epoch 3064/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7877 - val_loss: 1.3785\n",
      "Epoch 3065/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7884 - val_loss: 1.3585\n",
      "Epoch 3066/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7735 - val_loss: 1.3564\n",
      "Epoch 3067/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7895 - val_loss: 1.3728\n",
      "Epoch 3068/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7953 - val_loss: 1.3893\n",
      "Epoch 3069/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8019 - val_loss: 1.3558\n",
      "Epoch 3070/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7828 - val_loss: 1.3656\n",
      "Epoch 3071/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7906 - val_loss: 1.3636\n",
      "Epoch 3072/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7938 - val_loss: 1.3863\n",
      "Epoch 3073/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7879 - val_loss: 1.3581\n",
      "Epoch 3074/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7958 - val_loss: 1.3724\n",
      "Epoch 3075/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7921 - val_loss: 1.3443\n",
      "Epoch 3076/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7805 - val_loss: 1.3489\n",
      "Epoch 3077/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7821 - val_loss: 1.3369\n",
      "Epoch 3078/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7800 - val_loss: 1.3508\n",
      "Epoch 3079/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7849 - val_loss: 1.3402\n",
      "Epoch 3080/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7966 - val_loss: 1.3452\n",
      "Epoch 3081/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.8114 - val_loss: 1.3388\n",
      "Epoch 3082/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7798 - val_loss: 1.3182\n",
      "Epoch 3083/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8005 - val_loss: 1.3204\n",
      "Epoch 3084/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7906 - val_loss: 1.3204\n",
      "Epoch 3085/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7953 - val_loss: 1.3564\n",
      "Epoch 3086/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7896 - val_loss: 1.3456\n",
      "Epoch 3087/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7846 - val_loss: 1.3311\n",
      "Epoch 3088/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7926 - val_loss: 1.3216\n",
      "Epoch 3089/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7920 - val_loss: 1.3344\n",
      "Epoch 3090/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7947 - val_loss: 1.3353\n",
      "Epoch 3091/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8074 - val_loss: 1.3415\n",
      "Epoch 3092/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7812 - val_loss: 1.3487\n",
      "Epoch 3093/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7752 - val_loss: 1.3404\n",
      "Epoch 3094/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7893 - val_loss: 1.3492\n",
      "Epoch 3095/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8135 - val_loss: 1.3195\n",
      "Epoch 3096/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7918 - val_loss: 1.3312\n",
      "Epoch 3097/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7802 - val_loss: 1.3318\n",
      "Epoch 3098/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7914 - val_loss: 1.3359\n",
      "Epoch 3099/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8070 - val_loss: 1.3471\n",
      "Epoch 3100/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7930 - val_loss: 1.3645\n",
      "Epoch 3101/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.8011 - val_loss: 1.3386\n",
      "Epoch 3102/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8127 - val_loss: 1.3185\n",
      "Epoch 3103/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7854 - val_loss: 1.3355\n",
      "Epoch 3104/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7975 - val_loss: 1.3438\n",
      "Epoch 3105/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8005 - val_loss: 1.3402\n",
      "Epoch 3106/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7894 - val_loss: 1.3445\n",
      "Epoch 3107/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7945 - val_loss: 1.3250\n",
      "Epoch 3108/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7901 - val_loss: 1.3259\n",
      "Epoch 3109/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8044 - val_loss: 1.3217\n",
      "Epoch 3110/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7924 - val_loss: 1.3521\n",
      "Epoch 3111/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7923 - val_loss: 1.3421\n",
      "Epoch 3112/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7751 - val_loss: 1.3732\n",
      "Epoch 3113/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8084 - val_loss: 1.3720\n",
      "Epoch 3114/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7883 - val_loss: 1.3586\n",
      "Epoch 3115/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8062 - val_loss: 1.3295\n",
      "Epoch 3116/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7914 - val_loss: 1.3417\n",
      "Epoch 3117/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7958 - val_loss: 1.3501\n",
      "Epoch 3118/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7899 - val_loss: 1.3228\n",
      "Epoch 3119/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7869 - val_loss: 1.3317\n",
      "Epoch 3120/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7918 - val_loss: 1.3559\n",
      "Epoch 3121/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7990 - val_loss: 1.3580\n",
      "Epoch 3122/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7979 - val_loss: 1.3659\n",
      "Epoch 3123/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7837 - val_loss: 1.3567\n",
      "Epoch 3124/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7958 - val_loss: 1.3654\n",
      "Epoch 3125/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7824 - val_loss: 1.3669\n",
      "Epoch 3126/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7938 - val_loss: 1.3443\n",
      "Epoch 3127/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7869 - val_loss: 1.3277\n",
      "Epoch 3128/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7831 - val_loss: 1.3417\n",
      "Epoch 3129/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7795 - val_loss: 1.3633\n",
      "Epoch 3130/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7860 - val_loss: 1.3307\n",
      "Epoch 3131/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7903 - val_loss: 1.3195\n",
      "Epoch 3132/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7921 - val_loss: 1.3226\n",
      "Epoch 3133/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7992 - val_loss: 1.3189\n",
      "Epoch 3134/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7913 - val_loss: 1.3326\n",
      "Epoch 3135/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7767 - val_loss: 1.3552\n",
      "Epoch 3136/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7862 - val_loss: 1.3776\n",
      "Epoch 3137/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.8042 - val_loss: 1.3698\n",
      "Epoch 3138/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7926 - val_loss: 1.3594\n",
      "Epoch 3139/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7849 - val_loss: 1.3317\n",
      "Epoch 3140/5000\n",
      "572/572 [==============================] - 0s 507us/step - loss: 0.7964 - val_loss: 1.3107\n",
      "Epoch 3141/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7929 - val_loss: 1.3065\n",
      "Epoch 3142/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7805 - val_loss: 1.3137\n",
      "Epoch 3143/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7951 - val_loss: 1.3444\n",
      "Epoch 3144/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8025 - val_loss: 1.3343\n",
      "Epoch 3145/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7865 - val_loss: 1.3422\n",
      "Epoch 3146/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7877 - val_loss: 1.3512\n",
      "Epoch 3147/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7813 - val_loss: 1.3422\n",
      "Epoch 3148/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7836 - val_loss: 1.3506\n",
      "Epoch 3149/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7872 - val_loss: 1.3559\n",
      "Epoch 3150/5000\n",
      "572/572 [==============================] - 0s 478us/step - loss: 0.7895 - val_loss: 1.3420\n",
      "Epoch 3151/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7907 - val_loss: 1.3491\n",
      "Epoch 3152/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8043 - val_loss: 1.3360\n",
      "Epoch 3153/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7924 - val_loss: 1.3513\n",
      "Epoch 3154/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7853 - val_loss: 1.3572\n",
      "Epoch 3155/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8000 - val_loss: 1.3446\n",
      "Epoch 3156/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7848 - val_loss: 1.3518\n",
      "Epoch 3157/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7964 - val_loss: 1.3369\n",
      "Epoch 3158/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7827 - val_loss: 1.3374\n",
      "Epoch 3159/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7979 - val_loss: 1.3422\n",
      "Epoch 3160/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7837 - val_loss: 1.3260\n",
      "Epoch 3161/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7967 - val_loss: 1.3282\n",
      "Epoch 3162/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7916 - val_loss: 1.3380\n",
      "Epoch 3163/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7962 - val_loss: 1.3471\n",
      "Epoch 3164/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7860 - val_loss: 1.3417\n",
      "Epoch 3165/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7883 - val_loss: 1.3573\n",
      "Epoch 3166/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7873 - val_loss: 1.3754\n",
      "Epoch 3167/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7956 - val_loss: 1.3795\n",
      "Epoch 3168/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.7874 - val_loss: 1.3750\n",
      "Epoch 3169/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7937 - val_loss: 1.3716\n",
      "Epoch 3170/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7955 - val_loss: 1.3730\n",
      "Epoch 3171/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.7971 - val_loss: 1.3480\n",
      "Epoch 3172/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7815 - val_loss: 1.3334\n",
      "Epoch 3173/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7992 - val_loss: 1.3471\n",
      "Epoch 3174/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8031 - val_loss: 1.3562\n",
      "Epoch 3175/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7986 - val_loss: 1.3334\n",
      "Epoch 3176/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8068 - val_loss: 1.3243\n",
      "Epoch 3177/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7813 - val_loss: 1.3325\n",
      "Epoch 3178/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7928 - val_loss: 1.3369\n",
      "Epoch 3179/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7812 - val_loss: 1.3551\n",
      "Epoch 3180/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7868 - val_loss: 1.3379\n",
      "Epoch 3181/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7895 - val_loss: 1.3467\n",
      "Epoch 3182/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7901 - val_loss: 1.3172\n",
      "Epoch 3183/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7908 - val_loss: 1.3511\n",
      "Epoch 3184/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7805 - val_loss: 1.3682\n",
      "Epoch 3185/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8158 - val_loss: 1.3248\n",
      "Epoch 3186/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8019 - val_loss: 1.3354\n",
      "Epoch 3187/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7905 - val_loss: 1.3414\n",
      "Epoch 3188/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.8033 - val_loss: 1.3204\n",
      "Epoch 3189/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7887 - val_loss: 1.3120\n",
      "Epoch 3190/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7874 - val_loss: 1.3247\n",
      "Epoch 3191/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7899 - val_loss: 1.3142\n",
      "Epoch 3192/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7861 - val_loss: 1.3241\n",
      "Epoch 3193/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7917 - val_loss: 1.3219\n",
      "Epoch 3194/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8001 - val_loss: 1.3288\n",
      "Epoch 3195/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7863 - val_loss: 1.3352\n",
      "Epoch 3196/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7991 - val_loss: 1.3424\n",
      "Epoch 3197/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.8045 - val_loss: 1.3503\n",
      "Epoch 3198/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7820 - val_loss: 1.3594\n",
      "Epoch 3199/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7983 - val_loss: 1.3652\n",
      "Epoch 3200/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7888 - val_loss: 1.3540\n",
      "Epoch 3201/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7919 - val_loss: 1.3555\n",
      "Epoch 3202/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7815 - val_loss: 1.3498\n",
      "Epoch 3203/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7798 - val_loss: 1.3302\n",
      "Epoch 3204/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7910 - val_loss: 1.3063\n",
      "Epoch 3205/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7963 - val_loss: 1.3057\n",
      "Epoch 3206/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 482us/step - loss: 0.7940 - val_loss: 1.3145\n",
      "Epoch 3207/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8025 - val_loss: 1.3272\n",
      "Epoch 3208/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7684 - val_loss: 1.3579\n",
      "Epoch 3209/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7919 - val_loss: 1.3531\n",
      "Epoch 3210/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7946 - val_loss: 1.3669\n",
      "Epoch 3211/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7914 - val_loss: 1.3646\n",
      "Epoch 3212/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8180 - val_loss: 1.3616\n",
      "Epoch 3213/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7838 - val_loss: 1.3469\n",
      "Epoch 3214/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7871 - val_loss: 1.3628\n",
      "Epoch 3215/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7861 - val_loss: 1.3480\n",
      "Epoch 3216/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7942 - val_loss: 1.3514\n",
      "Epoch 3217/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8026 - val_loss: 1.3644\n",
      "Epoch 3218/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7904 - val_loss: 1.3403\n",
      "Epoch 3219/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7844 - val_loss: 1.3292\n",
      "Epoch 3220/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7991 - val_loss: 1.3520\n",
      "Epoch 3221/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7986 - val_loss: 1.3560\n",
      "Epoch 3222/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7848 - val_loss: 1.3417\n",
      "Epoch 3223/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.7780 - val_loss: 1.3351\n",
      "Epoch 3224/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7867 - val_loss: 1.3359\n",
      "Epoch 3225/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7952 - val_loss: 1.3432\n",
      "Epoch 3226/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7853 - val_loss: 1.3477\n",
      "Epoch 3227/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.8022 - val_loss: 1.3511\n",
      "Epoch 3228/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7938 - val_loss: 1.3466\n",
      "Epoch 3229/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.8006 - val_loss: 1.3174\n",
      "Epoch 3230/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7903 - val_loss: 1.3441\n",
      "Epoch 3231/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7897 - val_loss: 1.3375\n",
      "Epoch 3232/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7862 - val_loss: 1.3418\n",
      "Epoch 3233/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7695 - val_loss: 1.3330\n",
      "Epoch 3234/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7955 - val_loss: 1.3603\n",
      "Epoch 3235/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.8023 - val_loss: 1.3687\n",
      "Epoch 3236/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7786 - val_loss: 1.3616\n",
      "Epoch 3237/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7953 - val_loss: 1.3427\n",
      "Epoch 3238/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7914 - val_loss: 1.3559\n",
      "Epoch 3239/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8028 - val_loss: 1.3520\n",
      "Epoch 3240/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7932 - val_loss: 1.3744\n",
      "Epoch 3241/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.8023 - val_loss: 1.3455\n",
      "Epoch 3242/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7673 - val_loss: 1.3507\n",
      "Epoch 3243/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7981 - val_loss: 1.3394\n",
      "Epoch 3244/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7929 - val_loss: 1.3347\n",
      "Epoch 3245/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7982 - val_loss: 1.3600\n",
      "Epoch 3246/5000\n",
      "572/572 [==============================] - 0s 478us/step - loss: 0.7957 - val_loss: 1.3551\n",
      "Epoch 3247/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7845 - val_loss: 1.3402\n",
      "Epoch 3248/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7884 - val_loss: 1.3337\n",
      "Epoch 3249/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7927 - val_loss: 1.3529\n",
      "Epoch 3250/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7785 - val_loss: 1.3347\n",
      "Epoch 3251/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7821 - val_loss: 1.3326\n",
      "Epoch 3252/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7854 - val_loss: 1.3303\n",
      "Epoch 3253/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7921 - val_loss: 1.3137\n",
      "Epoch 3254/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7982 - val_loss: 1.3183\n",
      "Epoch 3255/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7881 - val_loss: 1.3196\n",
      "Epoch 3256/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7861 - val_loss: 1.3201\n",
      "Epoch 3257/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7970 - val_loss: 1.3407\n",
      "Epoch 3258/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7839 - val_loss: 1.2994\n",
      "Epoch 3259/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7790 - val_loss: 1.3188\n",
      "Epoch 3260/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7867 - val_loss: 1.3157\n",
      "Epoch 3261/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7790 - val_loss: 1.3108\n",
      "Epoch 3262/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7771 - val_loss: 1.3079\n",
      "Epoch 3263/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7781 - val_loss: 1.3076\n",
      "Epoch 3264/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7968 - val_loss: 1.3402\n",
      "Epoch 3265/5000\n",
      "572/572 [==============================] - 0s 478us/step - loss: 0.7752 - val_loss: 1.3347\n",
      "Epoch 3266/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7819 - val_loss: 1.3381\n",
      "Epoch 3267/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7913 - val_loss: 1.3164\n",
      "Epoch 3268/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7866 - val_loss: 1.2813\n",
      "Epoch 3269/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7948 - val_loss: 1.3043\n",
      "Epoch 3270/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7833 - val_loss: 1.3075\n",
      "Epoch 3271/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7884 - val_loss: 1.2979\n",
      "Epoch 3272/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7900 - val_loss: 1.2789\n",
      "Epoch 3273/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7916 - val_loss: 1.2799\n",
      "Epoch 3274/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7689 - val_loss: 1.3172\n",
      "Epoch 3275/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7748 - val_loss: 1.3077\n",
      "Epoch 3276/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7895 - val_loss: 1.3071\n",
      "Epoch 3277/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7950 - val_loss: 1.3428\n",
      "Epoch 3278/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7693 - val_loss: 1.3360\n",
      "Epoch 3279/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7877 - val_loss: 1.3253\n",
      "Epoch 3280/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7746 - val_loss: 1.2858\n",
      "Epoch 3281/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7795 - val_loss: 1.3054\n",
      "Epoch 3282/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7925 - val_loss: 1.3063\n",
      "Epoch 3283/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7728 - val_loss: 1.2984\n",
      "Epoch 3284/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7796 - val_loss: 1.2907\n",
      "Epoch 3285/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7852 - val_loss: 1.2935\n",
      "Epoch 3286/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7852 - val_loss: 1.2856\n",
      "Epoch 3287/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7817 - val_loss: 1.2818\n",
      "Epoch 3288/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7845 - val_loss: 1.2983\n",
      "Epoch 3289/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7796 - val_loss: 1.2735\n",
      "Epoch 3290/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7763 - val_loss: 1.2720\n",
      "Epoch 3291/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7721 - val_loss: 1.3146\n",
      "Epoch 3292/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7829 - val_loss: 1.3145\n",
      "Epoch 3293/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7848 - val_loss: 1.3099\n",
      "Epoch 3294/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7872 - val_loss: 1.2956\n",
      "Epoch 3295/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7914 - val_loss: 1.2562\n",
      "Epoch 3296/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7847 - val_loss: 1.2566\n",
      "Epoch 3297/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7779 - val_loss: 1.2977\n",
      "Epoch 3298/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7790 - val_loss: 1.3337\n",
      "Epoch 3299/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7711 - val_loss: 1.3153\n",
      "Epoch 3300/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7918 - val_loss: 1.3408\n",
      "Epoch 3301/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7884 - val_loss: 1.3644\n",
      "Epoch 3302/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.7813 - val_loss: 1.3038\n",
      "Epoch 3303/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7658 - val_loss: 1.2644\n",
      "Epoch 3304/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7888 - val_loss: 1.2972\n",
      "Epoch 3305/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7759 - val_loss: 1.2908\n",
      "Epoch 3306/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7913 - val_loss: 1.2797\n",
      "Epoch 3307/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7957 - val_loss: 1.2516\n",
      "Epoch 3308/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7678 - val_loss: 1.2638\n",
      "Epoch 3309/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7932 - val_loss: 1.2708\n",
      "Epoch 3310/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7665 - val_loss: 1.2958\n",
      "Epoch 3311/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7882 - val_loss: 1.3182\n",
      "Epoch 3312/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7975 - val_loss: 1.2925\n",
      "Epoch 3313/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7843 - val_loss: 1.2734\n",
      "Epoch 3314/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7895 - val_loss: 1.2863\n",
      "Epoch 3315/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7935 - val_loss: 1.2779\n",
      "Epoch 3316/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7974 - val_loss: 1.2770\n",
      "Epoch 3317/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7904 - val_loss: 1.2890\n",
      "Epoch 3318/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7758 - val_loss: 1.2863\n",
      "Epoch 3319/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7684 - val_loss: 1.2791\n",
      "Epoch 3320/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7698 - val_loss: 1.2857\n",
      "Epoch 3321/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7952 - val_loss: 1.2906\n",
      "Epoch 3322/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7979 - val_loss: 1.2904\n",
      "Epoch 3323/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7942 - val_loss: 1.2894\n",
      "Epoch 3324/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7933 - val_loss: 1.2905\n",
      "Epoch 3325/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7789 - val_loss: 1.2839\n",
      "Epoch 3326/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7745 - val_loss: 1.2876\n",
      "Epoch 3327/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7792 - val_loss: 1.2911\n",
      "Epoch 3328/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7673 - val_loss: 1.2892\n",
      "Epoch 3329/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.8090 - val_loss: 1.3019\n",
      "Epoch 3330/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7677 - val_loss: 1.2919\n",
      "Epoch 3331/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7708 - val_loss: 1.3131\n",
      "Epoch 3332/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7795 - val_loss: 1.3133\n",
      "Epoch 3333/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7653 - val_loss: 1.3124\n",
      "Epoch 3334/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7705 - val_loss: 1.3173\n",
      "Epoch 3335/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.7702 - val_loss: 1.2949\n",
      "Epoch 3336/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7842 - val_loss: 1.3176\n",
      "Epoch 3337/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7812 - val_loss: 1.3224\n",
      "Epoch 3338/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7885 - val_loss: 1.3028\n",
      "Epoch 3339/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7750 - val_loss: 1.2821\n",
      "Epoch 3340/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7947 - val_loss: 1.3035\n",
      "Epoch 3341/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7824 - val_loss: 1.2950\n",
      "Epoch 3342/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7861 - val_loss: 1.2594\n",
      "Epoch 3343/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7798 - val_loss: 1.2534\n",
      "Epoch 3344/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7708 - val_loss: 1.2525\n",
      "Epoch 3345/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7827 - val_loss: 1.2625\n",
      "Epoch 3346/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7842 - val_loss: 1.2426\n",
      "Epoch 3347/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7669 - val_loss: 1.2656\n",
      "Epoch 3348/5000\n",
      "572/572 [==============================] - 0s 541us/step - loss: 0.7804 - val_loss: 1.3031\n",
      "Epoch 3349/5000\n",
      "572/572 [==============================] - 0s 554us/step - loss: 0.7962 - val_loss: 1.2951\n",
      "Epoch 3350/5000\n",
      "572/572 [==============================] - 0s 561us/step - loss: 0.7861 - val_loss: 1.3495\n",
      "Epoch 3351/5000\n",
      "572/572 [==============================] - 0s 558us/step - loss: 0.7800 - val_loss: 1.3445\n",
      "Epoch 3352/5000\n",
      "572/572 [==============================] - 0s 562us/step - loss: 0.7947 - val_loss: 1.2968\n",
      "Epoch 3353/5000\n",
      "572/572 [==============================] - 0s 567us/step - loss: 0.7794 - val_loss: 1.2524\n",
      "Epoch 3354/5000\n",
      "572/572 [==============================] - 0s 558us/step - loss: 0.7731 - val_loss: 1.2711\n",
      "Epoch 3355/5000\n",
      "572/572 [==============================] - 0s 579us/step - loss: 0.7959 - val_loss: 1.2948\n",
      "Epoch 3356/5000\n",
      "572/572 [==============================] - 0s 560us/step - loss: 0.7854 - val_loss: 1.2773\n",
      "Epoch 3357/5000\n",
      "572/572 [==============================] - 0s 534us/step - loss: 0.7764 - val_loss: 1.3164\n",
      "Epoch 3358/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 488us/step - loss: 0.7878 - val_loss: 1.3135\n",
      "Epoch 3359/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7652 - val_loss: 1.3089\n",
      "Epoch 3360/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7732 - val_loss: 1.2843\n",
      "Epoch 3361/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7802 - val_loss: 1.2606\n",
      "Epoch 3362/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7760 - val_loss: 1.2636\n",
      "Epoch 3363/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7650 - val_loss: 1.2705\n",
      "Epoch 3364/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7882 - val_loss: 1.2992\n",
      "Epoch 3365/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7668 - val_loss: 1.2928\n",
      "Epoch 3366/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7769 - val_loss: 1.2947\n",
      "Epoch 3367/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7736 - val_loss: 1.2997\n",
      "Epoch 3368/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7698 - val_loss: 1.3192\n",
      "Epoch 3369/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7759 - val_loss: 1.3163\n",
      "Epoch 3370/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7709 - val_loss: 1.3165\n",
      "Epoch 3371/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7613 - val_loss: 1.3219\n",
      "Epoch 3372/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7779 - val_loss: 1.2805\n",
      "Epoch 3373/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7664 - val_loss: 1.3010\n",
      "Epoch 3374/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7756 - val_loss: 1.3226\n",
      "Epoch 3375/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7707 - val_loss: 1.3152\n",
      "Epoch 3376/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7745 - val_loss: 1.2738\n",
      "Epoch 3377/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7859 - val_loss: 1.3215\n",
      "Epoch 3378/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7715 - val_loss: 1.3040\n",
      "Epoch 3379/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7837 - val_loss: 1.2834\n",
      "Epoch 3380/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7833 - val_loss: 1.2874\n",
      "Epoch 3381/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7786 - val_loss: 1.2567\n",
      "Epoch 3382/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7925 - val_loss: 1.2602\n",
      "Epoch 3383/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7931 - val_loss: 1.2685\n",
      "Epoch 3384/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7794 - val_loss: 1.2648\n",
      "Epoch 3385/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7849 - val_loss: 1.2747\n",
      "Epoch 3386/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7862 - val_loss: 1.2690\n",
      "Epoch 3387/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7642 - val_loss: 1.3039\n",
      "Epoch 3388/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7807 - val_loss: 1.3074\n",
      "Epoch 3389/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7702 - val_loss: 1.2997\n",
      "Epoch 3390/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7681 - val_loss: 1.2971\n",
      "Epoch 3391/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7617 - val_loss: 1.3012\n",
      "Epoch 3392/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7674 - val_loss: 1.2933\n",
      "Epoch 3393/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7814 - val_loss: 1.3079\n",
      "Epoch 3394/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7949 - val_loss: 1.3180\n",
      "Epoch 3395/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7636 - val_loss: 1.3120\n",
      "Epoch 3396/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7757 - val_loss: 1.3294\n",
      "Epoch 3397/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7898 - val_loss: 1.3513\n",
      "Epoch 3398/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7773 - val_loss: 1.3061\n",
      "Epoch 3399/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7815 - val_loss: 1.2733\n",
      "Epoch 3400/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7803 - val_loss: 1.2692\n",
      "Epoch 3401/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7865 - val_loss: 1.3052\n",
      "Epoch 3402/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7831 - val_loss: 1.3041\n",
      "Epoch 3403/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7909 - val_loss: 1.2933\n",
      "Epoch 3404/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7805 - val_loss: 1.2864\n",
      "Epoch 3405/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7732 - val_loss: 1.2837\n",
      "Epoch 3406/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7881 - val_loss: 1.2717\n",
      "Epoch 3407/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7660 - val_loss: 1.2861\n",
      "Epoch 3408/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7804 - val_loss: 1.2766\n",
      "Epoch 3409/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7923 - val_loss: 1.2990\n",
      "Epoch 3410/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7692 - val_loss: 1.3327\n",
      "Epoch 3411/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7894 - val_loss: 1.2726\n",
      "Epoch 3412/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7760 - val_loss: 1.2995\n",
      "Epoch 3413/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7801 - val_loss: 1.2526\n",
      "Epoch 3414/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7924 - val_loss: 1.2817\n",
      "Epoch 3415/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7758 - val_loss: 1.2582\n",
      "Epoch 3416/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7924 - val_loss: 1.2683\n",
      "Epoch 3417/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7749 - val_loss: 1.2824\n",
      "Epoch 3418/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7851 - val_loss: 1.3159\n",
      "Epoch 3419/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7776 - val_loss: 1.2956\n",
      "Epoch 3420/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7763 - val_loss: 1.2997\n",
      "Epoch 3421/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7694 - val_loss: 1.3057\n",
      "Epoch 3422/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7940 - val_loss: 1.2727\n",
      "Epoch 3423/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7824 - val_loss: 1.2816\n",
      "Epoch 3424/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7799 - val_loss: 1.2833\n",
      "Epoch 3425/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7866 - val_loss: 1.2888\n",
      "Epoch 3426/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7646 - val_loss: 1.2728\n",
      "Epoch 3427/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7831 - val_loss: 1.2595\n",
      "Epoch 3428/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7787 - val_loss: 1.2973\n",
      "Epoch 3429/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7822 - val_loss: 1.2807\n",
      "Epoch 3430/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7551 - val_loss: 1.2866\n",
      "Epoch 3431/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7675 - val_loss: 1.3025\n",
      "Epoch 3432/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7996 - val_loss: 1.3221\n",
      "Epoch 3433/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7916 - val_loss: 1.3256\n",
      "Epoch 3434/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8035 - val_loss: 1.3109\n",
      "Epoch 3435/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7911 - val_loss: 1.3062\n",
      "Epoch 3436/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7736 - val_loss: 1.2942\n",
      "Epoch 3437/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7696 - val_loss: 1.2683\n",
      "Epoch 3438/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7701 - val_loss: 1.2791\n",
      "Epoch 3439/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7876 - val_loss: 1.3048\n",
      "Epoch 3440/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7809 - val_loss: 1.3065\n",
      "Epoch 3441/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7734 - val_loss: 1.2798\n",
      "Epoch 3442/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7875 - val_loss: 1.3183\n",
      "Epoch 3443/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7769 - val_loss: 1.3216\n",
      "Epoch 3444/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7765 - val_loss: 1.3226\n",
      "Epoch 3445/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7772 - val_loss: 1.3155\n",
      "Epoch 3446/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7719 - val_loss: 1.3256\n",
      "Epoch 3447/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7572 - val_loss: 1.2975\n",
      "Epoch 3448/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7627 - val_loss: 1.3442\n",
      "Epoch 3449/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7846 - val_loss: 1.2781\n",
      "Epoch 3450/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7919 - val_loss: 1.3030\n",
      "Epoch 3451/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7608 - val_loss: 1.2796\n",
      "Epoch 3452/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7800 - val_loss: 1.3435\n",
      "Epoch 3453/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7748 - val_loss: 1.3800\n",
      "Epoch 3454/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7833 - val_loss: 1.3714\n",
      "Epoch 3455/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7766 - val_loss: 1.2852\n",
      "Epoch 3456/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7901 - val_loss: 1.2630\n",
      "Epoch 3457/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7809 - val_loss: 1.2580\n",
      "Epoch 3458/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7612 - val_loss: 1.2548\n",
      "Epoch 3459/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7643 - val_loss: 1.2860\n",
      "Epoch 3460/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7661 - val_loss: 1.2868\n",
      "Epoch 3461/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7810 - val_loss: 1.2828\n",
      "Epoch 3462/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7911 - val_loss: 1.3174\n",
      "Epoch 3463/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7824 - val_loss: 1.2966\n",
      "Epoch 3464/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7831 - val_loss: 1.3120\n",
      "Epoch 3465/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7831 - val_loss: 1.3278\n",
      "Epoch 3466/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7846 - val_loss: 1.2773\n",
      "Epoch 3467/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7809 - val_loss: 1.2648\n",
      "Epoch 3468/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7883 - val_loss: 1.2652\n",
      "Epoch 3469/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7829 - val_loss: 1.2808\n",
      "Epoch 3470/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7888 - val_loss: 1.2964\n",
      "Epoch 3471/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7794 - val_loss: 1.2601\n",
      "Epoch 3472/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7914 - val_loss: 1.2537\n",
      "Epoch 3473/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7808 - val_loss: 1.2582\n",
      "Epoch 3474/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7767 - val_loss: 1.2600\n",
      "Epoch 3475/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7749 - val_loss: 1.2537\n",
      "Epoch 3476/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7803 - val_loss: 1.2481\n",
      "Epoch 3477/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7991 - val_loss: 1.2493\n",
      "Epoch 3478/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7732 - val_loss: 1.2392\n",
      "Epoch 3479/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7956 - val_loss: 1.2464\n",
      "Epoch 3480/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7717 - val_loss: 1.2600\n",
      "Epoch 3481/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7935 - val_loss: 1.2774\n",
      "Epoch 3482/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7788 - val_loss: 1.2935\n",
      "Epoch 3483/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7872 - val_loss: 1.3053\n",
      "Epoch 3484/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7685 - val_loss: 1.3092\n",
      "Epoch 3485/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7691 - val_loss: 1.3028\n",
      "Epoch 3486/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7689 - val_loss: 1.3009\n",
      "Epoch 3487/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7633 - val_loss: 1.2890\n",
      "Epoch 3488/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7791 - val_loss: 1.3309\n",
      "Epoch 3489/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7575 - val_loss: 1.3555\n",
      "Epoch 3490/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7939 - val_loss: 1.3286\n",
      "Epoch 3491/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7850 - val_loss: 1.3333\n",
      "Epoch 3492/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7736 - val_loss: 1.2910\n",
      "Epoch 3493/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7655 - val_loss: 1.3162\n",
      "Epoch 3494/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7699 - val_loss: 1.3014\n",
      "Epoch 3495/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7768 - val_loss: 1.2919\n",
      "Epoch 3496/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7911 - val_loss: 1.2701\n",
      "Epoch 3497/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7717 - val_loss: 1.2886\n",
      "Epoch 3498/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7821 - val_loss: 1.3051\n",
      "Epoch 3499/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7629 - val_loss: 1.2865\n",
      "Epoch 3500/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7772 - val_loss: 1.3037\n",
      "Epoch 3501/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7624 - val_loss: 1.3017\n",
      "Epoch 3502/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7923 - val_loss: 1.2874\n",
      "Epoch 3503/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7728 - val_loss: 1.2840\n",
      "Epoch 3504/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7805 - val_loss: 1.2842\n",
      "Epoch 3505/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7724 - val_loss: 1.3007\n",
      "Epoch 3506/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7683 - val_loss: 1.2943\n",
      "Epoch 3507/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7761 - val_loss: 1.2869\n",
      "Epoch 3508/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7856 - val_loss: 1.2955\n",
      "Epoch 3509/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7685 - val_loss: 1.3023\n",
      "Epoch 3510/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 492us/step - loss: 0.7958 - val_loss: 1.3253\n",
      "Epoch 3511/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.7821 - val_loss: 1.3111\n",
      "Epoch 3512/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7937 - val_loss: 1.2904\n",
      "Epoch 3513/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7818 - val_loss: 1.2898\n",
      "Epoch 3514/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7792 - val_loss: 1.2948\n",
      "Epoch 3515/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7918 - val_loss: 1.2717\n",
      "Epoch 3516/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7841 - val_loss: 1.2872\n",
      "Epoch 3517/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7772 - val_loss: 1.2740\n",
      "Epoch 3518/5000\n",
      "572/572 [==============================] - 0s 513us/step - loss: 0.7876 - val_loss: 1.2731\n",
      "Epoch 3519/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7707 - val_loss: 1.2846\n",
      "Epoch 3520/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7773 - val_loss: 1.2929\n",
      "Epoch 3521/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7688 - val_loss: 1.2834\n",
      "Epoch 3522/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7666 - val_loss: 1.2669\n",
      "Epoch 3523/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.7826 - val_loss: 1.2631\n",
      "Epoch 3524/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7890 - val_loss: 1.2723\n",
      "Epoch 3525/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7697 - val_loss: 1.3354\n",
      "Epoch 3526/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7809 - val_loss: 1.3580\n",
      "Epoch 3527/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7769 - val_loss: 1.3681\n",
      "Epoch 3528/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7946 - val_loss: 1.3307\n",
      "Epoch 3529/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7684 - val_loss: 1.3185\n",
      "Epoch 3530/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7742 - val_loss: 1.3253\n",
      "Epoch 3531/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7546 - val_loss: 1.2982\n",
      "Epoch 3532/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7839 - val_loss: 1.3226\n",
      "Epoch 3533/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7708 - val_loss: 1.2925\n",
      "Epoch 3534/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7805 - val_loss: 1.2973\n",
      "Epoch 3535/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7801 - val_loss: 1.2859\n",
      "Epoch 3536/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7785 - val_loss: 1.2796\n",
      "Epoch 3537/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7697 - val_loss: 1.2687\n",
      "Epoch 3538/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7819 - val_loss: 1.2985\n",
      "Epoch 3539/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7861 - val_loss: 1.2814\n",
      "Epoch 3540/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7704 - val_loss: 1.2920\n",
      "Epoch 3541/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7739 - val_loss: 1.3033\n",
      "Epoch 3542/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7728 - val_loss: 1.3084\n",
      "Epoch 3543/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7742 - val_loss: 1.3090\n",
      "Epoch 3544/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7822 - val_loss: 1.2841\n",
      "Epoch 3545/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7684 - val_loss: 1.2907\n",
      "Epoch 3546/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7792 - val_loss: 1.3035\n",
      "Epoch 3547/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7856 - val_loss: 1.2908\n",
      "Epoch 3548/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7672 - val_loss: 1.3095\n",
      "Epoch 3549/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7816 - val_loss: 1.2964\n",
      "Epoch 3550/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7878 - val_loss: 1.3007\n",
      "Epoch 3551/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7893 - val_loss: 1.2868\n",
      "Epoch 3552/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7807 - val_loss: 1.3111\n",
      "Epoch 3553/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7911 - val_loss: 1.3066\n",
      "Epoch 3554/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7729 - val_loss: 1.2722\n",
      "Epoch 3555/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7902 - val_loss: 1.2431\n",
      "Epoch 3556/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7698 - val_loss: 1.2703\n",
      "Epoch 3557/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7802 - val_loss: 1.2811\n",
      "Epoch 3558/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7912 - val_loss: 1.2968\n",
      "Epoch 3559/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7850 - val_loss: 1.2928\n",
      "Epoch 3560/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7786 - val_loss: 1.2987\n",
      "Epoch 3561/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7790 - val_loss: 1.2834\n",
      "Epoch 3562/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7691 - val_loss: 1.2596\n",
      "Epoch 3563/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7733 - val_loss: 1.2446\n",
      "Epoch 3564/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7745 - val_loss: 1.2666\n",
      "Epoch 3565/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7771 - val_loss: 1.3393\n",
      "Epoch 3566/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7891 - val_loss: 1.2890\n",
      "Epoch 3567/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7861 - val_loss: 1.3177\n",
      "Epoch 3568/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7883 - val_loss: 1.3123\n",
      "Epoch 3569/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7841 - val_loss: 1.3164\n",
      "Epoch 3570/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7900 - val_loss: 1.2945\n",
      "Epoch 3571/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7850 - val_loss: 1.3090\n",
      "Epoch 3572/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7717 - val_loss: 1.2903\n",
      "Epoch 3573/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7907 - val_loss: 1.2829\n",
      "Epoch 3574/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7853 - val_loss: 1.2990\n",
      "Epoch 3575/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7921 - val_loss: 1.2844\n",
      "Epoch 3576/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7727 - val_loss: 1.2576\n",
      "Epoch 3577/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7660 - val_loss: 1.2218\n",
      "Epoch 3578/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7972 - val_loss: 1.2445\n",
      "Epoch 3579/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7848 - val_loss: 1.2432\n",
      "Epoch 3580/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7777 - val_loss: 1.2676\n",
      "Epoch 3581/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7743 - val_loss: 1.2865\n",
      "Epoch 3582/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7722 - val_loss: 1.2716\n",
      "Epoch 3583/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7890 - val_loss: 1.2866\n",
      "Epoch 3584/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7760 - val_loss: 1.2943\n",
      "Epoch 3585/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7784 - val_loss: 1.2840\n",
      "Epoch 3586/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7946 - val_loss: 1.2750\n",
      "Epoch 3587/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7824 - val_loss: 1.2810\n",
      "Epoch 3588/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7642 - val_loss: 1.2626\n",
      "Epoch 3589/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7849 - val_loss: 1.2488\n",
      "Epoch 3590/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7697 - val_loss: 1.2487\n",
      "Epoch 3591/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7851 - val_loss: 1.2802\n",
      "Epoch 3592/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7807 - val_loss: 1.2635\n",
      "Epoch 3593/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7731 - val_loss: 1.2595\n",
      "Epoch 3594/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7745 - val_loss: 1.2769\n",
      "Epoch 3595/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7882 - val_loss: 1.2584\n",
      "Epoch 3596/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7708 - val_loss: 1.2749\n",
      "Epoch 3597/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7603 - val_loss: 1.3029\n",
      "Epoch 3598/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7926 - val_loss: 1.3145\n",
      "Epoch 3599/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7811 - val_loss: 1.3352\n",
      "Epoch 3600/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7873 - val_loss: 1.3395\n",
      "Epoch 3601/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7939 - val_loss: 1.3401\n",
      "Epoch 3602/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7947 - val_loss: 1.3006\n",
      "Epoch 3603/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7910 - val_loss: 1.3156\n",
      "Epoch 3604/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7680 - val_loss: 1.2749\n",
      "Epoch 3605/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7910 - val_loss: 1.2901\n",
      "Epoch 3606/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7769 - val_loss: 1.3407\n",
      "Epoch 3607/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7803 - val_loss: 1.3234\n",
      "Epoch 3608/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7749 - val_loss: 1.2762\n",
      "Epoch 3609/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7816 - val_loss: 1.2838\n",
      "Epoch 3610/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7956 - val_loss: 1.2839\n",
      "Epoch 3611/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7909 - val_loss: 1.2763\n",
      "Epoch 3612/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7852 - val_loss: 1.2464\n",
      "Epoch 3613/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7745 - val_loss: 1.2529\n",
      "Epoch 3614/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7736 - val_loss: 1.2604\n",
      "Epoch 3615/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7780 - val_loss: 1.2621\n",
      "Epoch 3616/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7653 - val_loss: 1.3281\n",
      "Epoch 3617/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7728 - val_loss: 1.3534\n",
      "Epoch 3618/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7746 - val_loss: 1.3263\n",
      "Epoch 3619/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7674 - val_loss: 1.2917\n",
      "Epoch 3620/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7826 - val_loss: 1.3244\n",
      "Epoch 3621/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7734 - val_loss: 1.3143\n",
      "Epoch 3622/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7709 - val_loss: 1.2963\n",
      "Epoch 3623/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7924 - val_loss: 1.2630\n",
      "Epoch 3624/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7609 - val_loss: 1.2607\n",
      "Epoch 3625/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7630 - val_loss: 1.2709\n",
      "Epoch 3626/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7960 - val_loss: 1.2420\n",
      "Epoch 3627/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7851 - val_loss: 1.2517\n",
      "Epoch 3628/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.7852 - val_loss: 1.2357\n",
      "Epoch 3629/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7695 - val_loss: 1.2476\n",
      "Epoch 3630/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7685 - val_loss: 1.2577\n",
      "Epoch 3631/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.7843 - val_loss: 1.2548\n",
      "Epoch 3632/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7794 - val_loss: 1.2758\n",
      "Epoch 3633/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7807 - val_loss: 1.2597\n",
      "Epoch 3634/5000\n",
      "572/572 [==============================] - 0s 476us/step - loss: 0.7806 - val_loss: 1.2704\n",
      "Epoch 3635/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7724 - val_loss: 1.2832\n",
      "Epoch 3636/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7805 - val_loss: 1.2691\n",
      "Epoch 3637/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7802 - val_loss: 1.2776\n",
      "Epoch 3638/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7638 - val_loss: 1.2821\n",
      "Epoch 3639/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7815 - val_loss: 1.2882\n",
      "Epoch 3640/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7749 - val_loss: 1.2695\n",
      "Epoch 3641/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7894 - val_loss: 1.2897\n",
      "Epoch 3642/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7718 - val_loss: 1.3333\n",
      "Epoch 3643/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7682 - val_loss: 1.3208\n",
      "Epoch 3644/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7768 - val_loss: 1.3694\n",
      "Epoch 3645/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7842 - val_loss: 1.2788\n",
      "Epoch 3646/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7803 - val_loss: 1.2668\n",
      "Epoch 3647/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7632 - val_loss: 1.2834\n",
      "Epoch 3648/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7745 - val_loss: 1.2857\n",
      "Epoch 3649/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7884 - val_loss: 1.2513\n",
      "Epoch 3650/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7912 - val_loss: 1.2486\n",
      "Epoch 3651/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7697 - val_loss: 1.2453\n",
      "Epoch 3652/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7862 - val_loss: 1.2404\n",
      "Epoch 3653/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7551 - val_loss: 1.2430\n",
      "Epoch 3654/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7560 - val_loss: 1.2543\n",
      "Epoch 3655/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7856 - val_loss: 1.2709\n",
      "Epoch 3656/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7755 - val_loss: 1.3209\n",
      "Epoch 3657/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.8020 - val_loss: 1.2899\n",
      "Epoch 3658/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7760 - val_loss: 1.2878\n",
      "Epoch 3659/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7739 - val_loss: 1.2983\n",
      "Epoch 3660/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7906 - val_loss: 1.3127\n",
      "Epoch 3661/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7924 - val_loss: 1.3087\n",
      "Epoch 3662/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 487us/step - loss: 0.7864 - val_loss: 1.3054\n",
      "Epoch 3663/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7677 - val_loss: 1.2960\n",
      "Epoch 3664/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7880 - val_loss: 1.3009\n",
      "Epoch 3665/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7646 - val_loss: 1.2829\n",
      "Epoch 3666/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7995 - val_loss: 1.2972\n",
      "Epoch 3667/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7909 - val_loss: 1.2796\n",
      "Epoch 3668/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7573 - val_loss: 1.2603\n",
      "Epoch 3669/5000\n",
      "572/572 [==============================] - 0s 504us/step - loss: 0.7778 - val_loss: 1.2658\n",
      "Epoch 3670/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7821 - val_loss: 1.2762\n",
      "Epoch 3671/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7715 - val_loss: 1.2877\n",
      "Epoch 3672/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7770 - val_loss: 1.2783\n",
      "Epoch 3673/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7648 - val_loss: 1.3112\n",
      "Epoch 3674/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7719 - val_loss: 1.3117\n",
      "Epoch 3675/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7737 - val_loss: 1.3200\n",
      "Epoch 3676/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7697 - val_loss: 1.3173\n",
      "Epoch 3677/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7711 - val_loss: 1.3167\n",
      "Epoch 3678/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7698 - val_loss: 1.3233\n",
      "Epoch 3679/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7723 - val_loss: 1.2997\n",
      "Epoch 3680/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7728 - val_loss: 1.3376\n",
      "Epoch 3681/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7778 - val_loss: 1.3043\n",
      "Epoch 3682/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7718 - val_loss: 1.3179\n",
      "Epoch 3683/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7739 - val_loss: 1.2987\n",
      "Epoch 3684/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7730 - val_loss: 1.2740\n",
      "Epoch 3685/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7701 - val_loss: 1.2907\n",
      "Epoch 3686/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8003 - val_loss: 1.3054\n",
      "Epoch 3687/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7876 - val_loss: 1.2605\n",
      "Epoch 3688/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7728 - val_loss: 1.2692\n",
      "Epoch 3689/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7807 - val_loss: 1.2607\n",
      "Epoch 3690/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7672 - val_loss: 1.2910\n",
      "Epoch 3691/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7851 - val_loss: 1.2807\n",
      "Epoch 3692/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7840 - val_loss: 1.2531\n",
      "Epoch 3693/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7576 - val_loss: 1.2728\n",
      "Epoch 3694/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7781 - val_loss: 1.2568\n",
      "Epoch 3695/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7617 - val_loss: 1.2571\n",
      "Epoch 3696/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7768 - val_loss: 1.2922\n",
      "Epoch 3697/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7803 - val_loss: 1.3346\n",
      "Epoch 3698/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7902 - val_loss: 1.3035\n",
      "Epoch 3699/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7765 - val_loss: 1.2926\n",
      "Epoch 3700/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7533 - val_loss: 1.3076\n",
      "Epoch 3701/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7679 - val_loss: 1.3402\n",
      "Epoch 3702/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7611 - val_loss: 1.3073\n",
      "Epoch 3703/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7721 - val_loss: 1.3018\n",
      "Epoch 3704/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7656 - val_loss: 1.2835\n",
      "Epoch 3705/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7685 - val_loss: 1.2837\n",
      "Epoch 3706/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7954 - val_loss: 1.2832\n",
      "Epoch 3707/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7761 - val_loss: 1.2849\n",
      "Epoch 3708/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7829 - val_loss: 1.2902\n",
      "Epoch 3709/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7809 - val_loss: 1.2737\n",
      "Epoch 3710/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7579 - val_loss: 1.2814\n",
      "Epoch 3711/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7781 - val_loss: 1.2829\n",
      "Epoch 3712/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7756 - val_loss: 1.2693\n",
      "Epoch 3713/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7681 - val_loss: 1.2370\n",
      "Epoch 3714/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7886 - val_loss: 1.2460\n",
      "Epoch 3715/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7653 - val_loss: 1.2925\n",
      "Epoch 3716/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7713 - val_loss: 1.2899\n",
      "Epoch 3717/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7845 - val_loss: 1.2706\n",
      "Epoch 3718/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7667 - val_loss: 1.2500\n",
      "Epoch 3719/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7787 - val_loss: 1.3105\n",
      "Epoch 3720/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7700 - val_loss: 1.3192\n",
      "Epoch 3721/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7804 - val_loss: 1.3004\n",
      "Epoch 3722/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7847 - val_loss: 1.2678\n",
      "Epoch 3723/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7673 - val_loss: 1.2451\n",
      "Epoch 3724/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7763 - val_loss: 1.2383\n",
      "Epoch 3725/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7696 - val_loss: 1.2340\n",
      "Epoch 3726/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7710 - val_loss: 1.2612\n",
      "Epoch 3727/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7707 - val_loss: 1.2860\n",
      "Epoch 3728/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7659 - val_loss: 1.3631\n",
      "Epoch 3729/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7684 - val_loss: 1.3260\n",
      "Epoch 3730/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7942 - val_loss: 1.3195\n",
      "Epoch 3731/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7786 - val_loss: 1.3834\n",
      "Epoch 3732/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7815 - val_loss: 1.3204\n",
      "Epoch 3733/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7706 - val_loss: 1.2663\n",
      "Epoch 3734/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7797 - val_loss: 1.2492\n",
      "Epoch 3735/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7798 - val_loss: 1.2253\n",
      "Epoch 3736/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7639 - val_loss: 1.2644\n",
      "Epoch 3737/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7775 - val_loss: 1.2381\n",
      "Epoch 3738/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7811 - val_loss: 1.2504\n",
      "Epoch 3739/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7757 - val_loss: 1.2556\n",
      "Epoch 3740/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7695 - val_loss: 1.2789\n",
      "Epoch 3741/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.8007 - val_loss: 1.2696\n",
      "Epoch 3742/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7801 - val_loss: 1.2719\n",
      "Epoch 3743/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7756 - val_loss: 1.2602\n",
      "Epoch 3744/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7682 - val_loss: 1.2586\n",
      "Epoch 3745/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7735 - val_loss: 1.2576\n",
      "Epoch 3746/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7884 - val_loss: 1.2572\n",
      "Epoch 3747/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7689 - val_loss: 1.2537\n",
      "Epoch 3748/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7703 - val_loss: 1.2664\n",
      "Epoch 3749/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7827 - val_loss: 1.2314\n",
      "Epoch 3750/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7569 - val_loss: 1.2386\n",
      "Epoch 3751/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7756 - val_loss: 1.2736\n",
      "Epoch 3752/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7670 - val_loss: 1.2614\n",
      "Epoch 3753/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7515 - val_loss: 1.2572\n",
      "Epoch 3754/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7919 - val_loss: 1.2628\n",
      "Epoch 3755/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7616 - val_loss: 1.2733\n",
      "Epoch 3756/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7739 - val_loss: 1.2607\n",
      "Epoch 3757/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7774 - val_loss: 1.2889\n",
      "Epoch 3758/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7737 - val_loss: 1.2504\n",
      "Epoch 3759/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7846 - val_loss: 1.2765\n",
      "Epoch 3760/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7749 - val_loss: 1.3163\n",
      "Epoch 3761/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7780 - val_loss: 1.2988\n",
      "Epoch 3762/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7678 - val_loss: 1.2936\n",
      "Epoch 3763/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7613 - val_loss: 1.2779\n",
      "Epoch 3764/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7660 - val_loss: 1.2797\n",
      "Epoch 3765/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7706 - val_loss: 1.2848\n",
      "Epoch 3766/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7568 - val_loss: 1.2794\n",
      "Epoch 3767/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7676 - val_loss: 1.2734\n",
      "Epoch 3768/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7617 - val_loss: 1.2890\n",
      "Epoch 3769/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7836 - val_loss: 1.2853\n",
      "Epoch 3770/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7702 - val_loss: 1.3078\n",
      "Epoch 3771/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7705 - val_loss: 1.2673\n",
      "Epoch 3772/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7878 - val_loss: 1.2584\n",
      "Epoch 3773/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7769 - val_loss: 1.2810\n",
      "Epoch 3774/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7801 - val_loss: 1.2834\n",
      "Epoch 3775/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7701 - val_loss: 1.2602\n",
      "Epoch 3776/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7814 - val_loss: 1.2382\n",
      "Epoch 3777/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7638 - val_loss: 1.2538\n",
      "Epoch 3778/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7721 - val_loss: 1.2735\n",
      "Epoch 3779/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7667 - val_loss: 1.2868\n",
      "Epoch 3780/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7618 - val_loss: 1.3345\n",
      "Epoch 3781/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7637 - val_loss: 1.3296\n",
      "Epoch 3782/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7768 - val_loss: 1.3513\n",
      "Epoch 3783/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7741 - val_loss: 1.2747\n",
      "Epoch 3784/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7751 - val_loss: 1.2879\n",
      "Epoch 3785/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7748 - val_loss: 1.3054\n",
      "Epoch 3786/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7695 - val_loss: 1.2456\n",
      "Epoch 3787/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7747 - val_loss: 1.2548\n",
      "Epoch 3788/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7844 - val_loss: 1.2609\n",
      "Epoch 3789/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7837 - val_loss: 1.2919\n",
      "Epoch 3790/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7705 - val_loss: 1.3058\n",
      "Epoch 3791/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7738 - val_loss: 1.3534\n",
      "Epoch 3792/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7778 - val_loss: 1.2850\n",
      "Epoch 3793/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7700 - val_loss: 1.2274\n",
      "Epoch 3794/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7803 - val_loss: 1.2707\n",
      "Epoch 3795/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7637 - val_loss: 1.2538\n",
      "Epoch 3796/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7888 - val_loss: 1.3388\n",
      "Epoch 3797/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7708 - val_loss: 1.3575\n",
      "Epoch 3798/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7855 - val_loss: 1.3258\n",
      "Epoch 3799/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7926 - val_loss: 1.2804\n",
      "Epoch 3800/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7783 - val_loss: 1.2513\n",
      "Epoch 3801/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7717 - val_loss: 1.2380\n",
      "Epoch 3802/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7789 - val_loss: 1.2145\n",
      "Epoch 3803/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7824 - val_loss: 1.2069\n",
      "Epoch 3804/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7701 - val_loss: 1.2306\n",
      "Epoch 3805/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7732 - val_loss: 1.2456\n",
      "Epoch 3806/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7739 - val_loss: 1.2840\n",
      "Epoch 3807/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7715 - val_loss: 1.2760\n",
      "Epoch 3808/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7642 - val_loss: 1.2273\n",
      "Epoch 3809/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7847 - val_loss: 1.2589\n",
      "Epoch 3810/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7613 - val_loss: 1.3306\n",
      "Epoch 3811/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7812 - val_loss: 1.3034\n",
      "Epoch 3812/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7624 - val_loss: 1.2863\n",
      "Epoch 3813/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7827 - val_loss: 1.2781\n",
      "Epoch 3814/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 489us/step - loss: 0.7803 - val_loss: 1.3241\n",
      "Epoch 3815/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7842 - val_loss: 1.3084\n",
      "Epoch 3816/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7849 - val_loss: 1.3377\n",
      "Epoch 3817/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7745 - val_loss: 1.2923\n",
      "Epoch 3818/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7641 - val_loss: 1.3040\n",
      "Epoch 3819/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7825 - val_loss: 1.2630\n",
      "Epoch 3820/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7650 - val_loss: 1.2917\n",
      "Epoch 3821/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7683 - val_loss: 1.3014\n",
      "Epoch 3822/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7649 - val_loss: 1.3022\n",
      "Epoch 3823/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7703 - val_loss: 1.3146\n",
      "Epoch 3824/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7625 - val_loss: 1.2910\n",
      "Epoch 3825/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7638 - val_loss: 1.3062\n",
      "Epoch 3826/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7712 - val_loss: 1.2754\n",
      "Epoch 3827/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7887 - val_loss: 1.2660\n",
      "Epoch 3828/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7862 - val_loss: 1.2583\n",
      "Epoch 3829/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7681 - val_loss: 1.2701\n",
      "Epoch 3830/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7726 - val_loss: 1.2530\n",
      "Epoch 3831/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7697 - val_loss: 1.2352\n",
      "Epoch 3832/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7833 - val_loss: 1.2519\n",
      "Epoch 3833/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7649 - val_loss: 1.2246\n",
      "Epoch 3834/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7843 - val_loss: 1.2556\n",
      "Epoch 3835/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7616 - val_loss: 1.2369\n",
      "Epoch 3836/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7817 - val_loss: 1.1836\n",
      "Epoch 3837/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7717 - val_loss: 1.1981\n",
      "Epoch 3838/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7814 - val_loss: 1.2611\n",
      "Epoch 3839/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7722 - val_loss: 1.2617\n",
      "Epoch 3840/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7769 - val_loss: 1.2313\n",
      "Epoch 3841/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7988 - val_loss: 1.2225\n",
      "Epoch 3842/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7762 - val_loss: 1.2420\n",
      "Epoch 3843/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7681 - val_loss: 1.2564\n",
      "Epoch 3844/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7709 - val_loss: 1.2568\n",
      "Epoch 3845/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.7598 - val_loss: 1.2694\n",
      "Epoch 3846/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7710 - val_loss: 1.3006\n",
      "Epoch 3847/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7757 - val_loss: 1.2865\n",
      "Epoch 3848/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7655 - val_loss: 1.2868\n",
      "Epoch 3849/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7774 - val_loss: 1.2612\n",
      "Epoch 3850/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7621 - val_loss: 1.2462\n",
      "Epoch 3851/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7715 - val_loss: 1.2619\n",
      "Epoch 3852/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7906 - val_loss: 1.2831\n",
      "Epoch 3853/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.7755 - val_loss: 1.2606\n",
      "Epoch 3854/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7718 - val_loss: 1.2494\n",
      "Epoch 3855/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7716 - val_loss: 1.2395\n",
      "Epoch 3856/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7708 - val_loss: 1.3010\n",
      "Epoch 3857/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7755 - val_loss: 1.2611\n",
      "Epoch 3858/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7959 - val_loss: 1.2347\n",
      "Epoch 3859/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7817 - val_loss: 1.2388\n",
      "Epoch 3860/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7875 - val_loss: 1.3141\n",
      "Epoch 3861/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7777 - val_loss: 1.3126\n",
      "Epoch 3862/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7893 - val_loss: 1.3295\n",
      "Epoch 3863/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7866 - val_loss: 1.2721\n",
      "Epoch 3864/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7803 - val_loss: 1.2348\n",
      "Epoch 3865/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7770 - val_loss: 1.2253\n",
      "Epoch 3866/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7705 - val_loss: 1.2419\n",
      "Epoch 3867/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7713 - val_loss: 1.2702\n",
      "Epoch 3868/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7832 - val_loss: 1.2910\n",
      "Epoch 3869/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7674 - val_loss: 1.2508\n",
      "Epoch 3870/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7862 - val_loss: 1.2769\n",
      "Epoch 3871/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7845 - val_loss: 1.2722\n",
      "Epoch 3872/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7791 - val_loss: 1.2567\n",
      "Epoch 3873/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7654 - val_loss: 1.2417\n",
      "Epoch 3874/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7756 - val_loss: 1.2279\n",
      "Epoch 3875/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7699 - val_loss: 1.2384\n",
      "Epoch 3876/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7709 - val_loss: 1.2266\n",
      "Epoch 3877/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7640 - val_loss: 1.2379\n",
      "Epoch 3878/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7760 - val_loss: 1.3049\n",
      "Epoch 3879/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7698 - val_loss: 1.2870\n",
      "Epoch 3880/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7585 - val_loss: 1.3116\n",
      "Epoch 3881/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7827 - val_loss: 1.2858\n",
      "Epoch 3882/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7601 - val_loss: 1.2775\n",
      "Epoch 3883/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7698 - val_loss: 1.2703\n",
      "Epoch 3884/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7704 - val_loss: 1.2719\n",
      "Epoch 3885/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7743 - val_loss: 1.2669\n",
      "Epoch 3886/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7589 - val_loss: 1.3074\n",
      "Epoch 3887/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7652 - val_loss: 1.3215\n",
      "Epoch 3888/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7657 - val_loss: 1.2912\n",
      "Epoch 3889/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7618 - val_loss: 1.2550\n",
      "Epoch 3890/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7796 - val_loss: 1.2542\n",
      "Epoch 3891/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7628 - val_loss: 1.2550\n",
      "Epoch 3892/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7739 - val_loss: 1.2812\n",
      "Epoch 3893/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7908 - val_loss: 1.2810\n",
      "Epoch 3894/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7606 - val_loss: 1.2840\n",
      "Epoch 3895/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7756 - val_loss: 1.3173\n",
      "Epoch 3896/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7581 - val_loss: 1.2943\n",
      "Epoch 3897/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7668 - val_loss: 1.2648\n",
      "Epoch 3898/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7618 - val_loss: 1.2852\n",
      "Epoch 3899/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7659 - val_loss: 1.2819\n",
      "Epoch 3900/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7599 - val_loss: 1.2954\n",
      "Epoch 3901/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7726 - val_loss: 1.3111\n",
      "Epoch 3902/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7510 - val_loss: 1.3135\n",
      "Epoch 3903/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7693 - val_loss: 1.2985\n",
      "Epoch 3904/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7824 - val_loss: 1.2850\n",
      "Epoch 3905/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7915 - val_loss: 1.2489\n",
      "Epoch 3906/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7727 - val_loss: 1.2777\n",
      "Epoch 3907/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7810 - val_loss: 1.2577\n",
      "Epoch 3908/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7875 - val_loss: 1.2344\n",
      "Epoch 3909/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7609 - val_loss: 1.2346\n",
      "Epoch 3910/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7605 - val_loss: 1.2296\n",
      "Epoch 3911/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7799 - val_loss: 1.2263\n",
      "Epoch 3912/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7727 - val_loss: 1.2373\n",
      "Epoch 3913/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7753 - val_loss: 1.2779\n",
      "Epoch 3914/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7909 - val_loss: 1.3063\n",
      "Epoch 3915/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7791 - val_loss: 1.2984\n",
      "Epoch 3916/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7785 - val_loss: 1.2740\n",
      "Epoch 3917/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7801 - val_loss: 1.2758\n",
      "Epoch 3918/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7723 - val_loss: 1.2567\n",
      "Epoch 3919/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7713 - val_loss: 1.2412\n",
      "Epoch 3920/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7698 - val_loss: 1.2836\n",
      "Epoch 3921/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7697 - val_loss: 1.2688\n",
      "Epoch 3922/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7770 - val_loss: 1.2705\n",
      "Epoch 3923/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7750 - val_loss: 1.2605\n",
      "Epoch 3924/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7663 - val_loss: 1.2624\n",
      "Epoch 3925/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7719 - val_loss: 1.2239\n",
      "Epoch 3926/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7807 - val_loss: 1.2133\n",
      "Epoch 3927/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7906 - val_loss: 1.2242\n",
      "Epoch 3928/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7742 - val_loss: 1.2710\n",
      "Epoch 3929/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7813 - val_loss: 1.2911\n",
      "Epoch 3930/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7882 - val_loss: 1.2723\n",
      "Epoch 3931/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.7724 - val_loss: 1.2735\n",
      "Epoch 3932/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7658 - val_loss: 1.2729\n",
      "Epoch 3933/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7670 - val_loss: 1.2913\n",
      "Epoch 3934/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7793 - val_loss: 1.3004\n",
      "Epoch 3935/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7699 - val_loss: 1.2981\n",
      "Epoch 3936/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7654 - val_loss: 1.2783\n",
      "Epoch 3937/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7603 - val_loss: 1.2742\n",
      "Epoch 3938/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7626 - val_loss: 1.2794\n",
      "Epoch 3939/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7708 - val_loss: 1.2769\n",
      "Epoch 3940/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7786 - val_loss: 1.2827\n",
      "Epoch 3941/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7685 - val_loss: 1.2593\n",
      "Epoch 3942/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7745 - val_loss: 1.2562\n",
      "Epoch 3943/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7778 - val_loss: 1.2416\n",
      "Epoch 3944/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7594 - val_loss: 1.2667\n",
      "Epoch 3945/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7740 - val_loss: 1.2712\n",
      "Epoch 3946/5000\n",
      "572/572 [==============================] - 0s 515us/step - loss: 0.7706 - val_loss: 1.2464\n",
      "Epoch 3947/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7708 - val_loss: 1.2641\n",
      "Epoch 3948/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7674 - val_loss: 1.2811\n",
      "Epoch 3949/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7597 - val_loss: 1.2630\n",
      "Epoch 3950/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7666 - val_loss: 1.2619\n",
      "Epoch 3951/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7825 - val_loss: 1.2708\n",
      "Epoch 3952/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7711 - val_loss: 1.2694\n",
      "Epoch 3953/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7586 - val_loss: 1.3123\n",
      "Epoch 3954/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7666 - val_loss: 1.3090\n",
      "Epoch 3955/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7672 - val_loss: 1.2872\n",
      "Epoch 3956/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7648 - val_loss: 1.3170\n",
      "Epoch 3957/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7775 - val_loss: 1.2954\n",
      "Epoch 3958/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7602 - val_loss: 1.3339\n",
      "Epoch 3959/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7656 - val_loss: 1.3225\n",
      "Epoch 3960/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7760 - val_loss: 1.3225\n",
      "Epoch 3961/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7748 - val_loss: 1.2759\n",
      "Epoch 3962/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7878 - val_loss: 1.2995\n",
      "Epoch 3963/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7665 - val_loss: 1.2504\n",
      "Epoch 3964/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7835 - val_loss: 1.2647\n",
      "Epoch 3965/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7806 - val_loss: 1.2813\n",
      "Epoch 3966/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 487us/step - loss: 0.7716 - val_loss: 1.2979\n",
      "Epoch 3967/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7725 - val_loss: 1.2644\n",
      "Epoch 3968/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7746 - val_loss: 1.2791\n",
      "Epoch 3969/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7669 - val_loss: 1.2573\n",
      "Epoch 3970/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7690 - val_loss: 1.2517\n",
      "Epoch 3971/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7670 - val_loss: 1.2501\n",
      "Epoch 3972/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7754 - val_loss: 1.2897\n",
      "Epoch 3973/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7891 - val_loss: 1.2132\n",
      "Epoch 3974/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7758 - val_loss: 1.2701\n",
      "Epoch 3975/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7803 - val_loss: 1.2480\n",
      "Epoch 3976/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7649 - val_loss: 1.2490\n",
      "Epoch 3977/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7762 - val_loss: 1.2700\n",
      "Epoch 3978/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7786 - val_loss: 1.2544\n",
      "Epoch 3979/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7939 - val_loss: 1.2610\n",
      "Epoch 3980/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7710 - val_loss: 1.2705\n",
      "Epoch 3981/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7889 - val_loss: 1.2612\n",
      "Epoch 3982/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7734 - val_loss: 1.2565\n",
      "Epoch 3983/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7612 - val_loss: 1.2557\n",
      "Epoch 3984/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7689 - val_loss: 1.2567\n",
      "Epoch 3985/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7870 - val_loss: 1.2173\n",
      "Epoch 3986/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7739 - val_loss: 1.1890\n",
      "Epoch 3987/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7858 - val_loss: 1.2144\n",
      "Epoch 3988/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7793 - val_loss: 1.2177\n",
      "Epoch 3989/5000\n",
      "572/572 [==============================] - 0s 544us/step - loss: 0.7690 - val_loss: 1.2365\n",
      "Epoch 3990/5000\n",
      "572/572 [==============================] - 0s 554us/step - loss: 0.7862 - val_loss: 1.2947\n",
      "Epoch 3991/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.7719 - val_loss: 1.2748\n",
      "Epoch 3992/5000\n",
      "572/572 [==============================] - 0s 592us/step - loss: 0.7834 - val_loss: 1.3421\n",
      "Epoch 3993/5000\n",
      "572/572 [==============================] - 0s 551us/step - loss: 0.7604 - val_loss: 1.3423\n",
      "Epoch 3994/5000\n",
      "572/572 [==============================] - 0s 564us/step - loss: 0.7726 - val_loss: 1.2913\n",
      "Epoch 3995/5000\n",
      "572/572 [==============================] - 0s 561us/step - loss: 0.7845 - val_loss: 1.2831\n",
      "Epoch 3996/5000\n",
      "572/572 [==============================] - 0s 563us/step - loss: 0.7726 - val_loss: 1.2621\n",
      "Epoch 3997/5000\n",
      "572/572 [==============================] - 0s 551us/step - loss: 0.7829 - val_loss: 1.2242\n",
      "Epoch 3998/5000\n",
      "572/572 [==============================] - 0s 536us/step - loss: 0.7658 - val_loss: 1.2249\n",
      "Epoch 3999/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7641 - val_loss: 1.2310\n",
      "Epoch 4000/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7626 - val_loss: 1.2479\n",
      "Epoch 4001/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7549 - val_loss: 1.2550\n",
      "Epoch 4002/5000\n",
      "572/572 [==============================] - 0s 501us/step - loss: 0.7604 - val_loss: 1.2517\n",
      "Epoch 4003/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7790 - val_loss: 1.2588\n",
      "Epoch 4004/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7751 - val_loss: 1.2727\n",
      "Epoch 4005/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7666 - val_loss: 1.2348\n",
      "Epoch 4006/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7682 - val_loss: 1.2625\n",
      "Epoch 4007/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7805 - val_loss: 1.2844\n",
      "Epoch 4008/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7764 - val_loss: 1.2760\n",
      "Epoch 4009/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7662 - val_loss: 1.2516\n",
      "Epoch 4010/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7645 - val_loss: 1.2814\n",
      "Epoch 4011/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7719 - val_loss: 1.2488\n",
      "Epoch 4012/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7974 - val_loss: 1.2281\n",
      "Epoch 4013/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7667 - val_loss: 1.2346\n",
      "Epoch 4014/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7821 - val_loss: 1.2497\n",
      "Epoch 4015/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7622 - val_loss: 1.2690\n",
      "Epoch 4016/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7706 - val_loss: 1.2290\n",
      "Epoch 4017/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7580 - val_loss: 1.2364\n",
      "Epoch 4018/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7725 - val_loss: 1.2981\n",
      "Epoch 4019/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7763 - val_loss: 1.3376\n",
      "Epoch 4020/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7825 - val_loss: 1.3407\n",
      "Epoch 4021/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7798 - val_loss: 1.4141\n",
      "Epoch 4022/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7761 - val_loss: 1.4158\n",
      "Epoch 4023/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7816 - val_loss: 1.2893\n",
      "Epoch 4024/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7656 - val_loss: 1.3022\n",
      "Epoch 4025/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7425 - val_loss: 1.2724\n",
      "Epoch 4026/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7723 - val_loss: 1.2480\n",
      "Epoch 4027/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7895 - val_loss: 1.2416\n",
      "Epoch 4028/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7915 - val_loss: 1.2269\n",
      "Epoch 4029/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7697 - val_loss: 1.2393\n",
      "Epoch 4030/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7777 - val_loss: 1.2325\n",
      "Epoch 4031/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7734 - val_loss: 1.2243\n",
      "Epoch 4032/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7874 - val_loss: 1.2289\n",
      "Epoch 4033/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7839 - val_loss: 1.2156\n",
      "Epoch 4034/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7622 - val_loss: 1.2343\n",
      "Epoch 4035/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7844 - val_loss: 1.2435\n",
      "Epoch 4036/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7654 - val_loss: 1.2261\n",
      "Epoch 4037/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7622 - val_loss: 1.2410\n",
      "Epoch 4038/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7748 - val_loss: 1.2277\n",
      "Epoch 4039/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7689 - val_loss: 1.2529\n",
      "Epoch 4040/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7854 - val_loss: 1.2488\n",
      "Epoch 4041/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7792 - val_loss: 1.2255\n",
      "Epoch 4042/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7726 - val_loss: 1.2106\n",
      "Epoch 4043/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7649 - val_loss: 1.2436\n",
      "Epoch 4044/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7648 - val_loss: 1.2780\n",
      "Epoch 4045/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7770 - val_loss: 1.3223\n",
      "Epoch 4046/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7682 - val_loss: 1.2988\n",
      "Epoch 4047/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7835 - val_loss: 1.3067\n",
      "Epoch 4048/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7644 - val_loss: 1.2548\n",
      "Epoch 4049/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7675 - val_loss: 1.2528\n",
      "Epoch 4050/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7763 - val_loss: 1.2308\n",
      "Epoch 4051/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7713 - val_loss: 1.2462\n",
      "Epoch 4052/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7772 - val_loss: 1.2236\n",
      "Epoch 4053/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7664 - val_loss: 1.2720\n",
      "Epoch 4054/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7585 - val_loss: 1.2289\n",
      "Epoch 4055/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7849 - val_loss: 1.2253\n",
      "Epoch 4056/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7820 - val_loss: 1.2496\n",
      "Epoch 4057/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7926 - val_loss: 1.3162\n",
      "Epoch 4058/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7658 - val_loss: 1.3050\n",
      "Epoch 4059/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7691 - val_loss: 1.2578\n",
      "Epoch 4060/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7734 - val_loss: 1.2580\n",
      "Epoch 4061/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7732 - val_loss: 1.2656\n",
      "Epoch 4062/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7700 - val_loss: 1.3148\n",
      "Epoch 4063/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7764 - val_loss: 1.2922\n",
      "Epoch 4064/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7740 - val_loss: 1.2576\n",
      "Epoch 4065/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7771 - val_loss: 1.2797\n",
      "Epoch 4066/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7595 - val_loss: 1.2620\n",
      "Epoch 4067/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7752 - val_loss: 1.3046\n",
      "Epoch 4068/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7709 - val_loss: 1.2905\n",
      "Epoch 4069/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7654 - val_loss: 1.2175\n",
      "Epoch 4070/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7644 - val_loss: 1.2462\n",
      "Epoch 4071/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7635 - val_loss: 1.2455\n",
      "Epoch 4072/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7654 - val_loss: 1.2255\n",
      "Epoch 4073/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7752 - val_loss: 1.2786\n",
      "Epoch 4074/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7798 - val_loss: 1.3320\n",
      "Epoch 4075/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7824 - val_loss: 1.2739\n",
      "Epoch 4076/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7718 - val_loss: 1.2250\n",
      "Epoch 4077/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7804 - val_loss: 1.2152\n",
      "Epoch 4078/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7902 - val_loss: 1.2301\n",
      "Epoch 4079/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7884 - val_loss: 1.2408\n",
      "Epoch 4080/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7853 - val_loss: 1.2554\n",
      "Epoch 4081/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7707 - val_loss: 1.2428\n",
      "Epoch 4082/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7748 - val_loss: 1.2194\n",
      "Epoch 4083/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7671 - val_loss: 1.1951\n",
      "Epoch 4084/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7775 - val_loss: 1.2113\n",
      "Epoch 4085/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7798 - val_loss: 1.2220\n",
      "Epoch 4086/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7757 - val_loss: 1.2474\n",
      "Epoch 4087/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7725 - val_loss: 1.3048\n",
      "Epoch 4088/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7693 - val_loss: 1.2860\n",
      "Epoch 4089/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7697 - val_loss: 1.2739\n",
      "Epoch 4090/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7734 - val_loss: 1.2803\n",
      "Epoch 4091/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7688 - val_loss: 1.2026\n",
      "Epoch 4092/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7665 - val_loss: 1.2190\n",
      "Epoch 4093/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7750 - val_loss: 1.2142\n",
      "Epoch 4094/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7726 - val_loss: 1.2324\n",
      "Epoch 4095/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7911 - val_loss: 1.2207\n",
      "Epoch 4096/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7620 - val_loss: 1.2251\n",
      "Epoch 4097/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7650 - val_loss: 1.1818\n",
      "Epoch 4098/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7607 - val_loss: 1.2182\n",
      "Epoch 4099/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7740 - val_loss: 1.2318\n",
      "Epoch 4100/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7955 - val_loss: 1.2630\n",
      "Epoch 4101/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7785 - val_loss: 1.2778\n",
      "Epoch 4102/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7691 - val_loss: 1.2423\n",
      "Epoch 4103/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7678 - val_loss: 1.2798\n",
      "Epoch 4104/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.7594 - val_loss: 1.2538\n",
      "Epoch 4105/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.7859 - val_loss: 1.2034\n",
      "Epoch 4106/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7572 - val_loss: 1.3209\n",
      "Epoch 4107/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7703 - val_loss: 1.2793\n",
      "Epoch 4108/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7621 - val_loss: 1.3132\n",
      "Epoch 4109/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7598 - val_loss: 1.2919\n",
      "Epoch 4110/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7672 - val_loss: 1.2109\n",
      "Epoch 4111/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7662 - val_loss: 1.2340\n",
      "Epoch 4112/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7779 - val_loss: 1.2249\n",
      "Epoch 4113/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7850 - val_loss: 1.2345\n",
      "Epoch 4114/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7689 - val_loss: 1.2384\n",
      "Epoch 4115/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7721 - val_loss: 1.2229\n",
      "Epoch 4116/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7666 - val_loss: 1.2321\n",
      "Epoch 4117/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7902 - val_loss: 1.2356\n",
      "Epoch 4118/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 481us/step - loss: 0.7652 - val_loss: 1.2283\n",
      "Epoch 4119/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7743 - val_loss: 1.2017\n",
      "Epoch 4120/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7619 - val_loss: 1.2062\n",
      "Epoch 4121/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.7695 - val_loss: 1.2495\n",
      "Epoch 4122/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7804 - val_loss: 1.2099\n",
      "Epoch 4123/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7834 - val_loss: 1.2049\n",
      "Epoch 4124/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7825 - val_loss: 1.2155\n",
      "Epoch 4125/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7774 - val_loss: 1.2174\n",
      "Epoch 4126/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7697 - val_loss: 1.2307\n",
      "Epoch 4127/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7672 - val_loss: 1.2494\n",
      "Epoch 4128/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7686 - val_loss: 1.2760\n",
      "Epoch 4129/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7603 - val_loss: 1.2760\n",
      "Epoch 4130/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7707 - val_loss: 1.2987\n",
      "Epoch 4131/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7701 - val_loss: 1.2998\n",
      "Epoch 4132/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7716 - val_loss: 1.2838\n",
      "Epoch 4133/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7966 - val_loss: 1.2882\n",
      "Epoch 4134/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7703 - val_loss: 1.2947\n",
      "Epoch 4135/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7636 - val_loss: 1.3314\n",
      "Epoch 4136/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7777 - val_loss: 1.3102\n",
      "Epoch 4137/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7587 - val_loss: 1.3048\n",
      "Epoch 4138/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7510 - val_loss: 1.2962\n",
      "Epoch 4139/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7713 - val_loss: 1.2936\n",
      "Epoch 4140/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7596 - val_loss: 1.3116\n",
      "Epoch 4141/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7621 - val_loss: 1.3113\n",
      "Epoch 4142/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7572 - val_loss: 1.2303\n",
      "Epoch 4143/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7739 - val_loss: 1.2204\n",
      "Epoch 4144/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7871 - val_loss: 1.2090\n",
      "Epoch 4145/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7685 - val_loss: 1.2512\n",
      "Epoch 4146/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7603 - val_loss: 1.2738\n",
      "Epoch 4147/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7665 - val_loss: 1.2509\n",
      "Epoch 4148/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7604 - val_loss: 1.2632\n",
      "Epoch 4149/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7895 - val_loss: 1.3020\n",
      "Epoch 4150/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7684 - val_loss: 1.2979\n",
      "Epoch 4151/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7692 - val_loss: 1.2888\n",
      "Epoch 4152/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7930 - val_loss: 1.2553\n",
      "Epoch 4153/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7838 - val_loss: 1.2703\n",
      "Epoch 4154/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7824 - val_loss: 1.2406\n",
      "Epoch 4155/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7611 - val_loss: 1.2273\n",
      "Epoch 4156/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7678 - val_loss: 1.1911\n",
      "Epoch 4157/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7598 - val_loss: 1.1955\n",
      "Epoch 4158/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7667 - val_loss: 1.2293\n",
      "Epoch 4159/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7751 - val_loss: 1.2726\n",
      "Epoch 4160/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7800 - val_loss: 1.2723\n",
      "Epoch 4161/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7734 - val_loss: 1.2998\n",
      "Epoch 4162/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7720 - val_loss: 1.3093\n",
      "Epoch 4163/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7771 - val_loss: 1.3570\n",
      "Epoch 4164/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7819 - val_loss: 1.3285\n",
      "Epoch 4165/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7454 - val_loss: 1.2603\n",
      "Epoch 4166/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7608 - val_loss: 1.2617\n",
      "Epoch 4167/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7780 - val_loss: 1.3991\n",
      "Epoch 4168/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7616 - val_loss: 1.2545\n",
      "Epoch 4169/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7775 - val_loss: 1.2868\n",
      "Epoch 4170/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7696 - val_loss: 1.3826\n",
      "Epoch 4171/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7671 - val_loss: 1.2158\n",
      "Epoch 4172/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7743 - val_loss: 1.2305\n",
      "Epoch 4173/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7863 - val_loss: 1.2018\n",
      "Epoch 4174/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7822 - val_loss: 1.2141\n",
      "Epoch 4175/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7692 - val_loss: 1.2144\n",
      "Epoch 4176/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7597 - val_loss: 1.2125\n",
      "Epoch 4177/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7487 - val_loss: 1.2227\n",
      "Epoch 4178/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7729 - val_loss: 1.2042\n",
      "Epoch 4179/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7675 - val_loss: 1.2200\n",
      "Epoch 4180/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7801 - val_loss: 1.2215\n",
      "Epoch 4181/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7577 - val_loss: 1.2185\n",
      "Epoch 4182/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7748 - val_loss: 1.2013\n",
      "Epoch 4183/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7768 - val_loss: 1.1947\n",
      "Epoch 4184/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7727 - val_loss: 1.2181\n",
      "Epoch 4185/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7814 - val_loss: 1.2352\n",
      "Epoch 4186/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7616 - val_loss: 1.2530\n",
      "Epoch 4187/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7695 - val_loss: 1.2461\n",
      "Epoch 4188/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7877 - val_loss: 1.2729\n",
      "Epoch 4189/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7869 - val_loss: 1.3267\n",
      "Epoch 4190/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7683 - val_loss: 1.3534\n",
      "Epoch 4191/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7826 - val_loss: 1.2836\n",
      "Epoch 4192/5000\n",
      "572/572 [==============================] - 0s 506us/step - loss: 0.7572 - val_loss: 1.2352\n",
      "Epoch 4193/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7856 - val_loss: 1.2216\n",
      "Epoch 4194/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7553 - val_loss: 1.2303\n",
      "Epoch 4195/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7864 - val_loss: 1.1859\n",
      "Epoch 4196/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7682 - val_loss: 1.1925\n",
      "Epoch 4197/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7599 - val_loss: 1.2441\n",
      "Epoch 4198/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7650 - val_loss: 1.2211\n",
      "Epoch 4199/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7753 - val_loss: 1.2593\n",
      "Epoch 4200/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7660 - val_loss: 1.2677\n",
      "Epoch 4201/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7771 - val_loss: 1.2065\n",
      "Epoch 4202/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7733 - val_loss: 1.2672\n",
      "Epoch 4203/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7694 - val_loss: 1.2557\n",
      "Epoch 4204/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7722 - val_loss: 1.2355\n",
      "Epoch 4205/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7672 - val_loss: 1.2116\n",
      "Epoch 4206/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7643 - val_loss: 1.2043\n",
      "Epoch 4207/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7696 - val_loss: 1.2271\n",
      "Epoch 4208/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7668 - val_loss: 1.2607\n",
      "Epoch 4209/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7865 - val_loss: 1.2885\n",
      "Epoch 4210/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7703 - val_loss: 1.3005\n",
      "Epoch 4211/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7845 - val_loss: 1.2577\n",
      "Epoch 4212/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7449 - val_loss: 1.2839\n",
      "Epoch 4213/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7521 - val_loss: 1.2875\n",
      "Epoch 4214/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7711 - val_loss: 1.2301\n",
      "Epoch 4215/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7824 - val_loss: 1.2153\n",
      "Epoch 4216/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7700 - val_loss: 1.2806\n",
      "Epoch 4217/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7703 - val_loss: 1.2967\n",
      "Epoch 4218/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7873 - val_loss: 1.2920\n",
      "Epoch 4219/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7700 - val_loss: 1.2750\n",
      "Epoch 4220/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7749 - val_loss: 1.2676\n",
      "Epoch 4221/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7648 - val_loss: 1.2388\n",
      "Epoch 4222/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7666 - val_loss: 1.2789\n",
      "Epoch 4223/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7655 - val_loss: 1.2279\n",
      "Epoch 4224/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7393 - val_loss: 1.2251\n",
      "Epoch 4225/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7811 - val_loss: 1.3126\n",
      "Epoch 4226/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7738 - val_loss: 1.3584\n",
      "Epoch 4227/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7669 - val_loss: 1.3069\n",
      "Epoch 4228/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7824 - val_loss: 1.2894\n",
      "Epoch 4229/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7598 - val_loss: 1.2440\n",
      "Epoch 4230/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7580 - val_loss: 1.1881\n",
      "Epoch 4231/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7685 - val_loss: 1.2215\n",
      "Epoch 4232/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7707 - val_loss: 1.2242\n",
      "Epoch 4233/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7758 - val_loss: 1.2190\n",
      "Epoch 4234/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7606 - val_loss: 1.2031\n",
      "Epoch 4235/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7818 - val_loss: 1.2209\n",
      "Epoch 4236/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7692 - val_loss: 1.2379\n",
      "Epoch 4237/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7708 - val_loss: 1.2869\n",
      "Epoch 4238/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7653 - val_loss: 1.2331\n",
      "Epoch 4239/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7585 - val_loss: 1.2282\n",
      "Epoch 4240/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7723 - val_loss: 1.2523\n",
      "Epoch 4241/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7942 - val_loss: 1.3623\n",
      "Epoch 4242/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7540 - val_loss: 1.2686\n",
      "Epoch 4243/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7684 - val_loss: 1.2400\n",
      "Epoch 4244/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7686 - val_loss: 1.2891\n",
      "Epoch 4245/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7790 - val_loss: 1.2547\n",
      "Epoch 4246/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7715 - val_loss: 1.3031\n",
      "Epoch 4247/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7524 - val_loss: 1.2984\n",
      "Epoch 4248/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7823 - val_loss: 1.2498\n",
      "Epoch 4249/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7767 - val_loss: 1.2104\n",
      "Epoch 4250/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7780 - val_loss: 1.2188\n",
      "Epoch 4251/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7635 - val_loss: 1.2194\n",
      "Epoch 4252/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7698 - val_loss: 1.1943\n",
      "Epoch 4253/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7721 - val_loss: 1.2015\n",
      "Epoch 4254/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7730 - val_loss: 1.1729\n",
      "Epoch 4255/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7634 - val_loss: 1.1984\n",
      "Epoch 4256/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7717 - val_loss: 1.1806\n",
      "Epoch 4257/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7880 - val_loss: 1.1817\n",
      "Epoch 4258/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7692 - val_loss: 1.2181\n",
      "Epoch 4259/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.7750 - val_loss: 1.2727\n",
      "Epoch 4260/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7814 - val_loss: 1.2516\n",
      "Epoch 4261/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7673 - val_loss: 1.1935\n",
      "Epoch 4262/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7685 - val_loss: 1.2038\n",
      "Epoch 4263/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7713 - val_loss: 1.2651\n",
      "Epoch 4264/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7735 - val_loss: 1.2434\n",
      "Epoch 4265/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7649 - val_loss: 1.2571\n",
      "Epoch 4266/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7679 - val_loss: 1.2398\n",
      "Epoch 4267/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7782 - val_loss: 1.2468\n",
      "Epoch 4268/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7673 - val_loss: 1.2099\n",
      "Epoch 4269/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7794 - val_loss: 1.2184\n",
      "Epoch 4270/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 487us/step - loss: 0.7708 - val_loss: 1.2782\n",
      "Epoch 4271/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7829 - val_loss: 1.2824\n",
      "Epoch 4272/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7824 - val_loss: 1.3643\n",
      "Epoch 4273/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7783 - val_loss: 1.3049\n",
      "Epoch 4274/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7748 - val_loss: 1.2222\n",
      "Epoch 4275/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7767 - val_loss: 1.2300\n",
      "Epoch 4276/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7671 - val_loss: 1.2162\n",
      "Epoch 4277/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7874 - val_loss: 1.2024\n",
      "Epoch 4278/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7599 - val_loss: 1.2257\n",
      "Epoch 4279/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7584 - val_loss: 1.2165\n",
      "Epoch 4280/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7790 - val_loss: 1.2182\n",
      "Epoch 4281/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7651 - val_loss: 1.2406\n",
      "Epoch 4282/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7574 - val_loss: 1.2615\n",
      "Epoch 4283/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7561 - val_loss: 1.2709\n",
      "Epoch 4284/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7416 - val_loss: 1.2793\n",
      "Epoch 4285/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7615 - val_loss: 1.2532\n",
      "Epoch 4286/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7735 - val_loss: 1.2510\n",
      "Epoch 4287/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7722 - val_loss: 1.2903\n",
      "Epoch 4288/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7492 - val_loss: 1.3018\n",
      "Epoch 4289/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7726 - val_loss: 1.2143\n",
      "Epoch 4290/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7950 - val_loss: 1.2430\n",
      "Epoch 4291/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7627 - val_loss: 1.2342\n",
      "Epoch 4292/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7603 - val_loss: 1.2550\n",
      "Epoch 4293/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7769 - val_loss: 1.2062\n",
      "Epoch 4294/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7559 - val_loss: 1.1879\n",
      "Epoch 4295/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7713 - val_loss: 1.2144\n",
      "Epoch 4296/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7611 - val_loss: 1.1755\n",
      "Epoch 4297/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7637 - val_loss: 1.1927\n",
      "Epoch 4298/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7741 - val_loss: 1.3144\n",
      "Epoch 4299/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7756 - val_loss: 1.3126\n",
      "Epoch 4300/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7743 - val_loss: 1.3343\n",
      "Epoch 4301/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7751 - val_loss: 1.3561\n",
      "Epoch 4302/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7692 - val_loss: 1.3745\n",
      "Epoch 4303/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7751 - val_loss: 1.3142\n",
      "Epoch 4304/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7563 - val_loss: 1.3004\n",
      "Epoch 4305/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7719 - val_loss: 1.3259\n",
      "Epoch 4306/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7534 - val_loss: 1.2931\n",
      "Epoch 4307/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7799 - val_loss: 1.2927\n",
      "Epoch 4308/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7675 - val_loss: 1.3085\n",
      "Epoch 4309/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7767 - val_loss: 1.2639\n",
      "Epoch 4310/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7667 - val_loss: 1.2118\n",
      "Epoch 4311/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7745 - val_loss: 1.1890\n",
      "Epoch 4312/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7714 - val_loss: 1.2049\n",
      "Epoch 4313/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7663 - val_loss: 1.1983\n",
      "Epoch 4314/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7576 - val_loss: 1.2189\n",
      "Epoch 4315/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7718 - val_loss: 1.2133\n",
      "Epoch 4316/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7733 - val_loss: 1.1842\n",
      "Epoch 4317/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7655 - val_loss: 1.2023\n",
      "Epoch 4318/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7724 - val_loss: 1.2014\n",
      "Epoch 4319/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7739 - val_loss: 1.2543\n",
      "Epoch 4320/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7604 - val_loss: 1.2129\n",
      "Epoch 4321/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.7693 - val_loss: 1.2259\n",
      "Epoch 4322/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7812 - val_loss: 1.2103\n",
      "Epoch 4323/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7692 - val_loss: 1.2106\n",
      "Epoch 4324/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7667 - val_loss: 1.2043\n",
      "Epoch 4325/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7604 - val_loss: 1.2066\n",
      "Epoch 4326/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7707 - val_loss: 1.2405\n",
      "Epoch 4327/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7803 - val_loss: 1.2466\n",
      "Epoch 4328/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7580 - val_loss: 1.2715\n",
      "Epoch 4329/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7608 - val_loss: 1.3004\n",
      "Epoch 4330/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.7746 - val_loss: 1.2696\n",
      "Epoch 4331/5000\n",
      "572/572 [==============================] - 0s 516us/step - loss: 0.7599 - val_loss: 1.2147\n",
      "Epoch 4332/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7645 - val_loss: 1.2225\n",
      "Epoch 4333/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7827 - val_loss: 1.2501\n",
      "Epoch 4334/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7698 - val_loss: 1.2853\n",
      "Epoch 4335/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7719 - val_loss: 1.2314\n",
      "Epoch 4336/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7657 - val_loss: 1.2726\n",
      "Epoch 4337/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7580 - val_loss: 1.2355\n",
      "Epoch 4338/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7712 - val_loss: 1.2523\n",
      "Epoch 4339/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7720 - val_loss: 1.2997\n",
      "Epoch 4340/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7651 - val_loss: 1.3199\n",
      "Epoch 4341/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7603 - val_loss: 1.2760\n",
      "Epoch 4342/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7511 - val_loss: 1.2375\n",
      "Epoch 4343/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7768 - val_loss: 1.2740\n",
      "Epoch 4344/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7791 - val_loss: 1.2878\n",
      "Epoch 4345/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7577 - val_loss: 1.3028\n",
      "Epoch 4346/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7725 - val_loss: 1.2355\n",
      "Epoch 4347/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7604 - val_loss: 1.2263\n",
      "Epoch 4348/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7723 - val_loss: 1.2285\n",
      "Epoch 4349/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7485 - val_loss: 1.2493\n",
      "Epoch 4350/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7608 - val_loss: 1.2867\n",
      "Epoch 4351/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7604 - val_loss: 1.2509\n",
      "Epoch 4352/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7652 - val_loss: 1.2578\n",
      "Epoch 4353/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7581 - val_loss: 1.2434\n",
      "Epoch 4354/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7726 - val_loss: 1.2610\n",
      "Epoch 4355/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7783 - val_loss: 1.3251\n",
      "Epoch 4356/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7683 - val_loss: 1.2623\n",
      "Epoch 4357/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7653 - val_loss: 1.2487\n",
      "Epoch 4358/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7671 - val_loss: 1.2041\n",
      "Epoch 4359/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7520 - val_loss: 1.1966\n",
      "Epoch 4360/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7725 - val_loss: 1.2317\n",
      "Epoch 4361/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7878 - val_loss: 1.2987\n",
      "Epoch 4362/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7761 - val_loss: 1.2706\n",
      "Epoch 4363/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7724 - val_loss: 1.2407\n",
      "Epoch 4364/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7880 - val_loss: 1.2353\n",
      "Epoch 4365/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7795 - val_loss: 1.2216\n",
      "Epoch 4366/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7794 - val_loss: 1.2361\n",
      "Epoch 4367/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7638 - val_loss: 1.2360\n",
      "Epoch 4368/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7595 - val_loss: 1.2515\n",
      "Epoch 4369/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7685 - val_loss: 1.2761\n",
      "Epoch 4370/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7725 - val_loss: 1.3150\n",
      "Epoch 4371/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7629 - val_loss: 1.2588\n",
      "Epoch 4372/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7605 - val_loss: 1.2928\n",
      "Epoch 4373/5000\n",
      "572/572 [==============================] - 0s 505us/step - loss: 0.7688 - val_loss: 1.2729\n",
      "Epoch 4374/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7751 - val_loss: 1.2278\n",
      "Epoch 4375/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7758 - val_loss: 1.1972\n",
      "Epoch 4376/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7599 - val_loss: 1.2185\n",
      "Epoch 4377/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7554 - val_loss: 1.2177\n",
      "Epoch 4378/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7678 - val_loss: 1.1822\n",
      "Epoch 4379/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7647 - val_loss: 1.1845\n",
      "Epoch 4380/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7675 - val_loss: 1.2011\n",
      "Epoch 4381/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7779 - val_loss: 1.1836\n",
      "Epoch 4382/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7604 - val_loss: 1.1923\n",
      "Epoch 4383/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7760 - val_loss: 1.1932\n",
      "Epoch 4384/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7739 - val_loss: 1.2024\n",
      "Epoch 4385/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7601 - val_loss: 1.1956\n",
      "Epoch 4386/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7909 - val_loss: 1.2031\n",
      "Epoch 4387/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7562 - val_loss: 1.2468\n",
      "Epoch 4388/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7749 - val_loss: 1.2277\n",
      "Epoch 4389/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7600 - val_loss: 1.2068\n",
      "Epoch 4390/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7610 - val_loss: 1.2504\n",
      "Epoch 4391/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7466 - val_loss: 1.2772\n",
      "Epoch 4392/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7694 - val_loss: 1.2311\n",
      "Epoch 4393/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7624 - val_loss: 1.2376\n",
      "Epoch 4394/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7714 - val_loss: 1.2783\n",
      "Epoch 4395/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7560 - val_loss: 1.3389\n",
      "Epoch 4396/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7737 - val_loss: 1.3405\n",
      "Epoch 4397/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7790 - val_loss: 1.4224\n",
      "Epoch 4398/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7690 - val_loss: 1.3032\n",
      "Epoch 4399/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7632 - val_loss: 1.2264\n",
      "Epoch 4400/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7742 - val_loss: 1.2014\n",
      "Epoch 4401/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7629 - val_loss: 1.2516\n",
      "Epoch 4402/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7834 - val_loss: 1.2331\n",
      "Epoch 4403/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7755 - val_loss: 1.2248\n",
      "Epoch 4404/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7766 - val_loss: 1.2238\n",
      "Epoch 4405/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7781 - val_loss: 1.1840\n",
      "Epoch 4406/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7782 - val_loss: 1.1755\n",
      "Epoch 4407/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7507 - val_loss: 1.1634\n",
      "Epoch 4408/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7640 - val_loss: 1.1686\n",
      "Epoch 4409/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7630 - val_loss: 1.1957\n",
      "Epoch 4410/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7679 - val_loss: 1.2555\n",
      "Epoch 4411/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7626 - val_loss: 1.2014\n",
      "Epoch 4412/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7714 - val_loss: 1.2024\n",
      "Epoch 4413/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7694 - val_loss: 1.2189\n",
      "Epoch 4414/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7619 - val_loss: 1.1920\n",
      "Epoch 4415/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7577 - val_loss: 1.1843\n",
      "Epoch 4416/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7654 - val_loss: 1.1982\n",
      "Epoch 4417/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7694 - val_loss: 1.1920\n",
      "Epoch 4418/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7551 - val_loss: 1.1911\n",
      "Epoch 4419/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7658 - val_loss: 1.1901\n",
      "Epoch 4420/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7699 - val_loss: 1.2060\n",
      "Epoch 4421/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7722 - val_loss: 1.2549\n",
      "Epoch 4422/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 492us/step - loss: 0.7679 - val_loss: 1.2817\n",
      "Epoch 4423/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7598 - val_loss: 1.3047\n",
      "Epoch 4424/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7689 - val_loss: 1.2608\n",
      "Epoch 4425/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7760 - val_loss: 1.2125\n",
      "Epoch 4426/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7767 - val_loss: 1.1928\n",
      "Epoch 4427/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7651 - val_loss: 1.2125\n",
      "Epoch 4428/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7740 - val_loss: 1.2270\n",
      "Epoch 4429/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7807 - val_loss: 1.2226\n",
      "Epoch 4430/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7753 - val_loss: 1.2145\n",
      "Epoch 4431/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7704 - val_loss: 1.2943\n",
      "Epoch 4432/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7659 - val_loss: 1.2881\n",
      "Epoch 4433/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7667 - val_loss: 1.2602\n",
      "Epoch 4434/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7703 - val_loss: 1.2830\n",
      "Epoch 4435/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7688 - val_loss: 1.2030\n",
      "Epoch 4436/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7644 - val_loss: 1.1587\n",
      "Epoch 4437/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7738 - val_loss: 1.2283\n",
      "Epoch 4438/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7740 - val_loss: 1.2012\n",
      "Epoch 4439/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7736 - val_loss: 1.2232\n",
      "Epoch 4440/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7683 - val_loss: 1.1470\n",
      "Epoch 4441/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7742 - val_loss: 1.1989\n",
      "Epoch 4442/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7677 - val_loss: 1.1612\n",
      "Epoch 4443/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7581 - val_loss: 1.1310\n",
      "Epoch 4444/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7704 - val_loss: 1.1361\n",
      "Epoch 4445/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7615 - val_loss: 1.1550\n",
      "Epoch 4446/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7754 - val_loss: 1.1705\n",
      "Epoch 4447/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7626 - val_loss: 1.1634\n",
      "Epoch 4448/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7781 - val_loss: 1.1831\n",
      "Epoch 4449/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7690 - val_loss: 1.1822\n",
      "Epoch 4450/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7624 - val_loss: 1.1890\n",
      "Epoch 4451/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7667 - val_loss: 1.1452\n",
      "Epoch 4452/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7653 - val_loss: 1.1848\n",
      "Epoch 4453/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7699 - val_loss: 1.1655\n",
      "Epoch 4454/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7736 - val_loss: 1.1628\n",
      "Epoch 4455/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7715 - val_loss: 1.1944\n",
      "Epoch 4456/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7807 - val_loss: 1.1894\n",
      "Epoch 4457/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7640 - val_loss: 1.1559\n",
      "Epoch 4458/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7707 - val_loss: 1.1592\n",
      "Epoch 4459/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7718 - val_loss: 1.1637\n",
      "Epoch 4460/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7721 - val_loss: 1.1761\n",
      "Epoch 4461/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7775 - val_loss: 1.1638\n",
      "Epoch 4462/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7664 - val_loss: 1.1796\n",
      "Epoch 4463/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7751 - val_loss: 1.1805\n",
      "Epoch 4464/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7823 - val_loss: 1.1968\n",
      "Epoch 4465/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7606 - val_loss: 1.1735\n",
      "Epoch 4466/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7640 - val_loss: 1.1523\n",
      "Epoch 4467/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7822 - val_loss: 1.1686\n",
      "Epoch 4468/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7441 - val_loss: 1.2037\n",
      "Epoch 4469/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7558 - val_loss: 1.2090\n",
      "Epoch 4470/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7551 - val_loss: 1.2122\n",
      "Epoch 4471/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7669 - val_loss: 1.1827\n",
      "Epoch 4472/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7675 - val_loss: 1.1859\n",
      "Epoch 4473/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7702 - val_loss: 1.1886\n",
      "Epoch 4474/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7625 - val_loss: 1.2098\n",
      "Epoch 4475/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7702 - val_loss: 1.2238\n",
      "Epoch 4476/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7753 - val_loss: 1.2372\n",
      "Epoch 4477/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7498 - val_loss: 1.1781\n",
      "Epoch 4478/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7766 - val_loss: 1.1915\n",
      "Epoch 4479/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7702 - val_loss: 1.1715\n",
      "Epoch 4480/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7700 - val_loss: 1.1496\n",
      "Epoch 4481/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7616 - val_loss: 1.1903\n",
      "Epoch 4482/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7790 - val_loss: 1.2262\n",
      "Epoch 4483/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7703 - val_loss: 1.2732\n",
      "Epoch 4484/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7656 - val_loss: 1.2430\n",
      "Epoch 4485/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7642 - val_loss: 1.2357\n",
      "Epoch 4486/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7805 - val_loss: 1.2153\n",
      "Epoch 4487/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7576 - val_loss: 1.2418\n",
      "Epoch 4488/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7688 - val_loss: 1.1875\n",
      "Epoch 4489/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7691 - val_loss: 1.1992\n",
      "Epoch 4490/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7711 - val_loss: 1.1943\n",
      "Epoch 4491/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7549 - val_loss: 1.1636\n",
      "Epoch 4492/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7580 - val_loss: 1.2614\n",
      "Epoch 4493/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7731 - val_loss: 1.1690\n",
      "Epoch 4494/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7684 - val_loss: 1.1621\n",
      "Epoch 4495/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7777 - val_loss: 1.1624\n",
      "Epoch 4496/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7632 - val_loss: 1.1761\n",
      "Epoch 4497/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7571 - val_loss: 1.2961\n",
      "Epoch 4498/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7656 - val_loss: 1.2931\n",
      "Epoch 4499/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7639 - val_loss: 1.2320\n",
      "Epoch 4500/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7717 - val_loss: 1.2722\n",
      "Epoch 4501/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7587 - val_loss: 1.2146\n",
      "Epoch 4502/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7637 - val_loss: 1.2021\n",
      "Epoch 4503/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7609 - val_loss: 1.2070\n",
      "Epoch 4504/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7650 - val_loss: 1.2309\n",
      "Epoch 4505/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7511 - val_loss: 1.1882\n",
      "Epoch 4506/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7577 - val_loss: 1.1754\n",
      "Epoch 4507/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7918 - val_loss: 1.2039\n",
      "Epoch 4508/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7609 - val_loss: 1.2310\n",
      "Epoch 4509/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7757 - val_loss: 1.2165\n",
      "Epoch 4510/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7741 - val_loss: 1.2206\n",
      "Epoch 4511/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7670 - val_loss: 1.2405\n",
      "Epoch 4512/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7779 - val_loss: 1.2878\n",
      "Epoch 4513/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7824 - val_loss: 1.3045\n",
      "Epoch 4514/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7785 - val_loss: 1.3707\n",
      "Epoch 4515/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7603 - val_loss: 1.2960\n",
      "Epoch 4516/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7772 - val_loss: 1.2757\n",
      "Epoch 4517/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7546 - val_loss: 1.2268\n",
      "Epoch 4518/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7743 - val_loss: 1.2783\n",
      "Epoch 4519/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7652 - val_loss: 1.2242\n",
      "Epoch 4520/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7625 - val_loss: 1.2177\n",
      "Epoch 4521/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7698 - val_loss: 1.2170\n",
      "Epoch 4522/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7809 - val_loss: 1.2788\n",
      "Epoch 4523/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7667 - val_loss: 1.2131\n",
      "Epoch 4524/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7812 - val_loss: 1.2071\n",
      "Epoch 4525/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7626 - val_loss: 1.2244\n",
      "Epoch 4526/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7713 - val_loss: 1.2258\n",
      "Epoch 4527/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7754 - val_loss: 1.2483\n",
      "Epoch 4528/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7795 - val_loss: 1.2224\n",
      "Epoch 4529/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7562 - val_loss: 1.2470\n",
      "Epoch 4530/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7605 - val_loss: 1.2639\n",
      "Epoch 4531/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7559 - val_loss: 1.2796\n",
      "Epoch 4532/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7632 - val_loss: 1.2921\n",
      "Epoch 4533/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7668 - val_loss: 1.2827\n",
      "Epoch 4534/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7705 - val_loss: 1.2959\n",
      "Epoch 4535/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7869 - val_loss: 1.2837\n",
      "Epoch 4536/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7599 - val_loss: 1.2931\n",
      "Epoch 4537/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7596 - val_loss: 1.3984\n",
      "Epoch 4538/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7745 - val_loss: 1.2457\n",
      "Epoch 4539/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7619 - val_loss: 1.2655\n",
      "Epoch 4540/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7596 - val_loss: 1.2193\n",
      "Epoch 4541/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7670 - val_loss: 1.2203\n",
      "Epoch 4542/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7698 - val_loss: 1.2007\n",
      "Epoch 4543/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7751 - val_loss: 1.2062\n",
      "Epoch 4544/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7529 - val_loss: 1.2006\n",
      "Epoch 4545/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7737 - val_loss: 1.2026\n",
      "Epoch 4546/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7765 - val_loss: 1.1900\n",
      "Epoch 4547/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7734 - val_loss: 1.2173\n",
      "Epoch 4548/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7737 - val_loss: 1.1882\n",
      "Epoch 4549/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7538 - val_loss: 1.2186\n",
      "Epoch 4550/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7567 - val_loss: 1.1989\n",
      "Epoch 4551/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7923 - val_loss: 1.2430\n",
      "Epoch 4552/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7690 - val_loss: 1.2242\n",
      "Epoch 4553/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7677 - val_loss: 1.2115\n",
      "Epoch 4554/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7739 - val_loss: 1.2165\n",
      "Epoch 4555/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7673 - val_loss: 1.2496\n",
      "Epoch 4556/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7676 - val_loss: 1.2287\n",
      "Epoch 4557/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7770 - val_loss: 1.1887\n",
      "Epoch 4558/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7708 - val_loss: 1.2112\n",
      "Epoch 4559/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7777 - val_loss: 1.2886\n",
      "Epoch 4560/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7686 - val_loss: 1.2132\n",
      "Epoch 4561/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.7663 - val_loss: 1.1710\n",
      "Epoch 4562/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7662 - val_loss: 1.2069\n",
      "Epoch 4563/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7715 - val_loss: 1.2315\n",
      "Epoch 4564/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7826 - val_loss: 1.2924\n",
      "Epoch 4565/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7619 - val_loss: 1.2518\n",
      "Epoch 4566/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7654 - val_loss: 1.2061\n",
      "Epoch 4567/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7734 - val_loss: 1.2369\n",
      "Epoch 4568/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7696 - val_loss: 1.2058\n",
      "Epoch 4569/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7728 - val_loss: 1.1957\n",
      "Epoch 4570/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7586 - val_loss: 1.2445\n",
      "Epoch 4571/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7838 - val_loss: 1.2273\n",
      "Epoch 4572/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 0.7527 - val_loss: 1.1993\n",
      "Epoch 4573/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7727 - val_loss: 1.2227\n",
      "Epoch 4574/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 491us/step - loss: 0.7667 - val_loss: 1.3278\n",
      "Epoch 4575/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7632 - val_loss: 1.3208\n",
      "Epoch 4576/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7714 - val_loss: 1.1914\n",
      "Epoch 4577/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7625 - val_loss: 1.1987\n",
      "Epoch 4578/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7640 - val_loss: 1.2933\n",
      "Epoch 4579/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7868 - val_loss: 1.3333\n",
      "Epoch 4580/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7719 - val_loss: 1.2815\n",
      "Epoch 4581/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7709 - val_loss: 1.1950\n",
      "Epoch 4582/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7755 - val_loss: 1.2670\n",
      "Epoch 4583/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7460 - val_loss: 1.2100\n",
      "Epoch 4584/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7660 - val_loss: 1.2048\n",
      "Epoch 4585/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7625 - val_loss: 1.2069\n",
      "Epoch 4586/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7714 - val_loss: 1.2099\n",
      "Epoch 4587/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7596 - val_loss: 1.1844\n",
      "Epoch 4588/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7661 - val_loss: 1.1873\n",
      "Epoch 4589/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7623 - val_loss: 1.1859\n",
      "Epoch 4590/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7500 - val_loss: 1.1989\n",
      "Epoch 4591/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7622 - val_loss: 1.1950\n",
      "Epoch 4592/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7694 - val_loss: 1.1947\n",
      "Epoch 4593/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7657 - val_loss: 1.2190\n",
      "Epoch 4594/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7822 - val_loss: 1.2898\n",
      "Epoch 4595/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7661 - val_loss: 1.3096\n",
      "Epoch 4596/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7688 - val_loss: 1.2043\n",
      "Epoch 4597/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7492 - val_loss: 1.1884\n",
      "Epoch 4598/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7726 - val_loss: 1.1785\n",
      "Epoch 4599/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7639 - val_loss: 1.2085\n",
      "Epoch 4600/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7808 - val_loss: 1.1979\n",
      "Epoch 4601/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7829 - val_loss: 1.2213\n",
      "Epoch 4602/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7550 - val_loss: 1.2127\n",
      "Epoch 4603/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7572 - val_loss: 1.2098\n",
      "Epoch 4604/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7618 - val_loss: 1.2329\n",
      "Epoch 4605/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7849 - val_loss: 1.2540\n",
      "Epoch 4606/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7677 - val_loss: 1.2436\n",
      "Epoch 4607/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7603 - val_loss: 1.2298\n",
      "Epoch 4608/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7641 - val_loss: 1.2373\n",
      "Epoch 4609/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7480 - val_loss: 1.2523\n",
      "Epoch 4610/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7724 - val_loss: 1.2477\n",
      "Epoch 4611/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7692 - val_loss: 1.2741\n",
      "Epoch 4612/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7760 - val_loss: 1.2223\n",
      "Epoch 4613/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7438 - val_loss: 1.2125\n",
      "Epoch 4614/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7612 - val_loss: 1.2463\n",
      "Epoch 4615/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7745 - val_loss: 1.2052\n",
      "Epoch 4616/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7589 - val_loss: 1.2078\n",
      "Epoch 4617/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7684 - val_loss: 1.2002\n",
      "Epoch 4618/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7698 - val_loss: 1.2376\n",
      "Epoch 4619/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7531 - val_loss: 1.2508\n",
      "Epoch 4620/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7509 - val_loss: 1.2644\n",
      "Epoch 4621/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7509 - val_loss: 1.2175\n",
      "Epoch 4622/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7616 - val_loss: 1.2322\n",
      "Epoch 4623/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7748 - val_loss: 1.2118\n",
      "Epoch 4624/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7755 - val_loss: 1.2291\n",
      "Epoch 4625/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7716 - val_loss: 1.2492\n",
      "Epoch 4626/5000\n",
      "572/572 [==============================] - 0s 478us/step - loss: 0.7791 - val_loss: 1.2419\n",
      "Epoch 4627/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7636 - val_loss: 1.2043\n",
      "Epoch 4628/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7638 - val_loss: 1.2405\n",
      "Epoch 4629/5000\n",
      "572/572 [==============================] - 0s 508us/step - loss: 0.7683 - val_loss: 1.2652\n",
      "Epoch 4630/5000\n",
      "572/572 [==============================] - 0s 540us/step - loss: 0.7663 - val_loss: 1.3014\n",
      "Epoch 4631/5000\n",
      "572/572 [==============================] - 0s 564us/step - loss: 0.7725 - val_loss: 1.2814\n",
      "Epoch 4632/5000\n",
      "572/572 [==============================] - 0s 577us/step - loss: 0.7626 - val_loss: 1.2442\n",
      "Epoch 4633/5000\n",
      "572/572 [==============================] - 0s 565us/step - loss: 0.7597 - val_loss: 1.2122\n",
      "Epoch 4634/5000\n",
      "572/572 [==============================] - 0s 572us/step - loss: 0.7656 - val_loss: 1.2237\n",
      "Epoch 4635/5000\n",
      "572/572 [==============================] - 0s 551us/step - loss: 0.7684 - val_loss: 1.2191\n",
      "Epoch 4636/5000\n",
      "572/572 [==============================] - 0s 558us/step - loss: 0.7788 - val_loss: 1.2223\n",
      "Epoch 4637/5000\n",
      "572/572 [==============================] - 0s 567us/step - loss: 0.7474 - val_loss: 1.2303\n",
      "Epoch 4638/5000\n",
      "572/572 [==============================] - 0s 570us/step - loss: 0.7862 - val_loss: 1.2213\n",
      "Epoch 4639/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7528 - val_loss: 1.2095\n",
      "Epoch 4640/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7642 - val_loss: 1.1940\n",
      "Epoch 4641/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7654 - val_loss: 1.2636\n",
      "Epoch 4642/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7689 - val_loss: 1.3406\n",
      "Epoch 4643/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7580 - val_loss: 1.3413\n",
      "Epoch 4644/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7720 - val_loss: 1.2513\n",
      "Epoch 4645/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7672 - val_loss: 1.2309\n",
      "Epoch 4646/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7735 - val_loss: 1.2252\n",
      "Epoch 4647/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7748 - val_loss: 1.2104\n",
      "Epoch 4648/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7737 - val_loss: 1.1923\n",
      "Epoch 4649/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7766 - val_loss: 1.1938\n",
      "Epoch 4650/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7528 - val_loss: 1.2018\n",
      "Epoch 4651/5000\n",
      "572/572 [==============================] - 0s 500us/step - loss: 0.7493 - val_loss: 1.2113\n",
      "Epoch 4652/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7585 - val_loss: 1.3077\n",
      "Epoch 4653/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7500 - val_loss: 1.2084\n",
      "Epoch 4654/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7845 - val_loss: 1.2987\n",
      "Epoch 4655/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7722 - val_loss: 1.2891\n",
      "Epoch 4656/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7722 - val_loss: 1.2450\n",
      "Epoch 4657/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7858 - val_loss: 1.2212\n",
      "Epoch 4658/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7665 - val_loss: 1.1936\n",
      "Epoch 4659/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7837 - val_loss: 1.2163\n",
      "Epoch 4660/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7854 - val_loss: 1.1856\n",
      "Epoch 4661/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7715 - val_loss: 1.2340\n",
      "Epoch 4662/5000\n",
      "572/572 [==============================] - 0s 503us/step - loss: 0.7702 - val_loss: 1.2577\n",
      "Epoch 4663/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.7654 - val_loss: 1.2496\n",
      "Epoch 4664/5000\n",
      "572/572 [==============================] - 0s 501us/step - loss: 0.7656 - val_loss: 1.2125\n",
      "Epoch 4665/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7682 - val_loss: 1.2509\n",
      "Epoch 4666/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7526 - val_loss: 1.2398\n",
      "Epoch 4667/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7646 - val_loss: 1.2565\n",
      "Epoch 4668/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7716 - val_loss: 1.1768\n",
      "Epoch 4669/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7800 - val_loss: 1.1898\n",
      "Epoch 4670/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7862 - val_loss: 1.2202\n",
      "Epoch 4671/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7569 - val_loss: 1.1923\n",
      "Epoch 4672/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7669 - val_loss: 1.2329\n",
      "Epoch 4673/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7647 - val_loss: 1.1824\n",
      "Epoch 4674/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7518 - val_loss: 1.1940\n",
      "Epoch 4675/5000\n",
      "572/572 [==============================] - 0s 501us/step - loss: 0.7794 - val_loss: 1.2083\n",
      "Epoch 4676/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7724 - val_loss: 1.1799\n",
      "Epoch 4677/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7870 - val_loss: 1.1718\n",
      "Epoch 4678/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.7931 - val_loss: 1.1773\n",
      "Epoch 4679/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7696 - val_loss: 1.1887\n",
      "Epoch 4680/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7783 - val_loss: 1.1908\n",
      "Epoch 4681/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7723 - val_loss: 1.1953\n",
      "Epoch 4682/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7669 - val_loss: 1.1701\n",
      "Epoch 4683/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7794 - val_loss: 1.2291\n",
      "Epoch 4684/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7791 - val_loss: 1.2338\n",
      "Epoch 4685/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7584 - val_loss: 1.1797\n",
      "Epoch 4686/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7851 - val_loss: 1.1986\n",
      "Epoch 4687/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7669 - val_loss: 1.1808\n",
      "Epoch 4688/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7650 - val_loss: 1.2028\n",
      "Epoch 4689/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7685 - val_loss: 1.1991\n",
      "Epoch 4690/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7846 - val_loss: 1.1912\n",
      "Epoch 4691/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7921 - val_loss: 1.2574\n",
      "Epoch 4692/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7749 - val_loss: 1.2029\n",
      "Epoch 4693/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7550 - val_loss: 1.2041\n",
      "Epoch 4694/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7720 - val_loss: 1.1966\n",
      "Epoch 4695/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7754 - val_loss: 1.2163\n",
      "Epoch 4696/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7631 - val_loss: 1.1981\n",
      "Epoch 4697/5000\n",
      "572/572 [==============================] - 0s 501us/step - loss: 0.7737 - val_loss: 1.1590\n",
      "Epoch 4698/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7739 - val_loss: 1.1517\n",
      "Epoch 4699/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7793 - val_loss: 1.2251\n",
      "Epoch 4700/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7715 - val_loss: 1.2618\n",
      "Epoch 4701/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7666 - val_loss: 1.2077\n",
      "Epoch 4702/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7823 - val_loss: 1.2404\n",
      "Epoch 4703/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7416 - val_loss: 1.2364\n",
      "Epoch 4704/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7828 - val_loss: 1.2204\n",
      "Epoch 4705/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7552 - val_loss: 1.1627\n",
      "Epoch 4706/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7570 - val_loss: 1.2133\n",
      "Epoch 4707/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7613 - val_loss: 1.1812\n",
      "Epoch 4708/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.7652 - val_loss: 1.2015\n",
      "Epoch 4709/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7692 - val_loss: 1.2074\n",
      "Epoch 4710/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7516 - val_loss: 1.1768\n",
      "Epoch 4711/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7526 - val_loss: 1.1548\n",
      "Epoch 4712/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7664 - val_loss: 1.1486\n",
      "Epoch 4713/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7773 - val_loss: 1.1676\n",
      "Epoch 4714/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7596 - val_loss: 1.1604\n",
      "Epoch 4715/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7704 - val_loss: 1.1783\n",
      "Epoch 4716/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7662 - val_loss: 1.2011\n",
      "Epoch 4717/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7809 - val_loss: 1.2091\n",
      "Epoch 4718/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 0.7708 - val_loss: 1.2067\n",
      "Epoch 4719/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7659 - val_loss: 1.1834\n",
      "Epoch 4720/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7774 - val_loss: 1.1760\n",
      "Epoch 4721/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7702 - val_loss: 1.1999\n",
      "Epoch 4722/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7751 - val_loss: 1.1672\n",
      "Epoch 4723/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7628 - val_loss: 1.1504\n",
      "Epoch 4724/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7667 - val_loss: 1.1614\n",
      "Epoch 4725/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7589 - val_loss: 1.1478\n",
      "Epoch 4726/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 488us/step - loss: 0.7774 - val_loss: 1.1412\n",
      "Epoch 4727/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7765 - val_loss: 1.1546\n",
      "Epoch 4728/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7665 - val_loss: 1.1443\n",
      "Epoch 4729/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7714 - val_loss: 1.1650\n",
      "Epoch 4730/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7673 - val_loss: 1.1473\n",
      "Epoch 4731/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7767 - val_loss: 1.1317\n",
      "Epoch 4732/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7844 - val_loss: 1.1232\n",
      "Epoch 4733/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7709 - val_loss: 1.1293\n",
      "Epoch 4734/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7545 - val_loss: 1.1135\n",
      "Epoch 4735/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7538 - val_loss: 1.1333\n",
      "Epoch 4736/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7726 - val_loss: 1.1508\n",
      "Epoch 4737/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7735 - val_loss: 1.1312\n",
      "Epoch 4738/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7504 - val_loss: 1.1592\n",
      "Epoch 4739/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7667 - val_loss: 1.1940\n",
      "Epoch 4740/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7826 - val_loss: 1.1547\n",
      "Epoch 4741/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7801 - val_loss: 1.1405\n",
      "Epoch 4742/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7698 - val_loss: 1.1307\n",
      "Epoch 4743/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7506 - val_loss: 1.1339\n",
      "Epoch 4744/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7595 - val_loss: 1.1433\n",
      "Epoch 4745/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7565 - val_loss: 1.1663\n",
      "Epoch 4746/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7614 - val_loss: 1.1589\n",
      "Epoch 4747/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7695 - val_loss: 1.1359\n",
      "Epoch 4748/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7500 - val_loss: 1.1351\n",
      "Epoch 4749/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7754 - val_loss: 1.1509\n",
      "Epoch 4750/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7769 - val_loss: 1.1509\n",
      "Epoch 4751/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7736 - val_loss: 1.1397\n",
      "Epoch 4752/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7617 - val_loss: 1.1727\n",
      "Epoch 4753/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7822 - val_loss: 1.1454\n",
      "Epoch 4754/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7688 - val_loss: 1.1543\n",
      "Epoch 4755/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7552 - val_loss: 1.1524\n",
      "Epoch 4756/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7652 - val_loss: 1.1422\n",
      "Epoch 4757/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7698 - val_loss: 1.1264\n",
      "Epoch 4758/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7607 - val_loss: 1.1282\n",
      "Epoch 4759/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7524 - val_loss: 1.1125\n",
      "Epoch 4760/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7656 - val_loss: 1.1470\n",
      "Epoch 4761/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7592 - val_loss: 1.1477\n",
      "Epoch 4762/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7734 - val_loss: 1.1572\n",
      "Epoch 4763/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7515 - val_loss: 1.1657\n",
      "Epoch 4764/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7641 - val_loss: 1.1741\n",
      "Epoch 4765/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7771 - val_loss: 1.1918\n",
      "Epoch 4766/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7599 - val_loss: 1.1969\n",
      "Epoch 4767/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7562 - val_loss: 1.1408\n",
      "Epoch 4768/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7760 - val_loss: 1.1529\n",
      "Epoch 4769/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7510 - val_loss: 1.1391\n",
      "Epoch 4770/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7823 - val_loss: 1.1340\n",
      "Epoch 4771/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7789 - val_loss: 1.1225\n",
      "Epoch 4772/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7583 - val_loss: 1.1367\n",
      "Epoch 4773/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7685 - val_loss: 1.1315\n",
      "Epoch 4774/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7637 - val_loss: 1.1611\n",
      "Epoch 4775/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7592 - val_loss: 1.1779\n",
      "Epoch 4776/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7431 - val_loss: 1.1451\n",
      "Epoch 4777/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7488 - val_loss: 1.1828\n",
      "Epoch 4778/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7614 - val_loss: 1.1662\n",
      "Epoch 4779/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7683 - val_loss: 1.1376\n",
      "Epoch 4780/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7511 - val_loss: 1.1358\n",
      "Epoch 4781/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7910 - val_loss: 1.1344\n",
      "Epoch 4782/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7475 - val_loss: 1.1592\n",
      "Epoch 4783/5000\n",
      "572/572 [==============================] - 0s 497us/step - loss: 0.7721 - val_loss: 1.1634\n",
      "Epoch 4784/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7700 - val_loss: 1.1606\n",
      "Epoch 4785/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7738 - val_loss: 1.1818\n",
      "Epoch 4786/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7594 - val_loss: 1.1386\n",
      "Epoch 4787/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7452 - val_loss: 1.1607\n",
      "Epoch 4788/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7837 - val_loss: 1.1695\n",
      "Epoch 4789/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7579 - val_loss: 1.1397\n",
      "Epoch 4790/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7635 - val_loss: 1.1915\n",
      "Epoch 4791/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7518 - val_loss: 1.1414\n",
      "Epoch 4792/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7626 - val_loss: 1.1662\n",
      "Epoch 4793/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7656 - val_loss: 1.1386\n",
      "Epoch 4794/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7606 - val_loss: 1.1474\n",
      "Epoch 4795/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7515 - val_loss: 1.1699\n",
      "Epoch 4796/5000\n",
      "572/572 [==============================] - 0s 499us/step - loss: 0.7533 - val_loss: 1.1639\n",
      "Epoch 4797/5000\n",
      "572/572 [==============================] - 0s 520us/step - loss: 0.7641 - val_loss: 1.1627\n",
      "Epoch 4798/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7719 - val_loss: 1.1364\n",
      "Epoch 4799/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7726 - val_loss: 1.1420\n",
      "Epoch 4800/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7620 - val_loss: 1.1260\n",
      "Epoch 4801/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7528 - val_loss: 1.1429\n",
      "Epoch 4802/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7848 - val_loss: 1.1077\n",
      "Epoch 4803/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7541 - val_loss: 1.1862\n",
      "Epoch 4804/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7519 - val_loss: 1.1452\n",
      "Epoch 4805/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7974 - val_loss: 1.1361\n",
      "Epoch 4806/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7800 - val_loss: 1.1254\n",
      "Epoch 4807/5000\n",
      "572/572 [==============================] - 0s 498us/step - loss: 0.7648 - val_loss: 1.1305\n",
      "Epoch 4808/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7617 - val_loss: 1.1390\n",
      "Epoch 4809/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7735 - val_loss: 1.1502\n",
      "Epoch 4810/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7691 - val_loss: 1.1560\n",
      "Epoch 4811/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7707 - val_loss: 1.1845\n",
      "Epoch 4812/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7581 - val_loss: 1.1666\n",
      "Epoch 4813/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7557 - val_loss: 1.1691\n",
      "Epoch 4814/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7788 - val_loss: 1.1630\n",
      "Epoch 4815/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7649 - val_loss: 1.1963\n",
      "Epoch 4816/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7696 - val_loss: 1.1703\n",
      "Epoch 4817/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7782 - val_loss: 1.1058\n",
      "Epoch 4818/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7641 - val_loss: 1.1173\n",
      "Epoch 4819/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7735 - val_loss: 1.1664\n",
      "Epoch 4820/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7530 - val_loss: 1.1174\n",
      "Epoch 4821/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7655 - val_loss: 1.1389\n",
      "Epoch 4822/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7648 - val_loss: 1.1418\n",
      "Epoch 4823/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7765 - val_loss: 1.1620\n",
      "Epoch 4824/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7581 - val_loss: 1.1381\n",
      "Epoch 4825/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7469 - val_loss: 1.1645\n",
      "Epoch 4826/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7722 - val_loss: 1.1326\n",
      "Epoch 4827/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7590 - val_loss: 1.1323\n",
      "Epoch 4828/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7682 - val_loss: 1.1354\n",
      "Epoch 4829/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7657 - val_loss: 1.1239\n",
      "Epoch 4830/5000\n",
      "572/572 [==============================] - 0s 480us/step - loss: 0.7691 - val_loss: 1.1152\n",
      "Epoch 4831/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7843 - val_loss: 1.1415\n",
      "Epoch 4832/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7779 - val_loss: 1.2093\n",
      "Epoch 4833/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7688 - val_loss: 1.1355\n",
      "Epoch 4834/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7557 - val_loss: 1.1373\n",
      "Epoch 4835/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7629 - val_loss: 1.1225\n",
      "Epoch 4836/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7675 - val_loss: 1.1164\n",
      "Epoch 4837/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7738 - val_loss: 1.1506\n",
      "Epoch 4838/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7742 - val_loss: 1.1224\n",
      "Epoch 4839/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7805 - val_loss: 1.1347\n",
      "Epoch 4840/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7729 - val_loss: 1.1448\n",
      "Epoch 4841/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7772 - val_loss: 1.1501\n",
      "Epoch 4842/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7631 - val_loss: 1.1403\n",
      "Epoch 4843/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7805 - val_loss: 1.1431\n",
      "Epoch 4844/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7680 - val_loss: 1.1703\n",
      "Epoch 4845/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7525 - val_loss: 1.1656\n",
      "Epoch 4846/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7645 - val_loss: 1.1469\n",
      "Epoch 4847/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7660 - val_loss: 1.1480\n",
      "Epoch 4848/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7650 - val_loss: 1.1638\n",
      "Epoch 4849/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7671 - val_loss: 1.1487\n",
      "Epoch 4850/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7454 - val_loss: 1.1649\n",
      "Epoch 4851/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7577 - val_loss: 1.1614\n",
      "Epoch 4852/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7641 - val_loss: 1.1669\n",
      "Epoch 4853/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7640 - val_loss: 1.1385\n",
      "Epoch 4854/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7552 - val_loss: 1.1412\n",
      "Epoch 4855/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7638 - val_loss: 1.1467\n",
      "Epoch 4856/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7487 - val_loss: 1.1746\n",
      "Epoch 4857/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7650 - val_loss: 1.1679\n",
      "Epoch 4858/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7609 - val_loss: 1.1788\n",
      "Epoch 4859/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7686 - val_loss: 1.1845\n",
      "Epoch 4860/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7536 - val_loss: 1.1574\n",
      "Epoch 4861/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7658 - val_loss: 1.1307\n",
      "Epoch 4862/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7725 - val_loss: 1.1512\n",
      "Epoch 4863/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7601 - val_loss: 1.1474\n",
      "Epoch 4864/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7627 - val_loss: 1.1691\n",
      "Epoch 4865/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7556 - val_loss: 1.1704\n",
      "Epoch 4866/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7739 - val_loss: 1.1394\n",
      "Epoch 4867/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7640 - val_loss: 1.1296\n",
      "Epoch 4868/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7679 - val_loss: 1.1525\n",
      "Epoch 4869/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7586 - val_loss: 1.1629\n",
      "Epoch 4870/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7659 - val_loss: 1.1559\n",
      "Epoch 4871/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7747 - val_loss: 1.1194\n",
      "Epoch 4872/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7732 - val_loss: 1.1147\n",
      "Epoch 4873/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7824 - val_loss: 1.1842\n",
      "Epoch 4874/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7748 - val_loss: 1.1101\n",
      "Epoch 4875/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7574 - val_loss: 1.1152\n",
      "Epoch 4876/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7587 - val_loss: 1.1105\n",
      "Epoch 4877/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7714 - val_loss: 1.1145\n",
      "Epoch 4878/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 488us/step - loss: 0.7643 - val_loss: 1.1726\n",
      "Epoch 4879/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7769 - val_loss: 1.1169\n",
      "Epoch 4880/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7638 - val_loss: 1.1282\n",
      "Epoch 4881/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7719 - val_loss: 1.1378\n",
      "Epoch 4882/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7606 - val_loss: 1.1332\n",
      "Epoch 4883/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7663 - val_loss: 1.1437\n",
      "Epoch 4884/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7644 - val_loss: 1.1356\n",
      "Epoch 4885/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7698 - val_loss: 1.1400\n",
      "Epoch 4886/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7803 - val_loss: 1.1368\n",
      "Epoch 4887/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7657 - val_loss: 1.1409\n",
      "Epoch 4888/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7763 - val_loss: 1.1555\n",
      "Epoch 4889/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7624 - val_loss: 1.1195\n",
      "Epoch 4890/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7474 - val_loss: 1.1422\n",
      "Epoch 4891/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7723 - val_loss: 1.1277\n",
      "Epoch 4892/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7834 - val_loss: 1.1084\n",
      "Epoch 4893/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7604 - val_loss: 1.1280\n",
      "Epoch 4894/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7831 - val_loss: 1.1133\n",
      "Epoch 4895/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7587 - val_loss: 1.1501\n",
      "Epoch 4896/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7663 - val_loss: 1.1424\n",
      "Epoch 4897/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 0.7534 - val_loss: 1.1920\n",
      "Epoch 4898/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7683 - val_loss: 1.1753\n",
      "Epoch 4899/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7586 - val_loss: 1.1518\n",
      "Epoch 4900/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7737 - val_loss: 1.1559\n",
      "Epoch 4901/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7620 - val_loss: 1.1335\n",
      "Epoch 4902/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7611 - val_loss: 1.1362\n",
      "Epoch 4903/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7660 - val_loss: 1.1387\n",
      "Epoch 4904/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7532 - val_loss: 1.1183\n",
      "Epoch 4905/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7721 - val_loss: 1.1332\n",
      "Epoch 4906/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7671 - val_loss: 1.1409\n",
      "Epoch 4907/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7691 - val_loss: 1.1301\n",
      "Epoch 4908/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7751 - val_loss: 1.1378\n",
      "Epoch 4909/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7528 - val_loss: 1.1417\n",
      "Epoch 4910/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7504 - val_loss: 1.1399\n",
      "Epoch 4911/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7661 - val_loss: 1.1435\n",
      "Epoch 4912/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7534 - val_loss: 1.1601\n",
      "Epoch 4913/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7797 - val_loss: 1.1458\n",
      "Epoch 4914/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7725 - val_loss: 1.1407\n",
      "Epoch 4915/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7527 - val_loss: 1.1377\n",
      "Epoch 4916/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7692 - val_loss: 1.1623\n",
      "Epoch 4917/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7474 - val_loss: 1.1518\n",
      "Epoch 4918/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7706 - val_loss: 1.1428\n",
      "Epoch 4919/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7759 - val_loss: 1.1342\n",
      "Epoch 4920/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7766 - val_loss: 1.1464\n",
      "Epoch 4921/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7612 - val_loss: 1.1276\n",
      "Epoch 4922/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7547 - val_loss: 1.1426\n",
      "Epoch 4923/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7650 - val_loss: 1.1612\n",
      "Epoch 4924/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7770 - val_loss: 1.1320\n",
      "Epoch 4925/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7678 - val_loss: 1.1082\n",
      "Epoch 4926/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7693 - val_loss: 1.1764\n",
      "Epoch 4927/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7677 - val_loss: 1.1307\n",
      "Epoch 4928/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7673 - val_loss: 1.1207\n",
      "Epoch 4929/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7514 - val_loss: 1.1233\n",
      "Epoch 4930/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7641 - val_loss: 1.1222\n",
      "Epoch 4931/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7454 - val_loss: 1.1299\n",
      "Epoch 4932/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7485 - val_loss: 1.1274\n",
      "Epoch 4933/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7797 - val_loss: 1.1485\n",
      "Epoch 4934/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7684 - val_loss: 1.1182\n",
      "Epoch 4935/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7752 - val_loss: 1.1278\n",
      "Epoch 4936/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7747 - val_loss: 1.1367\n",
      "Epoch 4937/5000\n",
      "572/572 [==============================] - 0s 495us/step - loss: 0.7569 - val_loss: 1.1284\n",
      "Epoch 4938/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 0.7650 - val_loss: 1.1379\n",
      "Epoch 4939/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7723 - val_loss: 1.1457\n",
      "Epoch 4940/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7786 - val_loss: 1.1767\n",
      "Epoch 4941/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7521 - val_loss: 1.1448\n",
      "Epoch 4942/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7498 - val_loss: 1.1672\n",
      "Epoch 4943/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7463 - val_loss: 1.1692\n",
      "Epoch 4944/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7623 - val_loss: 1.1813\n",
      "Epoch 4945/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7491 - val_loss: 1.1387\n",
      "Epoch 4946/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7418 - val_loss: 1.1296\n",
      "Epoch 4947/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7579 - val_loss: 1.1131\n",
      "Epoch 4948/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7562 - val_loss: 1.1364\n",
      "Epoch 4949/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7548 - val_loss: 1.1429\n",
      "Epoch 4950/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7766 - val_loss: 1.1413\n",
      "Epoch 4951/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7635 - val_loss: 1.1560\n",
      "Epoch 4952/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7665 - val_loss: 1.1266\n",
      "Epoch 4953/5000\n",
      "572/572 [==============================] - 0s 496us/step - loss: 0.7665 - val_loss: 1.1828\n",
      "Epoch 4954/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7586 - val_loss: 1.1474\n",
      "Epoch 4955/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7555 - val_loss: 1.1460\n",
      "Epoch 4956/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7654 - val_loss: 1.1381\n",
      "Epoch 4957/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7644 - val_loss: 1.1180\n",
      "Epoch 4958/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7451 - val_loss: 1.1407\n",
      "Epoch 4959/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7531 - val_loss: 1.1403\n",
      "Epoch 4960/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7570 - val_loss: 1.1777\n",
      "Epoch 4961/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7676 - val_loss: 1.2192\n",
      "Epoch 4962/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 0.7673 - val_loss: 1.1900\n",
      "Epoch 4963/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7599 - val_loss: 1.1644\n",
      "Epoch 4964/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7731 - val_loss: 1.1758\n",
      "Epoch 4965/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7544 - val_loss: 1.1408\n",
      "Epoch 4966/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7706 - val_loss: 1.1386\n",
      "Epoch 4967/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7601 - val_loss: 1.1240\n",
      "Epoch 4968/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7577 - val_loss: 1.1441\n",
      "Epoch 4969/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7631 - val_loss: 1.1575\n",
      "Epoch 4970/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7492 - val_loss: 1.1497\n",
      "Epoch 4971/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7768 - val_loss: 1.1240\n",
      "Epoch 4972/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7717 - val_loss: 1.1567\n",
      "Epoch 4973/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7590 - val_loss: 1.1113\n",
      "Epoch 4974/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7544 - val_loss: 1.1110\n",
      "Epoch 4975/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7554 - val_loss: 1.1359\n",
      "Epoch 4976/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7670 - val_loss: 1.1459\n",
      "Epoch 4977/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7737 - val_loss: 1.1386\n",
      "Epoch 4978/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7609 - val_loss: 1.1590\n",
      "Epoch 4979/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7668 - val_loss: 1.1510\n",
      "Epoch 4980/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7555 - val_loss: 1.1490\n",
      "Epoch 4981/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7539 - val_loss: 1.1523\n",
      "Epoch 4982/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 0.7589 - val_loss: 1.1801\n",
      "Epoch 4983/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7699 - val_loss: 1.1212\n",
      "Epoch 4984/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7597 - val_loss: 1.1329\n",
      "Epoch 4985/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7569 - val_loss: 1.1448\n",
      "Epoch 4986/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 0.7554 - val_loss: 1.1316\n",
      "Epoch 4987/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7682 - val_loss: 1.1245\n",
      "Epoch 4988/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 0.7586 - val_loss: 1.1388\n",
      "Epoch 4989/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7535 - val_loss: 1.1307\n",
      "Epoch 4990/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7539 - val_loss: 1.1299\n",
      "Epoch 4991/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7651 - val_loss: 1.1811\n",
      "Epoch 4992/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 0.7698 - val_loss: 1.1165\n",
      "Epoch 4993/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7642 - val_loss: 1.1132\n",
      "Epoch 4994/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 0.7552 - val_loss: 1.1711\n",
      "Epoch 4995/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7643 - val_loss: 1.1224\n",
      "Epoch 4996/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 0.7660 - val_loss: 1.1697\n",
      "Epoch 4997/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 0.7864 - val_loss: 1.1440\n",
      "Epoch 4998/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 0.7571 - val_loss: 1.1379\n",
      "Epoch 4999/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 0.7528 - val_loss: 1.1526\n",
      "Epoch 5000/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 0.7485 - val_loss: 1.1383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe9726f6e48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calibMMDNet.fit(source, sourceLabels, epochs=500 ,batch_size=10, validation_split=0.1, verbose=1,\n",
    "#               callbacks=[lrate, mn.monitorMMD(source, target, calibMMDNet.predict),\n",
    "#                          cb.EarlyStopping(monitor='val_loss',patience=50,mode='auto')]\n",
    "#               )\n",
    "\n",
    "calibMMDNet.fit(source, sourceLabels, epochs=5000, batch_size=20, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe96391f860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe9639c0828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "calibratedSource = calibMMDNet.predict(source)\n",
    "\n",
    "##################################### qualitative evaluation: PCA #####################################\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(target)\n",
    "\n",
    "# project data onto PCs\n",
    "target_sample_pca = pca.transform(target)\n",
    "projection_before = pca.transform(source)\n",
    "projection_after = pca.transform(calibratedSource)\n",
    "\n",
    "# choose PCs to plot\n",
    "pc1 = 0\n",
    "pc2 = 1\n",
    "axis1 = 'PC'+str(pc1)\n",
    "axis2 = 'PC'+str(pc2)\n",
    "sh.scatterHist(target_sample_pca[:,pc1], target_sample_pca[:,pc2], projection_before[:,pc1], \n",
    "               projection_before[:,pc2], axis1, axis2)\n",
    "sh.scatterHist(target_sample_pca[:,pc1], target_sample_pca[:,pc2], projection_after[:,pc1], \n",
    "               projection_after[:,pc2], axis1, axis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(calibratedSource)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibratedSourcePath = os.path.join(io.DeepLearningRoot(), 'data/calibratedBatch1-gtex-20PCs.csv')\n",
    "# df.to_csv(calibratedSourcePath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
