{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMD ResNet for RNA data - Quantile Normalized\n",
    "\n",
    "Use GTEX as source and TCGA as target since there are 2445 GTEX samples and only 683 TCGA samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import keras.optimizers\n",
    "from Calibration_Util import DataHandler as dh \n",
    "from Calibration_Util import FileIO as io\n",
    "from keras.layers import Input, Dense, merge, Activation, add\n",
    "from keras.models import Model\n",
    "from keras import callbacks as cb\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "#detect display\n",
    "import os\n",
    "havedisplay = \"DISPLAY\" in os.environ\n",
    "#if we have a display use a plotting backend\n",
    "if havedisplay:\n",
    "    matplotlib.use('TkAgg')\n",
    "else:\n",
    "    matplotlib.use('Agg')\n",
    "\n",
    "import CostFunctions as cf\n",
    "import Monitoring as mn\n",
    "from keras.regularizers import l2\n",
    "from sklearn import decomposition\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "import ScatterHist as sh\n",
    "from keras import initializers\n",
    "from numpy import genfromtxt\n",
    "import sklearn.preprocessing as prep\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmdNetLayerSizes = [20, 20]\n",
    "l2_penalty = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sourcePath = os.path.join(io.DeepLearningRoot(), 'data/rnaBatch1-gtex-20PCs.csv')\n",
    "# targetPath = os.path.join(io.DeepLearningRoot(), 'data/rnaBatch2-tcga-20PCs.csv')\n",
    "\n",
    "sourceFileName = 'unnorm-qn-20PC-GTEX-breast-prostate-thyroid.csv'\n",
    "targetFileName = 'unnorm-qn-20PC-TCGA-breast-prostate-thyroid.csv'\n",
    "\n",
    "sourcePath = os.path.join(io.DeepLearningRoot(), 'data/unnorm/' + sourceFileName)\n",
    "targetPath = os.path.join(io.DeepLearningRoot(), 'data/unnorm/' + targetFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# source = genfromtxt(sourcePath, delimiter=',', skip_header=1)\n",
    "# target = genfromtxt(targetPath, delimiter=',', skip_header=1)\n",
    "\n",
    "source = pd.read_csv(sourcePath, sep=',', header=0, index_col=0)\n",
    "target = pd.read_csv(targetPath, sep=',', header=0, index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GTEX.breast</th>\n",
       "      <td>-1045.388174</td>\n",
       "      <td>-69.278998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX.breast.1</th>\n",
       "      <td>-1039.645947</td>\n",
       "      <td>-47.799101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX.breast.2</th>\n",
       "      <td>-1045.533655</td>\n",
       "      <td>-78.585359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX.breast.3</th>\n",
       "      <td>-1043.787094</td>\n",
       "      <td>-70.776803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       PC1        PC2\n",
       "GTEX.breast   -1045.388174 -69.278998\n",
       "GTEX.breast.1 -1039.645947 -47.799101\n",
       "GTEX.breast.2 -1045.533655 -78.585359\n",
       "GTEX.breast.3 -1043.787094 -70.776803"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source[[\"PC1\", \"PC2\"]][0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA.breast</th>\n",
       "      <td>-1040.720188</td>\n",
       "      <td>-94.332494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.breast.1</th>\n",
       "      <td>-1037.086656</td>\n",
       "      <td>-73.924512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.breast.2</th>\n",
       "      <td>-1042.328732</td>\n",
       "      <td>-86.102301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.breast.3</th>\n",
       "      <td>-1040.036569</td>\n",
       "      <td>-89.419399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       PC1        PC2\n",
       "TCGA.breast   -1040.720188 -94.332494\n",
       "TCGA.breast.1 -1037.086656 -73.924512\n",
       "TCGA.breast.2 -1042.328732 -86.102301\n",
       "TCGA.breast.3 -1040.036569 -89.419399"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[[\"PC1\", \"PC2\"]][0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = source.values\n",
    "target = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1045.38817359   -69.27899809]\n",
      " [-1039.64594732   -47.79910136]\n",
      " [-1045.5336552    -78.58535871]\n",
      " [-1043.78709351   -70.77680287]]\n",
      "[[-1040.7201884    -94.33249386]\n",
      " [-1037.08665589   -73.92451195]\n",
      " [-1042.32873248   -86.10230122]\n",
      " [-1040.03656876   -89.4193985 ]]\n",
      "inputDim = 20\n"
     ]
    }
   ],
   "source": [
    "print(source[0:4, 0:2])\n",
    "print(target[0:4, 0:2])\n",
    "\n",
    "inputDim = target.shape[1]\n",
    "print(\"inputDim = \" + str(inputDim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtex = source shape = (636, 20)\n",
      "tcga = target shape = (211, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"gtex = source shape = \" + str(source.shape))\n",
    "print(\"tcga = target shape = \" + str(target.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build MMD Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "calibInput = Input(shape=(inputDim, ))\n",
    "\n",
    "# block 1\n",
    "block1_bn1 = BatchNormalization()(calibInput)\n",
    "block1_a1 = Activation('relu')(block1_bn1)\n",
    "block1_w1 = Dense(mmdNetLayerSizes[1], activation='linear', kernel_regularizer=l2(l2_penalty), \n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block1_a1)\n",
    "block1_bn2 = BatchNormalization()(block1_w1)\n",
    "block1_a2 = Activation('relu')(block1_bn2)\n",
    "block1_w2 = Dense(mmdNetLayerSizes[0], activation='linear', kernel_regularizer=l2(l2_penalty), \n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block1_a2)\n",
    "block1_output = add([block1_w2, calibInput])\n",
    "\n",
    "# block 2\n",
    "block2_bn1 = BatchNormalization()(block1_output)\n",
    "block2_a1 = Activation('relu')(block2_bn1)\n",
    "block2_w1 = Dense(mmdNetLayerSizes[1], activation='linear', kernel_regularizer=l2(l2_penalty), \n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block2_a1)\n",
    "block2_bn2 = BatchNormalization()(block1_w1)\n",
    "block2_a2 = Activation('relu')(block2_bn2)\n",
    "block2_w2 = Dense(mmdNetLayerSizes[0], activation='linear', kernel_regularizer=l2(l2_penalty), \n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block2_a2)\n",
    "block2_output = add([block2_w2, calibInput])\n",
    "\n",
    "# block 3\n",
    "block3_bn1 = BatchNormalization()(block2_output)\n",
    "block3_a1 = Activation('relu')(block3_bn1)\n",
    "block3_w1 = Dense(mmdNetLayerSizes[1], activation='linear', kernel_regularizer=l2(l2_penalty), \n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block3_a1)\n",
    "block3_bn2 = BatchNormalization()(block3_w1)\n",
    "block3_a2 = Activation('relu')(block3_bn2)\n",
    "block3_w2 = Dense(mmdNetLayerSizes[0], activation='linear', kernel_regularizer=l2(l2_penalty), \n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block3_a2)\n",
    "block3_output = add([block3_w2, calibInput])\n",
    "\n",
    "calibMMDNet = Model(inputs=calibInput, outputs=block3_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting scales using KNN\n",
      "[22.682515077192555, 45.36503015438511, 90.73006030877022]\n",
      "setting all scale weights to 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(636, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.1\n",
    "    epochs_drop = 250.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "# optimizer = keras.optimizers.rmsprop(lr=0.0)\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "calibMMDNet.compile(optimizer=optimizer, \n",
    "                    loss=lambda y_true,y_pred: \n",
    "                       cf.MMD(block3_output, target, MMDTargetValidation_split=0.1,\n",
    "                             MMDTargetSampleSize=100, n_neighbors=10).KerasCost(y_true,y_pred)\n",
    "                   )\n",
    "\n",
    "K.get_session().run(tf.global_variables_initializer())\n",
    "\n",
    "sourceLabels = np.zeros(source.shape)\n",
    "sourceLabels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 572 samples, validate on 64 samples\n",
      "Epoch 1/5000\n",
      "572/572 [==============================] - 1s 1ms/step - loss: 1.2896 - val_loss: 1.8627\n",
      "Epoch 2/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 1.2927 - val_loss: 1.8631\n",
      "Epoch 3/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.2958 - val_loss: 1.8633\n",
      "Epoch 4/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.2879 - val_loss: 1.8632\n",
      "Epoch 5/5000\n",
      "572/572 [==============================] - 0s 492us/step - loss: 1.2947 - val_loss: 1.8632\n",
      "Epoch 6/5000\n",
      "572/572 [==============================] - 0s 479us/step - loss: 1.2920 - val_loss: 1.8629\n",
      "Epoch 7/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 1.2855 - val_loss: 1.8628\n",
      "Epoch 8/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 1.2922 - val_loss: 1.8621\n",
      "Epoch 9/5000\n",
      "572/572 [==============================] - 0s 483us/step - loss: 1.2910 - val_loss: 1.8616\n",
      "Epoch 10/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 1.2862 - val_loss: 1.8603\n",
      "Epoch 11/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 1.2919 - val_loss: 1.8593\n",
      "Epoch 12/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 1.2886 - val_loss: 1.8591\n",
      "Epoch 13/5000\n",
      "572/572 [==============================] - 0s 486us/step - loss: 1.2854 - val_loss: 1.8559\n",
      "Epoch 14/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 1.2801 - val_loss: 1.8541\n",
      "Epoch 15/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.2858 - val_loss: 1.8512\n",
      "Epoch 16/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 1.2835 - val_loss: 1.8500\n",
      "Epoch 17/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.2863 - val_loss: 1.8414\n",
      "Epoch 18/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 1.2861 - val_loss: 1.8485\n",
      "Epoch 19/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 1.2827 - val_loss: 1.8393\n",
      "Epoch 20/5000\n",
      "572/572 [==============================] - 0s 494us/step - loss: 1.2768 - val_loss: 1.8372\n",
      "Epoch 21/5000\n",
      "572/572 [==============================] - 0s 508us/step - loss: 1.2710 - val_loss: 1.8372\n",
      "Epoch 22/5000\n",
      "572/572 [==============================] - 0s 502us/step - loss: 1.2759 - val_loss: 1.8221\n",
      "Epoch 23/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 1.2678 - val_loss: 1.8299\n",
      "Epoch 24/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 1.2681 - val_loss: 1.8317\n",
      "Epoch 25/5000\n",
      "572/572 [==============================] - 0s 491us/step - loss: 1.2664 - val_loss: 1.8368\n",
      "Epoch 26/5000\n",
      "572/572 [==============================] - 0s 487us/step - loss: 1.2672 - val_loss: 1.8237\n",
      "Epoch 27/5000\n",
      "572/572 [==============================] - 0s 490us/step - loss: 1.2666 - val_loss: 1.8317\n",
      "Epoch 28/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.2582 - val_loss: 1.8296\n",
      "Epoch 29/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.2645 - val_loss: 1.8235\n",
      "Epoch 30/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 1.2536 - val_loss: 1.8134\n",
      "Epoch 31/5000\n",
      "572/572 [==============================] - 0s 478us/step - loss: 1.2511 - val_loss: 1.8218\n",
      "Epoch 32/5000\n",
      "572/572 [==============================] - 0s 481us/step - loss: 1.2445 - val_loss: 1.8168\n",
      "Epoch 33/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 1.2481 - val_loss: 1.8445\n",
      "Epoch 34/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 1.2412 - val_loss: 1.8425\n",
      "Epoch 35/5000\n",
      "572/572 [==============================] - 0s 489us/step - loss: 1.2432 - val_loss: 1.8072\n",
      "Epoch 36/5000\n",
      "572/572 [==============================] - 0s 484us/step - loss: 1.2436 - val_loss: 1.7869\n",
      "Epoch 37/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 1.2406 - val_loss: 1.8257\n",
      "Epoch 38/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 1.2392 - val_loss: 1.8259\n",
      "Epoch 39/5000\n",
      "572/572 [==============================] - 0s 488us/step - loss: 1.2324 - val_loss: 1.8303\n",
      "Epoch 40/5000\n",
      "572/572 [==============================] - 0s 493us/step - loss: 1.2364 - val_loss: 1.8341\n",
      "Epoch 41/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 1.2275 - val_loss: 1.8256\n",
      "Epoch 42/5000\n",
      "572/572 [==============================] - 0s 482us/step - loss: 1.2263 - val_loss: 1.8245\n",
      "Epoch 43/5000\n",
      "572/572 [==============================] - 0s 485us/step - loss: 1.2257 - val_loss: 1.8338\n",
      "Epoch 44/5000\n",
      "572/572 [==============================] - 0s 519us/step - loss: 1.2247 - val_loss: 1.8138\n",
      "Epoch 45/5000\n",
      "572/572 [==============================] - 0s 592us/step - loss: 1.2244 - val_loss: 1.8207\n",
      "Epoch 46/5000\n",
      "572/572 [==============================] - 0s 568us/step - loss: 1.2234 - val_loss: 1.8018\n",
      "Epoch 47/5000\n",
      "572/572 [==============================] - 0s 562us/step - loss: 1.2174 - val_loss: 1.8105\n",
      "Epoch 48/5000\n",
      "572/572 [==============================] - 0s 564us/step - loss: 1.2160 - val_loss: 1.8056\n",
      "Epoch 49/5000\n",
      "572/572 [==============================] - 0s 557us/step - loss: 1.2206 - val_loss: 1.8160\n",
      "Epoch 50/5000\n",
      "572/572 [==============================] - 0s 578us/step - loss: 1.2122 - val_loss: 1.8172\n",
      "Epoch 51/5000\n",
      "572/572 [==============================] - 0s 594us/step - loss: 1.2099 - val_loss: 1.8053\n",
      "Epoch 52/5000\n",
      "572/572 [==============================] - 0s 585us/step - loss: 1.2115 - val_loss: 1.8062\n",
      "Epoch 53/5000\n",
      "572/572 [==============================] - 0s 602us/step - loss: 1.2133 - val_loss: 1.8059\n",
      "Epoch 54/5000\n",
      "572/572 [==============================] - 0s 568us/step - loss: 1.2054 - val_loss: 1.7761\n",
      "Epoch 55/5000\n",
      "572/572 [==============================] - 0s 603us/step - loss: 1.1984 - val_loss: 1.7857\n",
      "Epoch 56/5000\n",
      "572/572 [==============================] - 0s 561us/step - loss: 1.2127 - val_loss: 1.7879\n",
      "Epoch 57/5000\n",
      "572/572 [==============================] - 0s 590us/step - loss: 1.2019 - val_loss: 1.7997\n",
      "Epoch 58/5000\n",
      "572/572 [==============================] - 0s 583us/step - loss: 1.1988 - val_loss: 1.7847\n",
      "Epoch 59/5000\n",
      "572/572 [==============================] - 0s 569us/step - loss: 1.2000 - val_loss: 1.7909\n",
      "Epoch 60/5000\n",
      "572/572 [==============================] - 0s 574us/step - loss: 1.2013 - val_loss: 1.7618\n",
      "Epoch 61/5000\n",
      "572/572 [==============================] - 0s 746us/step - loss: 1.1951 - val_loss: 1.7753\n",
      "Epoch 62/5000\n",
      "572/572 [==============================] - 0s 688us/step - loss: 1.1887 - val_loss: 1.7694\n",
      "Epoch 63/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 1.1880 - val_loss: 1.7658\n",
      "Epoch 64/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 1.1877 - val_loss: 1.7579\n",
      "Epoch 65/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 1.1913 - val_loss: 1.7718\n",
      "Epoch 66/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 1.1853 - val_loss: 1.7821\n",
      "Epoch 67/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 1.1861 - val_loss: 1.7862\n",
      "Epoch 68/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 1.1769 - val_loss: 1.7843\n",
      "Epoch 69/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 1.1809 - val_loss: 1.7545\n",
      "Epoch 70/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 1.1825 - val_loss: 1.7677\n",
      "Epoch 71/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 1.1782 - val_loss: 1.7558\n",
      "Epoch 72/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 1.1809 - val_loss: 1.7949\n",
      "Epoch 73/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 1.1764 - val_loss: 1.7521\n",
      "Epoch 74/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 1.1802 - val_loss: 1.7666\n",
      "Epoch 75/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 1.1783 - val_loss: 1.7445\n",
      "Epoch 76/5000\n",
      "572/572 [==============================] - 0s 692us/step - loss: 1.1766 - val_loss: 1.7479\n",
      "Epoch 77/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 1.1744 - val_loss: 1.7318\n",
      "Epoch 78/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 671us/step - loss: 1.1746 - val_loss: 1.7397\n",
      "Epoch 79/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 1.1701 - val_loss: 1.7348\n",
      "Epoch 80/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 1.1768 - val_loss: 1.7667\n",
      "Epoch 81/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 1.1795 - val_loss: 1.7408\n",
      "Epoch 82/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 1.1679 - val_loss: 1.7456\n",
      "Epoch 83/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 1.1728 - val_loss: 1.7510\n",
      "Epoch 84/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 1.1746 - val_loss: 1.7458\n",
      "Epoch 85/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 1.1711 - val_loss: 1.7465\n",
      "Epoch 86/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 1.1682 - val_loss: 1.7478\n",
      "Epoch 87/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 1.1658 - val_loss: 1.7472\n",
      "Epoch 88/5000\n",
      "572/572 [==============================] - 0s 803us/step - loss: 1.1729 - val_loss: 1.7523\n",
      "Epoch 89/5000\n",
      "572/572 [==============================] - 0s 753us/step - loss: 1.1682 - val_loss: 1.7134\n",
      "Epoch 90/5000\n",
      "572/572 [==============================] - 0s 711us/step - loss: 1.1593 - val_loss: 1.7410\n",
      "Epoch 91/5000\n",
      "572/572 [==============================] - 0s 733us/step - loss: 1.1515 - val_loss: 1.7336\n",
      "Epoch 92/5000\n",
      "572/572 [==============================] - 0s 722us/step - loss: 1.1573 - val_loss: 1.7258\n",
      "Epoch 93/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 1.1590 - val_loss: 1.7121\n",
      "Epoch 94/5000\n",
      "572/572 [==============================] - 0s 777us/step - loss: 1.1581 - val_loss: 1.7325\n",
      "Epoch 95/5000\n",
      "572/572 [==============================] - 0s 820us/step - loss: 1.1613 - val_loss: 1.7133\n",
      "Epoch 96/5000\n",
      "572/572 [==============================] - 0s 858us/step - loss: 1.1478 - val_loss: 1.7572\n",
      "Epoch 97/5000\n",
      "572/572 [==============================] - 0s 794us/step - loss: 1.1575 - val_loss: 1.7174\n",
      "Epoch 98/5000\n",
      "572/572 [==============================] - 0s 779us/step - loss: 1.1461 - val_loss: 1.7150\n",
      "Epoch 99/5000\n",
      "572/572 [==============================] - 0s 800us/step - loss: 1.1511 - val_loss: 1.7081\n",
      "Epoch 100/5000\n",
      "572/572 [==============================] - 0s 742us/step - loss: 1.1459 - val_loss: 1.7341\n",
      "Epoch 101/5000\n",
      "572/572 [==============================] - 0s 811us/step - loss: 1.1574 - val_loss: 1.7290\n",
      "Epoch 102/5000\n",
      "572/572 [==============================] - 0s 748us/step - loss: 1.1482 - val_loss: 1.7088\n",
      "Epoch 103/5000\n",
      "572/572 [==============================] - 0s 782us/step - loss: 1.1473 - val_loss: 1.7122\n",
      "Epoch 104/5000\n",
      "572/572 [==============================] - 0s 831us/step - loss: 1.1461 - val_loss: 1.7083\n",
      "Epoch 105/5000\n",
      "572/572 [==============================] - 0s 813us/step - loss: 1.1509 - val_loss: 1.7294\n",
      "Epoch 106/5000\n",
      "572/572 [==============================] - 0s 718us/step - loss: 1.1497 - val_loss: 1.7271\n",
      "Epoch 107/5000\n",
      "572/572 [==============================] - 0s 784us/step - loss: 1.1427 - val_loss: 1.7062\n",
      "Epoch 108/5000\n",
      "572/572 [==============================] - 0s 835us/step - loss: 1.1416 - val_loss: 1.7175\n",
      "Epoch 109/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 1.1446 - val_loss: 1.7088\n",
      "Epoch 110/5000\n",
      "572/572 [==============================] - 0s 785us/step - loss: 1.1399 - val_loss: 1.6929\n",
      "Epoch 111/5000\n",
      "572/572 [==============================] - 0s 858us/step - loss: 1.1389 - val_loss: 1.7228\n",
      "Epoch 112/5000\n",
      "572/572 [==============================] - 0s 795us/step - loss: 1.1377 - val_loss: 1.6954\n",
      "Epoch 113/5000\n",
      "572/572 [==============================] - 0s 820us/step - loss: 1.1479 - val_loss: 1.7103\n",
      "Epoch 114/5000\n",
      "572/572 [==============================] - 0s 802us/step - loss: 1.1367 - val_loss: 1.7135\n",
      "Epoch 115/5000\n",
      "572/572 [==============================] - 0s 805us/step - loss: 1.1339 - val_loss: 1.7131\n",
      "Epoch 116/5000\n",
      "572/572 [==============================] - 1s 907us/step - loss: 1.1448 - val_loss: 1.6933\n",
      "Epoch 117/5000\n",
      "572/572 [==============================] - 1s 904us/step - loss: 1.1382 - val_loss: 1.7011\n",
      "Epoch 118/5000\n",
      "572/572 [==============================] - 1s 881us/step - loss: 1.1334 - val_loss: 1.6826\n",
      "Epoch 119/5000\n",
      "572/572 [==============================] - 0s 815us/step - loss: 1.1350 - val_loss: 1.6812\n",
      "Epoch 120/5000\n",
      "572/572 [==============================] - 0s 786us/step - loss: 1.1276 - val_loss: 1.7101\n",
      "Epoch 121/5000\n",
      "572/572 [==============================] - 0s 757us/step - loss: 1.1391 - val_loss: 1.6958\n",
      "Epoch 122/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 1.1319 - val_loss: 1.6870\n",
      "Epoch 123/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 1.1337 - val_loss: 1.7076\n",
      "Epoch 124/5000\n",
      "572/572 [==============================] - 0s 618us/step - loss: 1.1348 - val_loss: 1.6960\n",
      "Epoch 125/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 1.1339 - val_loss: 1.6895\n",
      "Epoch 126/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 1.1231 - val_loss: 1.6936\n",
      "Epoch 127/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 1.1323 - val_loss: 1.6942\n",
      "Epoch 128/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 1.1290 - val_loss: 1.6786\n",
      "Epoch 129/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 1.1345 - val_loss: 1.6880\n",
      "Epoch 130/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 1.1236 - val_loss: 1.6759\n",
      "Epoch 131/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 1.1250 - val_loss: 1.6907\n",
      "Epoch 132/5000\n",
      "572/572 [==============================] - 0s 851us/step - loss: 1.1343 - val_loss: 1.6694\n",
      "Epoch 133/5000\n",
      "572/572 [==============================] - 0s 802us/step - loss: 1.1252 - val_loss: 1.6796\n",
      "Epoch 134/5000\n",
      "572/572 [==============================] - 0s 786us/step - loss: 1.1218 - val_loss: 1.6720\n",
      "Epoch 135/5000\n",
      "572/572 [==============================] - 0s 742us/step - loss: 1.1257 - val_loss: 1.6841\n",
      "Epoch 136/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 1.1178 - val_loss: 1.6771\n",
      "Epoch 137/5000\n",
      "572/572 [==============================] - 0s 769us/step - loss: 1.1213 - val_loss: 1.6655\n",
      "Epoch 138/5000\n",
      "572/572 [==============================] - 0s 792us/step - loss: 1.1199 - val_loss: 1.7032\n",
      "Epoch 139/5000\n",
      "572/572 [==============================] - 0s 747us/step - loss: 1.1178 - val_loss: 1.6860\n",
      "Epoch 140/5000\n",
      "572/572 [==============================] - 0s 757us/step - loss: 1.1265 - val_loss: 1.6768\n",
      "Epoch 141/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 1.1222 - val_loss: 1.6756\n",
      "Epoch 142/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 1.1166 - val_loss: 1.6684\n",
      "Epoch 143/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 1.1211 - val_loss: 1.6644\n",
      "Epoch 144/5000\n",
      "572/572 [==============================] - 0s 698us/step - loss: 1.1219 - val_loss: 1.6760\n",
      "Epoch 145/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 1.1208 - val_loss: 1.6666\n",
      "Epoch 146/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 1.1243 - val_loss: 1.6738\n",
      "Epoch 147/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 1.1211 - val_loss: 1.6680\n",
      "Epoch 148/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 1.1203 - val_loss: 1.6713\n",
      "Epoch 149/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 1.1216 - val_loss: 1.6756\n",
      "Epoch 150/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 1.1154 - val_loss: 1.6643\n",
      "Epoch 151/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 1.1153 - val_loss: 1.6785\n",
      "Epoch 152/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 1.1080 - val_loss: 1.6680\n",
      "Epoch 153/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 1.1199 - val_loss: 1.6548\n",
      "Epoch 154/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 1.1197 - val_loss: 1.6668\n",
      "Epoch 155/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 661us/step - loss: 1.1142 - val_loss: 1.6697\n",
      "Epoch 156/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 1.1128 - val_loss: 1.6627\n",
      "Epoch 157/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 1.1031 - val_loss: 1.6596\n",
      "Epoch 158/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 1.1101 - val_loss: 1.6698\n",
      "Epoch 159/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 1.1145 - val_loss: 1.6690\n",
      "Epoch 160/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 1.1174 - val_loss: 1.6775\n",
      "Epoch 161/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 1.1134 - val_loss: 1.6789\n",
      "Epoch 162/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 1.1124 - val_loss: 1.6531\n",
      "Epoch 163/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 1.1038 - val_loss: 1.6535\n",
      "Epoch 164/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 1.1072 - val_loss: 1.6513\n",
      "Epoch 165/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 1.1079 - val_loss: 1.6524\n",
      "Epoch 166/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 1.1016 - val_loss: 1.6483\n",
      "Epoch 167/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 1.1088 - val_loss: 1.6516\n",
      "Epoch 168/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 1.1089 - val_loss: 1.6572\n",
      "Epoch 169/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 1.1032 - val_loss: 1.6664\n",
      "Epoch 170/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 1.1001 - val_loss: 1.6441\n",
      "Epoch 171/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 1.1027 - val_loss: 1.6397\n",
      "Epoch 172/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 1.0982 - val_loss: 1.6494\n",
      "Epoch 173/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 1.0993 - val_loss: 1.6568\n",
      "Epoch 174/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 1.1061 - val_loss: 1.6444\n",
      "Epoch 175/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 1.0973 - val_loss: 1.6490\n",
      "Epoch 176/5000\n",
      "572/572 [==============================] - 0s 688us/step - loss: 1.0942 - val_loss: 1.6399\n",
      "Epoch 177/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 1.1018 - val_loss: 1.6457\n",
      "Epoch 178/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 1.1006 - val_loss: 1.6331\n",
      "Epoch 179/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 1.0964 - val_loss: 1.6309\n",
      "Epoch 180/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 1.0935 - val_loss: 1.6178\n",
      "Epoch 181/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 1.0908 - val_loss: 1.6268\n",
      "Epoch 182/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 1.0944 - val_loss: 1.6171\n",
      "Epoch 183/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 1.0940 - val_loss: 1.5993\n",
      "Epoch 184/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 1.0821 - val_loss: 1.5797\n",
      "Epoch 185/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 1.0907 - val_loss: 1.5724\n",
      "Epoch 186/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 1.0913 - val_loss: 1.5634\n",
      "Epoch 187/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 1.0784 - val_loss: 1.5624\n",
      "Epoch 188/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 1.0804 - val_loss: 1.5458\n",
      "Epoch 189/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 1.0877 - val_loss: 1.5423\n",
      "Epoch 190/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 1.0819 - val_loss: 1.5501\n",
      "Epoch 191/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 1.0848 - val_loss: 1.5363\n",
      "Epoch 192/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 1.0775 - val_loss: 1.5328\n",
      "Epoch 193/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 1.0711 - val_loss: 1.5505\n",
      "Epoch 194/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 1.0824 - val_loss: 1.5303\n",
      "Epoch 195/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 1.0705 - val_loss: 1.5378\n",
      "Epoch 196/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 1.0720 - val_loss: 1.5252\n",
      "Epoch 197/5000\n",
      "572/572 [==============================] - 0s 702us/step - loss: 1.0691 - val_loss: 1.5271\n",
      "Epoch 198/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 1.0754 - val_loss: 1.5347\n",
      "Epoch 199/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 1.0660 - val_loss: 1.5430\n",
      "Epoch 200/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 1.0735 - val_loss: 1.5248\n",
      "Epoch 201/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 1.0709 - val_loss: 1.5251\n",
      "Epoch 202/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 1.0656 - val_loss: 1.5306\n",
      "Epoch 203/5000\n",
      "572/572 [==============================] - 0s 736us/step - loss: 1.0645 - val_loss: 1.5179\n",
      "Epoch 204/5000\n",
      "572/572 [==============================] - 0s 820us/step - loss: 1.0746 - val_loss: 1.5297\n",
      "Epoch 205/5000\n",
      "572/572 [==============================] - 0s 770us/step - loss: 1.0684 - val_loss: 1.5121\n",
      "Epoch 206/5000\n",
      "572/572 [==============================] - 0s 872us/step - loss: 1.0628 - val_loss: 1.5143\n",
      "Epoch 207/5000\n",
      "572/572 [==============================] - 0s 738us/step - loss: 1.0582 - val_loss: 1.5161\n",
      "Epoch 208/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 1.0711 - val_loss: 1.5178\n",
      "Epoch 209/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 1.0601 - val_loss: 1.5185\n",
      "Epoch 210/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 1.0568 - val_loss: 1.5180\n",
      "Epoch 211/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 1.0664 - val_loss: 1.5250\n",
      "Epoch 212/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 1.0604 - val_loss: 1.5229\n",
      "Epoch 213/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 1.0573 - val_loss: 1.5200\n",
      "Epoch 214/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 1.0659 - val_loss: 1.5211\n",
      "Epoch 215/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 1.0559 - val_loss: 1.5208\n",
      "Epoch 216/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 1.0551 - val_loss: 1.5187\n",
      "Epoch 217/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 1.0543 - val_loss: 1.5119\n",
      "Epoch 218/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 1.0584 - val_loss: 1.5094\n",
      "Epoch 219/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 1.0550 - val_loss: 1.5144\n",
      "Epoch 220/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 1.0483 - val_loss: 1.5172\n",
      "Epoch 221/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 1.0489 - val_loss: 1.5155\n",
      "Epoch 222/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 1.0571 - val_loss: 1.5151\n",
      "Epoch 223/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 1.0438 - val_loss: 1.5115\n",
      "Epoch 224/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 1.0506 - val_loss: 1.5057\n",
      "Epoch 225/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 1.0403 - val_loss: 1.5110\n",
      "Epoch 226/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 1.0527 - val_loss: 1.5145\n",
      "Epoch 227/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 1.0478 - val_loss: 1.5103\n",
      "Epoch 228/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 1.0520 - val_loss: 1.5155\n",
      "Epoch 229/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 1.0459 - val_loss: 1.5112\n",
      "Epoch 230/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 1.0454 - val_loss: 1.5188\n",
      "Epoch 231/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 1.0520 - val_loss: 1.5156\n",
      "Epoch 232/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 648us/step - loss: 1.0488 - val_loss: 1.5082\n",
      "Epoch 233/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 1.0436 - val_loss: 1.5075\n",
      "Epoch 234/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 1.0485 - val_loss: 1.5034\n",
      "Epoch 235/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 1.0480 - val_loss: 1.5094\n",
      "Epoch 236/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 1.0411 - val_loss: 1.5060\n",
      "Epoch 237/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 1.0452 - val_loss: 1.5109\n",
      "Epoch 238/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 1.0389 - val_loss: 1.5097\n",
      "Epoch 239/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 1.0401 - val_loss: 1.5071\n",
      "Epoch 240/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 1.0417 - val_loss: 1.4973\n",
      "Epoch 241/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 1.0383 - val_loss: 1.5049\n",
      "Epoch 242/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 1.0403 - val_loss: 1.5077\n",
      "Epoch 243/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 1.0352 - val_loss: 1.5068\n",
      "Epoch 244/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 1.0306 - val_loss: 1.4992\n",
      "Epoch 245/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 1.0385 - val_loss: 1.5179\n",
      "Epoch 246/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 1.0391 - val_loss: 1.5032\n",
      "Epoch 247/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 1.0400 - val_loss: 1.5037\n",
      "Epoch 248/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 1.0369 - val_loss: 1.4981\n",
      "Epoch 249/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 1.0426 - val_loss: 1.5030\n",
      "Epoch 250/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 1.0366 - val_loss: 1.5008\n",
      "Epoch 251/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 1.0360 - val_loss: 1.4978\n",
      "Epoch 252/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 1.0355 - val_loss: 1.5024\n",
      "Epoch 253/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 1.0402 - val_loss: 1.5090\n",
      "Epoch 254/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 1.0356 - val_loss: 1.4971\n",
      "Epoch 255/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 1.0388 - val_loss: 1.5028\n",
      "Epoch 256/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 1.0319 - val_loss: 1.4981\n",
      "Epoch 257/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 1.0327 - val_loss: 1.4963\n",
      "Epoch 258/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 1.0370 - val_loss: 1.4929\n",
      "Epoch 259/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 1.0288 - val_loss: 1.4952\n",
      "Epoch 260/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 1.0276 - val_loss: 1.5024\n",
      "Epoch 261/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 1.0316 - val_loss: 1.5062\n",
      "Epoch 262/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 1.0258 - val_loss: 1.5091\n",
      "Epoch 263/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 1.0221 - val_loss: 1.4982\n",
      "Epoch 264/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 1.0343 - val_loss: 1.4991\n",
      "Epoch 265/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 1.0204 - val_loss: 1.5016\n",
      "Epoch 266/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 1.0213 - val_loss: 1.5021\n",
      "Epoch 267/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 1.0206 - val_loss: 1.5058\n",
      "Epoch 268/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 1.0261 - val_loss: 1.5024\n",
      "Epoch 269/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 1.0328 - val_loss: 1.4970\n",
      "Epoch 270/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 1.0265 - val_loss: 1.4893\n",
      "Epoch 271/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 1.0216 - val_loss: 1.4936\n",
      "Epoch 272/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 1.0271 - val_loss: 1.5009\n",
      "Epoch 273/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 1.0193 - val_loss: 1.4938\n",
      "Epoch 274/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 1.0157 - val_loss: 1.4931\n",
      "Epoch 275/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 1.0247 - val_loss: 1.4882\n",
      "Epoch 276/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 1.0161 - val_loss: 1.4997\n",
      "Epoch 277/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 1.0202 - val_loss: 1.4953\n",
      "Epoch 278/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 1.0164 - val_loss: 1.4983\n",
      "Epoch 279/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 1.0174 - val_loss: 1.5075\n",
      "Epoch 280/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 1.0205 - val_loss: 1.5027\n",
      "Epoch 281/5000\n",
      "572/572 [==============================] - 0s 691us/step - loss: 1.0149 - val_loss: 1.4993\n",
      "Epoch 282/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 1.0268 - val_loss: 1.5053\n",
      "Epoch 283/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 1.0136 - val_loss: 1.5038\n",
      "Epoch 284/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 1.0086 - val_loss: 1.5085\n",
      "Epoch 285/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 1.0182 - val_loss: 1.5070\n",
      "Epoch 286/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 1.0130 - val_loss: 1.5037\n",
      "Epoch 287/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 1.0084 - val_loss: 1.5056\n",
      "Epoch 288/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 1.0017 - val_loss: 1.5129\n",
      "Epoch 289/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 1.0047 - val_loss: 1.5117\n",
      "Epoch 290/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 1.0097 - val_loss: 1.5167\n",
      "Epoch 291/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 1.0124 - val_loss: 1.5108\n",
      "Epoch 292/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 1.0116 - val_loss: 1.4962\n",
      "Epoch 293/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 1.0033 - val_loss: 1.5144\n",
      "Epoch 294/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.9984 - val_loss: 1.5152\n",
      "Epoch 295/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 1.0038 - val_loss: 1.5160\n",
      "Epoch 296/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.9981 - val_loss: 1.5143\n",
      "Epoch 297/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.9997 - val_loss: 1.5160\n",
      "Epoch 298/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 1.0180 - val_loss: 1.5093\n",
      "Epoch 299/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 1.0025 - val_loss: 1.5116\n",
      "Epoch 300/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.9930 - val_loss: 1.5188\n",
      "Epoch 301/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.9947 - val_loss: 1.5178\n",
      "Epoch 302/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.9881 - val_loss: 1.5127\n",
      "Epoch 303/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 1.0103 - val_loss: 1.5160\n",
      "Epoch 304/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 1.0059 - val_loss: 1.5053\n",
      "Epoch 305/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.9986 - val_loss: 1.5050\n",
      "Epoch 306/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 0.9961 - val_loss: 1.5049\n",
      "Epoch 307/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 1.0091 - val_loss: 1.5055\n",
      "Epoch 308/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 1.0019 - val_loss: 1.5072\n",
      "Epoch 309/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 660us/step - loss: 1.0096 - val_loss: 1.5054\n",
      "Epoch 310/5000\n",
      "572/572 [==============================] - 0s 690us/step - loss: 0.9953 - val_loss: 1.4995\n",
      "Epoch 311/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 1.0026 - val_loss: 1.5021\n",
      "Epoch 312/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.9941 - val_loss: 1.5140\n",
      "Epoch 313/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.9940 - val_loss: 1.5007\n",
      "Epoch 314/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.9889 - val_loss: 1.5063\n",
      "Epoch 315/5000\n",
      "572/572 [==============================] - 0s 707us/step - loss: 0.9829 - val_loss: 1.5024\n",
      "Epoch 316/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.9858 - val_loss: 1.5035\n",
      "Epoch 317/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.9919 - val_loss: 1.5081\n",
      "Epoch 318/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.9819 - val_loss: 1.5121\n",
      "Epoch 319/5000\n",
      "572/572 [==============================] - 0s 688us/step - loss: 0.9957 - val_loss: 1.5160\n",
      "Epoch 320/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.9929 - val_loss: 1.5075\n",
      "Epoch 321/5000\n",
      "572/572 [==============================] - 0s 690us/step - loss: 0.9846 - val_loss: 1.5069\n",
      "Epoch 322/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.9939 - val_loss: 1.5036\n",
      "Epoch 323/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.9853 - val_loss: 1.5074\n",
      "Epoch 324/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.9848 - val_loss: 1.5024\n",
      "Epoch 325/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.9835 - val_loss: 1.5015\n",
      "Epoch 326/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.9844 - val_loss: 1.5115\n",
      "Epoch 327/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.9954 - val_loss: 1.5070\n",
      "Epoch 328/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.9818 - val_loss: 1.5037\n",
      "Epoch 329/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.9893 - val_loss: 1.5037\n",
      "Epoch 330/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.9885 - val_loss: 1.4964\n",
      "Epoch 331/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.9751 - val_loss: 1.5046\n",
      "Epoch 332/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.9899 - val_loss: 1.5098\n",
      "Epoch 333/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.9896 - val_loss: 1.5022\n",
      "Epoch 334/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.9847 - val_loss: 1.5033\n",
      "Epoch 335/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.9785 - val_loss: 1.5067\n",
      "Epoch 336/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.9790 - val_loss: 1.5189\n",
      "Epoch 337/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.9780 - val_loss: 1.5086\n",
      "Epoch 338/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.9924 - val_loss: 1.5066\n",
      "Epoch 339/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.9658 - val_loss: 1.5145\n",
      "Epoch 340/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.9852 - val_loss: 1.4986\n",
      "Epoch 341/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.9802 - val_loss: 1.4987\n",
      "Epoch 342/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.9735 - val_loss: 1.4985\n",
      "Epoch 343/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.9782 - val_loss: 1.5019\n",
      "Epoch 344/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.9741 - val_loss: 1.5097\n",
      "Epoch 345/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.9738 - val_loss: 1.5057\n",
      "Epoch 346/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.9723 - val_loss: 1.5003\n",
      "Epoch 347/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.9756 - val_loss: 1.4976\n",
      "Epoch 348/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.9835 - val_loss: 1.5080\n",
      "Epoch 349/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.9747 - val_loss: 1.5056\n",
      "Epoch 350/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.9796 - val_loss: 1.5074\n",
      "Epoch 351/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.9816 - val_loss: 1.5088\n",
      "Epoch 352/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.9847 - val_loss: 1.5090\n",
      "Epoch 353/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.9744 - val_loss: 1.5077\n",
      "Epoch 354/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.9763 - val_loss: 1.4999\n",
      "Epoch 355/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.9703 - val_loss: 1.5050\n",
      "Epoch 356/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.9711 - val_loss: 1.5065\n",
      "Epoch 357/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.9745 - val_loss: 1.5056\n",
      "Epoch 358/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.9657 - val_loss: 1.5068\n",
      "Epoch 359/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.9665 - val_loss: 1.5061\n",
      "Epoch 360/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.9719 - val_loss: 1.5138\n",
      "Epoch 361/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.9777 - val_loss: 1.5095\n",
      "Epoch 362/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.9665 - val_loss: 1.5058\n",
      "Epoch 363/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.9653 - val_loss: 1.5064\n",
      "Epoch 364/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.9622 - val_loss: 1.5058\n",
      "Epoch 365/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.9786 - val_loss: 1.5039\n",
      "Epoch 366/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.9647 - val_loss: 1.5152\n",
      "Epoch 367/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.9714 - val_loss: 1.4984\n",
      "Epoch 368/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.9815 - val_loss: 1.5017\n",
      "Epoch 369/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.9736 - val_loss: 1.5057\n",
      "Epoch 370/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.9705 - val_loss: 1.5069\n",
      "Epoch 371/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.9738 - val_loss: 1.5060\n",
      "Epoch 372/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.9615 - val_loss: 1.5094\n",
      "Epoch 373/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.9613 - val_loss: 1.5046\n",
      "Epoch 374/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.9726 - val_loss: 1.4971\n",
      "Epoch 375/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.9710 - val_loss: 1.5005\n",
      "Epoch 376/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.9715 - val_loss: 1.5012\n",
      "Epoch 377/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.9667 - val_loss: 1.5032\n",
      "Epoch 378/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 0.9614 - val_loss: 1.5054\n",
      "Epoch 379/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.9748 - val_loss: 1.4987\n",
      "Epoch 380/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.9653 - val_loss: 1.4980\n",
      "Epoch 381/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.9719 - val_loss: 1.4966\n",
      "Epoch 382/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.9763 - val_loss: 1.4934\n",
      "Epoch 383/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.9625 - val_loss: 1.4991\n",
      "Epoch 384/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.9804 - val_loss: 1.4958\n",
      "Epoch 385/5000\n",
      "572/572 [==============================] - 0s 688us/step - loss: 0.9645 - val_loss: 1.4975\n",
      "Epoch 386/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 669us/step - loss: 0.9768 - val_loss: 1.4942\n",
      "Epoch 387/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.9671 - val_loss: 1.4925\n",
      "Epoch 388/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.9602 - val_loss: 1.4981\n",
      "Epoch 389/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.9688 - val_loss: 1.5014\n",
      "Epoch 390/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.9543 - val_loss: 1.4917\n",
      "Epoch 391/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.9525 - val_loss: 1.4899\n",
      "Epoch 392/5000\n",
      "572/572 [==============================] - 0s 720us/step - loss: 0.9604 - val_loss: 1.4979\n",
      "Epoch 393/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.9614 - val_loss: 1.4924\n",
      "Epoch 394/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.9554 - val_loss: 1.5002\n",
      "Epoch 395/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.9605 - val_loss: 1.5022\n",
      "Epoch 396/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.9636 - val_loss: 1.4957\n",
      "Epoch 397/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.9661 - val_loss: 1.4891\n",
      "Epoch 398/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.9610 - val_loss: 1.5000\n",
      "Epoch 399/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.9580 - val_loss: 1.4950\n",
      "Epoch 400/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.9703 - val_loss: 1.4967\n",
      "Epoch 401/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.9673 - val_loss: 1.5008\n",
      "Epoch 402/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.9585 - val_loss: 1.5029\n",
      "Epoch 403/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.9570 - val_loss: 1.4920\n",
      "Epoch 404/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.9578 - val_loss: 1.5032\n",
      "Epoch 405/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.9464 - val_loss: 1.5049\n",
      "Epoch 406/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.9484 - val_loss: 1.5045\n",
      "Epoch 407/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.9510 - val_loss: 1.5057\n",
      "Epoch 408/5000\n",
      "572/572 [==============================] - 0s 687us/step - loss: 0.9753 - val_loss: 1.4886\n",
      "Epoch 409/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.9515 - val_loss: 1.4908\n",
      "Epoch 410/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.9605 - val_loss: 1.5003\n",
      "Epoch 411/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.9545 - val_loss: 1.5002\n",
      "Epoch 412/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.9597 - val_loss: 1.5013\n",
      "Epoch 413/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.9573 - val_loss: 1.5092\n",
      "Epoch 414/5000\n",
      "572/572 [==============================] - 0s 706us/step - loss: 0.9608 - val_loss: 1.5063\n",
      "Epoch 415/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.9533 - val_loss: 1.5035\n",
      "Epoch 416/5000\n",
      "572/572 [==============================] - 0s 620us/step - loss: 0.9536 - val_loss: 1.5049\n",
      "Epoch 417/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.9622 - val_loss: 1.5050\n",
      "Epoch 418/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.9509 - val_loss: 1.5185\n",
      "Epoch 419/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.9570 - val_loss: 1.5099\n",
      "Epoch 420/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.9587 - val_loss: 1.5126\n",
      "Epoch 421/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.9593 - val_loss: 1.5069\n",
      "Epoch 422/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.9577 - val_loss: 1.5091\n",
      "Epoch 423/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.9520 - val_loss: 1.5036\n",
      "Epoch 424/5000\n",
      "572/572 [==============================] - 0s 693us/step - loss: 0.9660 - val_loss: 1.5026\n",
      "Epoch 425/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.9485 - val_loss: 1.4982\n",
      "Epoch 426/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.9526 - val_loss: 1.5005\n",
      "Epoch 427/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.9416 - val_loss: 1.4960\n",
      "Epoch 428/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.9401 - val_loss: 1.4947\n",
      "Epoch 429/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.9512 - val_loss: 1.4942\n",
      "Epoch 430/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.9550 - val_loss: 1.4972\n",
      "Epoch 431/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.9466 - val_loss: 1.4982\n",
      "Epoch 432/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.9496 - val_loss: 1.5064\n",
      "Epoch 433/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.9602 - val_loss: 1.5212\n",
      "Epoch 434/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.9487 - val_loss: 1.5020\n",
      "Epoch 435/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.9410 - val_loss: 1.5041\n",
      "Epoch 436/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.9486 - val_loss: 1.5002\n",
      "Epoch 437/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.9403 - val_loss: 1.4994\n",
      "Epoch 438/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.9417 - val_loss: 1.4938\n",
      "Epoch 439/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.9383 - val_loss: 1.4989\n",
      "Epoch 440/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.9534 - val_loss: 1.4988\n",
      "Epoch 441/5000\n",
      "572/572 [==============================] - 0s 687us/step - loss: 0.9472 - val_loss: 1.5018\n",
      "Epoch 442/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.9583 - val_loss: 1.5030\n",
      "Epoch 443/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.9454 - val_loss: 1.5025\n",
      "Epoch 444/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.9516 - val_loss: 1.5020\n",
      "Epoch 445/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.9525 - val_loss: 1.5199\n",
      "Epoch 446/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.9518 - val_loss: 1.5051\n",
      "Epoch 447/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.9513 - val_loss: 1.5000\n",
      "Epoch 448/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.9549 - val_loss: 1.5048\n",
      "Epoch 449/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.9453 - val_loss: 1.5076\n",
      "Epoch 450/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.9427 - val_loss: 1.4970\n",
      "Epoch 451/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.9517 - val_loss: 1.4959\n",
      "Epoch 452/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.9317 - val_loss: 1.5036\n",
      "Epoch 453/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.9350 - val_loss: 1.4984\n",
      "Epoch 454/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.9403 - val_loss: 1.4979\n",
      "Epoch 455/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.9466 - val_loss: 1.4908\n",
      "Epoch 456/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.9541 - val_loss: 1.5027\n",
      "Epoch 457/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.9451 - val_loss: 1.5075\n",
      "Epoch 458/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 0.9420 - val_loss: 1.4938\n",
      "Epoch 459/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.9471 - val_loss: 1.5013\n",
      "Epoch 460/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.9570 - val_loss: 1.4993\n",
      "Epoch 461/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.9430 - val_loss: 1.4979\n",
      "Epoch 462/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.9422 - val_loss: 1.4964\n",
      "Epoch 463/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 647us/step - loss: 0.9559 - val_loss: 1.5024\n",
      "Epoch 464/5000\n",
      "572/572 [==============================] - 0s 710us/step - loss: 0.9475 - val_loss: 1.4868\n",
      "Epoch 465/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.9471 - val_loss: 1.4908\n",
      "Epoch 466/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.9363 - val_loss: 1.4858\n",
      "Epoch 467/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.9362 - val_loss: 1.4870\n",
      "Epoch 468/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.9397 - val_loss: 1.4950\n",
      "Epoch 469/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.9316 - val_loss: 1.4853\n",
      "Epoch 470/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.9351 - val_loss: 1.5025\n",
      "Epoch 471/5000\n",
      "572/572 [==============================] - 0s 687us/step - loss: 0.9406 - val_loss: 1.5068\n",
      "Epoch 472/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.9367 - val_loss: 1.4977\n",
      "Epoch 473/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.9480 - val_loss: 1.5004\n",
      "Epoch 474/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.9403 - val_loss: 1.5037\n",
      "Epoch 475/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.9396 - val_loss: 1.4950\n",
      "Epoch 476/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.9306 - val_loss: 1.4955\n",
      "Epoch 477/5000\n",
      "572/572 [==============================] - 0s 689us/step - loss: 0.9434 - val_loss: 1.4940\n",
      "Epoch 478/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.9351 - val_loss: 1.4988\n",
      "Epoch 479/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.9316 - val_loss: 1.4966\n",
      "Epoch 480/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.9323 - val_loss: 1.4949\n",
      "Epoch 481/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.9419 - val_loss: 1.4919\n",
      "Epoch 482/5000\n",
      "572/572 [==============================] - 0s 687us/step - loss: 0.9215 - val_loss: 1.4840\n",
      "Epoch 483/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.9283 - val_loss: 1.4968\n",
      "Epoch 484/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.9259 - val_loss: 1.4958\n",
      "Epoch 485/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.9299 - val_loss: 1.5379\n",
      "Epoch 486/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.9316 - val_loss: 1.4898\n",
      "Epoch 487/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.9445 - val_loss: 1.4872\n",
      "Epoch 488/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.9278 - val_loss: 1.4803\n",
      "Epoch 489/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.9387 - val_loss: 1.4887\n",
      "Epoch 490/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.9255 - val_loss: 1.5075\n",
      "Epoch 491/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.9265 - val_loss: 1.4952\n",
      "Epoch 492/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.9200 - val_loss: 1.5042\n",
      "Epoch 493/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.9314 - val_loss: 1.5037\n",
      "Epoch 494/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.9370 - val_loss: 1.4988\n",
      "Epoch 495/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.9327 - val_loss: 1.4999\n",
      "Epoch 496/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.9297 - val_loss: 1.4904\n",
      "Epoch 497/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.9260 - val_loss: 1.4979\n",
      "Epoch 498/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.9364 - val_loss: 1.5012\n",
      "Epoch 499/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.9267 - val_loss: 1.5000\n",
      "Epoch 500/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.9277 - val_loss: 1.5012\n",
      "Epoch 501/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.9413 - val_loss: 1.5125\n",
      "Epoch 502/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.9308 - val_loss: 1.5114\n",
      "Epoch 503/5000\n",
      "572/572 [==============================] - 0s 691us/step - loss: 0.9303 - val_loss: 1.5045\n",
      "Epoch 504/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.9352 - val_loss: 1.5048\n",
      "Epoch 505/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.9309 - val_loss: 1.4962\n",
      "Epoch 506/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.9307 - val_loss: 1.5015\n",
      "Epoch 507/5000\n",
      "572/572 [==============================] - 0s 692us/step - loss: 0.9446 - val_loss: 1.5103\n",
      "Epoch 508/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.9153 - val_loss: 1.4932\n",
      "Epoch 509/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.9336 - val_loss: 1.4928\n",
      "Epoch 510/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.9253 - val_loss: 1.4892\n",
      "Epoch 511/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.9240 - val_loss: 1.4906\n",
      "Epoch 512/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.9160 - val_loss: 1.5011\n",
      "Epoch 513/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.9257 - val_loss: 1.4947\n",
      "Epoch 514/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.9348 - val_loss: 1.4868\n",
      "Epoch 515/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.9178 - val_loss: 1.4901\n",
      "Epoch 516/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.9359 - val_loss: 1.4967\n",
      "Epoch 517/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.9274 - val_loss: 1.4957\n",
      "Epoch 518/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.9324 - val_loss: 1.4947\n",
      "Epoch 519/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.9286 - val_loss: 1.4906\n",
      "Epoch 520/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.9170 - val_loss: 1.4832\n",
      "Epoch 521/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 0.9156 - val_loss: 1.4874\n",
      "Epoch 522/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.9197 - val_loss: 1.4880\n",
      "Epoch 523/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.9324 - val_loss: 1.4872\n",
      "Epoch 524/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.9153 - val_loss: 1.4915\n",
      "Epoch 525/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.9295 - val_loss: 1.4817\n",
      "Epoch 526/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.9339 - val_loss: 1.4840\n",
      "Epoch 527/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.9360 - val_loss: 1.4862\n",
      "Epoch 528/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.9173 - val_loss: 1.5016\n",
      "Epoch 529/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.9324 - val_loss: 1.4963\n",
      "Epoch 530/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.9251 - val_loss: 1.4964\n",
      "Epoch 531/5000\n",
      "572/572 [==============================] - 0s 687us/step - loss: 0.9258 - val_loss: 1.4899\n",
      "Epoch 532/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.9170 - val_loss: 1.4863\n",
      "Epoch 533/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.9270 - val_loss: 1.4894\n",
      "Epoch 534/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.9275 - val_loss: 1.4818\n",
      "Epoch 535/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.9173 - val_loss: 1.4895\n",
      "Epoch 536/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.9187 - val_loss: 1.4889\n",
      "Epoch 537/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.9074 - val_loss: 1.4821\n",
      "Epoch 538/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.9158 - val_loss: 1.4911\n",
      "Epoch 539/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.9238 - val_loss: 1.5056\n",
      "Epoch 540/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 640us/step - loss: 0.9221 - val_loss: 1.4961\n",
      "Epoch 541/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.9270 - val_loss: 1.4818\n",
      "Epoch 542/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.9183 - val_loss: 1.4896\n",
      "Epoch 543/5000\n",
      "572/572 [==============================] - 0s 692us/step - loss: 0.9152 - val_loss: 1.4890\n",
      "Epoch 544/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.9213 - val_loss: 1.4972\n",
      "Epoch 545/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.9297 - val_loss: 1.4919\n",
      "Epoch 546/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.9310 - val_loss: 1.4907\n",
      "Epoch 547/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.9335 - val_loss: 1.4942\n",
      "Epoch 548/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.9288 - val_loss: 1.4896\n",
      "Epoch 549/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 0.9179 - val_loss: 1.4913\n",
      "Epoch 550/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.9338 - val_loss: 1.4874\n",
      "Epoch 551/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.9387 - val_loss: 1.4942\n",
      "Epoch 552/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.9310 - val_loss: 1.4928\n",
      "Epoch 553/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.9078 - val_loss: 1.5075\n",
      "Epoch 554/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.9212 - val_loss: 1.4937\n",
      "Epoch 555/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.9170 - val_loss: 1.4968\n",
      "Epoch 556/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.9237 - val_loss: 1.4959\n",
      "Epoch 557/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.9206 - val_loss: 1.4852\n",
      "Epoch 558/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.9128 - val_loss: 1.4894\n",
      "Epoch 559/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.9193 - val_loss: 1.4894\n",
      "Epoch 560/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 0.9198 - val_loss: 1.4845\n",
      "Epoch 561/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.9239 - val_loss: 1.4861\n",
      "Epoch 562/5000\n",
      "572/572 [==============================] - 0s 689us/step - loss: 0.9095 - val_loss: 1.4934\n",
      "Epoch 563/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.9105 - val_loss: 1.4860\n",
      "Epoch 564/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.9157 - val_loss: 1.4939\n",
      "Epoch 565/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.9136 - val_loss: 1.4983\n",
      "Epoch 566/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.9094 - val_loss: 1.4859\n",
      "Epoch 567/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.9291 - val_loss: 1.4810\n",
      "Epoch 568/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.9084 - val_loss: 1.4888\n",
      "Epoch 569/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.9123 - val_loss: 1.4877\n",
      "Epoch 570/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.9096 - val_loss: 1.4850\n",
      "Epoch 571/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.9089 - val_loss: 1.4849\n",
      "Epoch 572/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.9222 - val_loss: 1.4802\n",
      "Epoch 573/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.9304 - val_loss: 1.4863\n",
      "Epoch 574/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.9233 - val_loss: 1.4952\n",
      "Epoch 575/5000\n",
      "572/572 [==============================] - 0s 689us/step - loss: 0.9155 - val_loss: 1.4872\n",
      "Epoch 576/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.9188 - val_loss: 1.4945\n",
      "Epoch 577/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.9091 - val_loss: 1.4924\n",
      "Epoch 578/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.9189 - val_loss: 1.4827\n",
      "Epoch 579/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.9263 - val_loss: 1.4950\n",
      "Epoch 580/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.9183 - val_loss: 1.4777\n",
      "Epoch 581/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.9036 - val_loss: 1.4797\n",
      "Epoch 582/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.9074 - val_loss: 1.4842\n",
      "Epoch 583/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.9185 - val_loss: 1.4802\n",
      "Epoch 584/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.9168 - val_loss: 1.4787\n",
      "Epoch 585/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.9224 - val_loss: 1.4945\n",
      "Epoch 586/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.9288 - val_loss: 1.4820\n",
      "Epoch 587/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.9061 - val_loss: 1.4867\n",
      "Epoch 588/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.9127 - val_loss: 1.4836\n",
      "Epoch 589/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.9226 - val_loss: 1.4771\n",
      "Epoch 590/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.9040 - val_loss: 1.4838\n",
      "Epoch 591/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.9047 - val_loss: 1.4798\n",
      "Epoch 592/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.9258 - val_loss: 1.4813\n",
      "Epoch 593/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.9064 - val_loss: 1.4782\n",
      "Epoch 594/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.9280 - val_loss: 1.4833\n",
      "Epoch 595/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.9182 - val_loss: 1.4819\n",
      "Epoch 596/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.9078 - val_loss: 1.4809\n",
      "Epoch 597/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.9236 - val_loss: 1.4835\n",
      "Epoch 598/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.9185 - val_loss: 1.4819\n",
      "Epoch 599/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.9148 - val_loss: 1.4988\n",
      "Epoch 600/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.9199 - val_loss: 1.4883\n",
      "Epoch 601/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.9095 - val_loss: 1.4878\n",
      "Epoch 602/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.9203 - val_loss: 1.4762\n",
      "Epoch 603/5000\n",
      "572/572 [==============================] - 0s 706us/step - loss: 0.9057 - val_loss: 1.4788\n",
      "Epoch 604/5000\n",
      "572/572 [==============================] - 0s 846us/step - loss: 0.9018 - val_loss: 1.5061\n",
      "Epoch 605/5000\n",
      "572/572 [==============================] - 0s 691us/step - loss: 0.9247 - val_loss: 1.4923\n",
      "Epoch 606/5000\n",
      "572/572 [==============================] - 0s 745us/step - loss: 0.9125 - val_loss: 1.4830\n",
      "Epoch 607/5000\n",
      "572/572 [==============================] - 0s 617us/step - loss: 0.9003 - val_loss: 1.5000\n",
      "Epoch 608/5000\n",
      "572/572 [==============================] - 0s 873us/step - loss: 0.9116 - val_loss: 1.4769\n",
      "Epoch 609/5000\n",
      "572/572 [==============================] - 0s 835us/step - loss: 0.8991 - val_loss: 1.4777\n",
      "Epoch 610/5000\n",
      "572/572 [==============================] - 0s 814us/step - loss: 0.9091 - val_loss: 1.4898\n",
      "Epoch 611/5000\n",
      "572/572 [==============================] - 0s 840us/step - loss: 0.9176 - val_loss: 1.4862\n",
      "Epoch 612/5000\n",
      "572/572 [==============================] - 0s 719us/step - loss: 0.9212 - val_loss: 1.4835\n",
      "Epoch 613/5000\n",
      "572/572 [==============================] - 0s 687us/step - loss: 0.8964 - val_loss: 1.4810\n",
      "Epoch 614/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.9056 - val_loss: 1.4889\n",
      "Epoch 615/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.9100 - val_loss: 1.4857\n",
      "Epoch 616/5000\n",
      "572/572 [==============================] - 0s 687us/step - loss: 0.8999 - val_loss: 1.4822\n",
      "Epoch 617/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 631us/step - loss: 0.9114 - val_loss: 1.4922\n",
      "Epoch 618/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.9200 - val_loss: 1.4822\n",
      "Epoch 619/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.9136 - val_loss: 1.4825\n",
      "Epoch 620/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8998 - val_loss: 1.4917\n",
      "Epoch 621/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.9078 - val_loss: 1.4855\n",
      "Epoch 622/5000\n",
      "572/572 [==============================] - 0s 619us/step - loss: 0.9134 - val_loss: 1.4818\n",
      "Epoch 623/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.9150 - val_loss: 1.4892\n",
      "Epoch 624/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.9033 - val_loss: 1.4822\n",
      "Epoch 625/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 0.9105 - val_loss: 1.4829\n",
      "Epoch 626/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.9183 - val_loss: 1.4821\n",
      "Epoch 627/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.9148 - val_loss: 1.4723\n",
      "Epoch 628/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.9072 - val_loss: 1.4733\n",
      "Epoch 629/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.9152 - val_loss: 1.4713\n",
      "Epoch 630/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.9092 - val_loss: 1.4798\n",
      "Epoch 631/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8981 - val_loss: 1.4841\n",
      "Epoch 632/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.9287 - val_loss: 1.4919\n",
      "Epoch 633/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.9104 - val_loss: 1.4831\n",
      "Epoch 634/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.9017 - val_loss: 1.4854\n",
      "Epoch 635/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.9186 - val_loss: 1.4815\n",
      "Epoch 636/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.9072 - val_loss: 1.4792\n",
      "Epoch 637/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.9109 - val_loss: 1.4821\n",
      "Epoch 638/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.9097 - val_loss: 1.4747\n",
      "Epoch 639/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8910 - val_loss: 1.4843\n",
      "Epoch 640/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.9077 - val_loss: 1.4745\n",
      "Epoch 641/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.9117 - val_loss: 1.4822\n",
      "Epoch 642/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.9171 - val_loss: 1.4748\n",
      "Epoch 643/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.9033 - val_loss: 1.4746\n",
      "Epoch 644/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.9043 - val_loss: 1.4744\n",
      "Epoch 645/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.9079 - val_loss: 1.4820\n",
      "Epoch 646/5000\n",
      "572/572 [==============================] - 0s 702us/step - loss: 0.9070 - val_loss: 1.4835\n",
      "Epoch 647/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.9111 - val_loss: 1.4737\n",
      "Epoch 648/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.9161 - val_loss: 1.4689\n",
      "Epoch 649/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.9172 - val_loss: 1.4648\n",
      "Epoch 650/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.8957 - val_loss: 1.4753\n",
      "Epoch 651/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.9067 - val_loss: 1.4737\n",
      "Epoch 652/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.9001 - val_loss: 1.4798\n",
      "Epoch 653/5000\n",
      "572/572 [==============================] - 0s 694us/step - loss: 0.8940 - val_loss: 1.4756\n",
      "Epoch 654/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.9120 - val_loss: 1.4724\n",
      "Epoch 655/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.9028 - val_loss: 1.4811\n",
      "Epoch 656/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8929 - val_loss: 1.4727\n",
      "Epoch 657/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.9111 - val_loss: 1.4661\n",
      "Epoch 658/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.9038 - val_loss: 1.4775\n",
      "Epoch 659/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.9007 - val_loss: 1.4786\n",
      "Epoch 660/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.9008 - val_loss: 1.4734\n",
      "Epoch 661/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.8881 - val_loss: 1.4763\n",
      "Epoch 662/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8990 - val_loss: 1.4772\n",
      "Epoch 663/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8993 - val_loss: 1.4783\n",
      "Epoch 664/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.9085 - val_loss: 1.4814\n",
      "Epoch 665/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8949 - val_loss: 1.4903\n",
      "Epoch 666/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.9106 - val_loss: 1.5007\n",
      "Epoch 667/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.9065 - val_loss: 1.4860\n",
      "Epoch 668/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.9117 - val_loss: 1.4733\n",
      "Epoch 669/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8987 - val_loss: 1.4762\n",
      "Epoch 670/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.9036 - val_loss: 1.4819\n",
      "Epoch 671/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8955 - val_loss: 1.4731\n",
      "Epoch 672/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.9065 - val_loss: 1.4735\n",
      "Epoch 673/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8992 - val_loss: 1.4675\n",
      "Epoch 674/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8932 - val_loss: 1.4795\n",
      "Epoch 675/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.9121 - val_loss: 1.4741\n",
      "Epoch 676/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.9037 - val_loss: 1.4694\n",
      "Epoch 677/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8965 - val_loss: 1.4622\n",
      "Epoch 678/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8959 - val_loss: 1.4787\n",
      "Epoch 679/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8901 - val_loss: 1.4800\n",
      "Epoch 680/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.9031 - val_loss: 1.4721\n",
      "Epoch 681/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.9027 - val_loss: 1.4828\n",
      "Epoch 682/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.9072 - val_loss: 1.4744\n",
      "Epoch 683/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8971 - val_loss: 1.4726\n",
      "Epoch 684/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.9114 - val_loss: 1.4901\n",
      "Epoch 685/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8931 - val_loss: 1.4717\n",
      "Epoch 686/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.9008 - val_loss: 1.4750\n",
      "Epoch 687/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8962 - val_loss: 1.4801\n",
      "Epoch 688/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8983 - val_loss: 1.4673\n",
      "Epoch 689/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.9032 - val_loss: 1.4816\n",
      "Epoch 690/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8992 - val_loss: 1.4867\n",
      "Epoch 691/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.9030 - val_loss: 1.4689\n",
      "Epoch 692/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8951 - val_loss: 1.4707\n",
      "Epoch 693/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.9024 - val_loss: 1.4693\n",
      "Epoch 694/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 646us/step - loss: 0.8986 - val_loss: 1.4649\n",
      "Epoch 695/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.9035 - val_loss: 1.4701\n",
      "Epoch 696/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.9122 - val_loss: 1.4614\n",
      "Epoch 697/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8996 - val_loss: 1.4698\n",
      "Epoch 698/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8974 - val_loss: 1.4762\n",
      "Epoch 699/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8981 - val_loss: 1.4688\n",
      "Epoch 700/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.9032 - val_loss: 1.4831\n",
      "Epoch 701/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8916 - val_loss: 1.4688\n",
      "Epoch 702/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8841 - val_loss: 1.4664\n",
      "Epoch 703/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.9077 - val_loss: 1.4707\n",
      "Epoch 704/5000\n",
      "572/572 [==============================] - 0s 622us/step - loss: 0.8987 - val_loss: 1.4704\n",
      "Epoch 705/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.9049 - val_loss: 1.4787\n",
      "Epoch 706/5000\n",
      "572/572 [==============================] - 0s 618us/step - loss: 0.9052 - val_loss: 1.4853\n",
      "Epoch 707/5000\n",
      "572/572 [==============================] - 0s 688us/step - loss: 0.9004 - val_loss: 1.4778\n",
      "Epoch 708/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.9005 - val_loss: 1.4834\n",
      "Epoch 709/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.9019 - val_loss: 1.4706\n",
      "Epoch 710/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8857 - val_loss: 1.4755\n",
      "Epoch 711/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.9021 - val_loss: 1.4867\n",
      "Epoch 712/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8840 - val_loss: 1.4651\n",
      "Epoch 713/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.9032 - val_loss: 1.4672\n",
      "Epoch 714/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.9074 - val_loss: 1.4702\n",
      "Epoch 715/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8905 - val_loss: 1.4541\n",
      "Epoch 716/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.9063 - val_loss: 1.4567\n",
      "Epoch 717/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8926 - val_loss: 1.4667\n",
      "Epoch 718/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8934 - val_loss: 1.4734\n",
      "Epoch 719/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8847 - val_loss: 1.4693\n",
      "Epoch 720/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.8978 - val_loss: 1.4848\n",
      "Epoch 721/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8890 - val_loss: 1.4712\n",
      "Epoch 722/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8932 - val_loss: 1.4577\n",
      "Epoch 723/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8963 - val_loss: 1.4606\n",
      "Epoch 724/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8885 - val_loss: 1.4684\n",
      "Epoch 725/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.9035 - val_loss: 1.4666\n",
      "Epoch 726/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8953 - val_loss: 1.4636\n",
      "Epoch 727/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8924 - val_loss: 1.4669\n",
      "Epoch 728/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8962 - val_loss: 1.4697\n",
      "Epoch 729/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8911 - val_loss: 1.4637\n",
      "Epoch 730/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.9059 - val_loss: 1.4641\n",
      "Epoch 731/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8820 - val_loss: 1.4760\n",
      "Epoch 732/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8919 - val_loss: 1.4749\n",
      "Epoch 733/5000\n",
      "572/572 [==============================] - 0s 700us/step - loss: 0.8888 - val_loss: 1.4774\n",
      "Epoch 734/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8963 - val_loss: 1.4641\n",
      "Epoch 735/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8891 - val_loss: 1.4687\n",
      "Epoch 736/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.9130 - val_loss: 1.4663\n",
      "Epoch 737/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8905 - val_loss: 1.4605\n",
      "Epoch 738/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8911 - val_loss: 1.4636\n",
      "Epoch 739/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.9039 - val_loss: 1.4730\n",
      "Epoch 740/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8825 - val_loss: 1.4726\n",
      "Epoch 741/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8919 - val_loss: 1.4759\n",
      "Epoch 742/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.9023 - val_loss: 1.4598\n",
      "Epoch 743/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8928 - val_loss: 1.4663\n",
      "Epoch 744/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8953 - val_loss: 1.4686\n",
      "Epoch 745/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8895 - val_loss: 1.4616\n",
      "Epoch 746/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8821 - val_loss: 1.4709\n",
      "Epoch 747/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8904 - val_loss: 1.4635\n",
      "Epoch 748/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8859 - val_loss: 1.4586\n",
      "Epoch 749/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8940 - val_loss: 1.4536\n",
      "Epoch 750/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8893 - val_loss: 1.4945\n",
      "Epoch 751/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.9081 - val_loss: 1.4523\n",
      "Epoch 752/5000\n",
      "572/572 [==============================] - 0s 696us/step - loss: 0.8892 - val_loss: 1.4689\n",
      "Epoch 753/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8893 - val_loss: 1.4586\n",
      "Epoch 754/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8793 - val_loss: 1.4798\n",
      "Epoch 755/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 0.8859 - val_loss: 1.4814\n",
      "Epoch 756/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8993 - val_loss: 1.4702\n",
      "Epoch 757/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8927 - val_loss: 1.4700\n",
      "Epoch 758/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8927 - val_loss: 1.4619\n",
      "Epoch 759/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8971 - val_loss: 1.4628\n",
      "Epoch 760/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8906 - val_loss: 1.4673\n",
      "Epoch 761/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8825 - val_loss: 1.4640\n",
      "Epoch 762/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8888 - val_loss: 1.4722\n",
      "Epoch 763/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8930 - val_loss: 1.4712\n",
      "Epoch 764/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8859 - val_loss: 1.4664\n",
      "Epoch 765/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8910 - val_loss: 1.4627\n",
      "Epoch 766/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8967 - val_loss: 1.4623\n",
      "Epoch 767/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8922 - val_loss: 1.4610\n",
      "Epoch 768/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8925 - val_loss: 1.4626\n",
      "Epoch 769/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8879 - val_loss: 1.4635\n",
      "Epoch 770/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8890 - val_loss: 1.4650\n",
      "Epoch 771/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 649us/step - loss: 0.8933 - val_loss: 1.4714\n",
      "Epoch 772/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8897 - val_loss: 1.4626\n",
      "Epoch 773/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8956 - val_loss: 1.4663\n",
      "Epoch 774/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.8992 - val_loss: 1.4630\n",
      "Epoch 775/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8934 - val_loss: 1.4928\n",
      "Epoch 776/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8947 - val_loss: 1.4817\n",
      "Epoch 777/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8863 - val_loss: 1.4657\n",
      "Epoch 778/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8929 - val_loss: 1.4563\n",
      "Epoch 779/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8945 - val_loss: 1.4527\n",
      "Epoch 780/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8893 - val_loss: 1.4528\n",
      "Epoch 781/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8939 - val_loss: 1.4538\n",
      "Epoch 782/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8887 - val_loss: 1.4558\n",
      "Epoch 783/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8787 - val_loss: 1.4575\n",
      "Epoch 784/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8857 - val_loss: 1.4731\n",
      "Epoch 785/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8930 - val_loss: 1.4562\n",
      "Epoch 786/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 0.8896 - val_loss: 1.4681\n",
      "Epoch 787/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8894 - val_loss: 1.4574\n",
      "Epoch 788/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8983 - val_loss: 1.4600\n",
      "Epoch 789/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8878 - val_loss: 1.4634\n",
      "Epoch 790/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8936 - val_loss: 1.4544\n",
      "Epoch 791/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8823 - val_loss: 1.4726\n",
      "Epoch 792/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8764 - val_loss: 1.4540\n",
      "Epoch 793/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8904 - val_loss: 1.4607\n",
      "Epoch 794/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8904 - val_loss: 1.4586\n",
      "Epoch 795/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8864 - val_loss: 1.4525\n",
      "Epoch 796/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.9004 - val_loss: 1.4550\n",
      "Epoch 797/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8751 - val_loss: 1.4503\n",
      "Epoch 798/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8931 - val_loss: 1.4642\n",
      "Epoch 799/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8851 - val_loss: 1.4676\n",
      "Epoch 800/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8811 - val_loss: 1.4678\n",
      "Epoch 801/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8791 - val_loss: 1.4586\n",
      "Epoch 802/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8909 - val_loss: 1.4525\n",
      "Epoch 803/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8863 - val_loss: 1.4471\n",
      "Epoch 804/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8836 - val_loss: 1.4540\n",
      "Epoch 805/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8887 - val_loss: 1.4592\n",
      "Epoch 806/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8822 - val_loss: 1.4719\n",
      "Epoch 807/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8876 - val_loss: 1.4759\n",
      "Epoch 808/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8895 - val_loss: 1.4510\n",
      "Epoch 809/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8881 - val_loss: 1.4508\n",
      "Epoch 810/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8834 - val_loss: 1.4476\n",
      "Epoch 811/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.8769 - val_loss: 1.4501\n",
      "Epoch 812/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8800 - val_loss: 1.4500\n",
      "Epoch 813/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8929 - val_loss: 1.4539\n",
      "Epoch 814/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8834 - val_loss: 1.4472\n",
      "Epoch 815/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8727 - val_loss: 1.4540\n",
      "Epoch 816/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8955 - val_loss: 1.4465\n",
      "Epoch 817/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8842 - val_loss: 1.4488\n",
      "Epoch 818/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8693 - val_loss: 1.4564\n",
      "Epoch 819/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.8863 - val_loss: 1.4588\n",
      "Epoch 820/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.8858 - val_loss: 1.4540\n",
      "Epoch 821/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.8822 - val_loss: 1.4534\n",
      "Epoch 822/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8941 - val_loss: 1.4626\n",
      "Epoch 823/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8853 - val_loss: 1.4513\n",
      "Epoch 824/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.8815 - val_loss: 1.4537\n",
      "Epoch 825/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8792 - val_loss: 1.4515\n",
      "Epoch 826/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8912 - val_loss: 1.4577\n",
      "Epoch 827/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8947 - val_loss: 1.4610\n",
      "Epoch 828/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8855 - val_loss: 1.4607\n",
      "Epoch 829/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8920 - val_loss: 1.4753\n",
      "Epoch 830/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8786 - val_loss: 1.4678\n",
      "Epoch 831/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8915 - val_loss: 1.4534\n",
      "Epoch 832/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8784 - val_loss: 1.4557\n",
      "Epoch 833/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8931 - val_loss: 1.4677\n",
      "Epoch 834/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8888 - val_loss: 1.4590\n",
      "Epoch 835/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.8908 - val_loss: 1.4576\n",
      "Epoch 836/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8934 - val_loss: 1.4527\n",
      "Epoch 837/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8793 - val_loss: 1.4694\n",
      "Epoch 838/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8764 - val_loss: 1.4588\n",
      "Epoch 839/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8781 - val_loss: 1.4563\n",
      "Epoch 840/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8862 - val_loss: 1.4652\n",
      "Epoch 841/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.8971 - val_loss: 1.4476\n",
      "Epoch 842/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8822 - val_loss: 1.4761\n",
      "Epoch 843/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8779 - val_loss: 1.4694\n",
      "Epoch 844/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8818 - val_loss: 1.4589\n",
      "Epoch 845/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8837 - val_loss: 1.4503\n",
      "Epoch 846/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8843 - val_loss: 1.4501\n",
      "Epoch 847/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8760 - val_loss: 1.4584\n",
      "Epoch 848/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 640us/step - loss: 0.8747 - val_loss: 1.4679\n",
      "Epoch 849/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8802 - val_loss: 1.4520\n",
      "Epoch 850/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8968 - val_loss: 1.4838\n",
      "Epoch 851/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8710 - val_loss: 1.4516\n",
      "Epoch 852/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8787 - val_loss: 1.4506\n",
      "Epoch 853/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8865 - val_loss: 1.4436\n",
      "Epoch 854/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8871 - val_loss: 1.4626\n",
      "Epoch 855/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8883 - val_loss: 1.4582\n",
      "Epoch 856/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8854 - val_loss: 1.4538\n",
      "Epoch 857/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8848 - val_loss: 1.4541\n",
      "Epoch 858/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.8953 - val_loss: 1.4491\n",
      "Epoch 859/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8782 - val_loss: 1.4711\n",
      "Epoch 860/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8951 - val_loss: 1.4579\n",
      "Epoch 861/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8709 - val_loss: 1.4645\n",
      "Epoch 862/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.8859 - val_loss: 1.4719\n",
      "Epoch 863/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8764 - val_loss: 1.4528\n",
      "Epoch 864/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8731 - val_loss: 1.4583\n",
      "Epoch 865/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.8871 - val_loss: 1.4476\n",
      "Epoch 866/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8731 - val_loss: 1.4515\n",
      "Epoch 867/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8801 - val_loss: 1.4555\n",
      "Epoch 868/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8788 - val_loss: 1.4508\n",
      "Epoch 869/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8788 - val_loss: 1.4524\n",
      "Epoch 870/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8872 - val_loss: 1.4439\n",
      "Epoch 871/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8878 - val_loss: 1.4468\n",
      "Epoch 872/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8830 - val_loss: 1.4502\n",
      "Epoch 873/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8805 - val_loss: 1.4573\n",
      "Epoch 874/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8835 - val_loss: 1.4436\n",
      "Epoch 875/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8873 - val_loss: 1.4435\n",
      "Epoch 876/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8722 - val_loss: 1.4408\n",
      "Epoch 877/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8864 - val_loss: 1.4495\n",
      "Epoch 878/5000\n",
      "572/572 [==============================] - 0s 699us/step - loss: 0.8764 - val_loss: 1.4483\n",
      "Epoch 879/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8883 - val_loss: 1.4595\n",
      "Epoch 880/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8896 - val_loss: 1.4424\n",
      "Epoch 881/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8834 - val_loss: 1.4442\n",
      "Epoch 882/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8785 - val_loss: 1.4350\n",
      "Epoch 883/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8754 - val_loss: 1.4462\n",
      "Epoch 884/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8770 - val_loss: 1.4479\n",
      "Epoch 885/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8872 - val_loss: 1.4421\n",
      "Epoch 886/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8884 - val_loss: 1.4629\n",
      "Epoch 887/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8801 - val_loss: 1.4638\n",
      "Epoch 888/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8872 - val_loss: 1.4493\n",
      "Epoch 889/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8892 - val_loss: 1.4633\n",
      "Epoch 890/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8662 - val_loss: 1.4484\n",
      "Epoch 891/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8812 - val_loss: 1.4425\n",
      "Epoch 892/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8797 - val_loss: 1.4484\n",
      "Epoch 893/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8859 - val_loss: 1.4586\n",
      "Epoch 894/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8854 - val_loss: 1.4463\n",
      "Epoch 895/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8612 - val_loss: 1.4418\n",
      "Epoch 896/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8806 - val_loss: 1.4472\n",
      "Epoch 897/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8845 - val_loss: 1.4479\n",
      "Epoch 898/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8784 - val_loss: 1.4618\n",
      "Epoch 899/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8771 - val_loss: 1.4433\n",
      "Epoch 900/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8887 - val_loss: 1.4471\n",
      "Epoch 901/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8863 - val_loss: 1.4481\n",
      "Epoch 902/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8844 - val_loss: 1.4465\n",
      "Epoch 903/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8889 - val_loss: 1.4393\n",
      "Epoch 904/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8856 - val_loss: 1.4365\n",
      "Epoch 905/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8802 - val_loss: 1.4361\n",
      "Epoch 906/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8768 - val_loss: 1.4501\n",
      "Epoch 907/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8903 - val_loss: 1.4414\n",
      "Epoch 908/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8594 - val_loss: 1.4394\n",
      "Epoch 909/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8707 - val_loss: 1.4476\n",
      "Epoch 910/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8851 - val_loss: 1.4529\n",
      "Epoch 911/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8736 - val_loss: 1.4506\n",
      "Epoch 912/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8836 - val_loss: 1.4522\n",
      "Epoch 913/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8632 - val_loss: 1.4418\n",
      "Epoch 914/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8833 - val_loss: 1.4366\n",
      "Epoch 915/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8706 - val_loss: 1.4459\n",
      "Epoch 916/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.8835 - val_loss: 1.4411\n",
      "Epoch 917/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8796 - val_loss: 1.4279\n",
      "Epoch 918/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8751 - val_loss: 1.4293\n",
      "Epoch 919/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 0.8776 - val_loss: 1.4344\n",
      "Epoch 920/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8770 - val_loss: 1.4378\n",
      "Epoch 921/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8704 - val_loss: 1.4858\n",
      "Epoch 922/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8919 - val_loss: 1.4470\n",
      "Epoch 923/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8800 - val_loss: 1.4610\n",
      "Epoch 924/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8848 - val_loss: 1.4449\n",
      "Epoch 925/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 624us/step - loss: 0.8722 - val_loss: 1.4452\n",
      "Epoch 926/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8854 - val_loss: 1.4583\n",
      "Epoch 927/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8803 - val_loss: 1.4397\n",
      "Epoch 928/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8712 - val_loss: 1.4351\n",
      "Epoch 929/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.8693 - val_loss: 1.4433\n",
      "Epoch 930/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8816 - val_loss: 1.4315\n",
      "Epoch 931/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 0.8694 - val_loss: 1.4297\n",
      "Epoch 932/5000\n",
      "572/572 [==============================] - 0s 620us/step - loss: 0.8693 - val_loss: 1.4385\n",
      "Epoch 933/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8845 - val_loss: 1.4444\n",
      "Epoch 934/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8781 - val_loss: 1.4580\n",
      "Epoch 935/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8776 - val_loss: 1.4504\n",
      "Epoch 936/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8739 - val_loss: 1.4563\n",
      "Epoch 937/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8658 - val_loss: 1.4584\n",
      "Epoch 938/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8788 - val_loss: 1.4451\n",
      "Epoch 939/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8689 - val_loss: 1.4399\n",
      "Epoch 940/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8749 - val_loss: 1.4455\n",
      "Epoch 941/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8733 - val_loss: 1.4448\n",
      "Epoch 942/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8818 - val_loss: 1.4469\n",
      "Epoch 943/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8819 - val_loss: 1.4364\n",
      "Epoch 944/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8716 - val_loss: 1.4404\n",
      "Epoch 945/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8785 - val_loss: 1.4539\n",
      "Epoch 946/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8889 - val_loss: 1.4468\n",
      "Epoch 947/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.8774 - val_loss: 1.4495\n",
      "Epoch 948/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8744 - val_loss: 1.4393\n",
      "Epoch 949/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8811 - val_loss: 1.4319\n",
      "Epoch 950/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8779 - val_loss: 1.4304\n",
      "Epoch 951/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8759 - val_loss: 1.4395\n",
      "Epoch 952/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8849 - val_loss: 1.4332\n",
      "Epoch 953/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8856 - val_loss: 1.4366\n",
      "Epoch 954/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8611 - val_loss: 1.4438\n",
      "Epoch 955/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8615 - val_loss: 1.4449\n",
      "Epoch 956/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8697 - val_loss: 1.4493\n",
      "Epoch 957/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8798 - val_loss: 1.4543\n",
      "Epoch 958/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8773 - val_loss: 1.4448\n",
      "Epoch 959/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8714 - val_loss: 1.4396\n",
      "Epoch 960/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8750 - val_loss: 1.4322\n",
      "Epoch 961/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8785 - val_loss: 1.4473\n",
      "Epoch 962/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8801 - val_loss: 1.4407\n",
      "Epoch 963/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8780 - val_loss: 1.4547\n",
      "Epoch 964/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8743 - val_loss: 1.4368\n",
      "Epoch 965/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8736 - val_loss: 1.4309\n",
      "Epoch 966/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8722 - val_loss: 1.4378\n",
      "Epoch 967/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8719 - val_loss: 1.4485\n",
      "Epoch 968/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8640 - val_loss: 1.4437\n",
      "Epoch 969/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8703 - val_loss: 1.4517\n",
      "Epoch 970/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8649 - val_loss: 1.4547\n",
      "Epoch 971/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8750 - val_loss: 1.4519\n",
      "Epoch 972/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8710 - val_loss: 1.4610\n",
      "Epoch 973/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8768 - val_loss: 1.4578\n",
      "Epoch 974/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8703 - val_loss: 1.4506\n",
      "Epoch 975/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8705 - val_loss: 1.4517\n",
      "Epoch 976/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8727 - val_loss: 1.4495\n",
      "Epoch 977/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8748 - val_loss: 1.4601\n",
      "Epoch 978/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.8725 - val_loss: 1.4738\n",
      "Epoch 979/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8737 - val_loss: 1.4932\n",
      "Epoch 980/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8746 - val_loss: 1.4470\n",
      "Epoch 981/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8695 - val_loss: 1.4461\n",
      "Epoch 982/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8625 - val_loss: 1.4340\n",
      "Epoch 983/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8684 - val_loss: 1.4366\n",
      "Epoch 984/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8642 - val_loss: 1.4288\n",
      "Epoch 985/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8764 - val_loss: 1.4396\n",
      "Epoch 986/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8689 - val_loss: 1.4324\n",
      "Epoch 987/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8757 - val_loss: 1.4349\n",
      "Epoch 988/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8688 - val_loss: 1.4388\n",
      "Epoch 989/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8767 - val_loss: 1.4462\n",
      "Epoch 990/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8842 - val_loss: 1.4433\n",
      "Epoch 991/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8701 - val_loss: 1.4449\n",
      "Epoch 992/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8567 - val_loss: 1.4496\n",
      "Epoch 993/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8619 - val_loss: 1.4423\n",
      "Epoch 994/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8764 - val_loss: 1.4435\n",
      "Epoch 995/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8714 - val_loss: 1.4363\n",
      "Epoch 996/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 0.8778 - val_loss: 1.4326\n",
      "Epoch 997/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8763 - val_loss: 1.4370\n",
      "Epoch 998/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8646 - val_loss: 1.4392\n",
      "Epoch 999/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.8743 - val_loss: 1.4290\n",
      "Epoch 1000/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8733 - val_loss: 1.4371\n",
      "Epoch 1001/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8779 - val_loss: 1.4430\n",
      "Epoch 1002/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 644us/step - loss: 0.8868 - val_loss: 1.4537\n",
      "Epoch 1003/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8653 - val_loss: 1.4607\n",
      "Epoch 1004/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8959 - val_loss: 1.4526\n",
      "Epoch 1005/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8597 - val_loss: 1.4459\n",
      "Epoch 1006/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8775 - val_loss: 1.4476\n",
      "Epoch 1007/5000\n",
      "572/572 [==============================] - 0s 708us/step - loss: 0.8715 - val_loss: 1.4432\n",
      "Epoch 1008/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8645 - val_loss: 1.4469\n",
      "Epoch 1009/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8611 - val_loss: 1.4468\n",
      "Epoch 1010/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8608 - val_loss: 1.4327\n",
      "Epoch 1011/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8685 - val_loss: 1.4431\n",
      "Epoch 1012/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8708 - val_loss: 1.4303\n",
      "Epoch 1013/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.8751 - val_loss: 1.4311\n",
      "Epoch 1014/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8828 - val_loss: 1.4421\n",
      "Epoch 1015/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8689 - val_loss: 1.4190\n",
      "Epoch 1016/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8600 - val_loss: 1.4248\n",
      "Epoch 1017/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8738 - val_loss: 1.4287\n",
      "Epoch 1018/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8897 - val_loss: 1.4321\n",
      "Epoch 1019/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8669 - val_loss: 1.4513\n",
      "Epoch 1020/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8767 - val_loss: 1.4367\n",
      "Epoch 1021/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8629 - val_loss: 1.4530\n",
      "Epoch 1022/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8752 - val_loss: 1.4439\n",
      "Epoch 1023/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8776 - val_loss: 1.4441\n",
      "Epoch 1024/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8661 - val_loss: 1.4563\n",
      "Epoch 1025/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8789 - val_loss: 1.4428\n",
      "Epoch 1026/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8752 - val_loss: 1.4368\n",
      "Epoch 1027/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8731 - val_loss: 1.4410\n",
      "Epoch 1028/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8643 - val_loss: 1.4425\n",
      "Epoch 1029/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8558 - val_loss: 1.4344\n",
      "Epoch 1030/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8741 - val_loss: 1.4316\n",
      "Epoch 1031/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8656 - val_loss: 1.4291\n",
      "Epoch 1032/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8737 - val_loss: 1.4545\n",
      "Epoch 1033/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8528 - val_loss: 1.4341\n",
      "Epoch 1034/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8780 - val_loss: 1.4489\n",
      "Epoch 1035/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8667 - val_loss: 1.4358\n",
      "Epoch 1036/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8745 - val_loss: 1.4373\n",
      "Epoch 1037/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8777 - val_loss: 1.4397\n",
      "Epoch 1038/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8646 - val_loss: 1.4361\n",
      "Epoch 1039/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8488 - val_loss: 1.4542\n",
      "Epoch 1040/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8591 - val_loss: 1.4422\n",
      "Epoch 1041/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8555 - val_loss: 1.4321\n",
      "Epoch 1042/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8611 - val_loss: 1.4502\n",
      "Epoch 1043/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8613 - val_loss: 1.4375\n",
      "Epoch 1044/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.8713 - val_loss: 1.4497\n",
      "Epoch 1045/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8750 - val_loss: 1.4335\n",
      "Epoch 1046/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8705 - val_loss: 1.4564\n",
      "Epoch 1047/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8608 - val_loss: 1.4359\n",
      "Epoch 1048/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8738 - val_loss: 1.4406\n",
      "Epoch 1049/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8696 - val_loss: 1.4541\n",
      "Epoch 1050/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8818 - val_loss: 1.4378\n",
      "Epoch 1051/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8705 - val_loss: 1.4343\n",
      "Epoch 1052/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.8640 - val_loss: 1.4568\n",
      "Epoch 1053/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8788 - val_loss: 1.4424\n",
      "Epoch 1054/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8713 - val_loss: 1.4305\n",
      "Epoch 1055/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8599 - val_loss: 1.4401\n",
      "Epoch 1056/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8620 - val_loss: 1.4501\n",
      "Epoch 1057/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8648 - val_loss: 1.4322\n",
      "Epoch 1058/5000\n",
      "572/572 [==============================] - 0s 619us/step - loss: 0.8779 - val_loss: 1.4323\n",
      "Epoch 1059/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8677 - val_loss: 1.4225\n",
      "Epoch 1060/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8722 - val_loss: 1.4209\n",
      "Epoch 1061/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8677 - val_loss: 1.4367\n",
      "Epoch 1062/5000\n",
      "572/572 [==============================] - 0s 687us/step - loss: 0.8673 - val_loss: 1.4528\n",
      "Epoch 1063/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8716 - val_loss: 1.4344\n",
      "Epoch 1064/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8649 - val_loss: 1.4223\n",
      "Epoch 1065/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8712 - val_loss: 1.4348\n",
      "Epoch 1066/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8698 - val_loss: 1.4351\n",
      "Epoch 1067/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8661 - val_loss: 1.4532\n",
      "Epoch 1068/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8755 - val_loss: 1.4584\n",
      "Epoch 1069/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8638 - val_loss: 1.4291\n",
      "Epoch 1070/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8621 - val_loss: 1.4223\n",
      "Epoch 1071/5000\n",
      "572/572 [==============================] - 0s 697us/step - loss: 0.8647 - val_loss: 1.4410\n",
      "Epoch 1072/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8648 - val_loss: 1.4324\n",
      "Epoch 1073/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.8674 - val_loss: 1.4359\n",
      "Epoch 1074/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8606 - val_loss: 1.4303\n",
      "Epoch 1075/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8659 - val_loss: 1.4245\n",
      "Epoch 1076/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8588 - val_loss: 1.4356\n",
      "Epoch 1077/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8766 - val_loss: 1.4379\n",
      "Epoch 1078/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 642us/step - loss: 0.8570 - val_loss: 1.4371\n",
      "Epoch 1079/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8685 - val_loss: 1.4277\n",
      "Epoch 1080/5000\n",
      "572/572 [==============================] - 0s 767us/step - loss: 0.8597 - val_loss: 1.4381\n",
      "Epoch 1081/5000\n",
      "572/572 [==============================] - 0s 854us/step - loss: 0.8643 - val_loss: 1.4381\n",
      "Epoch 1082/5000\n",
      "572/572 [==============================] - 0s 842us/step - loss: 0.8684 - val_loss: 1.4444\n",
      "Epoch 1083/5000\n",
      "572/572 [==============================] - 0s 817us/step - loss: 0.8658 - val_loss: 1.4360\n",
      "Epoch 1084/5000\n",
      "572/572 [==============================] - 0s 798us/step - loss: 0.8632 - val_loss: 1.4440\n",
      "Epoch 1085/5000\n",
      "572/572 [==============================] - 0s 812us/step - loss: 0.8629 - val_loss: 1.4136\n",
      "Epoch 1086/5000\n",
      "572/572 [==============================] - 0s 847us/step - loss: 0.8618 - val_loss: 1.4160\n",
      "Epoch 1087/5000\n",
      "572/572 [==============================] - 0s 811us/step - loss: 0.8603 - val_loss: 1.4296\n",
      "Epoch 1088/5000\n",
      "572/572 [==============================] - 0s 764us/step - loss: 0.8689 - val_loss: 1.4334\n",
      "Epoch 1089/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8690 - val_loss: 1.4253\n",
      "Epoch 1090/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8583 - val_loss: 1.4216\n",
      "Epoch 1091/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8557 - val_loss: 1.4709\n",
      "Epoch 1092/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8663 - val_loss: 1.4560\n",
      "Epoch 1093/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8604 - val_loss: 1.4311\n",
      "Epoch 1094/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8609 - val_loss: 1.4281\n",
      "Epoch 1095/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8690 - val_loss: 1.4452\n",
      "Epoch 1096/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8679 - val_loss: 1.4517\n",
      "Epoch 1097/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8766 - val_loss: 1.4319\n",
      "Epoch 1098/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8737 - val_loss: 1.4421\n",
      "Epoch 1099/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8582 - val_loss: 1.4380\n",
      "Epoch 1100/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8772 - val_loss: 1.4434\n",
      "Epoch 1101/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8734 - val_loss: 1.4785\n",
      "Epoch 1102/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8614 - val_loss: 1.4570\n",
      "Epoch 1103/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.8709 - val_loss: 1.4297\n",
      "Epoch 1104/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8729 - val_loss: 1.4526\n",
      "Epoch 1105/5000\n",
      "572/572 [==============================] - 0s 692us/step - loss: 0.8718 - val_loss: 1.4246\n",
      "Epoch 1106/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 0.8683 - val_loss: 1.4441\n",
      "Epoch 1107/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8758 - val_loss: 1.4316\n",
      "Epoch 1108/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8608 - val_loss: 1.4479\n",
      "Epoch 1109/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8568 - val_loss: 1.4373\n",
      "Epoch 1110/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8576 - val_loss: 1.4253\n",
      "Epoch 1111/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8453 - val_loss: 1.4283\n",
      "Epoch 1112/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8743 - val_loss: 1.4255\n",
      "Epoch 1113/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8611 - val_loss: 1.4399\n",
      "Epoch 1114/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8478 - val_loss: 1.4227\n",
      "Epoch 1115/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8625 - val_loss: 1.4225\n",
      "Epoch 1116/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8601 - val_loss: 1.4237\n",
      "Epoch 1117/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8497 - val_loss: 1.4287\n",
      "Epoch 1118/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8670 - val_loss: 1.4205\n",
      "Epoch 1119/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8671 - val_loss: 1.4329\n",
      "Epoch 1120/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8585 - val_loss: 1.4577\n",
      "Epoch 1121/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8523 - val_loss: 1.4565\n",
      "Epoch 1122/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8552 - val_loss: 1.4402\n",
      "Epoch 1123/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8649 - val_loss: 1.4326\n",
      "Epoch 1124/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8554 - val_loss: 1.4510\n",
      "Epoch 1125/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8703 - val_loss: 1.4169\n",
      "Epoch 1126/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8716 - val_loss: 1.4130\n",
      "Epoch 1127/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8689 - val_loss: 1.4175\n",
      "Epoch 1128/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8547 - val_loss: 1.4295\n",
      "Epoch 1129/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8537 - val_loss: 1.4211\n",
      "Epoch 1130/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8647 - val_loss: 1.4230\n",
      "Epoch 1131/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8576 - val_loss: 1.4145\n",
      "Epoch 1132/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8614 - val_loss: 1.4042\n",
      "Epoch 1133/5000\n",
      "572/572 [==============================] - 0s 692us/step - loss: 0.8489 - val_loss: 1.4369\n",
      "Epoch 1134/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8760 - val_loss: 1.4180\n",
      "Epoch 1135/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8571 - val_loss: 1.4164\n",
      "Epoch 1136/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8588 - val_loss: 1.4141\n",
      "Epoch 1137/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8741 - val_loss: 1.4109\n",
      "Epoch 1138/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8678 - val_loss: 1.4363\n",
      "Epoch 1139/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8497 - val_loss: 1.4269\n",
      "Epoch 1140/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8689 - val_loss: 1.4397\n",
      "Epoch 1141/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8595 - val_loss: 1.4219\n",
      "Epoch 1142/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8560 - val_loss: 1.4356\n",
      "Epoch 1143/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8739 - val_loss: 1.4371\n",
      "Epoch 1144/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8611 - val_loss: 1.4298\n",
      "Epoch 1145/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8584 - val_loss: 1.4420\n",
      "Epoch 1146/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8648 - val_loss: 1.4389\n",
      "Epoch 1147/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8675 - val_loss: 1.4306\n",
      "Epoch 1148/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8559 - val_loss: 1.4213\n",
      "Epoch 1149/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8651 - val_loss: 1.4433\n",
      "Epoch 1150/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8649 - val_loss: 1.4176\n",
      "Epoch 1151/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8769 - val_loss: 1.4464\n",
      "Epoch 1152/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8706 - val_loss: 1.4383\n",
      "Epoch 1153/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8680 - val_loss: 1.4398\n",
      "Epoch 1154/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 652us/step - loss: 0.8550 - val_loss: 1.4333\n",
      "Epoch 1155/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8533 - val_loss: 1.4216\n",
      "Epoch 1156/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8579 - val_loss: 1.4154\n",
      "Epoch 1157/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.8598 - val_loss: 1.4467\n",
      "Epoch 1158/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8719 - val_loss: 1.4220\n",
      "Epoch 1159/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8527 - val_loss: 1.4192\n",
      "Epoch 1160/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8558 - val_loss: 1.4249\n",
      "Epoch 1161/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8628 - val_loss: 1.4413\n",
      "Epoch 1162/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8533 - val_loss: 1.4313\n",
      "Epoch 1163/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8553 - val_loss: 1.4317\n",
      "Epoch 1164/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.8500 - val_loss: 1.4290\n",
      "Epoch 1165/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8563 - val_loss: 1.4470\n",
      "Epoch 1166/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8641 - val_loss: 1.4329\n",
      "Epoch 1167/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8551 - val_loss: 1.4299\n",
      "Epoch 1168/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8527 - val_loss: 1.4282\n",
      "Epoch 1169/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.8597 - val_loss: 1.4351\n",
      "Epoch 1170/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8548 - val_loss: 1.4557\n",
      "Epoch 1171/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8788 - val_loss: 1.4527\n",
      "Epoch 1172/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.8608 - val_loss: 1.4455\n",
      "Epoch 1173/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 0.8605 - val_loss: 1.4159\n",
      "Epoch 1174/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.8606 - val_loss: 1.4347\n",
      "Epoch 1175/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8521 - val_loss: 1.4352\n",
      "Epoch 1176/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8521 - val_loss: 1.4306\n",
      "Epoch 1177/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8614 - val_loss: 1.4213\n",
      "Epoch 1178/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8652 - val_loss: 1.4199\n",
      "Epoch 1179/5000\n",
      "572/572 [==============================] - 0s 621us/step - loss: 0.8676 - val_loss: 1.4105\n",
      "Epoch 1180/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8700 - val_loss: 1.4323\n",
      "Epoch 1181/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8514 - val_loss: 1.4361\n",
      "Epoch 1182/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8537 - val_loss: 1.4358\n",
      "Epoch 1183/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8638 - val_loss: 1.4605\n",
      "Epoch 1184/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.8686 - val_loss: 1.4845\n",
      "Epoch 1185/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8571 - val_loss: 1.4316\n",
      "Epoch 1186/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8556 - val_loss: 1.4125\n",
      "Epoch 1187/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8595 - val_loss: 1.4319\n",
      "Epoch 1188/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.8768 - val_loss: 1.4330\n",
      "Epoch 1189/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8617 - val_loss: 1.4249\n",
      "Epoch 1190/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8621 - val_loss: 1.4543\n",
      "Epoch 1191/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8710 - val_loss: 1.4325\n",
      "Epoch 1192/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8515 - val_loss: 1.4354\n",
      "Epoch 1193/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8694 - val_loss: 1.4449\n",
      "Epoch 1194/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8834 - val_loss: 1.4340\n",
      "Epoch 1195/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8577 - val_loss: 1.4395\n",
      "Epoch 1196/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8552 - val_loss: 1.4193\n",
      "Epoch 1197/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8624 - val_loss: 1.4126\n",
      "Epoch 1198/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8543 - val_loss: 1.4177\n",
      "Epoch 1199/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8728 - val_loss: 1.4265\n",
      "Epoch 1200/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8638 - val_loss: 1.4363\n",
      "Epoch 1201/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8486 - val_loss: 1.4081\n",
      "Epoch 1202/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8695 - val_loss: 1.4147\n",
      "Epoch 1203/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8614 - val_loss: 1.4435\n",
      "Epoch 1204/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8595 - val_loss: 1.4169\n",
      "Epoch 1205/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8564 - val_loss: 1.4228\n",
      "Epoch 1206/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8578 - val_loss: 1.4383\n",
      "Epoch 1207/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8461 - val_loss: 1.4720\n",
      "Epoch 1208/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.8444 - val_loss: 1.4399\n",
      "Epoch 1209/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8519 - val_loss: 1.4572\n",
      "Epoch 1210/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8491 - val_loss: 1.4457\n",
      "Epoch 1211/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8505 - val_loss: 1.4591\n",
      "Epoch 1212/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8588 - val_loss: 1.4427\n",
      "Epoch 1213/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8652 - val_loss: 1.4218\n",
      "Epoch 1214/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8608 - val_loss: 1.4165\n",
      "Epoch 1215/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8742 - val_loss: 1.4009\n",
      "Epoch 1216/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8688 - val_loss: 1.4411\n",
      "Epoch 1217/5000\n",
      "572/572 [==============================] - 0s 616us/step - loss: 0.8547 - val_loss: 1.4744\n",
      "Epoch 1218/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.8503 - val_loss: 1.4387\n",
      "Epoch 1219/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8629 - val_loss: 1.4536\n",
      "Epoch 1220/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8733 - val_loss: 1.4755\n",
      "Epoch 1221/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8656 - val_loss: 1.4693\n",
      "Epoch 1222/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8474 - val_loss: 1.4467\n",
      "Epoch 1223/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8563 - val_loss: 1.4236\n",
      "Epoch 1224/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8546 - val_loss: 1.4475\n",
      "Epoch 1225/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8507 - val_loss: 1.4519\n",
      "Epoch 1226/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8384 - val_loss: 1.4550\n",
      "Epoch 1227/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8732 - val_loss: 1.4212\n",
      "Epoch 1228/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8478 - val_loss: 1.4274\n",
      "Epoch 1229/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8754 - val_loss: 1.4327\n",
      "Epoch 1230/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 654us/step - loss: 0.8531 - val_loss: 1.4368\n",
      "Epoch 1231/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8653 - val_loss: 1.5066\n",
      "Epoch 1232/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8632 - val_loss: 1.4529\n",
      "Epoch 1233/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8602 - val_loss: 1.4348\n",
      "Epoch 1234/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8575 - val_loss: 1.4173\n",
      "Epoch 1235/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8518 - val_loss: 1.4112\n",
      "Epoch 1236/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8566 - val_loss: 1.4257\n",
      "Epoch 1237/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8465 - val_loss: 1.4443\n",
      "Epoch 1238/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8672 - val_loss: 1.4267\n",
      "Epoch 1239/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.8494 - val_loss: 1.4169\n",
      "Epoch 1240/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8592 - val_loss: 1.4383\n",
      "Epoch 1241/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8662 - val_loss: 1.4279\n",
      "Epoch 1242/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8625 - val_loss: 1.4412\n",
      "Epoch 1243/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8678 - val_loss: 1.4361\n",
      "Epoch 1244/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8482 - val_loss: 1.4327\n",
      "Epoch 1245/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8603 - val_loss: 1.4009\n",
      "Epoch 1246/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8507 - val_loss: 1.4094\n",
      "Epoch 1247/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8496 - val_loss: 1.4072\n",
      "Epoch 1248/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8492 - val_loss: 1.4171\n",
      "Epoch 1249/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8513 - val_loss: 1.4280\n",
      "Epoch 1250/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8603 - val_loss: 1.4519\n",
      "Epoch 1251/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8637 - val_loss: 1.4333\n",
      "Epoch 1252/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8616 - val_loss: 1.4319\n",
      "Epoch 1253/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8664 - val_loss: 1.4405\n",
      "Epoch 1254/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8624 - val_loss: 1.4442\n",
      "Epoch 1255/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8453 - val_loss: 1.4167\n",
      "Epoch 1256/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8582 - val_loss: 1.4429\n",
      "Epoch 1257/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8469 - val_loss: 1.4337\n",
      "Epoch 1258/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8574 - val_loss: 1.4336\n",
      "Epoch 1259/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8557 - val_loss: 1.4663\n",
      "Epoch 1260/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8602 - val_loss: 1.4246\n",
      "Epoch 1261/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8604 - val_loss: 1.4531\n",
      "Epoch 1262/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8562 - val_loss: 1.4619\n",
      "Epoch 1263/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8626 - val_loss: 1.4548\n",
      "Epoch 1264/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8521 - val_loss: 1.4964\n",
      "Epoch 1265/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8512 - val_loss: 1.4832\n",
      "Epoch 1266/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8636 - val_loss: 1.4525\n",
      "Epoch 1267/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8463 - val_loss: 1.4412\n",
      "Epoch 1268/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8585 - val_loss: 1.4276\n",
      "Epoch 1269/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8531 - val_loss: 1.4272\n",
      "Epoch 1270/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8550 - val_loss: 1.4331\n",
      "Epoch 1271/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8423 - val_loss: 1.4163\n",
      "Epoch 1272/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8563 - val_loss: 1.4176\n",
      "Epoch 1273/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8440 - val_loss: 1.4265\n",
      "Epoch 1274/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8592 - val_loss: 1.4184\n",
      "Epoch 1275/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8439 - val_loss: 1.4337\n",
      "Epoch 1276/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8498 - val_loss: 1.4458\n",
      "Epoch 1277/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8555 - val_loss: 1.4175\n",
      "Epoch 1278/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8615 - val_loss: 1.4206\n",
      "Epoch 1279/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8570 - val_loss: 1.4295\n",
      "Epoch 1280/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8597 - val_loss: 1.4236\n",
      "Epoch 1281/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8474 - val_loss: 1.4513\n",
      "Epoch 1282/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8633 - val_loss: 1.4905\n",
      "Epoch 1283/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8494 - val_loss: 1.4477\n",
      "Epoch 1284/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8543 - val_loss: 1.4562\n",
      "Epoch 1285/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8524 - val_loss: 1.4249\n",
      "Epoch 1286/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8570 - val_loss: 1.4361\n",
      "Epoch 1287/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8626 - val_loss: 1.4479\n",
      "Epoch 1288/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8413 - val_loss: 1.4370\n",
      "Epoch 1289/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.8574 - val_loss: 1.4779\n",
      "Epoch 1290/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8532 - val_loss: 1.4714\n",
      "Epoch 1291/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8588 - val_loss: 1.4572\n",
      "Epoch 1292/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8421 - val_loss: 1.4091\n",
      "Epoch 1293/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8606 - val_loss: 1.4297\n",
      "Epoch 1294/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8602 - val_loss: 1.4547\n",
      "Epoch 1295/5000\n",
      "572/572 [==============================] - 0s 620us/step - loss: 0.8630 - val_loss: 1.4238\n",
      "Epoch 1296/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8469 - val_loss: 1.4231\n",
      "Epoch 1297/5000\n",
      "572/572 [==============================] - 0s 691us/step - loss: 0.8521 - val_loss: 1.4073\n",
      "Epoch 1298/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8410 - val_loss: 1.4238\n",
      "Epoch 1299/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8624 - val_loss: 1.4714\n",
      "Epoch 1300/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8543 - val_loss: 1.4836\n",
      "Epoch 1301/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8572 - val_loss: 1.4193\n",
      "Epoch 1302/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8570 - val_loss: 1.4150\n",
      "Epoch 1303/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8486 - val_loss: 1.4138\n",
      "Epoch 1304/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8426 - val_loss: 1.4286\n",
      "Epoch 1305/5000\n",
      "572/572 [==============================] - 0s 620us/step - loss: 0.8649 - val_loss: 1.4162\n",
      "Epoch 1306/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 640us/step - loss: 0.8747 - val_loss: 1.4555\n",
      "Epoch 1307/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8351 - val_loss: 1.4336\n",
      "Epoch 1308/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8564 - val_loss: 1.4503\n",
      "Epoch 1309/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8698 - val_loss: 1.4471\n",
      "Epoch 1310/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8699 - val_loss: 1.4125\n",
      "Epoch 1311/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8573 - val_loss: 1.4265\n",
      "Epoch 1312/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8519 - val_loss: 1.4296\n",
      "Epoch 1313/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8524 - val_loss: 1.4356\n",
      "Epoch 1314/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8478 - val_loss: 1.4627\n",
      "Epoch 1315/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 0.8413 - val_loss: 1.4384\n",
      "Epoch 1316/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.8643 - val_loss: 1.4060\n",
      "Epoch 1317/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8605 - val_loss: 1.3973\n",
      "Epoch 1318/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8596 - val_loss: 1.4243\n",
      "Epoch 1319/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8706 - val_loss: 1.4364\n",
      "Epoch 1320/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8492 - val_loss: 1.4013\n",
      "Epoch 1321/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8521 - val_loss: 1.4150\n",
      "Epoch 1322/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8738 - val_loss: 1.4219\n",
      "Epoch 1323/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8570 - val_loss: 1.4199\n",
      "Epoch 1324/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8622 - val_loss: 1.4162\n",
      "Epoch 1325/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8478 - val_loss: 1.4229\n",
      "Epoch 1326/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8554 - val_loss: 1.4237\n",
      "Epoch 1327/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8389 - val_loss: 1.4245\n",
      "Epoch 1328/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8573 - val_loss: 1.4661\n",
      "Epoch 1329/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8450 - val_loss: 1.4723\n",
      "Epoch 1330/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8544 - val_loss: 1.4125\n",
      "Epoch 1331/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8496 - val_loss: 1.4139\n",
      "Epoch 1332/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8431 - val_loss: 1.4133\n",
      "Epoch 1333/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8375 - val_loss: 1.4478\n",
      "Epoch 1334/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8492 - val_loss: 1.4962\n",
      "Epoch 1335/5000\n",
      "572/572 [==============================] - 0s 618us/step - loss: 0.8533 - val_loss: 1.4384\n",
      "Epoch 1336/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8490 - val_loss: 1.4266\n",
      "Epoch 1337/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8489 - val_loss: 1.4203\n",
      "Epoch 1338/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8549 - val_loss: 1.4225\n",
      "Epoch 1339/5000\n",
      "572/572 [==============================] - 0s 621us/step - loss: 0.8583 - val_loss: 1.4504\n",
      "Epoch 1340/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8415 - val_loss: 1.4921\n",
      "Epoch 1341/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8466 - val_loss: 1.4449\n",
      "Epoch 1342/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8715 - val_loss: 1.4291\n",
      "Epoch 1343/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8562 - val_loss: 1.4910\n",
      "Epoch 1344/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8548 - val_loss: 1.4224\n",
      "Epoch 1345/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8425 - val_loss: 1.4614\n",
      "Epoch 1346/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8636 - val_loss: 1.4235\n",
      "Epoch 1347/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8474 - val_loss: 1.4354\n",
      "Epoch 1348/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8701 - val_loss: 1.4687\n",
      "Epoch 1349/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8565 - val_loss: 1.4359\n",
      "Epoch 1350/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8614 - val_loss: 1.4329\n",
      "Epoch 1351/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8475 - val_loss: 1.4369\n",
      "Epoch 1352/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8624 - val_loss: 1.4384\n",
      "Epoch 1353/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8402 - val_loss: 1.4248\n",
      "Epoch 1354/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8372 - val_loss: 1.4374\n",
      "Epoch 1355/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8527 - val_loss: 1.4361\n",
      "Epoch 1356/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8545 - val_loss: 1.4855\n",
      "Epoch 1357/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8802 - val_loss: 1.4889\n",
      "Epoch 1358/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8418 - val_loss: 1.4623\n",
      "Epoch 1359/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.8597 - val_loss: 1.4383\n",
      "Epoch 1360/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8452 - val_loss: 1.4299\n",
      "Epoch 1361/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8585 - val_loss: 1.4150\n",
      "Epoch 1362/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8609 - val_loss: 1.4302\n",
      "Epoch 1363/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8582 - val_loss: 1.4265\n",
      "Epoch 1364/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8432 - val_loss: 1.4070\n",
      "Epoch 1365/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8493 - val_loss: 1.4246\n",
      "Epoch 1366/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8503 - val_loss: 1.4248\n",
      "Epoch 1367/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8564 - val_loss: 1.4196\n",
      "Epoch 1368/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8467 - val_loss: 1.4222\n",
      "Epoch 1369/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8567 - val_loss: 1.4198\n",
      "Epoch 1370/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8628 - val_loss: 1.4331\n",
      "Epoch 1371/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8496 - val_loss: 1.4508\n",
      "Epoch 1372/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8499 - val_loss: 1.4636\n",
      "Epoch 1373/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8532 - val_loss: 1.4445\n",
      "Epoch 1374/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8557 - val_loss: 1.4344\n",
      "Epoch 1375/5000\n",
      "572/572 [==============================] - 0s 687us/step - loss: 0.8485 - val_loss: 1.4400\n",
      "Epoch 1376/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8392 - val_loss: 1.4303\n",
      "Epoch 1377/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8585 - val_loss: 1.4072\n",
      "Epoch 1378/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8495 - val_loss: 1.4008\n",
      "Epoch 1379/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8468 - val_loss: 1.4116\n",
      "Epoch 1380/5000\n",
      "572/572 [==============================] - 0s 689us/step - loss: 0.8573 - val_loss: 1.4089\n",
      "Epoch 1381/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8444 - val_loss: 1.4130\n",
      "Epoch 1382/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 650us/step - loss: 0.8464 - val_loss: 1.4115\n",
      "Epoch 1383/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8410 - val_loss: 1.4790\n",
      "Epoch 1384/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.8561 - val_loss: 1.4877\n",
      "Epoch 1385/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8491 - val_loss: 1.4713\n",
      "Epoch 1386/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8452 - val_loss: 1.4204\n",
      "Epoch 1387/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8509 - val_loss: 1.4149\n",
      "Epoch 1388/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8578 - val_loss: 1.4284\n",
      "Epoch 1389/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8436 - val_loss: 1.4162\n",
      "Epoch 1390/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8445 - val_loss: 1.4378\n",
      "Epoch 1391/5000\n",
      "572/572 [==============================] - 0s 618us/step - loss: 0.8455 - val_loss: 1.4222\n",
      "Epoch 1392/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8442 - val_loss: 1.4651\n",
      "Epoch 1393/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8477 - val_loss: 1.4370\n",
      "Epoch 1394/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8351 - val_loss: 1.4269\n",
      "Epoch 1395/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8499 - val_loss: 1.4496\n",
      "Epoch 1396/5000\n",
      "572/572 [==============================] - 0s 688us/step - loss: 0.8447 - val_loss: 1.4688\n",
      "Epoch 1397/5000\n",
      "572/572 [==============================] - 0s 615us/step - loss: 0.8561 - val_loss: 1.4270\n",
      "Epoch 1398/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8484 - val_loss: 1.4292\n",
      "Epoch 1399/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8425 - val_loss: 1.4174\n",
      "Epoch 1400/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8640 - val_loss: 1.4161\n",
      "Epoch 1401/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8634 - val_loss: 1.4108\n",
      "Epoch 1402/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8442 - val_loss: 1.4132\n",
      "Epoch 1403/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8674 - val_loss: 1.4010\n",
      "Epoch 1404/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8586 - val_loss: 1.4141\n",
      "Epoch 1405/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8525 - val_loss: 1.4123\n",
      "Epoch 1406/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8424 - val_loss: 1.4175\n",
      "Epoch 1407/5000\n",
      "572/572 [==============================] - 0s 613us/step - loss: 0.8488 - val_loss: 1.4326\n",
      "Epoch 1408/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8337 - val_loss: 1.4485\n",
      "Epoch 1409/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8564 - val_loss: 1.4116\n",
      "Epoch 1410/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8522 - val_loss: 1.4135\n",
      "Epoch 1411/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8504 - val_loss: 1.4284\n",
      "Epoch 1412/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8430 - val_loss: 1.4617\n",
      "Epoch 1413/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8558 - val_loss: 1.4043\n",
      "Epoch 1414/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8497 - val_loss: 1.4333\n",
      "Epoch 1415/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8444 - val_loss: 1.4442\n",
      "Epoch 1416/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8586 - val_loss: 1.4195\n",
      "Epoch 1417/5000\n",
      "572/572 [==============================] - 0s 622us/step - loss: 0.8526 - val_loss: 1.4450\n",
      "Epoch 1418/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8478 - val_loss: 1.4217\n",
      "Epoch 1419/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8490 - val_loss: 1.4192\n",
      "Epoch 1420/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8748 - val_loss: 1.4354\n",
      "Epoch 1421/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8467 - val_loss: 1.4305\n",
      "Epoch 1422/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.8499 - val_loss: 1.4354\n",
      "Epoch 1423/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8560 - val_loss: 1.4492\n",
      "Epoch 1424/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8390 - val_loss: 1.4510\n",
      "Epoch 1425/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8556 - val_loss: 1.4746\n",
      "Epoch 1426/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.8497 - val_loss: 1.4577\n",
      "Epoch 1427/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8486 - val_loss: 1.4802\n",
      "Epoch 1428/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.8574 - val_loss: 1.4255\n",
      "Epoch 1429/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8425 - val_loss: 1.4511\n",
      "Epoch 1430/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8494 - val_loss: 1.4424\n",
      "Epoch 1431/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8572 - val_loss: 1.4426\n",
      "Epoch 1432/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8321 - val_loss: 1.4291\n",
      "Epoch 1433/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8381 - val_loss: 1.4312\n",
      "Epoch 1434/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8629 - val_loss: 1.4361\n",
      "Epoch 1435/5000\n",
      "572/572 [==============================] - 0s 607us/step - loss: 0.8460 - val_loss: 1.4031\n",
      "Epoch 1436/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8415 - val_loss: 1.4427\n",
      "Epoch 1437/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8317 - val_loss: 1.4298\n",
      "Epoch 1438/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8507 - val_loss: 1.4564\n",
      "Epoch 1439/5000\n",
      "572/572 [==============================] - 0s 693us/step - loss: 0.8559 - val_loss: 1.4565\n",
      "Epoch 1440/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8595 - val_loss: 1.4817\n",
      "Epoch 1441/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8444 - val_loss: 1.4356\n",
      "Epoch 1442/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8701 - val_loss: 1.4794\n",
      "Epoch 1443/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8404 - val_loss: 1.4396\n",
      "Epoch 1444/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8421 - val_loss: 1.4261\n",
      "Epoch 1445/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8459 - val_loss: 1.4052\n",
      "Epoch 1446/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8518 - val_loss: 1.4481\n",
      "Epoch 1447/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8452 - val_loss: 1.4174\n",
      "Epoch 1448/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8423 - val_loss: 1.4423\n",
      "Epoch 1449/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8442 - val_loss: 1.4551\n",
      "Epoch 1450/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8517 - val_loss: 1.4254\n",
      "Epoch 1451/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8464 - val_loss: 1.4131\n",
      "Epoch 1452/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8465 - val_loss: 1.4224\n",
      "Epoch 1453/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8323 - val_loss: 1.4185\n",
      "Epoch 1454/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8533 - val_loss: 1.4241\n",
      "Epoch 1455/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8702 - val_loss: 1.4468\n",
      "Epoch 1456/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8460 - val_loss: 1.4161\n",
      "Epoch 1457/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8384 - val_loss: 1.4505\n",
      "Epoch 1458/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 670us/step - loss: 0.8493 - val_loss: 1.4304\n",
      "Epoch 1459/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8437 - val_loss: 1.4531\n",
      "Epoch 1460/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8479 - val_loss: 1.4461\n",
      "Epoch 1461/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8434 - val_loss: 1.4453\n",
      "Epoch 1462/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8366 - val_loss: 1.4384\n",
      "Epoch 1463/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8571 - val_loss: 1.4349\n",
      "Epoch 1464/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8406 - val_loss: 1.4584\n",
      "Epoch 1465/5000\n",
      "572/572 [==============================] - 0s 691us/step - loss: 0.8602 - val_loss: 1.4754\n",
      "Epoch 1466/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8469 - val_loss: 1.4118\n",
      "Epoch 1467/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8454 - val_loss: 1.4082\n",
      "Epoch 1468/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8431 - val_loss: 1.4045\n",
      "Epoch 1469/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8603 - val_loss: 1.4748\n",
      "Epoch 1470/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8467 - val_loss: 1.4105\n",
      "Epoch 1471/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8636 - val_loss: 1.4145\n",
      "Epoch 1472/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8508 - val_loss: 1.4174\n",
      "Epoch 1473/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8460 - val_loss: 1.4155\n",
      "Epoch 1474/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8553 - val_loss: 1.4384\n",
      "Epoch 1475/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8525 - val_loss: 1.4404\n",
      "Epoch 1476/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8479 - val_loss: 1.4410\n",
      "Epoch 1477/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8598 - val_loss: 1.4091\n",
      "Epoch 1478/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8433 - val_loss: 1.4194\n",
      "Epoch 1479/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8486 - val_loss: 1.4491\n",
      "Epoch 1480/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8461 - val_loss: 1.4487\n",
      "Epoch 1481/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8552 - val_loss: 1.4425\n",
      "Epoch 1482/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8494 - val_loss: 1.4636\n",
      "Epoch 1483/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8350 - val_loss: 1.4283\n",
      "Epoch 1484/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8461 - val_loss: 1.4495\n",
      "Epoch 1485/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8277 - val_loss: 1.4466\n",
      "Epoch 1486/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8519 - val_loss: 1.4235\n",
      "Epoch 1487/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8337 - val_loss: 1.4542\n",
      "Epoch 1488/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8487 - val_loss: 1.4610\n",
      "Epoch 1489/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8352 - val_loss: 1.4486\n",
      "Epoch 1490/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8677 - val_loss: 1.4540\n",
      "Epoch 1491/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8500 - val_loss: 1.4441\n",
      "Epoch 1492/5000\n",
      "572/572 [==============================] - 0s 620us/step - loss: 0.8480 - val_loss: 1.4246\n",
      "Epoch 1493/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8466 - val_loss: 1.4408\n",
      "Epoch 1494/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8305 - val_loss: 1.4334\n",
      "Epoch 1495/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8463 - val_loss: 1.4151\n",
      "Epoch 1496/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8582 - val_loss: 1.4464\n",
      "Epoch 1497/5000\n",
      "572/572 [==============================] - 0s 615us/step - loss: 0.8531 - val_loss: 1.4352\n",
      "Epoch 1498/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.8373 - val_loss: 1.4355\n",
      "Epoch 1499/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8455 - val_loss: 1.4066\n",
      "Epoch 1500/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8552 - val_loss: 1.4219\n",
      "Epoch 1501/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8631 - val_loss: 1.4263\n",
      "Epoch 1502/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8493 - val_loss: 1.4062\n",
      "Epoch 1503/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8520 - val_loss: 1.4412\n",
      "Epoch 1504/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8613 - val_loss: 1.4139\n",
      "Epoch 1505/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8446 - val_loss: 1.4522\n",
      "Epoch 1506/5000\n",
      "572/572 [==============================] - 0s 687us/step - loss: 0.8314 - val_loss: 1.4388\n",
      "Epoch 1507/5000\n",
      "572/572 [==============================] - 0s 619us/step - loss: 0.8507 - val_loss: 1.4305\n",
      "Epoch 1508/5000\n",
      "572/572 [==============================] - 0s 620us/step - loss: 0.8394 - val_loss: 1.4131\n",
      "Epoch 1509/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8363 - val_loss: 1.4215\n",
      "Epoch 1510/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8466 - val_loss: 1.4283\n",
      "Epoch 1511/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8444 - val_loss: 1.4249\n",
      "Epoch 1512/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8406 - val_loss: 1.4262\n",
      "Epoch 1513/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8587 - val_loss: 1.4264\n",
      "Epoch 1514/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8444 - val_loss: 1.4343\n",
      "Epoch 1515/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8545 - val_loss: 1.4136\n",
      "Epoch 1516/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8410 - val_loss: 1.4388\n",
      "Epoch 1517/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8465 - val_loss: 1.4567\n",
      "Epoch 1518/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8537 - val_loss: 1.4242\n",
      "Epoch 1519/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8305 - val_loss: 1.4549\n",
      "Epoch 1520/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8371 - val_loss: 1.5079\n",
      "Epoch 1521/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8451 - val_loss: 1.4986\n",
      "Epoch 1522/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8474 - val_loss: 1.4674\n",
      "Epoch 1523/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8461 - val_loss: 1.4146\n",
      "Epoch 1524/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8585 - val_loss: 1.4124\n",
      "Epoch 1525/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8494 - val_loss: 1.4100\n",
      "Epoch 1526/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8484 - val_loss: 1.4187\n",
      "Epoch 1527/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8455 - val_loss: 1.4209\n",
      "Epoch 1528/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8415 - val_loss: 1.4234\n",
      "Epoch 1529/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8662 - val_loss: 1.4519\n",
      "Epoch 1530/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8466 - val_loss: 1.4197\n",
      "Epoch 1531/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8436 - val_loss: 1.4592\n",
      "Epoch 1532/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8400 - val_loss: 1.4301\n",
      "Epoch 1533/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8495 - val_loss: 1.4296\n",
      "Epoch 1534/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 651us/step - loss: 0.8431 - val_loss: 1.4485\n",
      "Epoch 1535/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8495 - val_loss: 1.4215\n",
      "Epoch 1536/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8394 - val_loss: 1.4280\n",
      "Epoch 1537/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8351 - val_loss: 1.4100\n",
      "Epoch 1538/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8465 - val_loss: 1.4453\n",
      "Epoch 1539/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.8296 - val_loss: 1.4005\n",
      "Epoch 1540/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8521 - val_loss: 1.4016\n",
      "Epoch 1541/5000\n",
      "572/572 [==============================] - 0s 619us/step - loss: 0.8377 - val_loss: 1.3891\n",
      "Epoch 1542/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8348 - val_loss: 1.4097\n",
      "Epoch 1543/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8419 - val_loss: 1.4294\n",
      "Epoch 1544/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8575 - val_loss: 1.4804\n",
      "Epoch 1545/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8284 - val_loss: 1.4575\n",
      "Epoch 1546/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8368 - val_loss: 1.4469\n",
      "Epoch 1547/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8396 - val_loss: 1.4436\n",
      "Epoch 1548/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8319 - val_loss: 1.4405\n",
      "Epoch 1549/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8444 - val_loss: 1.4429\n",
      "Epoch 1550/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8414 - val_loss: 1.4204\n",
      "Epoch 1551/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8405 - val_loss: 1.4466\n",
      "Epoch 1552/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8475 - val_loss: 1.4238\n",
      "Epoch 1553/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8381 - val_loss: 1.4055\n",
      "Epoch 1554/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8457 - val_loss: 1.4051\n",
      "Epoch 1555/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8400 - val_loss: 1.4077\n",
      "Epoch 1556/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8443 - val_loss: 1.4570\n",
      "Epoch 1557/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8494 - val_loss: 1.4307\n",
      "Epoch 1558/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8364 - val_loss: 1.4475\n",
      "Epoch 1559/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8533 - val_loss: 1.4310\n",
      "Epoch 1560/5000\n",
      "572/572 [==============================] - 0s 817us/step - loss: 0.8425 - val_loss: 1.4111\n",
      "Epoch 1561/5000\n",
      "572/572 [==============================] - 0s 811us/step - loss: 0.8392 - val_loss: 1.3919\n",
      "Epoch 1562/5000\n",
      "572/572 [==============================] - 0s 870us/step - loss: 0.8490 - val_loss: 1.4244\n",
      "Epoch 1563/5000\n",
      "572/572 [==============================] - 0s 785us/step - loss: 0.8404 - val_loss: 1.4390\n",
      "Epoch 1564/5000\n",
      "572/572 [==============================] - 0s 756us/step - loss: 0.8572 - val_loss: 1.4744\n",
      "Epoch 1565/5000\n",
      "572/572 [==============================] - 0s 791us/step - loss: 0.8529 - val_loss: 1.4270\n",
      "Epoch 1566/5000\n",
      "572/572 [==============================] - 0s 714us/step - loss: 0.8342 - val_loss: 1.4385\n",
      "Epoch 1567/5000\n",
      "572/572 [==============================] - 0s 709us/step - loss: 0.8390 - val_loss: 1.4200\n",
      "Epoch 1568/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8572 - val_loss: 1.4413\n",
      "Epoch 1569/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8487 - val_loss: 1.5009\n",
      "Epoch 1570/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8519 - val_loss: 1.4651\n",
      "Epoch 1571/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8354 - val_loss: 1.4459\n",
      "Epoch 1572/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8369 - val_loss: 1.4666\n",
      "Epoch 1573/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8430 - val_loss: 1.4769\n",
      "Epoch 1574/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8426 - val_loss: 1.4745\n",
      "Epoch 1575/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8399 - val_loss: 1.4588\n",
      "Epoch 1576/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8262 - val_loss: 1.4241\n",
      "Epoch 1577/5000\n",
      "572/572 [==============================] - 0s 689us/step - loss: 0.8516 - val_loss: 1.4202\n",
      "Epoch 1578/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8463 - val_loss: 1.4372\n",
      "Epoch 1579/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8408 - val_loss: 1.4196\n",
      "Epoch 1580/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8298 - val_loss: 1.4358\n",
      "Epoch 1581/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8639 - val_loss: 1.4141\n",
      "Epoch 1582/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8444 - val_loss: 1.4071\n",
      "Epoch 1583/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8557 - val_loss: 1.4034\n",
      "Epoch 1584/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8488 - val_loss: 1.4372\n",
      "Epoch 1585/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8469 - val_loss: 1.4357\n",
      "Epoch 1586/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8489 - val_loss: 1.4658\n",
      "Epoch 1587/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8382 - val_loss: 1.4265\n",
      "Epoch 1588/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.8487 - val_loss: 1.4434\n",
      "Epoch 1589/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8476 - val_loss: 1.4124\n",
      "Epoch 1590/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 0.8472 - val_loss: 1.4263\n",
      "Epoch 1591/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8632 - val_loss: 1.4046\n",
      "Epoch 1592/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8389 - val_loss: 1.4226\n",
      "Epoch 1593/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8695 - val_loss: 1.4287\n",
      "Epoch 1594/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8323 - val_loss: 1.4069\n",
      "Epoch 1595/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8508 - val_loss: 1.4449\n",
      "Epoch 1596/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8431 - val_loss: 1.4103\n",
      "Epoch 1597/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8374 - val_loss: 1.4107\n",
      "Epoch 1598/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8220 - val_loss: 1.4534\n",
      "Epoch 1599/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8375 - val_loss: 1.4313\n",
      "Epoch 1600/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8460 - val_loss: 1.4642\n",
      "Epoch 1601/5000\n",
      "572/572 [==============================] - 0s 617us/step - loss: 0.8447 - val_loss: 1.4445\n",
      "Epoch 1602/5000\n",
      "572/572 [==============================] - 0s 688us/step - loss: 0.8407 - val_loss: 1.4447\n",
      "Epoch 1603/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8420 - val_loss: 1.4600\n",
      "Epoch 1604/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8231 - val_loss: 1.4606\n",
      "Epoch 1605/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8362 - val_loss: 1.4268\n",
      "Epoch 1606/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8460 - val_loss: 1.4343\n",
      "Epoch 1607/5000\n",
      "572/572 [==============================] - 0s 698us/step - loss: 0.8430 - val_loss: 1.4088\n",
      "Epoch 1608/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8413 - val_loss: 1.4440\n",
      "Epoch 1609/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8348 - val_loss: 1.3960\n",
      "Epoch 1610/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 691us/step - loss: 0.8442 - val_loss: 1.4353\n",
      "Epoch 1611/5000\n",
      "572/572 [==============================] - 0s 719us/step - loss: 0.8393 - val_loss: 1.4135\n",
      "Epoch 1612/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8317 - val_loss: 1.4076\n",
      "Epoch 1613/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8435 - val_loss: 1.4208\n",
      "Epoch 1614/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8445 - val_loss: 1.4483\n",
      "Epoch 1615/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8488 - val_loss: 1.4100\n",
      "Epoch 1616/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8332 - val_loss: 1.4267\n",
      "Epoch 1617/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8421 - val_loss: 1.4279\n",
      "Epoch 1618/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8361 - val_loss: 1.4446\n",
      "Epoch 1619/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8373 - val_loss: 1.4558\n",
      "Epoch 1620/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8463 - val_loss: 1.4419\n",
      "Epoch 1621/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8401 - val_loss: 1.4271\n",
      "Epoch 1622/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8451 - val_loss: 1.4175\n",
      "Epoch 1623/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8390 - val_loss: 1.4178\n",
      "Epoch 1624/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8373 - val_loss: 1.4281\n",
      "Epoch 1625/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8332 - val_loss: 1.4496\n",
      "Epoch 1626/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8541 - val_loss: 1.4733\n",
      "Epoch 1627/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8278 - val_loss: 1.5058\n",
      "Epoch 1628/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.8313 - val_loss: 1.4500\n",
      "Epoch 1629/5000\n",
      "572/572 [==============================] - 0s 690us/step - loss: 0.8387 - val_loss: 1.4129\n",
      "Epoch 1630/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8436 - val_loss: 1.4609\n",
      "Epoch 1631/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.8405 - val_loss: 1.4345\n",
      "Epoch 1632/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8416 - val_loss: 1.4132\n",
      "Epoch 1633/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8569 - val_loss: 1.4466\n",
      "Epoch 1634/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8438 - val_loss: 1.4409\n",
      "Epoch 1635/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8386 - val_loss: 1.4587\n",
      "Epoch 1636/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8457 - val_loss: 1.4225\n",
      "Epoch 1637/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8422 - val_loss: 1.4217\n",
      "Epoch 1638/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8276 - val_loss: 1.4605\n",
      "Epoch 1639/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8226 - val_loss: 1.4187\n",
      "Epoch 1640/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8429 - val_loss: 1.4445\n",
      "Epoch 1641/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8405 - val_loss: 1.4041\n",
      "Epoch 1642/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8353 - val_loss: 1.4237\n",
      "Epoch 1643/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8247 - val_loss: 1.4385\n",
      "Epoch 1644/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8422 - val_loss: 1.4621\n",
      "Epoch 1645/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8403 - val_loss: 1.4429\n",
      "Epoch 1646/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8597 - val_loss: 1.4374\n",
      "Epoch 1647/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8416 - val_loss: 1.4622\n",
      "Epoch 1648/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8545 - val_loss: 1.4264\n",
      "Epoch 1649/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8444 - val_loss: 1.4703\n",
      "Epoch 1650/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 0.8608 - val_loss: 1.4451\n",
      "Epoch 1651/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8528 - val_loss: 1.5041\n",
      "Epoch 1652/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8559 - val_loss: 1.4326\n",
      "Epoch 1653/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8420 - val_loss: 1.4350\n",
      "Epoch 1654/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8475 - val_loss: 1.5234\n",
      "Epoch 1655/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8445 - val_loss: 1.4405\n",
      "Epoch 1656/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8425 - val_loss: 1.4245\n",
      "Epoch 1657/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8380 - val_loss: 1.4780\n",
      "Epoch 1658/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8435 - val_loss: 1.4254\n",
      "Epoch 1659/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8405 - val_loss: 1.4090\n",
      "Epoch 1660/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8313 - val_loss: 1.4406\n",
      "Epoch 1661/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8432 - val_loss: 1.4554\n",
      "Epoch 1662/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8422 - val_loss: 1.4697\n",
      "Epoch 1663/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.8410 - val_loss: 1.4298\n",
      "Epoch 1664/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8275 - val_loss: 1.4566\n",
      "Epoch 1665/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8448 - val_loss: 1.4142\n",
      "Epoch 1666/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8332 - val_loss: 1.3995\n",
      "Epoch 1667/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8425 - val_loss: 1.4088\n",
      "Epoch 1668/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 0.8407 - val_loss: 1.4432\n",
      "Epoch 1669/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8332 - val_loss: 1.4309\n",
      "Epoch 1670/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 0.8388 - val_loss: 1.4406\n",
      "Epoch 1671/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8527 - val_loss: 1.4374\n",
      "Epoch 1672/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8415 - val_loss: 1.4310\n",
      "Epoch 1673/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8415 - val_loss: 1.4278\n",
      "Epoch 1674/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8362 - val_loss: 1.3975\n",
      "Epoch 1675/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8422 - val_loss: 1.3952\n",
      "Epoch 1676/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8295 - val_loss: 1.4054\n",
      "Epoch 1677/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8385 - val_loss: 1.4174\n",
      "Epoch 1678/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8419 - val_loss: 1.4198\n",
      "Epoch 1679/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8368 - val_loss: 1.4331\n",
      "Epoch 1680/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8389 - val_loss: 1.4192\n",
      "Epoch 1681/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8363 - val_loss: 1.4104\n",
      "Epoch 1682/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8453 - val_loss: 1.4362\n",
      "Epoch 1683/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8409 - val_loss: 1.4277\n",
      "Epoch 1684/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8316 - val_loss: 1.4363\n",
      "Epoch 1685/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8434 - val_loss: 1.4753\n",
      "Epoch 1686/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 626us/step - loss: 0.8309 - val_loss: 1.4514\n",
      "Epoch 1687/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8419 - val_loss: 1.4390\n",
      "Epoch 1688/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8580 - val_loss: 1.4328\n",
      "Epoch 1689/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8427 - val_loss: 1.4570\n",
      "Epoch 1690/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8382 - val_loss: 1.4251\n",
      "Epoch 1691/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8307 - val_loss: 1.4445\n",
      "Epoch 1692/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8411 - val_loss: 1.4752\n",
      "Epoch 1693/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8185 - val_loss: 1.4276\n",
      "Epoch 1694/5000\n",
      "572/572 [==============================] - 0s 611us/step - loss: 0.8368 - val_loss: 1.4281\n",
      "Epoch 1695/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8463 - val_loss: 1.4200\n",
      "Epoch 1696/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8592 - val_loss: 1.4087\n",
      "Epoch 1697/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8593 - val_loss: 1.3908\n",
      "Epoch 1698/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8296 - val_loss: 1.3935\n",
      "Epoch 1699/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8417 - val_loss: 1.4473\n",
      "Epoch 1700/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8381 - val_loss: 1.4393\n",
      "Epoch 1701/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8345 - val_loss: 1.4460\n",
      "Epoch 1702/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8497 - val_loss: 1.4036\n",
      "Epoch 1703/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8375 - val_loss: 1.3983\n",
      "Epoch 1704/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8512 - val_loss: 1.3900\n",
      "Epoch 1705/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8317 - val_loss: 1.4492\n",
      "Epoch 1706/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8374 - val_loss: 1.4076\n",
      "Epoch 1707/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 0.8319 - val_loss: 1.4189\n",
      "Epoch 1708/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8396 - val_loss: 1.4096\n",
      "Epoch 1709/5000\n",
      "572/572 [==============================] - 0s 620us/step - loss: 0.8517 - val_loss: 1.4144\n",
      "Epoch 1710/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8492 - val_loss: 1.4478\n",
      "Epoch 1711/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8308 - val_loss: 1.4505\n",
      "Epoch 1712/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8320 - val_loss: 1.4210\n",
      "Epoch 1713/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8335 - val_loss: 1.4106\n",
      "Epoch 1714/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8354 - val_loss: 1.4312\n",
      "Epoch 1715/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8248 - val_loss: 1.4217\n",
      "Epoch 1716/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8473 - val_loss: 1.4125\n",
      "Epoch 1717/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8343 - val_loss: 1.3998\n",
      "Epoch 1718/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8275 - val_loss: 1.4237\n",
      "Epoch 1719/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8239 - val_loss: 1.4380\n",
      "Epoch 1720/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8398 - val_loss: 1.4106\n",
      "Epoch 1721/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8398 - val_loss: 1.3956\n",
      "Epoch 1722/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8377 - val_loss: 1.4121\n",
      "Epoch 1723/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8397 - val_loss: 1.4100\n",
      "Epoch 1724/5000\n",
      "572/572 [==============================] - 0s 614us/step - loss: 0.8489 - val_loss: 1.4156\n",
      "Epoch 1725/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8410 - val_loss: 1.4080\n",
      "Epoch 1726/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8313 - val_loss: 1.4285\n",
      "Epoch 1727/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8379 - val_loss: 1.4361\n",
      "Epoch 1728/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8324 - val_loss: 1.4332\n",
      "Epoch 1729/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8285 - val_loss: 1.4386\n",
      "Epoch 1730/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8318 - val_loss: 1.4108\n",
      "Epoch 1731/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8288 - val_loss: 1.4373\n",
      "Epoch 1732/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8499 - val_loss: 1.4207\n",
      "Epoch 1733/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8343 - val_loss: 1.4372\n",
      "Epoch 1734/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8340 - val_loss: 1.4082\n",
      "Epoch 1735/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8466 - val_loss: 1.4472\n",
      "Epoch 1736/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.8386 - val_loss: 1.4512\n",
      "Epoch 1737/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8540 - val_loss: 1.4838\n",
      "Epoch 1738/5000\n",
      "572/572 [==============================] - 0s 621us/step - loss: 0.8270 - val_loss: 1.4327\n",
      "Epoch 1739/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8418 - val_loss: 1.4404\n",
      "Epoch 1740/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8439 - val_loss: 1.4321\n",
      "Epoch 1741/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8389 - val_loss: 1.4329\n",
      "Epoch 1742/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8487 - val_loss: 1.4379\n",
      "Epoch 1743/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8409 - val_loss: 1.4302\n",
      "Epoch 1744/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8399 - val_loss: 1.4046\n",
      "Epoch 1745/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8445 - val_loss: 1.4231\n",
      "Epoch 1746/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8487 - val_loss: 1.4110\n",
      "Epoch 1747/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8287 - val_loss: 1.4090\n",
      "Epoch 1748/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8458 - val_loss: 1.4154\n",
      "Epoch 1749/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8331 - val_loss: 1.4156\n",
      "Epoch 1750/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8451 - val_loss: 1.4182\n",
      "Epoch 1751/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8414 - val_loss: 1.4051\n",
      "Epoch 1752/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8408 - val_loss: 1.4042\n",
      "Epoch 1753/5000\n",
      "572/572 [==============================] - 0s 612us/step - loss: 0.8423 - val_loss: 1.3885\n",
      "Epoch 1754/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.8479 - val_loss: 1.3949\n",
      "Epoch 1755/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8537 - val_loss: 1.4024\n",
      "Epoch 1756/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8338 - val_loss: 1.4418\n",
      "Epoch 1757/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.8375 - val_loss: 1.5022\n",
      "Epoch 1758/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8468 - val_loss: 1.4664\n",
      "Epoch 1759/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8502 - val_loss: 1.4865\n",
      "Epoch 1760/5000\n",
      "572/572 [==============================] - 0s 687us/step - loss: 0.8370 - val_loss: 1.4400\n",
      "Epoch 1761/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8322 - val_loss: 1.4476\n",
      "Epoch 1762/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 668us/step - loss: 0.8371 - val_loss: 1.4405\n",
      "Epoch 1763/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8348 - val_loss: 1.4235\n",
      "Epoch 1764/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8384 - val_loss: 1.4445\n",
      "Epoch 1765/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8289 - val_loss: 1.3907\n",
      "Epoch 1766/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.8331 - val_loss: 1.4362\n",
      "Epoch 1767/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.8425 - val_loss: 1.4517\n",
      "Epoch 1768/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8500 - val_loss: 1.4888\n",
      "Epoch 1769/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8238 - val_loss: 1.4280\n",
      "Epoch 1770/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8395 - val_loss: 1.4141\n",
      "Epoch 1771/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8340 - val_loss: 1.4216\n",
      "Epoch 1772/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8429 - val_loss: 1.4710\n",
      "Epoch 1773/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8360 - val_loss: 1.3977\n",
      "Epoch 1774/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8496 - val_loss: 1.4146\n",
      "Epoch 1775/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.8421 - val_loss: 1.3902\n",
      "Epoch 1776/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8432 - val_loss: 1.3996\n",
      "Epoch 1777/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8401 - val_loss: 1.4020\n",
      "Epoch 1778/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8377 - val_loss: 1.4057\n",
      "Epoch 1779/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8462 - val_loss: 1.3710\n",
      "Epoch 1780/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8337 - val_loss: 1.3943\n",
      "Epoch 1781/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8571 - val_loss: 1.4331\n",
      "Epoch 1782/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8371 - val_loss: 1.4116\n",
      "Epoch 1783/5000\n",
      "572/572 [==============================] - 0s 621us/step - loss: 0.8329 - val_loss: 1.4600\n",
      "Epoch 1784/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8283 - val_loss: 1.4775\n",
      "Epoch 1785/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8233 - val_loss: 1.4045\n",
      "Epoch 1786/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8323 - val_loss: 1.4268\n",
      "Epoch 1787/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8327 - val_loss: 1.3799\n",
      "Epoch 1788/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8310 - val_loss: 1.3900\n",
      "Epoch 1789/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8433 - val_loss: 1.3987\n",
      "Epoch 1790/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8439 - val_loss: 1.4187\n",
      "Epoch 1791/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8503 - val_loss: 1.4296\n",
      "Epoch 1792/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8411 - val_loss: 1.4464\n",
      "Epoch 1793/5000\n",
      "572/572 [==============================] - 0s 687us/step - loss: 0.8276 - val_loss: 1.3985\n",
      "Epoch 1794/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8376 - val_loss: 1.3985\n",
      "Epoch 1795/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8344 - val_loss: 1.4107\n",
      "Epoch 1796/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8240 - val_loss: 1.4071\n",
      "Epoch 1797/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8297 - val_loss: 1.4132\n",
      "Epoch 1798/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8335 - val_loss: 1.4184\n",
      "Epoch 1799/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8444 - val_loss: 1.4550\n",
      "Epoch 1800/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8460 - val_loss: 1.4325\n",
      "Epoch 1801/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8330 - val_loss: 1.4478\n",
      "Epoch 1802/5000\n",
      "572/572 [==============================] - 0s 616us/step - loss: 0.8297 - val_loss: 1.4633\n",
      "Epoch 1803/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8394 - val_loss: 1.4177\n",
      "Epoch 1804/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8339 - val_loss: 1.4420\n",
      "Epoch 1805/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8338 - val_loss: 1.3987\n",
      "Epoch 1806/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8338 - val_loss: 1.3873\n",
      "Epoch 1807/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8311 - val_loss: 1.3811\n",
      "Epoch 1808/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8364 - val_loss: 1.3713\n",
      "Epoch 1809/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8443 - val_loss: 1.3987\n",
      "Epoch 1810/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.8417 - val_loss: 1.4167\n",
      "Epoch 1811/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8391 - val_loss: 1.4300\n",
      "Epoch 1812/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8354 - val_loss: 1.4399\n",
      "Epoch 1813/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8273 - val_loss: 1.4196\n",
      "Epoch 1814/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8305 - val_loss: 1.4144\n",
      "Epoch 1815/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8455 - val_loss: 1.4159\n",
      "Epoch 1816/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8425 - val_loss: 1.4092\n",
      "Epoch 1817/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8357 - val_loss: 1.4343\n",
      "Epoch 1818/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8253 - val_loss: 1.4010\n",
      "Epoch 1819/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8460 - val_loss: 1.4387\n",
      "Epoch 1820/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8401 - val_loss: 1.4105\n",
      "Epoch 1821/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8321 - val_loss: 1.4182\n",
      "Epoch 1822/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8410 - val_loss: 1.3782\n",
      "Epoch 1823/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8450 - val_loss: 1.3879\n",
      "Epoch 1824/5000\n",
      "572/572 [==============================] - 0s 620us/step - loss: 0.8309 - val_loss: 1.3992\n",
      "Epoch 1825/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8350 - val_loss: 1.3832\n",
      "Epoch 1826/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8414 - val_loss: 1.4022\n",
      "Epoch 1827/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8297 - val_loss: 1.4076\n",
      "Epoch 1828/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8344 - val_loss: 1.3995\n",
      "Epoch 1829/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8386 - val_loss: 1.4046\n",
      "Epoch 1830/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8425 - val_loss: 1.4159\n",
      "Epoch 1831/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.8353 - val_loss: 1.4109\n",
      "Epoch 1832/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8433 - val_loss: 1.3967\n",
      "Epoch 1833/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8291 - val_loss: 1.3885\n",
      "Epoch 1834/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8453 - val_loss: 1.3924\n",
      "Epoch 1835/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8363 - val_loss: 1.3909\n",
      "Epoch 1836/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8458 - val_loss: 1.3927\n",
      "Epoch 1837/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 0.8323 - val_loss: 1.3890\n",
      "Epoch 1838/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 675us/step - loss: 0.8404 - val_loss: 1.3960\n",
      "Epoch 1839/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8376 - val_loss: 1.4565\n",
      "Epoch 1840/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8293 - val_loss: 1.4555\n",
      "Epoch 1841/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8299 - val_loss: 1.4175\n",
      "Epoch 1842/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8290 - val_loss: 1.3902\n",
      "Epoch 1843/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8426 - val_loss: 1.4464\n",
      "Epoch 1844/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8338 - val_loss: 1.4526\n",
      "Epoch 1845/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8449 - val_loss: 1.4507\n",
      "Epoch 1846/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8508 - val_loss: 1.4076\n",
      "Epoch 1847/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8293 - val_loss: 1.4206\n",
      "Epoch 1848/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8341 - val_loss: 1.4128\n",
      "Epoch 1849/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8337 - val_loss: 1.4221\n",
      "Epoch 1850/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8459 - val_loss: 1.4291\n",
      "Epoch 1851/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8209 - val_loss: 1.4146\n",
      "Epoch 1852/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8322 - val_loss: 1.4134\n",
      "Epoch 1853/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8345 - val_loss: 1.4375\n",
      "Epoch 1854/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8239 - val_loss: 1.4357\n",
      "Epoch 1855/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8361 - val_loss: 1.4042\n",
      "Epoch 1856/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8312 - val_loss: 1.3935\n",
      "Epoch 1857/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8191 - val_loss: 1.4120\n",
      "Epoch 1858/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8332 - val_loss: 1.4169\n",
      "Epoch 1859/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8366 - val_loss: 1.4802\n",
      "Epoch 1860/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8315 - val_loss: 1.4491\n",
      "Epoch 1861/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8388 - val_loss: 1.4310\n",
      "Epoch 1862/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8319 - val_loss: 1.4122\n",
      "Epoch 1863/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8414 - val_loss: 1.4220\n",
      "Epoch 1864/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8308 - val_loss: 1.4312\n",
      "Epoch 1865/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8405 - val_loss: 1.4068\n",
      "Epoch 1866/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.8389 - val_loss: 1.3855\n",
      "Epoch 1867/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8203 - val_loss: 1.4189\n",
      "Epoch 1868/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8304 - val_loss: 1.3932\n",
      "Epoch 1869/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.8423 - val_loss: 1.4454\n",
      "Epoch 1870/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.8149 - val_loss: 1.4342\n",
      "Epoch 1871/5000\n",
      "572/572 [==============================] - 0s 622us/step - loss: 0.8388 - val_loss: 1.4189\n",
      "Epoch 1872/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8364 - val_loss: 1.4032\n",
      "Epoch 1873/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8466 - val_loss: 1.3968\n",
      "Epoch 1874/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8258 - val_loss: 1.4326\n",
      "Epoch 1875/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8231 - val_loss: 1.3913\n",
      "Epoch 1876/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8398 - val_loss: 1.3969\n",
      "Epoch 1877/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8374 - val_loss: 1.4015\n",
      "Epoch 1878/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8267 - val_loss: 1.4048\n",
      "Epoch 1879/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8499 - val_loss: 1.3945\n",
      "Epoch 1880/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8291 - val_loss: 1.3980\n",
      "Epoch 1881/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8383 - val_loss: 1.3892\n",
      "Epoch 1882/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8495 - val_loss: 1.3885\n",
      "Epoch 1883/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8395 - val_loss: 1.4180\n",
      "Epoch 1884/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8351 - val_loss: 1.4278\n",
      "Epoch 1885/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8293 - val_loss: 1.4362\n",
      "Epoch 1886/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8402 - val_loss: 1.3975\n",
      "Epoch 1887/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8323 - val_loss: 1.4385\n",
      "Epoch 1888/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.8298 - val_loss: 1.4128\n",
      "Epoch 1889/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8333 - val_loss: 1.4391\n",
      "Epoch 1890/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8277 - val_loss: 1.4127\n",
      "Epoch 1891/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8528 - val_loss: 1.4327\n",
      "Epoch 1892/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8378 - val_loss: 1.4171\n",
      "Epoch 1893/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8293 - val_loss: 1.4234\n",
      "Epoch 1894/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8219 - val_loss: 1.4032\n",
      "Epoch 1895/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8365 - val_loss: 1.3936\n",
      "Epoch 1896/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8340 - val_loss: 1.3906\n",
      "Epoch 1897/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8410 - val_loss: 1.4083\n",
      "Epoch 1898/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8468 - val_loss: 1.4032\n",
      "Epoch 1899/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8290 - val_loss: 1.4004\n",
      "Epoch 1900/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8396 - val_loss: 1.4080\n",
      "Epoch 1901/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8356 - val_loss: 1.4082\n",
      "Epoch 1902/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8300 - val_loss: 1.4094\n",
      "Epoch 1903/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8390 - val_loss: 1.4015\n",
      "Epoch 1904/5000\n",
      "572/572 [==============================] - 0s 689us/step - loss: 0.8497 - val_loss: 1.4505\n",
      "Epoch 1905/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8348 - val_loss: 1.4272\n",
      "Epoch 1906/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8476 - val_loss: 1.4315\n",
      "Epoch 1907/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8316 - val_loss: 1.4185\n",
      "Epoch 1908/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8334 - val_loss: 1.4428\n",
      "Epoch 1909/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8355 - val_loss: 1.4338\n",
      "Epoch 1910/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.8270 - val_loss: 1.4153\n",
      "Epoch 1911/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8426 - val_loss: 1.4275\n",
      "Epoch 1912/5000\n",
      "572/572 [==============================] - 0s 708us/step - loss: 0.8281 - val_loss: 1.4450\n",
      "Epoch 1913/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8361 - val_loss: 1.4229\n",
      "Epoch 1914/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 611us/step - loss: 0.8406 - val_loss: 1.3976\n",
      "Epoch 1915/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8248 - val_loss: 1.4123\n",
      "Epoch 1916/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 0.8417 - val_loss: 1.4413\n",
      "Epoch 1917/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8347 - val_loss: 1.4395\n",
      "Epoch 1918/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8320 - val_loss: 1.4230\n",
      "Epoch 1919/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8484 - val_loss: 1.4269\n",
      "Epoch 1920/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8470 - val_loss: 1.4146\n",
      "Epoch 1921/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8413 - val_loss: 1.4002\n",
      "Epoch 1922/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8268 - val_loss: 1.4228\n",
      "Epoch 1923/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8348 - val_loss: 1.4102\n",
      "Epoch 1924/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8468 - val_loss: 1.3771\n",
      "Epoch 1925/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8448 - val_loss: 1.3672\n",
      "Epoch 1926/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8350 - val_loss: 1.3992\n",
      "Epoch 1927/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8297 - val_loss: 1.4093\n",
      "Epoch 1928/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8203 - val_loss: 1.4002\n",
      "Epoch 1929/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8327 - val_loss: 1.4144\n",
      "Epoch 1930/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8351 - val_loss: 1.4118\n",
      "Epoch 1931/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8273 - val_loss: 1.4149\n",
      "Epoch 1932/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 0.8199 - val_loss: 1.3913\n",
      "Epoch 1933/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8226 - val_loss: 1.4456\n",
      "Epoch 1934/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8360 - val_loss: 1.4122\n",
      "Epoch 1935/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8575 - val_loss: 1.4099\n",
      "Epoch 1936/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8444 - val_loss: 1.4269\n",
      "Epoch 1937/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8322 - val_loss: 1.4090\n",
      "Epoch 1938/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8265 - val_loss: 1.3999\n",
      "Epoch 1939/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8333 - val_loss: 1.3916\n",
      "Epoch 1940/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8368 - val_loss: 1.4323\n",
      "Epoch 1941/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8394 - val_loss: 1.4135\n",
      "Epoch 1942/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8302 - val_loss: 1.3963\n",
      "Epoch 1943/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8271 - val_loss: 1.4326\n",
      "Epoch 1944/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8390 - val_loss: 1.4365\n",
      "Epoch 1945/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8410 - val_loss: 1.4070\n",
      "Epoch 1946/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8389 - val_loss: 1.4009\n",
      "Epoch 1947/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8334 - val_loss: 1.4242\n",
      "Epoch 1948/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8452 - val_loss: 1.4570\n",
      "Epoch 1949/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8445 - val_loss: 1.4229\n",
      "Epoch 1950/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8306 - val_loss: 1.4031\n",
      "Epoch 1951/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8389 - val_loss: 1.4130\n",
      "Epoch 1952/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8348 - val_loss: 1.4073\n",
      "Epoch 1953/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8278 - val_loss: 1.4327\n",
      "Epoch 1954/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.8353 - val_loss: 1.4275\n",
      "Epoch 1955/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8371 - val_loss: 1.4232\n",
      "Epoch 1956/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8432 - val_loss: 1.4039\n",
      "Epoch 1957/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8292 - val_loss: 1.4267\n",
      "Epoch 1958/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.8198 - val_loss: 1.4363\n",
      "Epoch 1959/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8304 - val_loss: 1.4052\n",
      "Epoch 1960/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.8271 - val_loss: 1.3788\n",
      "Epoch 1961/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8282 - val_loss: 1.4563\n",
      "Epoch 1962/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8297 - val_loss: 1.4100\n",
      "Epoch 1963/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8283 - val_loss: 1.4279\n",
      "Epoch 1964/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8376 - val_loss: 1.4217\n",
      "Epoch 1965/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8237 - val_loss: 1.4564\n",
      "Epoch 1966/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.8314 - val_loss: 1.4452\n",
      "Epoch 1967/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8383 - val_loss: 1.4432\n",
      "Epoch 1968/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8248 - val_loss: 1.4719\n",
      "Epoch 1969/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8539 - val_loss: 1.4116\n",
      "Epoch 1970/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8426 - val_loss: 1.3953\n",
      "Epoch 1971/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8370 - val_loss: 1.4023\n",
      "Epoch 1972/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8572 - val_loss: 1.4223\n",
      "Epoch 1973/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8428 - val_loss: 1.4108\n",
      "Epoch 1974/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.8212 - val_loss: 1.4048\n",
      "Epoch 1975/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8275 - val_loss: 1.4287\n",
      "Epoch 1976/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8264 - val_loss: 1.4366\n",
      "Epoch 1977/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8452 - val_loss: 1.4477\n",
      "Epoch 1978/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8338 - val_loss: 1.4092\n",
      "Epoch 1979/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8366 - val_loss: 1.4280\n",
      "Epoch 1980/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8396 - val_loss: 1.4264\n",
      "Epoch 1981/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8255 - val_loss: 1.4072\n",
      "Epoch 1982/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8325 - val_loss: 1.4526\n",
      "Epoch 1983/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8313 - val_loss: 1.4656\n",
      "Epoch 1984/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8260 - val_loss: 1.4335\n",
      "Epoch 1985/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8337 - val_loss: 1.4145\n",
      "Epoch 1986/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8395 - val_loss: 1.4088\n",
      "Epoch 1987/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8495 - val_loss: 1.4398\n",
      "Epoch 1988/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8361 - val_loss: 1.3978\n",
      "Epoch 1989/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8308 - val_loss: 1.4287\n",
      "Epoch 1990/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 670us/step - loss: 0.8206 - val_loss: 1.3907\n",
      "Epoch 1991/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8328 - val_loss: 1.3938\n",
      "Epoch 1992/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8402 - val_loss: 1.4139\n",
      "Epoch 1993/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8287 - val_loss: 1.4353\n",
      "Epoch 1994/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8395 - val_loss: 1.4275\n",
      "Epoch 1995/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8247 - val_loss: 1.4222\n",
      "Epoch 1996/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8286 - val_loss: 1.4258\n",
      "Epoch 1997/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8456 - val_loss: 1.4483\n",
      "Epoch 1998/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.8200 - val_loss: 1.4185\n",
      "Epoch 1999/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8319 - val_loss: 1.3857\n",
      "Epoch 2000/5000\n",
      "572/572 [==============================] - 0s 689us/step - loss: 0.8357 - val_loss: 1.4150\n",
      "Epoch 2001/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8340 - val_loss: 1.3997\n",
      "Epoch 2002/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8372 - val_loss: 1.4112\n",
      "Epoch 2003/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8384 - val_loss: 1.4014\n",
      "Epoch 2004/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8375 - val_loss: 1.4058\n",
      "Epoch 2005/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8231 - val_loss: 1.3900\n",
      "Epoch 2006/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8162 - val_loss: 1.3973\n",
      "Epoch 2007/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8207 - val_loss: 1.3977\n",
      "Epoch 2008/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8249 - val_loss: 1.4063\n",
      "Epoch 2009/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8322 - val_loss: 1.3911\n",
      "Epoch 2010/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.8302 - val_loss: 1.4362\n",
      "Epoch 2011/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8243 - val_loss: 1.4412\n",
      "Epoch 2012/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8436 - val_loss: 1.4426\n",
      "Epoch 2013/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8331 - val_loss: 1.4081\n",
      "Epoch 2014/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8261 - val_loss: 1.4619\n",
      "Epoch 2015/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8362 - val_loss: 1.4388\n",
      "Epoch 2016/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8177 - val_loss: 1.3908\n",
      "Epoch 2017/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8363 - val_loss: 1.4244\n",
      "Epoch 2018/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8313 - val_loss: 1.4043\n",
      "Epoch 2019/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8300 - val_loss: 1.4152\n",
      "Epoch 2020/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8378 - val_loss: 1.4083\n",
      "Epoch 2021/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8290 - val_loss: 1.3901\n",
      "Epoch 2022/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8312 - val_loss: 1.4091\n",
      "Epoch 2023/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8321 - val_loss: 1.4050\n",
      "Epoch 2024/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8351 - val_loss: 1.3709\n",
      "Epoch 2025/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8231 - val_loss: 1.3709\n",
      "Epoch 2026/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8320 - val_loss: 1.3998\n",
      "Epoch 2027/5000\n",
      "572/572 [==============================] - 0s 619us/step - loss: 0.8243 - val_loss: 1.4061\n",
      "Epoch 2028/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8246 - val_loss: 1.3958\n",
      "Epoch 2029/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8305 - val_loss: 1.3985\n",
      "Epoch 2030/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8436 - val_loss: 1.3811\n",
      "Epoch 2031/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8353 - val_loss: 1.3730\n",
      "Epoch 2032/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8214 - val_loss: 1.4159\n",
      "Epoch 2033/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8326 - val_loss: 1.4049\n",
      "Epoch 2034/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8282 - val_loss: 1.4180\n",
      "Epoch 2035/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8304 - val_loss: 1.4006\n",
      "Epoch 2036/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8400 - val_loss: 1.4556\n",
      "Epoch 2037/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8420 - val_loss: 1.4911\n",
      "Epoch 2038/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8290 - val_loss: 1.4509\n",
      "Epoch 2039/5000\n",
      "572/572 [==============================] - 0s 736us/step - loss: 0.8380 - val_loss: 1.4519\n",
      "Epoch 2040/5000\n",
      "572/572 [==============================] - 0s 758us/step - loss: 0.8379 - val_loss: 1.4510\n",
      "Epoch 2041/5000\n",
      "572/572 [==============================] - 0s 730us/step - loss: 0.8346 - val_loss: 1.4169\n",
      "Epoch 2042/5000\n",
      "572/572 [==============================] - 0s 801us/step - loss: 0.8396 - val_loss: 1.4127\n",
      "Epoch 2043/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8386 - val_loss: 1.4252\n",
      "Epoch 2044/5000\n",
      "572/572 [==============================] - 0s 839us/step - loss: 0.8342 - val_loss: 1.4064\n",
      "Epoch 2045/5000\n",
      "572/572 [==============================] - 0s 789us/step - loss: 0.8239 - val_loss: 1.4270\n",
      "Epoch 2046/5000\n",
      "572/572 [==============================] - 0s 800us/step - loss: 0.8353 - val_loss: 1.4135\n",
      "Epoch 2047/5000\n",
      "572/572 [==============================] - 0s 740us/step - loss: 0.8249 - val_loss: 1.3944\n",
      "Epoch 2048/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8237 - val_loss: 1.4096\n",
      "Epoch 2049/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8315 - val_loss: 1.3759\n",
      "Epoch 2050/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8250 - val_loss: 1.3887\n",
      "Epoch 2051/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.8297 - val_loss: 1.3811\n",
      "Epoch 2052/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8480 - val_loss: 1.3745\n",
      "Epoch 2053/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8387 - val_loss: 1.4076\n",
      "Epoch 2054/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8208 - val_loss: 1.4270\n",
      "Epoch 2055/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8528 - val_loss: 1.4011\n",
      "Epoch 2056/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8337 - val_loss: 1.3908\n",
      "Epoch 2057/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8355 - val_loss: 1.3806\n",
      "Epoch 2058/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8292 - val_loss: 1.3957\n",
      "Epoch 2059/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8217 - val_loss: 1.3945\n",
      "Epoch 2060/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8171 - val_loss: 1.4262\n",
      "Epoch 2061/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8196 - val_loss: 1.3943\n",
      "Epoch 2062/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8346 - val_loss: 1.3878\n",
      "Epoch 2063/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8244 - val_loss: 1.4001\n",
      "Epoch 2064/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8308 - val_loss: 1.4096\n",
      "Epoch 2065/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8384 - val_loss: 1.3802\n",
      "Epoch 2066/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 650us/step - loss: 0.8327 - val_loss: 1.3712\n",
      "Epoch 2067/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8476 - val_loss: 1.3810\n",
      "Epoch 2068/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8333 - val_loss: 1.3826\n",
      "Epoch 2069/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8481 - val_loss: 1.3931\n",
      "Epoch 2070/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8047 - val_loss: 1.4067\n",
      "Epoch 2071/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8380 - val_loss: 1.3842\n",
      "Epoch 2072/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8517 - val_loss: 1.3976\n",
      "Epoch 2073/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8199 - val_loss: 1.3866\n",
      "Epoch 2074/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8194 - val_loss: 1.4092\n",
      "Epoch 2075/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8437 - val_loss: 1.4018\n",
      "Epoch 2076/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8160 - val_loss: 1.4397\n",
      "Epoch 2077/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8398 - val_loss: 1.3944\n",
      "Epoch 2078/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8191 - val_loss: 1.4144\n",
      "Epoch 2079/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8295 - val_loss: 1.4187\n",
      "Epoch 2080/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8264 - val_loss: 1.4234\n",
      "Epoch 2081/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8251 - val_loss: 1.4207\n",
      "Epoch 2082/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8351 - val_loss: 1.3905\n",
      "Epoch 2083/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8297 - val_loss: 1.3901\n",
      "Epoch 2084/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8324 - val_loss: 1.4643\n",
      "Epoch 2085/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8326 - val_loss: 1.4347\n",
      "Epoch 2086/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8314 - val_loss: 1.3913\n",
      "Epoch 2087/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8360 - val_loss: 1.3797\n",
      "Epoch 2088/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8358 - val_loss: 1.3863\n",
      "Epoch 2089/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 0.8204 - val_loss: 1.3856\n",
      "Epoch 2090/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8326 - val_loss: 1.3848\n",
      "Epoch 2091/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8259 - val_loss: 1.4104\n",
      "Epoch 2092/5000\n",
      "572/572 [==============================] - 0s 615us/step - loss: 0.8138 - val_loss: 1.4011\n",
      "Epoch 2093/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8275 - val_loss: 1.3909\n",
      "Epoch 2094/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8084 - val_loss: 1.4036\n",
      "Epoch 2095/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8454 - val_loss: 1.4201\n",
      "Epoch 2096/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8318 - val_loss: 1.3956\n",
      "Epoch 2097/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8242 - val_loss: 1.3867\n",
      "Epoch 2098/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8253 - val_loss: 1.3894\n",
      "Epoch 2099/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8344 - val_loss: 1.3909\n",
      "Epoch 2100/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8168 - val_loss: 1.4078\n",
      "Epoch 2101/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8130 - val_loss: 1.4108\n",
      "Epoch 2102/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8321 - val_loss: 1.4501\n",
      "Epoch 2103/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8266 - val_loss: 1.4015\n",
      "Epoch 2104/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8358 - val_loss: 1.4262\n",
      "Epoch 2105/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8275 - val_loss: 1.4093\n",
      "Epoch 2106/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8346 - val_loss: 1.3998\n",
      "Epoch 2107/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8197 - val_loss: 1.3876\n",
      "Epoch 2108/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8264 - val_loss: 1.3888\n",
      "Epoch 2109/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8450 - val_loss: 1.4028\n",
      "Epoch 2110/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8342 - val_loss: 1.4117\n",
      "Epoch 2111/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8306 - val_loss: 1.4227\n",
      "Epoch 2112/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8484 - val_loss: 1.4169\n",
      "Epoch 2113/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8343 - val_loss: 1.4381\n",
      "Epoch 2114/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8412 - val_loss: 1.4425\n",
      "Epoch 2115/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8290 - val_loss: 1.4007\n",
      "Epoch 2116/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8389 - val_loss: 1.4232\n",
      "Epoch 2117/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8405 - val_loss: 1.4077\n",
      "Epoch 2118/5000\n",
      "572/572 [==============================] - 0s 688us/step - loss: 0.8466 - val_loss: 1.4195\n",
      "Epoch 2119/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8274 - val_loss: 1.4367\n",
      "Epoch 2120/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8309 - val_loss: 1.4019\n",
      "Epoch 2121/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8220 - val_loss: 1.4066\n",
      "Epoch 2122/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8191 - val_loss: 1.4241\n",
      "Epoch 2123/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8277 - val_loss: 1.4238\n",
      "Epoch 2124/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8207 - val_loss: 1.3991\n",
      "Epoch 2125/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8252 - val_loss: 1.4038\n",
      "Epoch 2126/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8234 - val_loss: 1.3771\n",
      "Epoch 2127/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8264 - val_loss: 1.4143\n",
      "Epoch 2128/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8378 - val_loss: 1.4294\n",
      "Epoch 2129/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8371 - val_loss: 1.3999\n",
      "Epoch 2130/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8306 - val_loss: 1.4297\n",
      "Epoch 2131/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.8323 - val_loss: 1.3975\n",
      "Epoch 2132/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8398 - val_loss: 1.4062\n",
      "Epoch 2133/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8219 - val_loss: 1.4158\n",
      "Epoch 2134/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8316 - val_loss: 1.3927\n",
      "Epoch 2135/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8100 - val_loss: 1.4617\n",
      "Epoch 2136/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8263 - val_loss: 1.4435\n",
      "Epoch 2137/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8427 - val_loss: 1.4437\n",
      "Epoch 2138/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8372 - val_loss: 1.4067\n",
      "Epoch 2139/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8480 - val_loss: 1.4168\n",
      "Epoch 2140/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8222 - val_loss: 1.4143\n",
      "Epoch 2141/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8261 - val_loss: 1.4249\n",
      "Epoch 2142/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 642us/step - loss: 0.8312 - val_loss: 1.3802\n",
      "Epoch 2143/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8320 - val_loss: 1.4233\n",
      "Epoch 2144/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8211 - val_loss: 1.4186\n",
      "Epoch 2145/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.8503 - val_loss: 1.4223\n",
      "Epoch 2146/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8371 - val_loss: 1.3975\n",
      "Epoch 2147/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8357 - val_loss: 1.3771\n",
      "Epoch 2148/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8413 - val_loss: 1.4187\n",
      "Epoch 2149/5000\n",
      "572/572 [==============================] - 0s 616us/step - loss: 0.8163 - val_loss: 1.4048\n",
      "Epoch 2150/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8190 - val_loss: 1.4103\n",
      "Epoch 2151/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8191 - val_loss: 1.4313\n",
      "Epoch 2152/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8356 - val_loss: 1.4331\n",
      "Epoch 2153/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8313 - val_loss: 1.3901\n",
      "Epoch 2154/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8379 - val_loss: 1.3863\n",
      "Epoch 2155/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8390 - val_loss: 1.4147\n",
      "Epoch 2156/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8212 - val_loss: 1.4061\n",
      "Epoch 2157/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8224 - val_loss: 1.3955\n",
      "Epoch 2158/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8328 - val_loss: 1.4122\n",
      "Epoch 2159/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8302 - val_loss: 1.4321\n",
      "Epoch 2160/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8243 - val_loss: 1.4054\n",
      "Epoch 2161/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8399 - val_loss: 1.4152\n",
      "Epoch 2162/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8199 - val_loss: 1.3763\n",
      "Epoch 2163/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8370 - val_loss: 1.4085\n",
      "Epoch 2164/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8292 - val_loss: 1.4354\n",
      "Epoch 2165/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8344 - val_loss: 1.4310\n",
      "Epoch 2166/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8370 - val_loss: 1.4183\n",
      "Epoch 2167/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8214 - val_loss: 1.3968\n",
      "Epoch 2168/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8316 - val_loss: 1.4026\n",
      "Epoch 2169/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8351 - val_loss: 1.4041\n",
      "Epoch 2170/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8183 - val_loss: 1.4298\n",
      "Epoch 2171/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8288 - val_loss: 1.3959\n",
      "Epoch 2172/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8262 - val_loss: 1.4116\n",
      "Epoch 2173/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8432 - val_loss: 1.4206\n",
      "Epoch 2174/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8376 - val_loss: 1.4091\n",
      "Epoch 2175/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8142 - val_loss: 1.4170\n",
      "Epoch 2176/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8398 - val_loss: 1.4021\n",
      "Epoch 2177/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8138 - val_loss: 1.3986\n",
      "Epoch 2178/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8333 - val_loss: 1.4149\n",
      "Epoch 2179/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8232 - val_loss: 1.4467\n",
      "Epoch 2180/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8411 - val_loss: 1.3925\n",
      "Epoch 2181/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8349 - val_loss: 1.3866\n",
      "Epoch 2182/5000\n",
      "572/572 [==============================] - 0s 619us/step - loss: 0.8335 - val_loss: 1.3853\n",
      "Epoch 2183/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8280 - val_loss: 1.3839\n",
      "Epoch 2184/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8358 - val_loss: 1.4309\n",
      "Epoch 2185/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8262 - val_loss: 1.4533\n",
      "Epoch 2186/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8385 - val_loss: 1.4036\n",
      "Epoch 2187/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8207 - val_loss: 1.3845\n",
      "Epoch 2188/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8395 - val_loss: 1.3998\n",
      "Epoch 2189/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8226 - val_loss: 1.4301\n",
      "Epoch 2190/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8291 - val_loss: 1.4487\n",
      "Epoch 2191/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8453 - val_loss: 1.4093\n",
      "Epoch 2192/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8120 - val_loss: 1.4017\n",
      "Epoch 2193/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8194 - val_loss: 1.4043\n",
      "Epoch 2194/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8382 - val_loss: 1.4326\n",
      "Epoch 2195/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8175 - val_loss: 1.4177\n",
      "Epoch 2196/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8118 - val_loss: 1.4072\n",
      "Epoch 2197/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.8357 - val_loss: 1.4389\n",
      "Epoch 2198/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8372 - val_loss: 1.4319\n",
      "Epoch 2199/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8376 - val_loss: 1.4112\n",
      "Epoch 2200/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8166 - val_loss: 1.4094\n",
      "Epoch 2201/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8212 - val_loss: 1.3775\n",
      "Epoch 2202/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8450 - val_loss: 1.3718\n",
      "Epoch 2203/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8243 - val_loss: 1.4084\n",
      "Epoch 2204/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8293 - val_loss: 1.4428\n",
      "Epoch 2205/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8317 - val_loss: 1.4170\n",
      "Epoch 2206/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8266 - val_loss: 1.4323\n",
      "Epoch 2207/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8318 - val_loss: 1.4042\n",
      "Epoch 2208/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8378 - val_loss: 1.4130\n",
      "Epoch 2209/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.8259 - val_loss: 1.4649\n",
      "Epoch 2210/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8280 - val_loss: 1.4384\n",
      "Epoch 2211/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8193 - val_loss: 1.4018\n",
      "Epoch 2212/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8433 - val_loss: 1.4004\n",
      "Epoch 2213/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8197 - val_loss: 1.3960\n",
      "Epoch 2214/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8293 - val_loss: 1.4015\n",
      "Epoch 2215/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8185 - val_loss: 1.3881\n",
      "Epoch 2216/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8147 - val_loss: 1.4131\n",
      "Epoch 2217/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8253 - val_loss: 1.4199\n",
      "Epoch 2218/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 643us/step - loss: 0.8285 - val_loss: 1.4096\n",
      "Epoch 2219/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8288 - val_loss: 1.3777\n",
      "Epoch 2220/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8188 - val_loss: 1.4197\n",
      "Epoch 2221/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.8173 - val_loss: 1.3967\n",
      "Epoch 2222/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8257 - val_loss: 1.4164\n",
      "Epoch 2223/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8253 - val_loss: 1.4618\n",
      "Epoch 2224/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8213 - val_loss: 1.5024\n",
      "Epoch 2225/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8371 - val_loss: 1.4357\n",
      "Epoch 2226/5000\n",
      "572/572 [==============================] - 0s 691us/step - loss: 0.8346 - val_loss: 1.4398\n",
      "Epoch 2227/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8299 - val_loss: 1.4315\n",
      "Epoch 2228/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8415 - val_loss: 1.4055\n",
      "Epoch 2229/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8272 - val_loss: 1.4054\n",
      "Epoch 2230/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8312 - val_loss: 1.4519\n",
      "Epoch 2231/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8145 - val_loss: 1.4116\n",
      "Epoch 2232/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8212 - val_loss: 1.3969\n",
      "Epoch 2233/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8160 - val_loss: 1.3962\n",
      "Epoch 2234/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8268 - val_loss: 1.4024\n",
      "Epoch 2235/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8127 - val_loss: 1.4109\n",
      "Epoch 2236/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.8244 - val_loss: 1.4009\n",
      "Epoch 2237/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8341 - val_loss: 1.3960\n",
      "Epoch 2238/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.8409 - val_loss: 1.3866\n",
      "Epoch 2239/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8192 - val_loss: 1.3963\n",
      "Epoch 2240/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8249 - val_loss: 1.4263\n",
      "Epoch 2241/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8388 - val_loss: 1.3875\n",
      "Epoch 2242/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8270 - val_loss: 1.4169\n",
      "Epoch 2243/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8314 - val_loss: 1.4117\n",
      "Epoch 2244/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8270 - val_loss: 1.4552\n",
      "Epoch 2245/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8148 - val_loss: 1.4352\n",
      "Epoch 2246/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8121 - val_loss: 1.4081\n",
      "Epoch 2247/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8166 - val_loss: 1.4203\n",
      "Epoch 2248/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8349 - val_loss: 1.3825\n",
      "Epoch 2249/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8175 - val_loss: 1.4032\n",
      "Epoch 2250/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8217 - val_loss: 1.4019\n",
      "Epoch 2251/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.8375 - val_loss: 1.3996\n",
      "Epoch 2252/5000\n",
      "572/572 [==============================] - 0s 708us/step - loss: 0.8408 - val_loss: 1.3898\n",
      "Epoch 2253/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8237 - val_loss: 1.3698\n",
      "Epoch 2254/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8465 - val_loss: 1.3769\n",
      "Epoch 2255/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8293 - val_loss: 1.3995\n",
      "Epoch 2256/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8260 - val_loss: 1.4259\n",
      "Epoch 2257/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8189 - val_loss: 1.4051\n",
      "Epoch 2258/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8336 - val_loss: 1.4549\n",
      "Epoch 2259/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8286 - val_loss: 1.4435\n",
      "Epoch 2260/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8295 - val_loss: 1.4602\n",
      "Epoch 2261/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8355 - val_loss: 1.4271\n",
      "Epoch 2262/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8117 - val_loss: 1.4154\n",
      "Epoch 2263/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8351 - val_loss: 1.4578\n",
      "Epoch 2264/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8338 - val_loss: 1.3958\n",
      "Epoch 2265/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8370 - val_loss: 1.3761\n",
      "Epoch 2266/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8166 - val_loss: 1.3945\n",
      "Epoch 2267/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8117 - val_loss: 1.4002\n",
      "Epoch 2268/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8305 - val_loss: 1.4127\n",
      "Epoch 2269/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8240 - val_loss: 1.3938\n",
      "Epoch 2270/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8309 - val_loss: 1.4042\n",
      "Epoch 2271/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8338 - val_loss: 1.3838\n",
      "Epoch 2272/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8355 - val_loss: 1.3912\n",
      "Epoch 2273/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8291 - val_loss: 1.4075\n",
      "Epoch 2274/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.8184 - val_loss: 1.4327\n",
      "Epoch 2275/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8400 - val_loss: 1.4342\n",
      "Epoch 2276/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8253 - val_loss: 1.3964\n",
      "Epoch 2277/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8202 - val_loss: 1.4199\n",
      "Epoch 2278/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8302 - val_loss: 1.4435\n",
      "Epoch 2279/5000\n",
      "572/572 [==============================] - 0s 621us/step - loss: 0.8351 - val_loss: 1.4161\n",
      "Epoch 2280/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8322 - val_loss: 1.4320\n",
      "Epoch 2281/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8318 - val_loss: 1.4163\n",
      "Epoch 2282/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8328 - val_loss: 1.4158\n",
      "Epoch 2283/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8085 - val_loss: 1.4043\n",
      "Epoch 2284/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8282 - val_loss: 1.4020\n",
      "Epoch 2285/5000\n",
      "572/572 [==============================] - 0s 609us/step - loss: 0.8050 - val_loss: 1.3932\n",
      "Epoch 2286/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8268 - val_loss: 1.4208\n",
      "Epoch 2287/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8115 - val_loss: 1.4053\n",
      "Epoch 2288/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8260 - val_loss: 1.3811\n",
      "Epoch 2289/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.8285 - val_loss: 1.3980\n",
      "Epoch 2290/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8208 - val_loss: 1.3981\n",
      "Epoch 2291/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8226 - val_loss: 1.3925\n",
      "Epoch 2292/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.8328 - val_loss: 1.3825\n",
      "Epoch 2293/5000\n",
      "572/572 [==============================] - 0s 616us/step - loss: 0.8240 - val_loss: 1.3854\n",
      "Epoch 2294/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 669us/step - loss: 0.8254 - val_loss: 1.4241\n",
      "Epoch 2295/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8404 - val_loss: 1.4157\n",
      "Epoch 2296/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8121 - val_loss: 1.3911\n",
      "Epoch 2297/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8245 - val_loss: 1.3956\n",
      "Epoch 2298/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8332 - val_loss: 1.3710\n",
      "Epoch 2299/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8447 - val_loss: 1.4096\n",
      "Epoch 2300/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8261 - val_loss: 1.4048\n",
      "Epoch 2301/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8255 - val_loss: 1.3746\n",
      "Epoch 2302/5000\n",
      "572/572 [==============================] - 0s 622us/step - loss: 0.8178 - val_loss: 1.4332\n",
      "Epoch 2303/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8318 - val_loss: 1.4046\n",
      "Epoch 2304/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8113 - val_loss: 1.4432\n",
      "Epoch 2305/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8315 - val_loss: 1.4284\n",
      "Epoch 2306/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8217 - val_loss: 1.4132\n",
      "Epoch 2307/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8326 - val_loss: 1.4091\n",
      "Epoch 2308/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8221 - val_loss: 1.4211\n",
      "Epoch 2309/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8417 - val_loss: 1.4663\n",
      "Epoch 2310/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8420 - val_loss: 1.3899\n",
      "Epoch 2311/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8327 - val_loss: 1.4027\n",
      "Epoch 2312/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8150 - val_loss: 1.3841\n",
      "Epoch 2313/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8282 - val_loss: 1.3806\n",
      "Epoch 2314/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8099 - val_loss: 1.3784\n",
      "Epoch 2315/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8211 - val_loss: 1.3995\n",
      "Epoch 2316/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.8093 - val_loss: 1.3950\n",
      "Epoch 2317/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8541 - val_loss: 1.3930\n",
      "Epoch 2318/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8239 - val_loss: 1.3992\n",
      "Epoch 2319/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8125 - val_loss: 1.4264\n",
      "Epoch 2320/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8315 - val_loss: 1.3979\n",
      "Epoch 2321/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8284 - val_loss: 1.3756\n",
      "Epoch 2322/5000\n",
      "572/572 [==============================] - 0s 618us/step - loss: 0.8349 - val_loss: 1.4005\n",
      "Epoch 2323/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8402 - val_loss: 1.4412\n",
      "Epoch 2324/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8499 - val_loss: 1.3993\n",
      "Epoch 2325/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8266 - val_loss: 1.3806\n",
      "Epoch 2326/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8346 - val_loss: 1.3827\n",
      "Epoch 2327/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8299 - val_loss: 1.3968\n",
      "Epoch 2328/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8323 - val_loss: 1.4164\n",
      "Epoch 2329/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8434 - val_loss: 1.4065\n",
      "Epoch 2330/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8411 - val_loss: 1.4113\n",
      "Epoch 2331/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8239 - val_loss: 1.4057\n",
      "Epoch 2332/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8247 - val_loss: 1.3936\n",
      "Epoch 2333/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8382 - val_loss: 1.4119\n",
      "Epoch 2334/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8114 - val_loss: 1.3840\n",
      "Epoch 2335/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8186 - val_loss: 1.4062\n",
      "Epoch 2336/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8344 - val_loss: 1.4172\n",
      "Epoch 2337/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8331 - val_loss: 1.4110\n",
      "Epoch 2338/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8185 - val_loss: 1.3962\n",
      "Epoch 2339/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8279 - val_loss: 1.3796\n",
      "Epoch 2340/5000\n",
      "572/572 [==============================] - 0s 619us/step - loss: 0.8421 - val_loss: 1.3749\n",
      "Epoch 2341/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8218 - val_loss: 1.4003\n",
      "Epoch 2342/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8231 - val_loss: 1.3908\n",
      "Epoch 2343/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8340 - val_loss: 1.3777\n",
      "Epoch 2344/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8239 - val_loss: 1.3986\n",
      "Epoch 2345/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8320 - val_loss: 1.4223\n",
      "Epoch 2346/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8308 - val_loss: 1.4170\n",
      "Epoch 2347/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8254 - val_loss: 1.3840\n",
      "Epoch 2348/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8301 - val_loss: 1.4100\n",
      "Epoch 2349/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8217 - val_loss: 1.4404\n",
      "Epoch 2350/5000\n",
      "572/572 [==============================] - 0s 692us/step - loss: 0.8239 - val_loss: 1.4309\n",
      "Epoch 2351/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8192 - val_loss: 1.4653\n",
      "Epoch 2352/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8165 - val_loss: 1.4039\n",
      "Epoch 2353/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8253 - val_loss: 1.4135\n",
      "Epoch 2354/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8209 - val_loss: 1.3957\n",
      "Epoch 2355/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8303 - val_loss: 1.4148\n",
      "Epoch 2356/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8217 - val_loss: 1.4436\n",
      "Epoch 2357/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8318 - val_loss: 1.4681\n",
      "Epoch 2358/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8383 - val_loss: 1.4619\n",
      "Epoch 2359/5000\n",
      "572/572 [==============================] - 0s 622us/step - loss: 0.8165 - val_loss: 1.4397\n",
      "Epoch 2360/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8347 - val_loss: 1.4409\n",
      "Epoch 2361/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8433 - val_loss: 1.4111\n",
      "Epoch 2362/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8380 - val_loss: 1.3853\n",
      "Epoch 2363/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8314 - val_loss: 1.3791\n",
      "Epoch 2364/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8192 - val_loss: 1.3959\n",
      "Epoch 2365/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8312 - val_loss: 1.3940\n",
      "Epoch 2366/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8270 - val_loss: 1.3739\n",
      "Epoch 2367/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8311 - val_loss: 1.3928\n",
      "Epoch 2368/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.8264 - val_loss: 1.4266\n",
      "Epoch 2369/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8388 - val_loss: 1.3858\n",
      "Epoch 2370/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 663us/step - loss: 0.8300 - val_loss: 1.4029\n",
      "Epoch 2371/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8311 - val_loss: 1.4080\n",
      "Epoch 2372/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8193 - val_loss: 1.4002\n",
      "Epoch 2373/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8359 - val_loss: 1.3890\n",
      "Epoch 2374/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8274 - val_loss: 1.4307\n",
      "Epoch 2375/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8215 - val_loss: 1.3964\n",
      "Epoch 2376/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.8044 - val_loss: 1.4229\n",
      "Epoch 2377/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8178 - val_loss: 1.4460\n",
      "Epoch 2378/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8298 - val_loss: 1.3917\n",
      "Epoch 2379/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.8377 - val_loss: 1.4082\n",
      "Epoch 2380/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8314 - val_loss: 1.4051\n",
      "Epoch 2381/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8138 - val_loss: 1.4311\n",
      "Epoch 2382/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8148 - val_loss: 1.3982\n",
      "Epoch 2383/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8133 - val_loss: 1.4158\n",
      "Epoch 2384/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8498 - val_loss: 1.3810\n",
      "Epoch 2385/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 0.8209 - val_loss: 1.4120\n",
      "Epoch 2386/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8158 - val_loss: 1.3998\n",
      "Epoch 2387/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8324 - val_loss: 1.4022\n",
      "Epoch 2388/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8282 - val_loss: 1.3941\n",
      "Epoch 2389/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8200 - val_loss: 1.3836\n",
      "Epoch 2390/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8351 - val_loss: 1.3773\n",
      "Epoch 2391/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8222 - val_loss: 1.3946\n",
      "Epoch 2392/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8100 - val_loss: 1.4044\n",
      "Epoch 2393/5000\n",
      "572/572 [==============================] - 0s 687us/step - loss: 0.8189 - val_loss: 1.4019\n",
      "Epoch 2394/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8177 - val_loss: 1.4280\n",
      "Epoch 2395/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8144 - val_loss: 1.4214\n",
      "Epoch 2396/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8321 - val_loss: 1.3991\n",
      "Epoch 2397/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8208 - val_loss: 1.4073\n",
      "Epoch 2398/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.8256 - val_loss: 1.4335\n",
      "Epoch 2399/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8318 - val_loss: 1.4387\n",
      "Epoch 2400/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.8387 - val_loss: 1.4261\n",
      "Epoch 2401/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8364 - val_loss: 1.4667\n",
      "Epoch 2402/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8199 - val_loss: 1.4549\n",
      "Epoch 2403/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8258 - val_loss: 1.4206\n",
      "Epoch 2404/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8314 - val_loss: 1.4332\n",
      "Epoch 2405/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8175 - val_loss: 1.4365\n",
      "Epoch 2406/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8212 - val_loss: 1.4138\n",
      "Epoch 2407/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8202 - val_loss: 1.3989\n",
      "Epoch 2408/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8384 - val_loss: 1.3795\n",
      "Epoch 2409/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8165 - val_loss: 1.3935\n",
      "Epoch 2410/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8268 - val_loss: 1.4051\n",
      "Epoch 2411/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8230 - val_loss: 1.4181\n",
      "Epoch 2412/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8209 - val_loss: 1.3926\n",
      "Epoch 2413/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8176 - val_loss: 1.3859\n",
      "Epoch 2414/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8196 - val_loss: 1.3861\n",
      "Epoch 2415/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8167 - val_loss: 1.3924\n",
      "Epoch 2416/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8348 - val_loss: 1.4331\n",
      "Epoch 2417/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8221 - val_loss: 1.4304\n",
      "Epoch 2418/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8167 - val_loss: 1.3968\n",
      "Epoch 2419/5000\n",
      "572/572 [==============================] - 0s 701us/step - loss: 0.8218 - val_loss: 1.4094\n",
      "Epoch 2420/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8206 - val_loss: 1.3969\n",
      "Epoch 2421/5000\n",
      "572/572 [==============================] - 0s 714us/step - loss: 0.8281 - val_loss: 1.3931\n",
      "Epoch 2422/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8319 - val_loss: 1.3925\n",
      "Epoch 2423/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8190 - val_loss: 1.3760\n",
      "Epoch 2424/5000\n",
      "572/572 [==============================] - 0s 690us/step - loss: 0.8161 - val_loss: 1.3829\n",
      "Epoch 2425/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 0.8337 - val_loss: 1.3890\n",
      "Epoch 2426/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8331 - val_loss: 1.4016\n",
      "Epoch 2427/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8303 - val_loss: 1.4154\n",
      "Epoch 2428/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8168 - val_loss: 1.4527\n",
      "Epoch 2429/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8217 - val_loss: 1.4455\n",
      "Epoch 2430/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8214 - val_loss: 1.4324\n",
      "Epoch 2431/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8286 - val_loss: 1.4020\n",
      "Epoch 2432/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8181 - val_loss: 1.4381\n",
      "Epoch 2433/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8379 - val_loss: 1.4254\n",
      "Epoch 2434/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8296 - val_loss: 1.4119\n",
      "Epoch 2435/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8235 - val_loss: 1.4159\n",
      "Epoch 2436/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8167 - val_loss: 1.4072\n",
      "Epoch 2437/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8267 - val_loss: 1.3829\n",
      "Epoch 2438/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8219 - val_loss: 1.4150\n",
      "Epoch 2439/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8400 - val_loss: 1.4350\n",
      "Epoch 2440/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8290 - val_loss: 1.4007\n",
      "Epoch 2441/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8280 - val_loss: 1.3961\n",
      "Epoch 2442/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8224 - val_loss: 1.3784\n",
      "Epoch 2443/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8379 - val_loss: 1.3945\n",
      "Epoch 2444/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8211 - val_loss: 1.4081\n",
      "Epoch 2445/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.8322 - val_loss: 1.4071\n",
      "Epoch 2446/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 640us/step - loss: 0.8258 - val_loss: 1.4119\n",
      "Epoch 2447/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8248 - val_loss: 1.3989\n",
      "Epoch 2448/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.8161 - val_loss: 1.3933\n",
      "Epoch 2449/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8176 - val_loss: 1.3841\n",
      "Epoch 2450/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8207 - val_loss: 1.4074\n",
      "Epoch 2451/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8185 - val_loss: 1.4457\n",
      "Epoch 2452/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8127 - val_loss: 1.3975\n",
      "Epoch 2453/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8248 - val_loss: 1.4174\n",
      "Epoch 2454/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8254 - val_loss: 1.3927\n",
      "Epoch 2455/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8203 - val_loss: 1.4363\n",
      "Epoch 2456/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8288 - val_loss: 1.4809\n",
      "Epoch 2457/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8167 - val_loss: 1.4559\n",
      "Epoch 2458/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8242 - val_loss: 1.4144\n",
      "Epoch 2459/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8170 - val_loss: 1.4241\n",
      "Epoch 2460/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.8228 - val_loss: 1.3879\n",
      "Epoch 2461/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8256 - val_loss: 1.3917\n",
      "Epoch 2462/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8317 - val_loss: 1.4095\n",
      "Epoch 2463/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8251 - val_loss: 1.4295\n",
      "Epoch 2464/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8309 - val_loss: 1.4252\n",
      "Epoch 2465/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8428 - val_loss: 1.4118\n",
      "Epoch 2466/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8111 - val_loss: 1.3992\n",
      "Epoch 2467/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8280 - val_loss: 1.4070\n",
      "Epoch 2468/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8335 - val_loss: 1.4311\n",
      "Epoch 2469/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8398 - val_loss: 1.3715\n",
      "Epoch 2470/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8379 - val_loss: 1.3639\n",
      "Epoch 2471/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8121 - val_loss: 1.3770\n",
      "Epoch 2472/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8234 - val_loss: 1.4043\n",
      "Epoch 2473/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8286 - val_loss: 1.3907\n",
      "Epoch 2474/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8229 - val_loss: 1.3764\n",
      "Epoch 2475/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8241 - val_loss: 1.4015\n",
      "Epoch 2476/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8362 - val_loss: 1.4413\n",
      "Epoch 2477/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8247 - val_loss: 1.4075\n",
      "Epoch 2478/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8327 - val_loss: 1.3905\n",
      "Epoch 2479/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8176 - val_loss: 1.4255\n",
      "Epoch 2480/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8115 - val_loss: 1.4247\n",
      "Epoch 2481/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8430 - val_loss: 1.3973\n",
      "Epoch 2482/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8307 - val_loss: 1.3757\n",
      "Epoch 2483/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.8263 - val_loss: 1.3819\n",
      "Epoch 2484/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8183 - val_loss: 1.3744\n",
      "Epoch 2485/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8356 - val_loss: 1.4164\n",
      "Epoch 2486/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8270 - val_loss: 1.3982\n",
      "Epoch 2487/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8233 - val_loss: 1.3826\n",
      "Epoch 2488/5000\n",
      "572/572 [==============================] - 0s 621us/step - loss: 0.8247 - val_loss: 1.3985\n",
      "Epoch 2489/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8208 - val_loss: 1.3906\n",
      "Epoch 2490/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8331 - val_loss: 1.3880\n",
      "Epoch 2491/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8236 - val_loss: 1.3871\n",
      "Epoch 2492/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8314 - val_loss: 1.4112\n",
      "Epoch 2493/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8084 - val_loss: 1.3771\n",
      "Epoch 2494/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8241 - val_loss: 1.3772\n",
      "Epoch 2495/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8227 - val_loss: 1.3987\n",
      "Epoch 2496/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8196 - val_loss: 1.4212\n",
      "Epoch 2497/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8325 - val_loss: 1.4163\n",
      "Epoch 2498/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8176 - val_loss: 1.4195\n",
      "Epoch 2499/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8161 - val_loss: 1.4034\n",
      "Epoch 2500/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8101 - val_loss: 1.4231\n",
      "Epoch 2501/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8254 - val_loss: 1.4294\n",
      "Epoch 2502/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8218 - val_loss: 1.4098\n",
      "Epoch 2503/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8363 - val_loss: 1.3948\n",
      "Epoch 2504/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8154 - val_loss: 1.4323\n",
      "Epoch 2505/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8184 - val_loss: 1.4175\n",
      "Epoch 2506/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8256 - val_loss: 1.3705\n",
      "Epoch 2507/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8279 - val_loss: 1.3725\n",
      "Epoch 2508/5000\n",
      "572/572 [==============================] - 0s 619us/step - loss: 0.8456 - val_loss: 1.4142\n",
      "Epoch 2509/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8330 - val_loss: 1.4145\n",
      "Epoch 2510/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8333 - val_loss: 1.3876\n",
      "Epoch 2511/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8111 - val_loss: 1.3761\n",
      "Epoch 2512/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8118 - val_loss: 1.3931\n",
      "Epoch 2513/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8181 - val_loss: 1.4021\n",
      "Epoch 2514/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8251 - val_loss: 1.3950\n",
      "Epoch 2515/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8370 - val_loss: 1.3937\n",
      "Epoch 2516/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8229 - val_loss: 1.3870\n",
      "Epoch 2517/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.8190 - val_loss: 1.3763\n",
      "Epoch 2518/5000\n",
      "572/572 [==============================] - 0s 831us/step - loss: 0.8400 - val_loss: 1.3792\n",
      "Epoch 2519/5000\n",
      "572/572 [==============================] - 0s 700us/step - loss: 0.8365 - val_loss: 1.3985\n",
      "Epoch 2520/5000\n",
      "572/572 [==============================] - 0s 830us/step - loss: 0.8223 - val_loss: 1.3939\n",
      "Epoch 2521/5000\n",
      "572/572 [==============================] - 0s 869us/step - loss: 0.8292 - val_loss: 1.4078\n",
      "Epoch 2522/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 684us/step - loss: 0.8204 - val_loss: 1.3882\n",
      "Epoch 2523/5000\n",
      "572/572 [==============================] - 0s 715us/step - loss: 0.8100 - val_loss: 1.3769\n",
      "Epoch 2524/5000\n",
      "572/572 [==============================] - 0s 800us/step - loss: 0.8228 - val_loss: 1.3696\n",
      "Epoch 2525/5000\n",
      "572/572 [==============================] - 0s 761us/step - loss: 0.8341 - val_loss: 1.4340\n",
      "Epoch 2526/5000\n",
      "572/572 [==============================] - 0s 781us/step - loss: 0.8283 - val_loss: 1.4476\n",
      "Epoch 2527/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8382 - val_loss: 1.4354\n",
      "Epoch 2528/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8210 - val_loss: 1.3921\n",
      "Epoch 2529/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8275 - val_loss: 1.3955\n",
      "Epoch 2530/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8301 - val_loss: 1.3887\n",
      "Epoch 2531/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.8258 - val_loss: 1.4093\n",
      "Epoch 2532/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8121 - val_loss: 1.3976\n",
      "Epoch 2533/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.8191 - val_loss: 1.3994\n",
      "Epoch 2534/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8272 - val_loss: 1.4217\n",
      "Epoch 2535/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8295 - val_loss: 1.3984\n",
      "Epoch 2536/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8188 - val_loss: 1.4105\n",
      "Epoch 2537/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8293 - val_loss: 1.3770\n",
      "Epoch 2538/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8144 - val_loss: 1.3725\n",
      "Epoch 2539/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8291 - val_loss: 1.3716\n",
      "Epoch 2540/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8236 - val_loss: 1.4013\n",
      "Epoch 2541/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8300 - val_loss: 1.3935\n",
      "Epoch 2542/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8230 - val_loss: 1.3756\n",
      "Epoch 2543/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8139 - val_loss: 1.3974\n",
      "Epoch 2544/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8183 - val_loss: 1.4276\n",
      "Epoch 2545/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8051 - val_loss: 1.4241\n",
      "Epoch 2546/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8164 - val_loss: 1.3845\n",
      "Epoch 2547/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8234 - val_loss: 1.3928\n",
      "Epoch 2548/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8247 - val_loss: 1.4144\n",
      "Epoch 2549/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8287 - val_loss: 1.4135\n",
      "Epoch 2550/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8308 - val_loss: 1.4192\n",
      "Epoch 2551/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8188 - val_loss: 1.4294\n",
      "Epoch 2552/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8271 - val_loss: 1.3939\n",
      "Epoch 2553/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8258 - val_loss: 1.3718\n",
      "Epoch 2554/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8194 - val_loss: 1.3804\n",
      "Epoch 2555/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8262 - val_loss: 1.3892\n",
      "Epoch 2556/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8347 - val_loss: 1.3787\n",
      "Epoch 2557/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8217 - val_loss: 1.3679\n",
      "Epoch 2558/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8222 - val_loss: 1.3690\n",
      "Epoch 2559/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8207 - val_loss: 1.3778\n",
      "Epoch 2560/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8192 - val_loss: 1.3797\n",
      "Epoch 2561/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8280 - val_loss: 1.3735\n",
      "Epoch 2562/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8401 - val_loss: 1.3761\n",
      "Epoch 2563/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8351 - val_loss: 1.4115\n",
      "Epoch 2564/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8237 - val_loss: 1.3759\n",
      "Epoch 2565/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8181 - val_loss: 1.3854\n",
      "Epoch 2566/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8151 - val_loss: 1.4056\n",
      "Epoch 2567/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8193 - val_loss: 1.4319\n",
      "Epoch 2568/5000\n",
      "572/572 [==============================] - 0s 692us/step - loss: 0.8283 - val_loss: 1.4571\n",
      "Epoch 2569/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8127 - val_loss: 1.4827\n",
      "Epoch 2570/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.8190 - val_loss: 1.4578\n",
      "Epoch 2571/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8192 - val_loss: 1.4252\n",
      "Epoch 2572/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8233 - val_loss: 1.4056\n",
      "Epoch 2573/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8252 - val_loss: 1.3818\n",
      "Epoch 2574/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8150 - val_loss: 1.3973\n",
      "Epoch 2575/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8272 - val_loss: 1.3848\n",
      "Epoch 2576/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8361 - val_loss: 1.3888\n",
      "Epoch 2577/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8166 - val_loss: 1.4309\n",
      "Epoch 2578/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8227 - val_loss: 1.4334\n",
      "Epoch 2579/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8132 - val_loss: 1.3946\n",
      "Epoch 2580/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8257 - val_loss: 1.3988\n",
      "Epoch 2581/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8220 - val_loss: 1.3834\n",
      "Epoch 2582/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8223 - val_loss: 1.4058\n",
      "Epoch 2583/5000\n",
      "572/572 [==============================] - 0s 608us/step - loss: 0.8063 - val_loss: 1.4256\n",
      "Epoch 2584/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8120 - val_loss: 1.4146\n",
      "Epoch 2585/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8198 - val_loss: 1.4074\n",
      "Epoch 2586/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8337 - val_loss: 1.3807\n",
      "Epoch 2587/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8191 - val_loss: 1.3887\n",
      "Epoch 2588/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8248 - val_loss: 1.3840\n",
      "Epoch 2589/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8364 - val_loss: 1.3681\n",
      "Epoch 2590/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8382 - val_loss: 1.3872\n",
      "Epoch 2591/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8313 - val_loss: 1.3761\n",
      "Epoch 2592/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.8178 - val_loss: 1.3727\n",
      "Epoch 2593/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8268 - val_loss: 1.3871\n",
      "Epoch 2594/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8257 - val_loss: 1.3603\n",
      "Epoch 2595/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8112 - val_loss: 1.3874\n",
      "Epoch 2596/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8062 - val_loss: 1.4017\n",
      "Epoch 2597/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.8167 - val_loss: 1.3790\n",
      "Epoch 2598/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 655us/step - loss: 0.8137 - val_loss: 1.3961\n",
      "Epoch 2599/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8188 - val_loss: 1.3933\n",
      "Epoch 2600/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8342 - val_loss: 1.3826\n",
      "Epoch 2601/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8206 - val_loss: 1.3911\n",
      "Epoch 2602/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8123 - val_loss: 1.3760\n",
      "Epoch 2603/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8407 - val_loss: 1.3827\n",
      "Epoch 2604/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8258 - val_loss: 1.3960\n",
      "Epoch 2605/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8221 - val_loss: 1.3769\n",
      "Epoch 2606/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8355 - val_loss: 1.4238\n",
      "Epoch 2607/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8312 - val_loss: 1.4236\n",
      "Epoch 2608/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8214 - val_loss: 1.4112\n",
      "Epoch 2609/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8129 - val_loss: 1.3934\n",
      "Epoch 2610/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8282 - val_loss: 1.3869\n",
      "Epoch 2611/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8278 - val_loss: 1.3918\n",
      "Epoch 2612/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8199 - val_loss: 1.4002\n",
      "Epoch 2613/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8413 - val_loss: 1.3805\n",
      "Epoch 2614/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8074 - val_loss: 1.3857\n",
      "Epoch 2615/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8073 - val_loss: 1.3740\n",
      "Epoch 2616/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8137 - val_loss: 1.3990\n",
      "Epoch 2617/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8250 - val_loss: 1.4102\n",
      "Epoch 2618/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8270 - val_loss: 1.4026\n",
      "Epoch 2619/5000\n",
      "572/572 [==============================] - 0s 619us/step - loss: 0.8448 - val_loss: 1.4066\n",
      "Epoch 2620/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8220 - val_loss: 1.3870\n",
      "Epoch 2621/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8214 - val_loss: 1.4330\n",
      "Epoch 2622/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8193 - val_loss: 1.4004\n",
      "Epoch 2623/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8271 - val_loss: 1.4133\n",
      "Epoch 2624/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8192 - val_loss: 1.4246\n",
      "Epoch 2625/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8335 - val_loss: 1.3812\n",
      "Epoch 2626/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8264 - val_loss: 1.3893\n",
      "Epoch 2627/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8209 - val_loss: 1.4196\n",
      "Epoch 2628/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8267 - val_loss: 1.3825\n",
      "Epoch 2629/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8126 - val_loss: 1.3794\n",
      "Epoch 2630/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8160 - val_loss: 1.4323\n",
      "Epoch 2631/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8187 - val_loss: 1.4007\n",
      "Epoch 2632/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8242 - val_loss: 1.4193\n",
      "Epoch 2633/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8216 - val_loss: 1.3682\n",
      "Epoch 2634/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8255 - val_loss: 1.4008\n",
      "Epoch 2635/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8160 - val_loss: 1.4152\n",
      "Epoch 2636/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8280 - val_loss: 1.3908\n",
      "Epoch 2637/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.8353 - val_loss: 1.4040\n",
      "Epoch 2638/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8215 - val_loss: 1.4137\n",
      "Epoch 2639/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8112 - val_loss: 1.4106\n",
      "Epoch 2640/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8187 - val_loss: 1.3904\n",
      "Epoch 2641/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8251 - val_loss: 1.4003\n",
      "Epoch 2642/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8186 - val_loss: 1.3866\n",
      "Epoch 2643/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8104 - val_loss: 1.3899\n",
      "Epoch 2644/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8311 - val_loss: 1.3891\n",
      "Epoch 2645/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8361 - val_loss: 1.3809\n",
      "Epoch 2646/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8129 - val_loss: 1.3922\n",
      "Epoch 2647/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8172 - val_loss: 1.3781\n",
      "Epoch 2648/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8237 - val_loss: 1.4098\n",
      "Epoch 2649/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8253 - val_loss: 1.4313\n",
      "Epoch 2650/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.8141 - val_loss: 1.4009\n",
      "Epoch 2651/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8364 - val_loss: 1.4195\n",
      "Epoch 2652/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8284 - val_loss: 1.3802\n",
      "Epoch 2653/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8239 - val_loss: 1.3691\n",
      "Epoch 2654/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8134 - val_loss: 1.3675\n",
      "Epoch 2655/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8193 - val_loss: 1.3775\n",
      "Epoch 2656/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8219 - val_loss: 1.3782\n",
      "Epoch 2657/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8249 - val_loss: 1.4064\n",
      "Epoch 2658/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8325 - val_loss: 1.3871\n",
      "Epoch 2659/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8181 - val_loss: 1.3923\n",
      "Epoch 2660/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8330 - val_loss: 1.3637\n",
      "Epoch 2661/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8311 - val_loss: 1.3686\n",
      "Epoch 2662/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8221 - val_loss: 1.3799\n",
      "Epoch 2663/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.8254 - val_loss: 1.3917\n",
      "Epoch 2664/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8206 - val_loss: 1.3919\n",
      "Epoch 2665/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8228 - val_loss: 1.3767\n",
      "Epoch 2666/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8330 - val_loss: 1.3915\n",
      "Epoch 2667/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8083 - val_loss: 1.4008\n",
      "Epoch 2668/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8176 - val_loss: 1.3833\n",
      "Epoch 2669/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8204 - val_loss: 1.3825\n",
      "Epoch 2670/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8196 - val_loss: 1.3822\n",
      "Epoch 2671/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8171 - val_loss: 1.3886\n",
      "Epoch 2672/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8159 - val_loss: 1.4127\n",
      "Epoch 2673/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8293 - val_loss: 1.4116\n",
      "Epoch 2674/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 643us/step - loss: 0.8277 - val_loss: 1.3990\n",
      "Epoch 2675/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8259 - val_loss: 1.3791\n",
      "Epoch 2676/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8250 - val_loss: 1.3916\n",
      "Epoch 2677/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8239 - val_loss: 1.4457\n",
      "Epoch 2678/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8305 - val_loss: 1.4271\n",
      "Epoch 2679/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8218 - val_loss: 1.3992\n",
      "Epoch 2680/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8217 - val_loss: 1.3925\n",
      "Epoch 2681/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8192 - val_loss: 1.3887\n",
      "Epoch 2682/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8095 - val_loss: 1.4204\n",
      "Epoch 2683/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8184 - val_loss: 1.3888\n",
      "Epoch 2684/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8432 - val_loss: 1.3801\n",
      "Epoch 2685/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8211 - val_loss: 1.3784\n",
      "Epoch 2686/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8246 - val_loss: 1.3726\n",
      "Epoch 2687/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8142 - val_loss: 1.3655\n",
      "Epoch 2688/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8223 - val_loss: 1.3816\n",
      "Epoch 2689/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8087 - val_loss: 1.4033\n",
      "Epoch 2690/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8172 - val_loss: 1.3725\n",
      "Epoch 2691/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8126 - val_loss: 1.3855\n",
      "Epoch 2692/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8077 - val_loss: 1.4042\n",
      "Epoch 2693/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8131 - val_loss: 1.3971\n",
      "Epoch 2694/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8132 - val_loss: 1.4006\n",
      "Epoch 2695/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8099 - val_loss: 1.3804\n",
      "Epoch 2696/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8203 - val_loss: 1.3772\n",
      "Epoch 2697/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8202 - val_loss: 1.3678\n",
      "Epoch 2698/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8251 - val_loss: 1.4052\n",
      "Epoch 2699/5000\n",
      "572/572 [==============================] - 0s 620us/step - loss: 0.8318 - val_loss: 1.3978\n",
      "Epoch 2700/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8160 - val_loss: 1.3993\n",
      "Epoch 2701/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.8298 - val_loss: 1.3981\n",
      "Epoch 2702/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8238 - val_loss: 1.3779\n",
      "Epoch 2703/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8191 - val_loss: 1.3762\n",
      "Epoch 2704/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8061 - val_loss: 1.4082\n",
      "Epoch 2705/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8316 - val_loss: 1.3964\n",
      "Epoch 2706/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8112 - val_loss: 1.4048\n",
      "Epoch 2707/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8382 - val_loss: 1.3957\n",
      "Epoch 2708/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8274 - val_loss: 1.3642\n",
      "Epoch 2709/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8181 - val_loss: 1.3798\n",
      "Epoch 2710/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8240 - val_loss: 1.4118\n",
      "Epoch 2711/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8283 - val_loss: 1.3658\n",
      "Epoch 2712/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8135 - val_loss: 1.3588\n",
      "Epoch 2713/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8202 - val_loss: 1.3767\n",
      "Epoch 2714/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8280 - val_loss: 1.3754\n",
      "Epoch 2715/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8337 - val_loss: 1.3938\n",
      "Epoch 2716/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8265 - val_loss: 1.4008\n",
      "Epoch 2717/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8048 - val_loss: 1.4123\n",
      "Epoch 2718/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8154 - val_loss: 1.3727\n",
      "Epoch 2719/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8277 - val_loss: 1.4194\n",
      "Epoch 2720/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8070 - val_loss: 1.3790\n",
      "Epoch 2721/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8217 - val_loss: 1.4279\n",
      "Epoch 2722/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8214 - val_loss: 1.3714\n",
      "Epoch 2723/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8297 - val_loss: 1.4148\n",
      "Epoch 2724/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8238 - val_loss: 1.3818\n",
      "Epoch 2725/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8164 - val_loss: 1.3702\n",
      "Epoch 2726/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8216 - val_loss: 1.3673\n",
      "Epoch 2727/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8423 - val_loss: 1.3831\n",
      "Epoch 2728/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8138 - val_loss: 1.3871\n",
      "Epoch 2729/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8148 - val_loss: 1.3926\n",
      "Epoch 2730/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8271 - val_loss: 1.4006\n",
      "Epoch 2731/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8204 - val_loss: 1.3860\n",
      "Epoch 2732/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8164 - val_loss: 1.3944\n",
      "Epoch 2733/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8072 - val_loss: 1.4007\n",
      "Epoch 2734/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8172 - val_loss: 1.3758\n",
      "Epoch 2735/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8216 - val_loss: 1.3826\n",
      "Epoch 2736/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8216 - val_loss: 1.3870\n",
      "Epoch 2737/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8075 - val_loss: 1.3807\n",
      "Epoch 2738/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.8237 - val_loss: 1.3748\n",
      "Epoch 2739/5000\n",
      "572/572 [==============================] - 0s 690us/step - loss: 0.8118 - val_loss: 1.3861\n",
      "Epoch 2740/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8176 - val_loss: 1.3881\n",
      "Epoch 2741/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8229 - val_loss: 1.3907\n",
      "Epoch 2742/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8205 - val_loss: 1.3954\n",
      "Epoch 2743/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8203 - val_loss: 1.4183\n",
      "Epoch 2744/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8256 - val_loss: 1.3995\n",
      "Epoch 2745/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8196 - val_loss: 1.3680\n",
      "Epoch 2746/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8185 - val_loss: 1.3992\n",
      "Epoch 2747/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8281 - val_loss: 1.3815\n",
      "Epoch 2748/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8165 - val_loss: 1.3970\n",
      "Epoch 2749/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8183 - val_loss: 1.3817\n",
      "Epoch 2750/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 645us/step - loss: 0.8192 - val_loss: 1.3749\n",
      "Epoch 2751/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8118 - val_loss: 1.3926\n",
      "Epoch 2752/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8367 - val_loss: 1.3740\n",
      "Epoch 2753/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8151 - val_loss: 1.3608\n",
      "Epoch 2754/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8347 - val_loss: 1.3561\n",
      "Epoch 2755/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8228 - val_loss: 1.3764\n",
      "Epoch 2756/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8147 - val_loss: 1.3650\n",
      "Epoch 2757/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8190 - val_loss: 1.3895\n",
      "Epoch 2758/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8291 - val_loss: 1.3941\n",
      "Epoch 2759/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.8338 - val_loss: 1.3984\n",
      "Epoch 2760/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8350 - val_loss: 1.4032\n",
      "Epoch 2761/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.8271 - val_loss: 1.3769\n",
      "Epoch 2762/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8230 - val_loss: 1.3675\n",
      "Epoch 2763/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8105 - val_loss: 1.3682\n",
      "Epoch 2764/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8220 - val_loss: 1.3686\n",
      "Epoch 2765/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8169 - val_loss: 1.3908\n",
      "Epoch 2766/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8195 - val_loss: 1.3893\n",
      "Epoch 2767/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8234 - val_loss: 1.3965\n",
      "Epoch 2768/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8274 - val_loss: 1.3816\n",
      "Epoch 2769/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8287 - val_loss: 1.3710\n",
      "Epoch 2770/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8282 - val_loss: 1.3677\n",
      "Epoch 2771/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8285 - val_loss: 1.3891\n",
      "Epoch 2772/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8215 - val_loss: 1.3787\n",
      "Epoch 2773/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8197 - val_loss: 1.3942\n",
      "Epoch 2774/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8336 - val_loss: 1.4088\n",
      "Epoch 2775/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8285 - val_loss: 1.4276\n",
      "Epoch 2776/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8104 - val_loss: 1.3772\n",
      "Epoch 2777/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8124 - val_loss: 1.3748\n",
      "Epoch 2778/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8206 - val_loss: 1.3931\n",
      "Epoch 2779/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8248 - val_loss: 1.3655\n",
      "Epoch 2780/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8228 - val_loss: 1.3646\n",
      "Epoch 2781/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8047 - val_loss: 1.3768\n",
      "Epoch 2782/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8045 - val_loss: 1.3688\n",
      "Epoch 2783/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8138 - val_loss: 1.4054\n",
      "Epoch 2784/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.8196 - val_loss: 1.3957\n",
      "Epoch 2785/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8179 - val_loss: 1.4026\n",
      "Epoch 2786/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8204 - val_loss: 1.3780\n",
      "Epoch 2787/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8350 - val_loss: 1.3727\n",
      "Epoch 2788/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8157 - val_loss: 1.3879\n",
      "Epoch 2789/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8275 - val_loss: 1.3758\n",
      "Epoch 2790/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.8200 - val_loss: 1.4455\n",
      "Epoch 2791/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8076 - val_loss: 1.4164\n",
      "Epoch 2792/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8145 - val_loss: 1.3734\n",
      "Epoch 2793/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8160 - val_loss: 1.3654\n",
      "Epoch 2794/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8162 - val_loss: 1.3784\n",
      "Epoch 2795/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8202 - val_loss: 1.3813\n",
      "Epoch 2796/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8396 - val_loss: 1.3949\n",
      "Epoch 2797/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8241 - val_loss: 1.3970\n",
      "Epoch 2798/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.8302 - val_loss: 1.3839\n",
      "Epoch 2799/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8190 - val_loss: 1.3686\n",
      "Epoch 2800/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8241 - val_loss: 1.3827\n",
      "Epoch 2801/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8107 - val_loss: 1.3984\n",
      "Epoch 2802/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8177 - val_loss: 1.3949\n",
      "Epoch 2803/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8081 - val_loss: 1.3654\n",
      "Epoch 2804/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8173 - val_loss: 1.3773\n",
      "Epoch 2805/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8227 - val_loss: 1.3744\n",
      "Epoch 2806/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8128 - val_loss: 1.3824\n",
      "Epoch 2807/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.8040 - val_loss: 1.3833\n",
      "Epoch 2808/5000\n",
      "572/572 [==============================] - 0s 622us/step - loss: 0.8088 - val_loss: 1.3723\n",
      "Epoch 2809/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8340 - val_loss: 1.3583\n",
      "Epoch 2810/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8118 - val_loss: 1.3826\n",
      "Epoch 2811/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8181 - val_loss: 1.4030\n",
      "Epoch 2812/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8329 - val_loss: 1.3939\n",
      "Epoch 2813/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8057 - val_loss: 1.3950\n",
      "Epoch 2814/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8069 - val_loss: 1.3945\n",
      "Epoch 2815/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8252 - val_loss: 1.4115\n",
      "Epoch 2816/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8092 - val_loss: 1.4081\n",
      "Epoch 2817/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8244 - val_loss: 1.4148\n",
      "Epoch 2818/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.8236 - val_loss: 1.4104\n",
      "Epoch 2819/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8360 - val_loss: 1.3797\n",
      "Epoch 2820/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8326 - val_loss: 1.3912\n",
      "Epoch 2821/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8222 - val_loss: 1.3739\n",
      "Epoch 2822/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8320 - val_loss: 1.3905\n",
      "Epoch 2823/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8167 - val_loss: 1.3532\n",
      "Epoch 2824/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8054 - val_loss: 1.3863\n",
      "Epoch 2825/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8167 - val_loss: 1.3759\n",
      "Epoch 2826/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 656us/step - loss: 0.8324 - val_loss: 1.4141\n",
      "Epoch 2827/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8279 - val_loss: 1.3998\n",
      "Epoch 2828/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8297 - val_loss: 1.3673\n",
      "Epoch 2829/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8211 - val_loss: 1.3786\n",
      "Epoch 2830/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8201 - val_loss: 1.3909\n",
      "Epoch 2831/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8259 - val_loss: 1.4048\n",
      "Epoch 2832/5000\n",
      "572/572 [==============================] - 0s 620us/step - loss: 0.8081 - val_loss: 1.4299\n",
      "Epoch 2833/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8056 - val_loss: 1.4144\n",
      "Epoch 2834/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.8153 - val_loss: 1.4072\n",
      "Epoch 2835/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8097 - val_loss: 1.4023\n",
      "Epoch 2836/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8138 - val_loss: 1.3965\n",
      "Epoch 2837/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8216 - val_loss: 1.4028\n",
      "Epoch 2838/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8101 - val_loss: 1.3832\n",
      "Epoch 2839/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8014 - val_loss: 1.4011\n",
      "Epoch 2840/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7966 - val_loss: 1.4002\n",
      "Epoch 2841/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8109 - val_loss: 1.3839\n",
      "Epoch 2842/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8024 - val_loss: 1.4367\n",
      "Epoch 2843/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8271 - val_loss: 1.4086\n",
      "Epoch 2844/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8163 - val_loss: 1.4320\n",
      "Epoch 2845/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8198 - val_loss: 1.4243\n",
      "Epoch 2846/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8245 - val_loss: 1.3623\n",
      "Epoch 2847/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8195 - val_loss: 1.3797\n",
      "Epoch 2848/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8080 - val_loss: 1.4079\n",
      "Epoch 2849/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8040 - val_loss: 1.4001\n",
      "Epoch 2850/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8021 - val_loss: 1.3857\n",
      "Epoch 2851/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8235 - val_loss: 1.3762\n",
      "Epoch 2852/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8314 - val_loss: 1.3979\n",
      "Epoch 2853/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8276 - val_loss: 1.4318\n",
      "Epoch 2854/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8249 - val_loss: 1.4298\n",
      "Epoch 2855/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8278 - val_loss: 1.3915\n",
      "Epoch 2856/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8248 - val_loss: 1.4509\n",
      "Epoch 2857/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8184 - val_loss: 1.3963\n",
      "Epoch 2858/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.8178 - val_loss: 1.3888\n",
      "Epoch 2859/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8229 - val_loss: 1.3682\n",
      "Epoch 2860/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8261 - val_loss: 1.3753\n",
      "Epoch 2861/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8127 - val_loss: 1.3702\n",
      "Epoch 2862/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8092 - val_loss: 1.3735\n",
      "Epoch 2863/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8195 - val_loss: 1.3725\n",
      "Epoch 2864/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8256 - val_loss: 1.3733\n",
      "Epoch 2865/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8209 - val_loss: 1.3668\n",
      "Epoch 2866/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8122 - val_loss: 1.3771\n",
      "Epoch 2867/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8232 - val_loss: 1.3595\n",
      "Epoch 2868/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8106 - val_loss: 1.3717\n",
      "Epoch 2869/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8266 - val_loss: 1.3645\n",
      "Epoch 2870/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8183 - val_loss: 1.3889\n",
      "Epoch 2871/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8145 - val_loss: 1.4023\n",
      "Epoch 2872/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8138 - val_loss: 1.4353\n",
      "Epoch 2873/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8148 - val_loss: 1.4792\n",
      "Epoch 2874/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8154 - val_loss: 1.4086\n",
      "Epoch 2875/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8090 - val_loss: 1.4013\n",
      "Epoch 2876/5000\n",
      "572/572 [==============================] - 0s 690us/step - loss: 0.8127 - val_loss: 1.4016\n",
      "Epoch 2877/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8219 - val_loss: 1.3687\n",
      "Epoch 2878/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8133 - val_loss: 1.3772\n",
      "Epoch 2879/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8107 - val_loss: 1.3657\n",
      "Epoch 2880/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8057 - val_loss: 1.3750\n",
      "Epoch 2881/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8355 - val_loss: 1.3713\n",
      "Epoch 2882/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8123 - val_loss: 1.3958\n",
      "Epoch 2883/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8242 - val_loss: 1.4009\n",
      "Epoch 2884/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8174 - val_loss: 1.4005\n",
      "Epoch 2885/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8195 - val_loss: 1.3832\n",
      "Epoch 2886/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8115 - val_loss: 1.3791\n",
      "Epoch 2887/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8217 - val_loss: 1.3915\n",
      "Epoch 2888/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 0.8266 - val_loss: 1.3769\n",
      "Epoch 2889/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8095 - val_loss: 1.3724\n",
      "Epoch 2890/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8119 - val_loss: 1.3803\n",
      "Epoch 2891/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8207 - val_loss: 1.3819\n",
      "Epoch 2892/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8221 - val_loss: 1.4234\n",
      "Epoch 2893/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8175 - val_loss: 1.4045\n",
      "Epoch 2894/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8335 - val_loss: 1.4021\n",
      "Epoch 2895/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8237 - val_loss: 1.4343\n",
      "Epoch 2896/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8173 - val_loss: 1.4073\n",
      "Epoch 2897/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8187 - val_loss: 1.3761\n",
      "Epoch 2898/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8166 - val_loss: 1.3784\n",
      "Epoch 2899/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8011 - val_loss: 1.3932\n",
      "Epoch 2900/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8301 - val_loss: 1.3858\n",
      "Epoch 2901/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8255 - val_loss: 1.3938\n",
      "Epoch 2902/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 672us/step - loss: 0.8209 - val_loss: 1.3993\n",
      "Epoch 2903/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8215 - val_loss: 1.3676\n",
      "Epoch 2904/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8142 - val_loss: 1.3699\n",
      "Epoch 2905/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8154 - val_loss: 1.3760\n",
      "Epoch 2906/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8240 - val_loss: 1.3911\n",
      "Epoch 2907/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8098 - val_loss: 1.3914\n",
      "Epoch 2908/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8132 - val_loss: 1.3895\n",
      "Epoch 2909/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8047 - val_loss: 1.3987\n",
      "Epoch 2910/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8278 - val_loss: 1.3636\n",
      "Epoch 2911/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8112 - val_loss: 1.3793\n",
      "Epoch 2912/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8198 - val_loss: 1.4055\n",
      "Epoch 2913/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8222 - val_loss: 1.3826\n",
      "Epoch 2914/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8203 - val_loss: 1.3669\n",
      "Epoch 2915/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8225 - val_loss: 1.3809\n",
      "Epoch 2916/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8101 - val_loss: 1.4266\n",
      "Epoch 2917/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8140 - val_loss: 1.4034\n",
      "Epoch 2918/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8162 - val_loss: 1.4115\n",
      "Epoch 2919/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8262 - val_loss: 1.3723\n",
      "Epoch 2920/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.8142 - val_loss: 1.3995\n",
      "Epoch 2921/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8266 - val_loss: 1.3854\n",
      "Epoch 2922/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8206 - val_loss: 1.3938\n",
      "Epoch 2923/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8308 - val_loss: 1.3866\n",
      "Epoch 2924/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8278 - val_loss: 1.3857\n",
      "Epoch 2925/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8115 - val_loss: 1.3986\n",
      "Epoch 2926/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8067 - val_loss: 1.4229\n",
      "Epoch 2927/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.8147 - val_loss: 1.4022\n",
      "Epoch 2928/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8155 - val_loss: 1.3721\n",
      "Epoch 2929/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.8106 - val_loss: 1.3585\n",
      "Epoch 2930/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8036 - val_loss: 1.3945\n",
      "Epoch 2931/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.8070 - val_loss: 1.4133\n",
      "Epoch 2932/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8126 - val_loss: 1.3952\n",
      "Epoch 2933/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8094 - val_loss: 1.4166\n",
      "Epoch 2934/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8226 - val_loss: 1.3929\n",
      "Epoch 2935/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8139 - val_loss: 1.3934\n",
      "Epoch 2936/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8180 - val_loss: 1.4084\n",
      "Epoch 2937/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8137 - val_loss: 1.3988\n",
      "Epoch 2938/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8134 - val_loss: 1.3647\n",
      "Epoch 2939/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8021 - val_loss: 1.3705\n",
      "Epoch 2940/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8307 - val_loss: 1.4011\n",
      "Epoch 2941/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8241 - val_loss: 1.3713\n",
      "Epoch 2942/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8266 - val_loss: 1.3725\n",
      "Epoch 2943/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8194 - val_loss: 1.3538\n",
      "Epoch 2944/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8223 - val_loss: 1.3743\n",
      "Epoch 2945/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8293 - val_loss: 1.3656\n",
      "Epoch 2946/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8342 - val_loss: 1.3819\n",
      "Epoch 2947/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8217 - val_loss: 1.3743\n",
      "Epoch 2948/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8091 - val_loss: 1.3720\n",
      "Epoch 2949/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8149 - val_loss: 1.3696\n",
      "Epoch 2950/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8211 - val_loss: 1.3532\n",
      "Epoch 2951/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8194 - val_loss: 1.3537\n",
      "Epoch 2952/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8086 - val_loss: 1.3691\n",
      "Epoch 2953/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.8108 - val_loss: 1.3869\n",
      "Epoch 2954/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8198 - val_loss: 1.3987\n",
      "Epoch 2955/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8225 - val_loss: 1.3696\n",
      "Epoch 2956/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8297 - val_loss: 1.3912\n",
      "Epoch 2957/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8170 - val_loss: 1.3840\n",
      "Epoch 2958/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8139 - val_loss: 1.3743\n",
      "Epoch 2959/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8000 - val_loss: 1.4030\n",
      "Epoch 2960/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8148 - val_loss: 1.4059\n",
      "Epoch 2961/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8272 - val_loss: 1.3989\n",
      "Epoch 2962/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8214 - val_loss: 1.3970\n",
      "Epoch 2963/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8093 - val_loss: 1.4317\n",
      "Epoch 2964/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8136 - val_loss: 1.3989\n",
      "Epoch 2965/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8097 - val_loss: 1.3964\n",
      "Epoch 2966/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8087 - val_loss: 1.3920\n",
      "Epoch 2967/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8097 - val_loss: 1.3962\n",
      "Epoch 2968/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8167 - val_loss: 1.3861\n",
      "Epoch 2969/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8181 - val_loss: 1.3682\n",
      "Epoch 2970/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8252 - val_loss: 1.3577\n",
      "Epoch 2971/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8233 - val_loss: 1.3719\n",
      "Epoch 2972/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8373 - val_loss: 1.3825\n",
      "Epoch 2973/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8097 - val_loss: 1.3659\n",
      "Epoch 2974/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8293 - val_loss: 1.3591\n",
      "Epoch 2975/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8261 - val_loss: 1.3556\n",
      "Epoch 2976/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8100 - val_loss: 1.3679\n",
      "Epoch 2977/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8151 - val_loss: 1.3734\n",
      "Epoch 2978/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 650us/step - loss: 0.8220 - val_loss: 1.3680\n",
      "Epoch 2979/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8192 - val_loss: 1.4109\n",
      "Epoch 2980/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8172 - val_loss: 1.3828\n",
      "Epoch 2981/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8319 - val_loss: 1.3967\n",
      "Epoch 2982/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8204 - val_loss: 1.3816\n",
      "Epoch 2983/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8190 - val_loss: 1.4095\n",
      "Epoch 2984/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8219 - val_loss: 1.3905\n",
      "Epoch 2985/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8139 - val_loss: 1.3745\n",
      "Epoch 2986/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8228 - val_loss: 1.3808\n",
      "Epoch 2987/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8106 - val_loss: 1.3808\n",
      "Epoch 2988/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8214 - val_loss: 1.3738\n",
      "Epoch 2989/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8121 - val_loss: 1.3732\n",
      "Epoch 2990/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.8148 - val_loss: 1.3644\n",
      "Epoch 2991/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8139 - val_loss: 1.3750\n",
      "Epoch 2992/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8225 - val_loss: 1.4237\n",
      "Epoch 2993/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8208 - val_loss: 1.4023\n",
      "Epoch 2994/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8043 - val_loss: 1.4222\n",
      "Epoch 2995/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.8110 - val_loss: 1.3934\n",
      "Epoch 2996/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8109 - val_loss: 1.3841\n",
      "Epoch 2997/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8098 - val_loss: 1.3912\n",
      "Epoch 2998/5000\n",
      "572/572 [==============================] - 0s 700us/step - loss: 0.8189 - val_loss: 1.3613\n",
      "Epoch 2999/5000\n",
      "572/572 [==============================] - 0s 751us/step - loss: 0.8275 - val_loss: 1.4004\n",
      "Epoch 3000/5000\n",
      "572/572 [==============================] - 0s 831us/step - loss: 0.8161 - val_loss: 1.3551\n",
      "Epoch 3001/5000\n",
      "572/572 [==============================] - 0s 840us/step - loss: 0.8286 - val_loss: 1.3654\n",
      "Epoch 3002/5000\n",
      "572/572 [==============================] - 0s 748us/step - loss: 0.8189 - val_loss: 1.3661\n",
      "Epoch 3003/5000\n",
      "572/572 [==============================] - 0s 794us/step - loss: 0.8157 - val_loss: 1.3738\n",
      "Epoch 3004/5000\n",
      "572/572 [==============================] - 0s 704us/step - loss: 0.8317 - val_loss: 1.3716\n",
      "Epoch 3005/5000\n",
      "572/572 [==============================] - 0s 801us/step - loss: 0.8124 - val_loss: 1.3723\n",
      "Epoch 3006/5000\n",
      "572/572 [==============================] - 0s 844us/step - loss: 0.8112 - val_loss: 1.3775\n",
      "Epoch 3007/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8124 - val_loss: 1.3522\n",
      "Epoch 3008/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8211 - val_loss: 1.3585\n",
      "Epoch 3009/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8195 - val_loss: 1.3535\n",
      "Epoch 3010/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8186 - val_loss: 1.3788\n",
      "Epoch 3011/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8159 - val_loss: 1.3629\n",
      "Epoch 3012/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8103 - val_loss: 1.3612\n",
      "Epoch 3013/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8149 - val_loss: 1.3743\n",
      "Epoch 3014/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8170 - val_loss: 1.3932\n",
      "Epoch 3015/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8105 - val_loss: 1.4033\n",
      "Epoch 3016/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8218 - val_loss: 1.3726\n",
      "Epoch 3017/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8110 - val_loss: 1.3761\n",
      "Epoch 3018/5000\n",
      "572/572 [==============================] - 0s 622us/step - loss: 0.8175 - val_loss: 1.3846\n",
      "Epoch 3019/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8097 - val_loss: 1.4089\n",
      "Epoch 3020/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8284 - val_loss: 1.3849\n",
      "Epoch 3021/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8305 - val_loss: 1.3763\n",
      "Epoch 3022/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8150 - val_loss: 1.4008\n",
      "Epoch 3023/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8153 - val_loss: 1.4051\n",
      "Epoch 3024/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8063 - val_loss: 1.4031\n",
      "Epoch 3025/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8058 - val_loss: 1.3878\n",
      "Epoch 3026/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.8271 - val_loss: 1.4161\n",
      "Epoch 3027/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8142 - val_loss: 1.4195\n",
      "Epoch 3028/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8226 - val_loss: 1.4061\n",
      "Epoch 3029/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8285 - val_loss: 1.4302\n",
      "Epoch 3030/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8194 - val_loss: 1.3982\n",
      "Epoch 3031/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8091 - val_loss: 1.3828\n",
      "Epoch 3032/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8128 - val_loss: 1.3862\n",
      "Epoch 3033/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8153 - val_loss: 1.3716\n",
      "Epoch 3034/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8037 - val_loss: 1.3778\n",
      "Epoch 3035/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8181 - val_loss: 1.3796\n",
      "Epoch 3036/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8159 - val_loss: 1.3769\n",
      "Epoch 3037/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8123 - val_loss: 1.3834\n",
      "Epoch 3038/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8247 - val_loss: 1.3708\n",
      "Epoch 3039/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8172 - val_loss: 1.3687\n",
      "Epoch 3040/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8134 - val_loss: 1.3776\n",
      "Epoch 3041/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8225 - val_loss: 1.3928\n",
      "Epoch 3042/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8114 - val_loss: 1.3845\n",
      "Epoch 3043/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8118 - val_loss: 1.3896\n",
      "Epoch 3044/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8174 - val_loss: 1.3945\n",
      "Epoch 3045/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7997 - val_loss: 1.3638\n",
      "Epoch 3046/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8166 - val_loss: 1.3709\n",
      "Epoch 3047/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8145 - val_loss: 1.3615\n",
      "Epoch 3048/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8156 - val_loss: 1.3844\n",
      "Epoch 3049/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8233 - val_loss: 1.3971\n",
      "Epoch 3050/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8105 - val_loss: 1.4069\n",
      "Epoch 3051/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8084 - val_loss: 1.3902\n",
      "Epoch 3052/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8288 - val_loss: 1.3896\n",
      "Epoch 3053/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8093 - val_loss: 1.3943\n",
      "Epoch 3054/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 663us/step - loss: 0.8055 - val_loss: 1.3665\n",
      "Epoch 3055/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8087 - val_loss: 1.3691\n",
      "Epoch 3056/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.8068 - val_loss: 1.3569\n",
      "Epoch 3057/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8222 - val_loss: 1.3987\n",
      "Epoch 3058/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8023 - val_loss: 1.3684\n",
      "Epoch 3059/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8144 - val_loss: 1.3635\n",
      "Epoch 3060/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8105 - val_loss: 1.3629\n",
      "Epoch 3061/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8017 - val_loss: 1.3829\n",
      "Epoch 3062/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8040 - val_loss: 1.3929\n",
      "Epoch 3063/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.8246 - val_loss: 1.3669\n",
      "Epoch 3064/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8212 - val_loss: 1.3591\n",
      "Epoch 3065/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.8301 - val_loss: 1.3591\n",
      "Epoch 3066/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8183 - val_loss: 1.3721\n",
      "Epoch 3067/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8118 - val_loss: 1.3528\n",
      "Epoch 3068/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8134 - val_loss: 1.3638\n",
      "Epoch 3069/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8196 - val_loss: 1.3847\n",
      "Epoch 3070/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8118 - val_loss: 1.3604\n",
      "Epoch 3071/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8089 - val_loss: 1.3666\n",
      "Epoch 3072/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8226 - val_loss: 1.3768\n",
      "Epoch 3073/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.8024 - val_loss: 1.3976\n",
      "Epoch 3074/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8234 - val_loss: 1.3747\n",
      "Epoch 3075/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8184 - val_loss: 1.3889\n",
      "Epoch 3076/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8167 - val_loss: 1.3968\n",
      "Epoch 3077/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8183 - val_loss: 1.3826\n",
      "Epoch 3078/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8114 - val_loss: 1.3946\n",
      "Epoch 3079/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8268 - val_loss: 1.3652\n",
      "Epoch 3080/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8152 - val_loss: 1.3626\n",
      "Epoch 3081/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8233 - val_loss: 1.3766\n",
      "Epoch 3082/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8287 - val_loss: 1.3758\n",
      "Epoch 3083/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8193 - val_loss: 1.3700\n",
      "Epoch 3084/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8038 - val_loss: 1.3775\n",
      "Epoch 3085/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7937 - val_loss: 1.3699\n",
      "Epoch 3086/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8167 - val_loss: 1.3695\n",
      "Epoch 3087/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8194 - val_loss: 1.3688\n",
      "Epoch 3088/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.8201 - val_loss: 1.3660\n",
      "Epoch 3089/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8137 - val_loss: 1.3667\n",
      "Epoch 3090/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8229 - val_loss: 1.3704\n",
      "Epoch 3091/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8170 - val_loss: 1.3660\n",
      "Epoch 3092/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8264 - val_loss: 1.4029\n",
      "Epoch 3093/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8160 - val_loss: 1.3592\n",
      "Epoch 3094/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8208 - val_loss: 1.3669\n",
      "Epoch 3095/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8110 - val_loss: 1.3556\n",
      "Epoch 3096/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8133 - val_loss: 1.3672\n",
      "Epoch 3097/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8187 - val_loss: 1.3710\n",
      "Epoch 3098/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8247 - val_loss: 1.3514\n",
      "Epoch 3099/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8086 - val_loss: 1.3531\n",
      "Epoch 3100/5000\n",
      "572/572 [==============================] - 0s 619us/step - loss: 0.8184 - val_loss: 1.3566\n",
      "Epoch 3101/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8211 - val_loss: 1.3709\n",
      "Epoch 3102/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8070 - val_loss: 1.4003\n",
      "Epoch 3103/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8226 - val_loss: 1.3965\n",
      "Epoch 3104/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.8055 - val_loss: 1.3818\n",
      "Epoch 3105/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8083 - val_loss: 1.3824\n",
      "Epoch 3106/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8056 - val_loss: 1.3731\n",
      "Epoch 3107/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8225 - val_loss: 1.3820\n",
      "Epoch 3108/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8103 - val_loss: 1.3733\n",
      "Epoch 3109/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8068 - val_loss: 1.3783\n",
      "Epoch 3110/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.7990 - val_loss: 1.3790\n",
      "Epoch 3111/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8075 - val_loss: 1.3822\n",
      "Epoch 3112/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.8201 - val_loss: 1.3744\n",
      "Epoch 3113/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8070 - val_loss: 1.3747\n",
      "Epoch 3114/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8068 - val_loss: 1.3804\n",
      "Epoch 3115/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8178 - val_loss: 1.3563\n",
      "Epoch 3116/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8147 - val_loss: 1.3556\n",
      "Epoch 3117/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8002 - val_loss: 1.3559\n",
      "Epoch 3118/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8065 - val_loss: 1.3792\n",
      "Epoch 3119/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8266 - val_loss: 1.3842\n",
      "Epoch 3120/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8101 - val_loss: 1.3961\n",
      "Epoch 3121/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8087 - val_loss: 1.4094\n",
      "Epoch 3122/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8098 - val_loss: 1.3912\n",
      "Epoch 3123/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8119 - val_loss: 1.3688\n",
      "Epoch 3124/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8174 - val_loss: 1.3821\n",
      "Epoch 3125/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8133 - val_loss: 1.3875\n",
      "Epoch 3126/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8267 - val_loss: 1.4017\n",
      "Epoch 3127/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8387 - val_loss: 1.3693\n",
      "Epoch 3128/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8175 - val_loss: 1.3646\n",
      "Epoch 3129/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8157 - val_loss: 1.3623\n",
      "Epoch 3130/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 668us/step - loss: 0.8069 - val_loss: 1.3705\n",
      "Epoch 3131/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8179 - val_loss: 1.3614\n",
      "Epoch 3132/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.8136 - val_loss: 1.3620\n",
      "Epoch 3133/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8217 - val_loss: 1.3730\n",
      "Epoch 3134/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8019 - val_loss: 1.3960\n",
      "Epoch 3135/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8152 - val_loss: 1.4108\n",
      "Epoch 3136/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8060 - val_loss: 1.4114\n",
      "Epoch 3137/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8109 - val_loss: 1.4259\n",
      "Epoch 3138/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8248 - val_loss: 1.3886\n",
      "Epoch 3139/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8063 - val_loss: 1.4112\n",
      "Epoch 3140/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8039 - val_loss: 1.3866\n",
      "Epoch 3141/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8174 - val_loss: 1.4152\n",
      "Epoch 3142/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8128 - val_loss: 1.3740\n",
      "Epoch 3143/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8096 - val_loss: 1.3657\n",
      "Epoch 3144/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8081 - val_loss: 1.3775\n",
      "Epoch 3145/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8107 - val_loss: 1.3839\n",
      "Epoch 3146/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8300 - val_loss: 1.4006\n",
      "Epoch 3147/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8094 - val_loss: 1.3914\n",
      "Epoch 3148/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8034 - val_loss: 1.4300\n",
      "Epoch 3149/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8132 - val_loss: 1.3912\n",
      "Epoch 3150/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8166 - val_loss: 1.3792\n",
      "Epoch 3151/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8350 - val_loss: 1.3741\n",
      "Epoch 3152/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8116 - val_loss: 1.3547\n",
      "Epoch 3153/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8110 - val_loss: 1.3643\n",
      "Epoch 3154/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8227 - val_loss: 1.3667\n",
      "Epoch 3155/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8308 - val_loss: 1.3721\n",
      "Epoch 3156/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8058 - val_loss: 1.3800\n",
      "Epoch 3157/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8223 - val_loss: 1.3846\n",
      "Epoch 3158/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8223 - val_loss: 1.3863\n",
      "Epoch 3159/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8056 - val_loss: 1.3722\n",
      "Epoch 3160/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8199 - val_loss: 1.3799\n",
      "Epoch 3161/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8407 - val_loss: 1.3678\n",
      "Epoch 3162/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8285 - val_loss: 1.3884\n",
      "Epoch 3163/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8243 - val_loss: 1.3752\n",
      "Epoch 3164/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8194 - val_loss: 1.3739\n",
      "Epoch 3165/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8298 - val_loss: 1.3579\n",
      "Epoch 3166/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.8344 - val_loss: 1.3790\n",
      "Epoch 3167/5000\n",
      "572/572 [==============================] - 0s 618us/step - loss: 0.8177 - val_loss: 1.3543\n",
      "Epoch 3168/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8145 - val_loss: 1.3721\n",
      "Epoch 3169/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8077 - val_loss: 1.3745\n",
      "Epoch 3170/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8221 - val_loss: 1.3845\n",
      "Epoch 3171/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8176 - val_loss: 1.3625\n",
      "Epoch 3172/5000\n",
      "572/572 [==============================] - 0s 616us/step - loss: 0.8088 - val_loss: 1.3779\n",
      "Epoch 3173/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8191 - val_loss: 1.3751\n",
      "Epoch 3174/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8245 - val_loss: 1.3772\n",
      "Epoch 3175/5000\n",
      "572/572 [==============================] - 0s 601us/step - loss: 0.8293 - val_loss: 1.3822\n",
      "Epoch 3176/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8164 - val_loss: 1.4113\n",
      "Epoch 3177/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8230 - val_loss: 1.4262\n",
      "Epoch 3178/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8308 - val_loss: 1.3794\n",
      "Epoch 3179/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8303 - val_loss: 1.3792\n",
      "Epoch 3180/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8038 - val_loss: 1.3685\n",
      "Epoch 3181/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8092 - val_loss: 1.3799\n",
      "Epoch 3182/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8164 - val_loss: 1.4065\n",
      "Epoch 3183/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8183 - val_loss: 1.3674\n",
      "Epoch 3184/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8136 - val_loss: 1.3834\n",
      "Epoch 3185/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8130 - val_loss: 1.3781\n",
      "Epoch 3186/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8333 - val_loss: 1.3765\n",
      "Epoch 3187/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8201 - val_loss: 1.4017\n",
      "Epoch 3188/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8092 - val_loss: 1.3772\n",
      "Epoch 3189/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.8134 - val_loss: 1.3757\n",
      "Epoch 3190/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8131 - val_loss: 1.3808\n",
      "Epoch 3191/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8279 - val_loss: 1.3597\n",
      "Epoch 3192/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8139 - val_loss: 1.3631\n",
      "Epoch 3193/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8001 - val_loss: 1.3978\n",
      "Epoch 3194/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8190 - val_loss: 1.3837\n",
      "Epoch 3195/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8254 - val_loss: 1.3794\n",
      "Epoch 3196/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8327 - val_loss: 1.3703\n",
      "Epoch 3197/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8185 - val_loss: 1.3702\n",
      "Epoch 3198/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8052 - val_loss: 1.3794\n",
      "Epoch 3199/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8184 - val_loss: 1.3738\n",
      "Epoch 3200/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8079 - val_loss: 1.3667\n",
      "Epoch 3201/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8092 - val_loss: 1.3637\n",
      "Epoch 3202/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8034 - val_loss: 1.3709\n",
      "Epoch 3203/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8176 - val_loss: 1.3671\n",
      "Epoch 3204/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8004 - val_loss: 1.3674\n",
      "Epoch 3205/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8260 - val_loss: 1.3669\n",
      "Epoch 3206/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 620us/step - loss: 0.8101 - val_loss: 1.3705\n",
      "Epoch 3207/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8228 - val_loss: 1.3786\n",
      "Epoch 3208/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8283 - val_loss: 1.3737\n",
      "Epoch 3209/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8251 - val_loss: 1.4141\n",
      "Epoch 3210/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8126 - val_loss: 1.4755\n",
      "Epoch 3211/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8162 - val_loss: 1.4162\n",
      "Epoch 3212/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8105 - val_loss: 1.4015\n",
      "Epoch 3213/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8007 - val_loss: 1.4052\n",
      "Epoch 3214/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8187 - val_loss: 1.3747\n",
      "Epoch 3215/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8303 - val_loss: 1.3605\n",
      "Epoch 3216/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8171 - val_loss: 1.3880\n",
      "Epoch 3217/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8296 - val_loss: 1.3622\n",
      "Epoch 3218/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8273 - val_loss: 1.3905\n",
      "Epoch 3219/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8176 - val_loss: 1.3709\n",
      "Epoch 3220/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.8261 - val_loss: 1.3654\n",
      "Epoch 3221/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8104 - val_loss: 1.3691\n",
      "Epoch 3222/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8261 - val_loss: 1.3620\n",
      "Epoch 3223/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8138 - val_loss: 1.3598\n",
      "Epoch 3224/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8163 - val_loss: 1.3557\n",
      "Epoch 3225/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8156 - val_loss: 1.3830\n",
      "Epoch 3226/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8194 - val_loss: 1.3802\n",
      "Epoch 3227/5000\n",
      "572/572 [==============================] - 0s 692us/step - loss: 0.8032 - val_loss: 1.3849\n",
      "Epoch 3228/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8248 - val_loss: 1.3745\n",
      "Epoch 3229/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8143 - val_loss: 1.3566\n",
      "Epoch 3230/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8123 - val_loss: 1.3577\n",
      "Epoch 3231/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8291 - val_loss: 1.3776\n",
      "Epoch 3232/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8074 - val_loss: 1.3631\n",
      "Epoch 3233/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8162 - val_loss: 1.3818\n",
      "Epoch 3234/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8023 - val_loss: 1.4106\n",
      "Epoch 3235/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8272 - val_loss: 1.3778\n",
      "Epoch 3236/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8045 - val_loss: 1.4131\n",
      "Epoch 3237/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8270 - val_loss: 1.3910\n",
      "Epoch 3238/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8205 - val_loss: 1.3586\n",
      "Epoch 3239/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8197 - val_loss: 1.3780\n",
      "Epoch 3240/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.8189 - val_loss: 1.3650\n",
      "Epoch 3241/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.8039 - val_loss: 1.3741\n",
      "Epoch 3242/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8141 - val_loss: 1.3840\n",
      "Epoch 3243/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7994 - val_loss: 1.3617\n",
      "Epoch 3244/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8202 - val_loss: 1.3658\n",
      "Epoch 3245/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7976 - val_loss: 1.3660\n",
      "Epoch 3246/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 0.8117 - val_loss: 1.3632\n",
      "Epoch 3247/5000\n",
      "572/572 [==============================] - 0s 621us/step - loss: 0.8069 - val_loss: 1.3777\n",
      "Epoch 3248/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8118 - val_loss: 1.3702\n",
      "Epoch 3249/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8047 - val_loss: 1.3822\n",
      "Epoch 3250/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7907 - val_loss: 1.3651\n",
      "Epoch 3251/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8177 - val_loss: 1.3927\n",
      "Epoch 3252/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8227 - val_loss: 1.3686\n",
      "Epoch 3253/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8100 - val_loss: 1.3571\n",
      "Epoch 3254/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8089 - val_loss: 1.3693\n",
      "Epoch 3255/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8070 - val_loss: 1.3567\n",
      "Epoch 3256/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8191 - val_loss: 1.3678\n",
      "Epoch 3257/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.8106 - val_loss: 1.4003\n",
      "Epoch 3258/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7947 - val_loss: 1.3831\n",
      "Epoch 3259/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8287 - val_loss: 1.3651\n",
      "Epoch 3260/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8086 - val_loss: 1.3662\n",
      "Epoch 3261/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8111 - val_loss: 1.3592\n",
      "Epoch 3262/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8295 - val_loss: 1.3482\n",
      "Epoch 3263/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8098 - val_loss: 1.3784\n",
      "Epoch 3264/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8118 - val_loss: 1.3682\n",
      "Epoch 3265/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8288 - val_loss: 1.3892\n",
      "Epoch 3266/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8170 - val_loss: 1.3801\n",
      "Epoch 3267/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8155 - val_loss: 1.3980\n",
      "Epoch 3268/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8048 - val_loss: 1.3834\n",
      "Epoch 3269/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8032 - val_loss: 1.3700\n",
      "Epoch 3270/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8162 - val_loss: 1.3933\n",
      "Epoch 3271/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.8043 - val_loss: 1.4075\n",
      "Epoch 3272/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8167 - val_loss: 1.3963\n",
      "Epoch 3273/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8153 - val_loss: 1.3925\n",
      "Epoch 3274/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8176 - val_loss: 1.3654\n",
      "Epoch 3275/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8167 - val_loss: 1.3758\n",
      "Epoch 3276/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8296 - val_loss: 1.3864\n",
      "Epoch 3277/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8107 - val_loss: 1.3784\n",
      "Epoch 3278/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8018 - val_loss: 1.4252\n",
      "Epoch 3279/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8235 - val_loss: 1.3902\n",
      "Epoch 3280/5000\n",
      "572/572 [==============================] - 0s 621us/step - loss: 0.8148 - val_loss: 1.3776\n",
      "Epoch 3281/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8240 - val_loss: 1.3775\n",
      "Epoch 3282/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 665us/step - loss: 0.8052 - val_loss: 1.3605\n",
      "Epoch 3283/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8070 - val_loss: 1.4188\n",
      "Epoch 3284/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8195 - val_loss: 1.3825\n",
      "Epoch 3285/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8120 - val_loss: 1.4435\n",
      "Epoch 3286/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8138 - val_loss: 1.4193\n",
      "Epoch 3287/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8106 - val_loss: 1.3605\n",
      "Epoch 3288/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8129 - val_loss: 1.3744\n",
      "Epoch 3289/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8070 - val_loss: 1.3761\n",
      "Epoch 3290/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8103 - val_loss: 1.3635\n",
      "Epoch 3291/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8109 - val_loss: 1.3803\n",
      "Epoch 3292/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8211 - val_loss: 1.4001\n",
      "Epoch 3293/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.8208 - val_loss: 1.4289\n",
      "Epoch 3294/5000\n",
      "572/572 [==============================] - 0s 621us/step - loss: 0.8187 - val_loss: 1.4538\n",
      "Epoch 3295/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8150 - val_loss: 1.4137\n",
      "Epoch 3296/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8061 - val_loss: 1.3817\n",
      "Epoch 3297/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8166 - val_loss: 1.4036\n",
      "Epoch 3298/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8026 - val_loss: 1.4494\n",
      "Epoch 3299/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8072 - val_loss: 1.4003\n",
      "Epoch 3300/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8319 - val_loss: 1.3822\n",
      "Epoch 3301/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8175 - val_loss: 1.3644\n",
      "Epoch 3302/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8112 - val_loss: 1.3632\n",
      "Epoch 3303/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8016 - val_loss: 1.3748\n",
      "Epoch 3304/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.8126 - val_loss: 1.3582\n",
      "Epoch 3305/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8118 - val_loss: 1.3391\n",
      "Epoch 3306/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8202 - val_loss: 1.3643\n",
      "Epoch 3307/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8123 - val_loss: 1.3783\n",
      "Epoch 3308/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8107 - val_loss: 1.3623\n",
      "Epoch 3309/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8059 - val_loss: 1.3572\n",
      "Epoch 3310/5000\n",
      "572/572 [==============================] - 0s 609us/step - loss: 0.8009 - val_loss: 1.3898\n",
      "Epoch 3311/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.8193 - val_loss: 1.3633\n",
      "Epoch 3312/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8099 - val_loss: 1.3718\n",
      "Epoch 3313/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8180 - val_loss: 1.4054\n",
      "Epoch 3314/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8362 - val_loss: 1.3825\n",
      "Epoch 3315/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8125 - val_loss: 1.3636\n",
      "Epoch 3316/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8161 - val_loss: 1.3505\n",
      "Epoch 3317/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8117 - val_loss: 1.3416\n",
      "Epoch 3318/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8094 - val_loss: 1.3488\n",
      "Epoch 3319/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8134 - val_loss: 1.3733\n",
      "Epoch 3320/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8089 - val_loss: 1.3569\n",
      "Epoch 3321/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.8093 - val_loss: 1.3749\n",
      "Epoch 3322/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8298 - val_loss: 1.3850\n",
      "Epoch 3323/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8069 - val_loss: 1.3472\n",
      "Epoch 3324/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8098 - val_loss: 1.3526\n",
      "Epoch 3325/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8119 - val_loss: 1.3437\n",
      "Epoch 3326/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8091 - val_loss: 1.3538\n",
      "Epoch 3327/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8135 - val_loss: 1.3756\n",
      "Epoch 3328/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8002 - val_loss: 1.3593\n",
      "Epoch 3329/5000\n",
      "572/572 [==============================] - 0s 611us/step - loss: 0.7982 - val_loss: 1.3473\n",
      "Epoch 3330/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8218 - val_loss: 1.3880\n",
      "Epoch 3331/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8092 - val_loss: 1.3783\n",
      "Epoch 3332/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8040 - val_loss: 1.3805\n",
      "Epoch 3333/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8116 - val_loss: 1.3553\n",
      "Epoch 3334/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8135 - val_loss: 1.3465\n",
      "Epoch 3335/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8222 - val_loss: 1.3575\n",
      "Epoch 3336/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8068 - val_loss: 1.3674\n",
      "Epoch 3337/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8248 - val_loss: 1.3579\n",
      "Epoch 3338/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8060 - val_loss: 1.3469\n",
      "Epoch 3339/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8048 - val_loss: 1.3545\n",
      "Epoch 3340/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8218 - val_loss: 1.3485\n",
      "Epoch 3341/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8227 - val_loss: 1.3364\n",
      "Epoch 3342/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.8162 - val_loss: 1.3461\n",
      "Epoch 3343/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.8236 - val_loss: 1.3462\n",
      "Epoch 3344/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8230 - val_loss: 1.3615\n",
      "Epoch 3345/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.8157 - val_loss: 1.3980\n",
      "Epoch 3346/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.8185 - val_loss: 1.3824\n",
      "Epoch 3347/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.8099 - val_loss: 1.3492\n",
      "Epoch 3348/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8111 - val_loss: 1.3674\n",
      "Epoch 3349/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.8008 - val_loss: 1.3720\n",
      "Epoch 3350/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.8083 - val_loss: 1.3637\n",
      "Epoch 3351/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8102 - val_loss: 1.3373\n",
      "Epoch 3352/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8032 - val_loss: 1.3299\n",
      "Epoch 3353/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8032 - val_loss: 1.3717\n",
      "Epoch 3354/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8166 - val_loss: 1.3578\n",
      "Epoch 3355/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8256 - val_loss: 1.3416\n",
      "Epoch 3356/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.8099 - val_loss: 1.3512\n",
      "Epoch 3357/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8150 - val_loss: 1.3052\n",
      "Epoch 3358/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 663us/step - loss: 0.8059 - val_loss: 1.2755\n",
      "Epoch 3359/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8105 - val_loss: 1.2877\n",
      "Epoch 3360/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7963 - val_loss: 1.2762\n",
      "Epoch 3361/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8033 - val_loss: 1.2505\n",
      "Epoch 3362/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7954 - val_loss: 1.2897\n",
      "Epoch 3363/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8121 - val_loss: 1.2593\n",
      "Epoch 3364/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8203 - val_loss: 1.2288\n",
      "Epoch 3365/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8061 - val_loss: 1.2137\n",
      "Epoch 3366/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.8051 - val_loss: 1.2513\n",
      "Epoch 3367/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.8093 - val_loss: 1.2511\n",
      "Epoch 3368/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.7912 - val_loss: 1.2397\n",
      "Epoch 3369/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8107 - val_loss: 1.2173\n",
      "Epoch 3370/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8099 - val_loss: 1.1898\n",
      "Epoch 3371/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8024 - val_loss: 1.2375\n",
      "Epoch 3372/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7973 - val_loss: 1.2448\n",
      "Epoch 3373/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7827 - val_loss: 1.2404\n",
      "Epoch 3374/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8172 - val_loss: 1.2807\n",
      "Epoch 3375/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7902 - val_loss: 1.2210\n",
      "Epoch 3376/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8058 - val_loss: 1.2703\n",
      "Epoch 3377/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.8121 - val_loss: 1.2167\n",
      "Epoch 3378/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7963 - val_loss: 1.1905\n",
      "Epoch 3379/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8055 - val_loss: 1.1957\n",
      "Epoch 3380/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7996 - val_loss: 1.2273\n",
      "Epoch 3381/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.7915 - val_loss: 1.2127\n",
      "Epoch 3382/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8001 - val_loss: 1.2455\n",
      "Epoch 3383/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.8037 - val_loss: 1.2264\n",
      "Epoch 3384/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8074 - val_loss: 1.1795\n",
      "Epoch 3385/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7998 - val_loss: 1.1878\n",
      "Epoch 3386/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7893 - val_loss: 1.2286\n",
      "Epoch 3387/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.7874 - val_loss: 1.1984\n",
      "Epoch 3388/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.8108 - val_loss: 1.2050\n",
      "Epoch 3389/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8118 - val_loss: 1.2034\n",
      "Epoch 3390/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7975 - val_loss: 1.1616\n",
      "Epoch 3391/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7879 - val_loss: 1.1923\n",
      "Epoch 3392/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8053 - val_loss: 1.1875\n",
      "Epoch 3393/5000\n",
      "572/572 [==============================] - 0s 693us/step - loss: 0.7957 - val_loss: 1.1954\n",
      "Epoch 3394/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7774 - val_loss: 1.1953\n",
      "Epoch 3395/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.8131 - val_loss: 1.1840\n",
      "Epoch 3396/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7889 - val_loss: 1.1870\n",
      "Epoch 3397/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8001 - val_loss: 1.2054\n",
      "Epoch 3398/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7994 - val_loss: 1.2559\n",
      "Epoch 3399/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.7863 - val_loss: 1.2219\n",
      "Epoch 3400/5000\n",
      "572/572 [==============================] - 0s 618us/step - loss: 0.7863 - val_loss: 1.2065\n",
      "Epoch 3401/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8028 - val_loss: 1.1833\n",
      "Epoch 3402/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7959 - val_loss: 1.1780\n",
      "Epoch 3403/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7890 - val_loss: 1.1666\n",
      "Epoch 3404/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7923 - val_loss: 1.1445\n",
      "Epoch 3405/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7993 - val_loss: 1.1344\n",
      "Epoch 3406/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7993 - val_loss: 1.1342\n",
      "Epoch 3407/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7915 - val_loss: 1.1621\n",
      "Epoch 3408/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7917 - val_loss: 1.1689\n",
      "Epoch 3409/5000\n",
      "572/572 [==============================] - 0s 622us/step - loss: 0.8015 - val_loss: 1.1485\n",
      "Epoch 3410/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.7863 - val_loss: 1.1321\n",
      "Epoch 3411/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7943 - val_loss: 1.1536\n",
      "Epoch 3412/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7956 - val_loss: 1.1177\n",
      "Epoch 3413/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.7847 - val_loss: 1.1339\n",
      "Epoch 3414/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7959 - val_loss: 1.1520\n",
      "Epoch 3415/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7924 - val_loss: 1.1438\n",
      "Epoch 3416/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7892 - val_loss: 1.1699\n",
      "Epoch 3417/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.7941 - val_loss: 1.1816\n",
      "Epoch 3418/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 0.7919 - val_loss: 1.1793\n",
      "Epoch 3419/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7928 - val_loss: 1.1621\n",
      "Epoch 3420/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.7851 - val_loss: 1.1579\n",
      "Epoch 3421/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7911 - val_loss: 1.1750\n",
      "Epoch 3422/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7887 - val_loss: 1.1694\n",
      "Epoch 3423/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7852 - val_loss: 1.1534\n",
      "Epoch 3424/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8158 - val_loss: 1.1936\n",
      "Epoch 3425/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7837 - val_loss: 1.1689\n",
      "Epoch 3426/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7961 - val_loss: 1.1868\n",
      "Epoch 3427/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7846 - val_loss: 1.1677\n",
      "Epoch 3428/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7947 - val_loss: 1.1767\n",
      "Epoch 3429/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7911 - val_loss: 1.1712\n",
      "Epoch 3430/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7979 - val_loss: 1.1955\n",
      "Epoch 3431/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8021 - val_loss: 1.2264\n",
      "Epoch 3432/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7840 - val_loss: 1.1691\n",
      "Epoch 3433/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8049 - val_loss: 1.1398\n",
      "Epoch 3434/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 642us/step - loss: 0.7905 - val_loss: 1.1739\n",
      "Epoch 3435/5000\n",
      "572/572 [==============================] - 0s 622us/step - loss: 0.7937 - val_loss: 1.1730\n",
      "Epoch 3436/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7846 - val_loss: 1.2110\n",
      "Epoch 3437/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.8006 - val_loss: 1.1560\n",
      "Epoch 3438/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7957 - val_loss: 1.1433\n",
      "Epoch 3439/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7772 - val_loss: 1.1479\n",
      "Epoch 3440/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7856 - val_loss: 1.1372\n",
      "Epoch 3441/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.8002 - val_loss: 1.1479\n",
      "Epoch 3442/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7928 - val_loss: 1.1529\n",
      "Epoch 3443/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7895 - val_loss: 1.1216\n",
      "Epoch 3444/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7824 - val_loss: 1.1708\n",
      "Epoch 3445/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7822 - val_loss: 1.1373\n",
      "Epoch 3446/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7930 - val_loss: 1.1527\n",
      "Epoch 3447/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7798 - val_loss: 1.1594\n",
      "Epoch 3448/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7883 - val_loss: 1.1822\n",
      "Epoch 3449/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7887 - val_loss: 1.2006\n",
      "Epoch 3450/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.7950 - val_loss: 1.1793\n",
      "Epoch 3451/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8034 - val_loss: 1.1690\n",
      "Epoch 3452/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8041 - val_loss: 1.1754\n",
      "Epoch 3453/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7934 - val_loss: 1.1960\n",
      "Epoch 3454/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7997 - val_loss: 1.1841\n",
      "Epoch 3455/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8089 - val_loss: 1.1840\n",
      "Epoch 3456/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7945 - val_loss: 1.1868\n",
      "Epoch 3457/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7931 - val_loss: 1.1820\n",
      "Epoch 3458/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7910 - val_loss: 1.2004\n",
      "Epoch 3459/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7928 - val_loss: 1.2027\n",
      "Epoch 3460/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7922 - val_loss: 1.1781\n",
      "Epoch 3461/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8000 - val_loss: 1.1751\n",
      "Epoch 3462/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7964 - val_loss: 1.1545\n",
      "Epoch 3463/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8029 - val_loss: 1.1814\n",
      "Epoch 3464/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7934 - val_loss: 1.1829\n",
      "Epoch 3465/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.7881 - val_loss: 1.1594\n",
      "Epoch 3466/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7879 - val_loss: 1.1587\n",
      "Epoch 3467/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7969 - val_loss: 1.1580\n",
      "Epoch 3468/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7852 - val_loss: 1.1527\n",
      "Epoch 3469/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7994 - val_loss: 1.1491\n",
      "Epoch 3470/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.8009 - val_loss: 1.1654\n",
      "Epoch 3471/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.8010 - val_loss: 1.1183\n",
      "Epoch 3472/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.7849 - val_loss: 1.1256\n",
      "Epoch 3473/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7977 - val_loss: 1.1172\n",
      "Epoch 3474/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7918 - val_loss: 1.1434\n",
      "Epoch 3475/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7845 - val_loss: 1.1553\n",
      "Epoch 3476/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7931 - val_loss: 1.1565\n",
      "Epoch 3477/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.7944 - val_loss: 1.1329\n",
      "Epoch 3478/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7941 - val_loss: 1.1219\n",
      "Epoch 3479/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7928 - val_loss: 1.1564\n",
      "Epoch 3480/5000\n",
      "572/572 [==============================] - 0s 783us/step - loss: 0.7929 - val_loss: 1.1659\n",
      "Epoch 3481/5000\n",
      "572/572 [==============================] - 0s 720us/step - loss: 0.8006 - val_loss: 1.1380\n",
      "Epoch 3482/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7808 - val_loss: 1.1270\n",
      "Epoch 3483/5000\n",
      "572/572 [==============================] - 1s 899us/step - loss: 0.8041 - val_loss: 1.1255\n",
      "Epoch 3484/5000\n",
      "572/572 [==============================] - 0s 706us/step - loss: 0.8016 - val_loss: 1.1142\n",
      "Epoch 3485/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8008 - val_loss: 1.2376\n",
      "Epoch 3486/5000\n",
      "572/572 [==============================] - 0s 783us/step - loss: 0.7836 - val_loss: 1.2070\n",
      "Epoch 3487/5000\n",
      "572/572 [==============================] - 0s 711us/step - loss: 0.7855 - val_loss: 1.1314\n",
      "Epoch 3488/5000\n",
      "572/572 [==============================] - 0s 693us/step - loss: 0.7888 - val_loss: 1.1526\n",
      "Epoch 3489/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.8025 - val_loss: 1.1622\n",
      "Epoch 3490/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7883 - val_loss: 1.1828\n",
      "Epoch 3491/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7730 - val_loss: 1.1456\n",
      "Epoch 3492/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7832 - val_loss: 1.1571\n",
      "Epoch 3493/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7845 - val_loss: 1.1415\n",
      "Epoch 3494/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.8073 - val_loss: 1.1337\n",
      "Epoch 3495/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.7743 - val_loss: 1.1351\n",
      "Epoch 3496/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7857 - val_loss: 1.1319\n",
      "Epoch 3497/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7897 - val_loss: 1.1294\n",
      "Epoch 3498/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7874 - val_loss: 1.1369\n",
      "Epoch 3499/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7920 - val_loss: 1.1505\n",
      "Epoch 3500/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7994 - val_loss: 1.1289\n",
      "Epoch 3501/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7895 - val_loss: 1.1254\n",
      "Epoch 3502/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7830 - val_loss: 1.1099\n",
      "Epoch 3503/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7728 - val_loss: 1.1201\n",
      "Epoch 3504/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7879 - val_loss: 1.1399\n",
      "Epoch 3505/5000\n",
      "572/572 [==============================] - 0s 621us/step - loss: 0.7934 - val_loss: 1.1123\n",
      "Epoch 3506/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7846 - val_loss: 1.1246\n",
      "Epoch 3507/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7940 - val_loss: 1.1217\n",
      "Epoch 3508/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7832 - val_loss: 1.1511\n",
      "Epoch 3509/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7828 - val_loss: 1.1322\n",
      "Epoch 3510/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 670us/step - loss: 0.7832 - val_loss: 1.1544\n",
      "Epoch 3511/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7972 - val_loss: 1.1244\n",
      "Epoch 3512/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7880 - val_loss: 1.1387\n",
      "Epoch 3513/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7789 - val_loss: 1.1470\n",
      "Epoch 3514/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.7950 - val_loss: 1.1606\n",
      "Epoch 3515/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7994 - val_loss: 1.1834\n",
      "Epoch 3516/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7799 - val_loss: 1.1880\n",
      "Epoch 3517/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.8012 - val_loss: 1.2104\n",
      "Epoch 3518/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7768 - val_loss: 1.1812\n",
      "Epoch 3519/5000\n",
      "572/572 [==============================] - 0s 617us/step - loss: 0.7791 - val_loss: 1.1647\n",
      "Epoch 3520/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7826 - val_loss: 1.1848\n",
      "Epoch 3521/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.7938 - val_loss: 1.1563\n",
      "Epoch 3522/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7784 - val_loss: 1.1276\n",
      "Epoch 3523/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.8009 - val_loss: 1.1499\n",
      "Epoch 3524/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7991 - val_loss: 1.1821\n",
      "Epoch 3525/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7984 - val_loss: 1.1524\n",
      "Epoch 3526/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7837 - val_loss: 1.1514\n",
      "Epoch 3527/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7901 - val_loss: 1.1482\n",
      "Epoch 3528/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7845 - val_loss: 1.1897\n",
      "Epoch 3529/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7850 - val_loss: 1.1700\n",
      "Epoch 3530/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8110 - val_loss: 1.1670\n",
      "Epoch 3531/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.8095 - val_loss: 1.1591\n",
      "Epoch 3532/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7904 - val_loss: 1.1370\n",
      "Epoch 3533/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7812 - val_loss: 1.1441\n",
      "Epoch 3534/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7990 - val_loss: 1.1287\n",
      "Epoch 3535/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.7894 - val_loss: 1.1325\n",
      "Epoch 3536/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7908 - val_loss: 1.1125\n",
      "Epoch 3537/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.7800 - val_loss: 1.1418\n",
      "Epoch 3538/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7943 - val_loss: 1.1698\n",
      "Epoch 3539/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7890 - val_loss: 1.1629\n",
      "Epoch 3540/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7726 - val_loss: 1.1263\n",
      "Epoch 3541/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7783 - val_loss: 1.1472\n",
      "Epoch 3542/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7835 - val_loss: 1.1826\n",
      "Epoch 3543/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7966 - val_loss: 1.1760\n",
      "Epoch 3544/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7823 - val_loss: 1.1653\n",
      "Epoch 3545/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7920 - val_loss: 1.1606\n",
      "Epoch 3546/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7908 - val_loss: 1.1545\n",
      "Epoch 3547/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7904 - val_loss: 1.1355\n",
      "Epoch 3548/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.8019 - val_loss: 1.1276\n",
      "Epoch 3549/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 0.7789 - val_loss: 1.1333\n",
      "Epoch 3550/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7987 - val_loss: 1.1358\n",
      "Epoch 3551/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7902 - val_loss: 1.1619\n",
      "Epoch 3552/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7832 - val_loss: 1.1504\n",
      "Epoch 3553/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7894 - val_loss: 1.1447\n",
      "Epoch 3554/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7832 - val_loss: 1.1374\n",
      "Epoch 3555/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7850 - val_loss: 1.1805\n",
      "Epoch 3556/5000\n",
      "572/572 [==============================] - 0s 619us/step - loss: 0.7897 - val_loss: 1.1795\n",
      "Epoch 3557/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7967 - val_loss: 1.2395\n",
      "Epoch 3558/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7817 - val_loss: 1.2408\n",
      "Epoch 3559/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7764 - val_loss: 1.2285\n",
      "Epoch 3560/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7801 - val_loss: 1.1986\n",
      "Epoch 3561/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7975 - val_loss: 1.1667\n",
      "Epoch 3562/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7881 - val_loss: 1.2037\n",
      "Epoch 3563/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7840 - val_loss: 1.2126\n",
      "Epoch 3564/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7842 - val_loss: 1.2136\n",
      "Epoch 3565/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7769 - val_loss: 1.2473\n",
      "Epoch 3566/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7958 - val_loss: 1.2178\n",
      "Epoch 3567/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7858 - val_loss: 1.1959\n",
      "Epoch 3568/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7849 - val_loss: 1.1971\n",
      "Epoch 3569/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7984 - val_loss: 1.2120\n",
      "Epoch 3570/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7916 - val_loss: 1.2229\n",
      "Epoch 3571/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7924 - val_loss: 1.1733\n",
      "Epoch 3572/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7822 - val_loss: 1.1825\n",
      "Epoch 3573/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7991 - val_loss: 1.2076\n",
      "Epoch 3574/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.8033 - val_loss: 1.1684\n",
      "Epoch 3575/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7823 - val_loss: 1.1710\n",
      "Epoch 3576/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7944 - val_loss: 1.1933\n",
      "Epoch 3577/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7859 - val_loss: 1.2200\n",
      "Epoch 3578/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.7960 - val_loss: 1.2224\n",
      "Epoch 3579/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7782 - val_loss: 1.2573\n",
      "Epoch 3580/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7906 - val_loss: 1.2248\n",
      "Epoch 3581/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7892 - val_loss: 1.1869\n",
      "Epoch 3582/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7853 - val_loss: 1.1956\n",
      "Epoch 3583/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7783 - val_loss: 1.1816\n",
      "Epoch 3584/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7873 - val_loss: 1.2056\n",
      "Epoch 3585/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.8039 - val_loss: 1.1779\n",
      "Epoch 3586/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 640us/step - loss: 0.8063 - val_loss: 1.1631\n",
      "Epoch 3587/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7897 - val_loss: 1.1762\n",
      "Epoch 3588/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7840 - val_loss: 1.1744\n",
      "Epoch 3589/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7949 - val_loss: 1.2491\n",
      "Epoch 3590/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7788 - val_loss: 1.2343\n",
      "Epoch 3591/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7918 - val_loss: 1.1942\n",
      "Epoch 3592/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7862 - val_loss: 1.1468\n",
      "Epoch 3593/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7949 - val_loss: 1.1467\n",
      "Epoch 3594/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7791 - val_loss: 1.1432\n",
      "Epoch 3595/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.8023 - val_loss: 1.1865\n",
      "Epoch 3596/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7786 - val_loss: 1.1834\n",
      "Epoch 3597/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7821 - val_loss: 1.1412\n",
      "Epoch 3598/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7988 - val_loss: 1.1325\n",
      "Epoch 3599/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7836 - val_loss: 1.1567\n",
      "Epoch 3600/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7871 - val_loss: 1.1540\n",
      "Epoch 3601/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7864 - val_loss: 1.1470\n",
      "Epoch 3602/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7982 - val_loss: 1.1775\n",
      "Epoch 3603/5000\n",
      "572/572 [==============================] - 0s 619us/step - loss: 0.8083 - val_loss: 1.1334\n",
      "Epoch 3604/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7744 - val_loss: 1.1481\n",
      "Epoch 3605/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7823 - val_loss: 1.2357\n",
      "Epoch 3606/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7847 - val_loss: 1.1420\n",
      "Epoch 3607/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8035 - val_loss: 1.1446\n",
      "Epoch 3608/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7929 - val_loss: 1.1406\n",
      "Epoch 3609/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7878 - val_loss: 1.1152\n",
      "Epoch 3610/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7814 - val_loss: 1.1421\n",
      "Epoch 3611/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7884 - val_loss: 1.1261\n",
      "Epoch 3612/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.7850 - val_loss: 1.1357\n",
      "Epoch 3613/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7745 - val_loss: 1.1595\n",
      "Epoch 3614/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7853 - val_loss: 1.1326\n",
      "Epoch 3615/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7930 - val_loss: 1.1406\n",
      "Epoch 3616/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7835 - val_loss: 1.1599\n",
      "Epoch 3617/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.7837 - val_loss: 1.2012\n",
      "Epoch 3618/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7917 - val_loss: 1.1656\n",
      "Epoch 3619/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7844 - val_loss: 1.1762\n",
      "Epoch 3620/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7830 - val_loss: 1.1884\n",
      "Epoch 3621/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7982 - val_loss: 1.1423\n",
      "Epoch 3622/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7836 - val_loss: 1.1863\n",
      "Epoch 3623/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7851 - val_loss: 1.2064\n",
      "Epoch 3624/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7872 - val_loss: 1.1515\n",
      "Epoch 3625/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7937 - val_loss: 1.1497\n",
      "Epoch 3626/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7747 - val_loss: 1.1550\n",
      "Epoch 3627/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7793 - val_loss: 1.1316\n",
      "Epoch 3628/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.8000 - val_loss: 1.1195\n",
      "Epoch 3629/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7927 - val_loss: 1.1268\n",
      "Epoch 3630/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.8037 - val_loss: 1.1385\n",
      "Epoch 3631/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8099 - val_loss: 1.1550\n",
      "Epoch 3632/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7816 - val_loss: 1.1242\n",
      "Epoch 3633/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7697 - val_loss: 1.1675\n",
      "Epoch 3634/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7759 - val_loss: 1.1951\n",
      "Epoch 3635/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7973 - val_loss: 1.1736\n",
      "Epoch 3636/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.8066 - val_loss: 1.1782\n",
      "Epoch 3637/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7917 - val_loss: 1.1414\n",
      "Epoch 3638/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7821 - val_loss: 1.1607\n",
      "Epoch 3639/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7958 - val_loss: 1.1703\n",
      "Epoch 3640/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7772 - val_loss: 1.1728\n",
      "Epoch 3641/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7774 - val_loss: 1.1779\n",
      "Epoch 3642/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7952 - val_loss: 1.1820\n",
      "Epoch 3643/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7923 - val_loss: 1.1781\n",
      "Epoch 3644/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7839 - val_loss: 1.1763\n",
      "Epoch 3645/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7871 - val_loss: 1.1696\n",
      "Epoch 3646/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7878 - val_loss: 1.1445\n",
      "Epoch 3647/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7968 - val_loss: 1.1933\n",
      "Epoch 3648/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7906 - val_loss: 1.2283\n",
      "Epoch 3649/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7925 - val_loss: 1.1834\n",
      "Epoch 3650/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7802 - val_loss: 1.2306\n",
      "Epoch 3651/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7793 - val_loss: 1.2379\n",
      "Epoch 3652/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7893 - val_loss: 1.2160\n",
      "Epoch 3653/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7917 - val_loss: 1.2023\n",
      "Epoch 3654/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7849 - val_loss: 1.2143\n",
      "Epoch 3655/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7956 - val_loss: 1.2052\n",
      "Epoch 3656/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.7807 - val_loss: 1.1707\n",
      "Epoch 3657/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7856 - val_loss: 1.1298\n",
      "Epoch 3658/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7724 - val_loss: 1.1501\n",
      "Epoch 3659/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7962 - val_loss: 1.1462\n",
      "Epoch 3660/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7726 - val_loss: 1.1573\n",
      "Epoch 3661/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7764 - val_loss: 1.1846\n",
      "Epoch 3662/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 642us/step - loss: 0.7793 - val_loss: 1.1652\n",
      "Epoch 3663/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7725 - val_loss: 1.1498\n",
      "Epoch 3664/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7854 - val_loss: 1.1566\n",
      "Epoch 3665/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7962 - val_loss: 1.1854\n",
      "Epoch 3666/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7779 - val_loss: 1.1514\n",
      "Epoch 3667/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7789 - val_loss: 1.1862\n",
      "Epoch 3668/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7886 - val_loss: 1.1788\n",
      "Epoch 3669/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.7830 - val_loss: 1.1879\n",
      "Epoch 3670/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7866 - val_loss: 1.1896\n",
      "Epoch 3671/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7885 - val_loss: 1.1757\n",
      "Epoch 3672/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7775 - val_loss: 1.1652\n",
      "Epoch 3673/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7900 - val_loss: 1.1825\n",
      "Epoch 3674/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7918 - val_loss: 1.1158\n",
      "Epoch 3675/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7968 - val_loss: 1.1204\n",
      "Epoch 3676/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7852 - val_loss: 1.1179\n",
      "Epoch 3677/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7784 - val_loss: 1.1562\n",
      "Epoch 3678/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7733 - val_loss: 1.1862\n",
      "Epoch 3679/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7928 - val_loss: 1.1879\n",
      "Epoch 3680/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7783 - val_loss: 1.1483\n",
      "Epoch 3681/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7740 - val_loss: 1.1073\n",
      "Epoch 3682/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7936 - val_loss: 1.1566\n",
      "Epoch 3683/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.8042 - val_loss: 1.1456\n",
      "Epoch 3684/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7867 - val_loss: 1.1588\n",
      "Epoch 3685/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7690 - val_loss: 1.1525\n",
      "Epoch 3686/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7857 - val_loss: 1.1481\n",
      "Epoch 3687/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7884 - val_loss: 1.1456\n",
      "Epoch 3688/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7896 - val_loss: 1.1329\n",
      "Epoch 3689/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8118 - val_loss: 1.1675\n",
      "Epoch 3690/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7850 - val_loss: 1.1970\n",
      "Epoch 3691/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.7905 - val_loss: 1.1942\n",
      "Epoch 3692/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7922 - val_loss: 1.2763\n",
      "Epoch 3693/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7834 - val_loss: 1.1784\n",
      "Epoch 3694/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7833 - val_loss: 1.2074\n",
      "Epoch 3695/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7994 - val_loss: 1.1933\n",
      "Epoch 3696/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7811 - val_loss: 1.1848\n",
      "Epoch 3697/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7805 - val_loss: 1.1660\n",
      "Epoch 3698/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7853 - val_loss: 1.1550\n",
      "Epoch 3699/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7887 - val_loss: 1.1394\n",
      "Epoch 3700/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7833 - val_loss: 1.1860\n",
      "Epoch 3701/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7923 - val_loss: 1.1636\n",
      "Epoch 3702/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8048 - val_loss: 1.1386\n",
      "Epoch 3703/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8078 - val_loss: 1.1797\n",
      "Epoch 3704/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7833 - val_loss: 1.1555\n",
      "Epoch 3705/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7912 - val_loss: 1.1622\n",
      "Epoch 3706/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7858 - val_loss: 1.1471\n",
      "Epoch 3707/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.7842 - val_loss: 1.1289\n",
      "Epoch 3708/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7873 - val_loss: 1.1413\n",
      "Epoch 3709/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7785 - val_loss: 1.1694\n",
      "Epoch 3710/5000\n",
      "572/572 [==============================] - 0s 690us/step - loss: 0.7927 - val_loss: 1.2075\n",
      "Epoch 3711/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7769 - val_loss: 1.1840\n",
      "Epoch 3712/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7889 - val_loss: 1.1683\n",
      "Epoch 3713/5000\n",
      "572/572 [==============================] - 0s 611us/step - loss: 0.7967 - val_loss: 1.1617\n",
      "Epoch 3714/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7740 - val_loss: 1.1467\n",
      "Epoch 3715/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7783 - val_loss: 1.1300\n",
      "Epoch 3716/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7866 - val_loss: 1.1761\n",
      "Epoch 3717/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7820 - val_loss: 1.1621\n",
      "Epoch 3718/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8061 - val_loss: 1.2006\n",
      "Epoch 3719/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.7866 - val_loss: 1.1537\n",
      "Epoch 3720/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7797 - val_loss: 1.1404\n",
      "Epoch 3721/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7764 - val_loss: 1.1252\n",
      "Epoch 3722/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7711 - val_loss: 1.1519\n",
      "Epoch 3723/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8045 - val_loss: 1.1569\n",
      "Epoch 3724/5000\n",
      "572/572 [==============================] - 0s 620us/step - loss: 0.7845 - val_loss: 1.1524\n",
      "Epoch 3725/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.8056 - val_loss: 1.1346\n",
      "Epoch 3726/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7969 - val_loss: 1.1471\n",
      "Epoch 3727/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7775 - val_loss: 1.1288\n",
      "Epoch 3728/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7805 - val_loss: 1.1337\n",
      "Epoch 3729/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7710 - val_loss: 1.2085\n",
      "Epoch 3730/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7921 - val_loss: 1.1973\n",
      "Epoch 3731/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.8010 - val_loss: 1.1718\n",
      "Epoch 3732/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7842 - val_loss: 1.1120\n",
      "Epoch 3733/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7949 - val_loss: 1.1495\n",
      "Epoch 3734/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.7831 - val_loss: 1.1935\n",
      "Epoch 3735/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7935 - val_loss: 1.1667\n",
      "Epoch 3736/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7852 - val_loss: 1.1470\n",
      "Epoch 3737/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7894 - val_loss: 1.1943\n",
      "Epoch 3738/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 673us/step - loss: 0.7874 - val_loss: 1.1692\n",
      "Epoch 3739/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7764 - val_loss: 1.1906\n",
      "Epoch 3740/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7838 - val_loss: 1.1209\n",
      "Epoch 3741/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7910 - val_loss: 1.1181\n",
      "Epoch 3742/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7867 - val_loss: 1.1229\n",
      "Epoch 3743/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7973 - val_loss: 1.1501\n",
      "Epoch 3744/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7860 - val_loss: 1.1681\n",
      "Epoch 3745/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7778 - val_loss: 1.1438\n",
      "Epoch 3746/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7852 - val_loss: 1.1636\n",
      "Epoch 3747/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.8080 - val_loss: 1.1758\n",
      "Epoch 3748/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7894 - val_loss: 1.1801\n",
      "Epoch 3749/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7890 - val_loss: 1.1937\n",
      "Epoch 3750/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7780 - val_loss: 1.2205\n",
      "Epoch 3751/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7842 - val_loss: 1.2521\n",
      "Epoch 3752/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.8056 - val_loss: 1.1500\n",
      "Epoch 3753/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7815 - val_loss: 1.1654\n",
      "Epoch 3754/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.7931 - val_loss: 1.1783\n",
      "Epoch 3755/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7674 - val_loss: 1.1553\n",
      "Epoch 3756/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7879 - val_loss: 1.1777\n",
      "Epoch 3757/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7799 - val_loss: 1.1871\n",
      "Epoch 3758/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7880 - val_loss: 1.1692\n",
      "Epoch 3759/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7787 - val_loss: 1.1480\n",
      "Epoch 3760/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7870 - val_loss: 1.1429\n",
      "Epoch 3761/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7849 - val_loss: 1.1632\n",
      "Epoch 3762/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7875 - val_loss: 1.1758\n",
      "Epoch 3763/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.8043 - val_loss: 1.1336\n",
      "Epoch 3764/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.7914 - val_loss: 1.1386\n",
      "Epoch 3765/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.7832 - val_loss: 1.1478\n",
      "Epoch 3766/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7937 - val_loss: 1.1376\n",
      "Epoch 3767/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7956 - val_loss: 1.1326\n",
      "Epoch 3768/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7750 - val_loss: 1.2098\n",
      "Epoch 3769/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.8051 - val_loss: 1.1685\n",
      "Epoch 3770/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7808 - val_loss: 1.1525\n",
      "Epoch 3771/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7805 - val_loss: 1.1645\n",
      "Epoch 3772/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7774 - val_loss: 1.1574\n",
      "Epoch 3773/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7721 - val_loss: 1.1558\n",
      "Epoch 3774/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7776 - val_loss: 1.1401\n",
      "Epoch 3775/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7858 - val_loss: 1.1225\n",
      "Epoch 3776/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.7810 - val_loss: 1.1815\n",
      "Epoch 3777/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7774 - val_loss: 1.1690\n",
      "Epoch 3778/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.7772 - val_loss: 1.1632\n",
      "Epoch 3779/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7736 - val_loss: 1.1370\n",
      "Epoch 3780/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7741 - val_loss: 1.1383\n",
      "Epoch 3781/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7876 - val_loss: 1.1461\n",
      "Epoch 3782/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7748 - val_loss: 1.1284\n",
      "Epoch 3783/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7844 - val_loss: 1.1571\n",
      "Epoch 3784/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7846 - val_loss: 1.1449\n",
      "Epoch 3785/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7917 - val_loss: 1.1733\n",
      "Epoch 3786/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7815 - val_loss: 1.1917\n",
      "Epoch 3787/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7875 - val_loss: 1.1659\n",
      "Epoch 3788/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7875 - val_loss: 1.1567\n",
      "Epoch 3789/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7840 - val_loss: 1.1567\n",
      "Epoch 3790/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7979 - val_loss: 1.1566\n",
      "Epoch 3791/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7883 - val_loss: 1.1418\n",
      "Epoch 3792/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7790 - val_loss: 1.1475\n",
      "Epoch 3793/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7832 - val_loss: 1.1582\n",
      "Epoch 3794/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7736 - val_loss: 1.1450\n",
      "Epoch 3795/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7884 - val_loss: 1.1227\n",
      "Epoch 3796/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7826 - val_loss: 1.1215\n",
      "Epoch 3797/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7680 - val_loss: 1.1388\n",
      "Epoch 3798/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7795 - val_loss: 1.1432\n",
      "Epoch 3799/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7874 - val_loss: 1.1623\n",
      "Epoch 3800/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7825 - val_loss: 1.1647\n",
      "Epoch 3801/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7912 - val_loss: 1.1642\n",
      "Epoch 3802/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7816 - val_loss: 1.1700\n",
      "Epoch 3803/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7813 - val_loss: 1.1302\n",
      "Epoch 3804/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7967 - val_loss: 1.1602\n",
      "Epoch 3805/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7864 - val_loss: 1.1504\n",
      "Epoch 3806/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7833 - val_loss: 1.1815\n",
      "Epoch 3807/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7643 - val_loss: 1.1400\n",
      "Epoch 3808/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7983 - val_loss: 1.1399\n",
      "Epoch 3809/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7869 - val_loss: 1.1431\n",
      "Epoch 3810/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7950 - val_loss: 1.1722\n",
      "Epoch 3811/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7850 - val_loss: 1.1444\n",
      "Epoch 3812/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7793 - val_loss: 1.1194\n",
      "Epoch 3813/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7853 - val_loss: 1.1146\n",
      "Epoch 3814/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 664us/step - loss: 0.7825 - val_loss: 1.1056\n",
      "Epoch 3815/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7920 - val_loss: 1.1242\n",
      "Epoch 3816/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7860 - val_loss: 1.1357\n",
      "Epoch 3817/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7965 - val_loss: 1.1607\n",
      "Epoch 3818/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7989 - val_loss: 1.1259\n",
      "Epoch 3819/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7867 - val_loss: 1.1458\n",
      "Epoch 3820/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.7815 - val_loss: 1.0979\n",
      "Epoch 3821/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7674 - val_loss: 1.1066\n",
      "Epoch 3822/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7770 - val_loss: 1.0927\n",
      "Epoch 3823/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.7868 - val_loss: 1.0980\n",
      "Epoch 3824/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.8109 - val_loss: 1.2204\n",
      "Epoch 3825/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7806 - val_loss: 1.2741\n",
      "Epoch 3826/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7925 - val_loss: 1.2184\n",
      "Epoch 3827/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7739 - val_loss: 1.1729\n",
      "Epoch 3828/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7875 - val_loss: 1.1695\n",
      "Epoch 3829/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.7825 - val_loss: 1.1324\n",
      "Epoch 3830/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7850 - val_loss: 1.2923\n",
      "Epoch 3831/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7887 - val_loss: 1.2188\n",
      "Epoch 3832/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7840 - val_loss: 1.1664\n",
      "Epoch 3833/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7964 - val_loss: 1.1057\n",
      "Epoch 3834/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7763 - val_loss: 1.0953\n",
      "Epoch 3835/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7852 - val_loss: 1.1659\n",
      "Epoch 3836/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7835 - val_loss: 1.1695\n",
      "Epoch 3837/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7772 - val_loss: 1.2134\n",
      "Epoch 3838/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7890 - val_loss: 1.1955\n",
      "Epoch 3839/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7771 - val_loss: 1.1631\n",
      "Epoch 3840/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7971 - val_loss: 1.1250\n",
      "Epoch 3841/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7693 - val_loss: 1.1158\n",
      "Epoch 3842/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7928 - val_loss: 1.1106\n",
      "Epoch 3843/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7805 - val_loss: 1.1494\n",
      "Epoch 3844/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.8059 - val_loss: 1.1226\n",
      "Epoch 3845/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7862 - val_loss: 1.1478\n",
      "Epoch 3846/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7766 - val_loss: 1.1680\n",
      "Epoch 3847/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7868 - val_loss: 1.1779\n",
      "Epoch 3848/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7822 - val_loss: 1.1841\n",
      "Epoch 3849/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7941 - val_loss: 1.1551\n",
      "Epoch 3850/5000\n",
      "572/572 [==============================] - 0s 614us/step - loss: 0.7811 - val_loss: 1.1371\n",
      "Epoch 3851/5000\n",
      "572/572 [==============================] - 0s 693us/step - loss: 0.7774 - val_loss: 1.1203\n",
      "Epoch 3852/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.7915 - val_loss: 1.1137\n",
      "Epoch 3853/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.7820 - val_loss: 1.1283\n",
      "Epoch 3854/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7859 - val_loss: 1.1466\n",
      "Epoch 3855/5000\n",
      "572/572 [==============================] - 0s 622us/step - loss: 0.7867 - val_loss: 1.1628\n",
      "Epoch 3856/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7829 - val_loss: 1.1615\n",
      "Epoch 3857/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.7927 - val_loss: 1.1346\n",
      "Epoch 3858/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7910 - val_loss: 1.1075\n",
      "Epoch 3859/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.8119 - val_loss: 1.1175\n",
      "Epoch 3860/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7894 - val_loss: 1.0987\n",
      "Epoch 3861/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7800 - val_loss: 1.0928\n",
      "Epoch 3862/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7907 - val_loss: 1.1248\n",
      "Epoch 3863/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7864 - val_loss: 1.0960\n",
      "Epoch 3864/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7864 - val_loss: 1.1617\n",
      "Epoch 3865/5000\n",
      "572/572 [==============================] - 0s 619us/step - loss: 0.7833 - val_loss: 1.1054\n",
      "Epoch 3866/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7866 - val_loss: 1.1370\n",
      "Epoch 3867/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7830 - val_loss: 1.1402\n",
      "Epoch 3868/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7897 - val_loss: 1.2188\n",
      "Epoch 3869/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7764 - val_loss: 1.1905\n",
      "Epoch 3870/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7951 - val_loss: 1.1130\n",
      "Epoch 3871/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7806 - val_loss: 1.0992\n",
      "Epoch 3872/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.7839 - val_loss: 1.1050\n",
      "Epoch 3873/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7945 - val_loss: 1.1199\n",
      "Epoch 3874/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7765 - val_loss: 1.1191\n",
      "Epoch 3875/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7796 - val_loss: 1.1338\n",
      "Epoch 3876/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7891 - val_loss: 1.1499\n",
      "Epoch 3877/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7811 - val_loss: 1.1758\n",
      "Epoch 3878/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7992 - val_loss: 1.1851\n",
      "Epoch 3879/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7931 - val_loss: 1.1884\n",
      "Epoch 3880/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7866 - val_loss: 1.1959\n",
      "Epoch 3881/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7715 - val_loss: 1.1735\n",
      "Epoch 3882/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7777 - val_loss: 1.1336\n",
      "Epoch 3883/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7967 - val_loss: 1.1075\n",
      "Epoch 3884/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.7773 - val_loss: 1.1096\n",
      "Epoch 3885/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7766 - val_loss: 1.1715\n",
      "Epoch 3886/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7772 - val_loss: 1.1241\n",
      "Epoch 3887/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7869 - val_loss: 1.1039\n",
      "Epoch 3888/5000\n",
      "572/572 [==============================] - 0s 616us/step - loss: 0.7951 - val_loss: 1.1267\n",
      "Epoch 3889/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7817 - val_loss: 1.1751\n",
      "Epoch 3890/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 653us/step - loss: 0.7856 - val_loss: 1.1744\n",
      "Epoch 3891/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7802 - val_loss: 1.1354\n",
      "Epoch 3892/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7762 - val_loss: 1.1605\n",
      "Epoch 3893/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7737 - val_loss: 1.1112\n",
      "Epoch 3894/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7878 - val_loss: 1.1168\n",
      "Epoch 3895/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.7835 - val_loss: 1.1185\n",
      "Epoch 3896/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7880 - val_loss: 1.1240\n",
      "Epoch 3897/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7888 - val_loss: 1.1280\n",
      "Epoch 3898/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7820 - val_loss: 1.1396\n",
      "Epoch 3899/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7833 - val_loss: 1.1467\n",
      "Epoch 3900/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7736 - val_loss: 1.1244\n",
      "Epoch 3901/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7939 - val_loss: 1.1142\n",
      "Epoch 3902/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.7813 - val_loss: 1.1305\n",
      "Epoch 3903/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7712 - val_loss: 1.1288\n",
      "Epoch 3904/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7877 - val_loss: 1.1939\n",
      "Epoch 3905/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7832 - val_loss: 1.1873\n",
      "Epoch 3906/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7872 - val_loss: 1.1432\n",
      "Epoch 3907/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.7773 - val_loss: 1.1416\n",
      "Epoch 3908/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8018 - val_loss: 1.1075\n",
      "Epoch 3909/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7661 - val_loss: 1.1102\n",
      "Epoch 3910/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7935 - val_loss: 1.1224\n",
      "Epoch 3911/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7827 - val_loss: 1.1513\n",
      "Epoch 3912/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7781 - val_loss: 1.1371\n",
      "Epoch 3913/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7727 - val_loss: 1.1555\n",
      "Epoch 3914/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7884 - val_loss: 1.1122\n",
      "Epoch 3915/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7899 - val_loss: 1.1106\n",
      "Epoch 3916/5000\n",
      "572/572 [==============================] - 0s 608us/step - loss: 0.7834 - val_loss: 1.0981\n",
      "Epoch 3917/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7841 - val_loss: 1.1065\n",
      "Epoch 3918/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7862 - val_loss: 1.1639\n",
      "Epoch 3919/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.7834 - val_loss: 1.1539\n",
      "Epoch 3920/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7790 - val_loss: 1.1594\n",
      "Epoch 3921/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7840 - val_loss: 1.1395\n",
      "Epoch 3922/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7811 - val_loss: 1.1398\n",
      "Epoch 3923/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7842 - val_loss: 1.1250\n",
      "Epoch 3924/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7895 - val_loss: 1.1790\n",
      "Epoch 3925/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.7892 - val_loss: 1.2407\n",
      "Epoch 3926/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7691 - val_loss: 1.1364\n",
      "Epoch 3927/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7950 - val_loss: 1.1353\n",
      "Epoch 3928/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7795 - val_loss: 1.1165\n",
      "Epoch 3929/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7819 - val_loss: 1.1169\n",
      "Epoch 3930/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7755 - val_loss: 1.1196\n",
      "Epoch 3931/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.7690 - val_loss: 1.1328\n",
      "Epoch 3932/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7839 - val_loss: 1.1329\n",
      "Epoch 3933/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7836 - val_loss: 1.1214\n",
      "Epoch 3934/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7724 - val_loss: 1.1792\n",
      "Epoch 3935/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7825 - val_loss: 1.1600\n",
      "Epoch 3936/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7909 - val_loss: 1.1102\n",
      "Epoch 3937/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7828 - val_loss: 1.1007\n",
      "Epoch 3938/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7753 - val_loss: 1.1348\n",
      "Epoch 3939/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7779 - val_loss: 1.1460\n",
      "Epoch 3940/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7924 - val_loss: 1.1140\n",
      "Epoch 3941/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7919 - val_loss: 1.1424\n",
      "Epoch 3942/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7838 - val_loss: 1.1568\n",
      "Epoch 3943/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.7849 - val_loss: 1.1645\n",
      "Epoch 3944/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7804 - val_loss: 1.1604\n",
      "Epoch 3945/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7640 - val_loss: 1.1597\n",
      "Epoch 3946/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7772 - val_loss: 1.1271\n",
      "Epoch 3947/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7939 - val_loss: 1.1424\n",
      "Epoch 3948/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7884 - val_loss: 1.1377\n",
      "Epoch 3949/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7774 - val_loss: 1.1393\n",
      "Epoch 3950/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7817 - val_loss: 1.1561\n",
      "Epoch 3951/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.7859 - val_loss: 1.1513\n",
      "Epoch 3952/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7884 - val_loss: 1.1605\n",
      "Epoch 3953/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.7947 - val_loss: 1.1893\n",
      "Epoch 3954/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.8003 - val_loss: 1.1740\n",
      "Epoch 3955/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7727 - val_loss: 1.1544\n",
      "Epoch 3956/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7820 - val_loss: 1.1570\n",
      "Epoch 3957/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7848 - val_loss: 1.1424\n",
      "Epoch 3958/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7836 - val_loss: 1.1422\n",
      "Epoch 3959/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7822 - val_loss: 1.1761\n",
      "Epoch 3960/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7820 - val_loss: 1.1080\n",
      "Epoch 3961/5000\n",
      "572/572 [==============================] - 0s 814us/step - loss: 0.7742 - val_loss: 1.1067\n",
      "Epoch 3962/5000\n",
      "572/572 [==============================] - 0s 763us/step - loss: 0.7967 - val_loss: 1.1596\n",
      "Epoch 3963/5000\n",
      "572/572 [==============================] - 0s 746us/step - loss: 0.7870 - val_loss: 1.1666\n",
      "Epoch 3964/5000\n",
      "572/572 [==============================] - 0s 742us/step - loss: 0.7793 - val_loss: 1.1270\n",
      "Epoch 3965/5000\n",
      "572/572 [==============================] - 0s 702us/step - loss: 0.7752 - val_loss: 1.1662\n",
      "Epoch 3966/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 634us/step - loss: 0.7822 - val_loss: 1.1219\n",
      "Epoch 3967/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.7619 - val_loss: 1.1523\n",
      "Epoch 3968/5000\n",
      "572/572 [==============================] - 0s 787us/step - loss: 0.7893 - val_loss: 1.1459\n",
      "Epoch 3969/5000\n",
      "572/572 [==============================] - 0s 759us/step - loss: 0.7831 - val_loss: 1.1773\n",
      "Epoch 3970/5000\n",
      "572/572 [==============================] - 0s 691us/step - loss: 0.7874 - val_loss: 1.1384\n",
      "Epoch 3971/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7909 - val_loss: 1.1503\n",
      "Epoch 3972/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7825 - val_loss: 1.1821\n",
      "Epoch 3973/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7646 - val_loss: 1.1275\n",
      "Epoch 3974/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7848 - val_loss: 1.0980\n",
      "Epoch 3975/5000\n",
      "572/572 [==============================] - 0s 613us/step - loss: 0.8079 - val_loss: 1.1520\n",
      "Epoch 3976/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7767 - val_loss: 1.1299\n",
      "Epoch 3977/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7721 - val_loss: 1.1243\n",
      "Epoch 3978/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7769 - val_loss: 1.0934\n",
      "Epoch 3979/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7915 - val_loss: 1.1069\n",
      "Epoch 3980/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.8017 - val_loss: 1.1725\n",
      "Epoch 3981/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7770 - val_loss: 1.1478\n",
      "Epoch 3982/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7945 - val_loss: 1.1426\n",
      "Epoch 3983/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7850 - val_loss: 1.1245\n",
      "Epoch 3984/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7821 - val_loss: 1.1659\n",
      "Epoch 3985/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7873 - val_loss: 1.1542\n",
      "Epoch 3986/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.7889 - val_loss: 1.1372\n",
      "Epoch 3987/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7760 - val_loss: 1.1289\n",
      "Epoch 3988/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7975 - val_loss: 1.1185\n",
      "Epoch 3989/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7786 - val_loss: 1.1296\n",
      "Epoch 3990/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7759 - val_loss: 1.1634\n",
      "Epoch 3991/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.7791 - val_loss: 1.1441\n",
      "Epoch 3992/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.7716 - val_loss: 1.1235\n",
      "Epoch 3993/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7909 - val_loss: 1.1423\n",
      "Epoch 3994/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7734 - val_loss: 1.1840\n",
      "Epoch 3995/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7881 - val_loss: 1.1484\n",
      "Epoch 3996/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.7958 - val_loss: 1.1564\n",
      "Epoch 3997/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7791 - val_loss: 1.1169\n",
      "Epoch 3998/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7782 - val_loss: 1.1627\n",
      "Epoch 3999/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7919 - val_loss: 1.1618\n",
      "Epoch 4000/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7950 - val_loss: 1.1530\n",
      "Epoch 4001/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7829 - val_loss: 1.1436\n",
      "Epoch 4002/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7832 - val_loss: 1.1606\n",
      "Epoch 4003/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7832 - val_loss: 1.1599\n",
      "Epoch 4004/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7736 - val_loss: 1.1670\n",
      "Epoch 4005/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7746 - val_loss: 1.1488\n",
      "Epoch 4006/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7955 - val_loss: 1.1840\n",
      "Epoch 4007/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7976 - val_loss: 1.1665\n",
      "Epoch 4008/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7751 - val_loss: 1.2041\n",
      "Epoch 4009/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7739 - val_loss: 1.1436\n",
      "Epoch 4010/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7832 - val_loss: 1.1155\n",
      "Epoch 4011/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7722 - val_loss: 1.1306\n",
      "Epoch 4012/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7709 - val_loss: 1.1535\n",
      "Epoch 4013/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7738 - val_loss: 1.1980\n",
      "Epoch 4014/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.7721 - val_loss: 1.1721\n",
      "Epoch 4015/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7838 - val_loss: 1.1663\n",
      "Epoch 4016/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7968 - val_loss: 1.1418\n",
      "Epoch 4017/5000\n",
      "572/572 [==============================] - 0s 621us/step - loss: 0.7810 - val_loss: 1.1319\n",
      "Epoch 4018/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7914 - val_loss: 1.1205\n",
      "Epoch 4019/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8017 - val_loss: 1.1432\n",
      "Epoch 4020/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.7898 - val_loss: 1.1723\n",
      "Epoch 4021/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7834 - val_loss: 1.1384\n",
      "Epoch 4022/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7732 - val_loss: 1.1160\n",
      "Epoch 4023/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.7664 - val_loss: 1.1299\n",
      "Epoch 4024/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7871 - val_loss: 1.1593\n",
      "Epoch 4025/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7846 - val_loss: 1.1185\n",
      "Epoch 4026/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7824 - val_loss: 1.1054\n",
      "Epoch 4027/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7764 - val_loss: 1.1485\n",
      "Epoch 4028/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7863 - val_loss: 1.1650\n",
      "Epoch 4029/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7781 - val_loss: 1.1377\n",
      "Epoch 4030/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7904 - val_loss: 1.1029\n",
      "Epoch 4031/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7748 - val_loss: 1.2023\n",
      "Epoch 4032/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7810 - val_loss: 1.1441\n",
      "Epoch 4033/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7846 - val_loss: 1.1713\n",
      "Epoch 4034/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7879 - val_loss: 1.1644\n",
      "Epoch 4035/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7830 - val_loss: 1.1409\n",
      "Epoch 4036/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7849 - val_loss: 1.1058\n",
      "Epoch 4037/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7887 - val_loss: 1.1948\n",
      "Epoch 4038/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7762 - val_loss: 1.1724\n",
      "Epoch 4039/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7882 - val_loss: 1.2361\n",
      "Epoch 4040/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7921 - val_loss: 1.1766\n",
      "Epoch 4041/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7912 - val_loss: 1.1764\n",
      "Epoch 4042/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 637us/step - loss: 0.7786 - val_loss: 1.1574\n",
      "Epoch 4043/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7811 - val_loss: 1.1407\n",
      "Epoch 4044/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.7798 - val_loss: 1.1475\n",
      "Epoch 4045/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7807 - val_loss: 1.1255\n",
      "Epoch 4046/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7860 - val_loss: 1.1399\n",
      "Epoch 4047/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7713 - val_loss: 1.1257\n",
      "Epoch 4048/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7906 - val_loss: 1.1860\n",
      "Epoch 4049/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7782 - val_loss: 1.1662\n",
      "Epoch 4050/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7846 - val_loss: 1.1485\n",
      "Epoch 4051/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7781 - val_loss: 1.1436\n",
      "Epoch 4052/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7844 - val_loss: 1.1318\n",
      "Epoch 4053/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7975 - val_loss: 1.1271\n",
      "Epoch 4054/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7819 - val_loss: 1.1280\n",
      "Epoch 4055/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.7889 - val_loss: 1.1319\n",
      "Epoch 4056/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7968 - val_loss: 1.1530\n",
      "Epoch 4057/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7797 - val_loss: 1.1445\n",
      "Epoch 4058/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7842 - val_loss: 1.1556\n",
      "Epoch 4059/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7922 - val_loss: 1.1355\n",
      "Epoch 4060/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7880 - val_loss: 1.1377\n",
      "Epoch 4061/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7832 - val_loss: 1.1281\n",
      "Epoch 4062/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7858 - val_loss: 1.1031\n",
      "Epoch 4063/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7695 - val_loss: 1.1227\n",
      "Epoch 4064/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7726 - val_loss: 1.1200\n",
      "Epoch 4065/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7762 - val_loss: 1.1629\n",
      "Epoch 4066/5000\n",
      "572/572 [==============================] - 0s 692us/step - loss: 0.7789 - val_loss: 1.1207\n",
      "Epoch 4067/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7778 - val_loss: 1.1404\n",
      "Epoch 4068/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7836 - val_loss: 1.1339\n",
      "Epoch 4069/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7787 - val_loss: 1.1489\n",
      "Epoch 4070/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7880 - val_loss: 1.1454\n",
      "Epoch 4071/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7768 - val_loss: 1.1888\n",
      "Epoch 4072/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7899 - val_loss: 1.1440\n",
      "Epoch 4073/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7931 - val_loss: 1.1607\n",
      "Epoch 4074/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7922 - val_loss: 1.1652\n",
      "Epoch 4075/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7875 - val_loss: 1.1318\n",
      "Epoch 4076/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7682 - val_loss: 1.1610\n",
      "Epoch 4077/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7965 - val_loss: 1.1687\n",
      "Epoch 4078/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7797 - val_loss: 1.1363\n",
      "Epoch 4079/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7761 - val_loss: 1.1364\n",
      "Epoch 4080/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.7886 - val_loss: 1.1915\n",
      "Epoch 4081/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7914 - val_loss: 1.1948\n",
      "Epoch 4082/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7774 - val_loss: 1.1585\n",
      "Epoch 4083/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7790 - val_loss: 1.1978\n",
      "Epoch 4084/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7885 - val_loss: 1.1880\n",
      "Epoch 4085/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7801 - val_loss: 1.1347\n",
      "Epoch 4086/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7750 - val_loss: 1.1586\n",
      "Epoch 4087/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.7793 - val_loss: 1.1789\n",
      "Epoch 4088/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7606 - val_loss: 1.1413\n",
      "Epoch 4089/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7856 - val_loss: 1.1153\n",
      "Epoch 4090/5000\n",
      "572/572 [==============================] - 0s 613us/step - loss: 0.7638 - val_loss: 1.1150\n",
      "Epoch 4091/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7880 - val_loss: 1.1229\n",
      "Epoch 4092/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.7992 - val_loss: 1.1179\n",
      "Epoch 4093/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7700 - val_loss: 1.1146\n",
      "Epoch 4094/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7815 - val_loss: 1.1260\n",
      "Epoch 4095/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7665 - val_loss: 1.1435\n",
      "Epoch 4096/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7701 - val_loss: 1.1707\n",
      "Epoch 4097/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7864 - val_loss: 1.1530\n",
      "Epoch 4098/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7802 - val_loss: 1.1230\n",
      "Epoch 4099/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7814 - val_loss: 1.1187\n",
      "Epoch 4100/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.8142 - val_loss: 1.1227\n",
      "Epoch 4101/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7704 - val_loss: 1.1464\n",
      "Epoch 4102/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7693 - val_loss: 1.1246\n",
      "Epoch 4103/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7882 - val_loss: 1.1583\n",
      "Epoch 4104/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7834 - val_loss: 1.1455\n",
      "Epoch 4105/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7786 - val_loss: 1.1093\n",
      "Epoch 4106/5000\n",
      "572/572 [==============================] - 0s 687us/step - loss: 0.7902 - val_loss: 1.1228\n",
      "Epoch 4107/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7898 - val_loss: 1.1506\n",
      "Epoch 4108/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7848 - val_loss: 1.1743\n",
      "Epoch 4109/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7923 - val_loss: 1.1378\n",
      "Epoch 4110/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.7803 - val_loss: 1.1330\n",
      "Epoch 4111/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7957 - val_loss: 1.1326\n",
      "Epoch 4112/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7737 - val_loss: 1.1472\n",
      "Epoch 4113/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7793 - val_loss: 1.1459\n",
      "Epoch 4114/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7769 - val_loss: 1.1144\n",
      "Epoch 4115/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7761 - val_loss: 1.1190\n",
      "Epoch 4116/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7746 - val_loss: 1.1068\n",
      "Epoch 4117/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7803 - val_loss: 1.1108\n",
      "Epoch 4118/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 646us/step - loss: 0.8028 - val_loss: 1.1507\n",
      "Epoch 4119/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7753 - val_loss: 1.1277\n",
      "Epoch 4120/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7868 - val_loss: 1.1488\n",
      "Epoch 4121/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7787 - val_loss: 1.1826\n",
      "Epoch 4122/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7730 - val_loss: 1.1341\n",
      "Epoch 4123/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7841 - val_loss: 1.1758\n",
      "Epoch 4124/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7847 - val_loss: 1.1013\n",
      "Epoch 4125/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7804 - val_loss: 1.1171\n",
      "Epoch 4126/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7915 - val_loss: 1.0753\n",
      "Epoch 4127/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7955 - val_loss: 1.0803\n",
      "Epoch 4128/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7699 - val_loss: 1.0679\n",
      "Epoch 4129/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7755 - val_loss: 1.0923\n",
      "Epoch 4130/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7801 - val_loss: 1.1066\n",
      "Epoch 4131/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7791 - val_loss: 1.0894\n",
      "Epoch 4132/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7722 - val_loss: 1.0752\n",
      "Epoch 4133/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7835 - val_loss: 1.1344\n",
      "Epoch 4134/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.7655 - val_loss: 1.1610\n",
      "Epoch 4135/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7886 - val_loss: 1.1066\n",
      "Epoch 4136/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7850 - val_loss: 1.0983\n",
      "Epoch 4137/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7806 - val_loss: 1.1918\n",
      "Epoch 4138/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7792 - val_loss: 1.1542\n",
      "Epoch 4139/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7765 - val_loss: 1.1132\n",
      "Epoch 4140/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7890 - val_loss: 1.1405\n",
      "Epoch 4141/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7865 - val_loss: 1.1275\n",
      "Epoch 4142/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7785 - val_loss: 1.1282\n",
      "Epoch 4143/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7855 - val_loss: 1.1208\n",
      "Epoch 4144/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7859 - val_loss: 1.1310\n",
      "Epoch 4145/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7680 - val_loss: 1.1222\n",
      "Epoch 4146/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7929 - val_loss: 1.1001\n",
      "Epoch 4147/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7845 - val_loss: 1.1387\n",
      "Epoch 4148/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7954 - val_loss: 1.1394\n",
      "Epoch 4149/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7774 - val_loss: 1.1352\n",
      "Epoch 4150/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7832 - val_loss: 1.1346\n",
      "Epoch 4151/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.8011 - val_loss: 1.1289\n",
      "Epoch 4152/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.7826 - val_loss: 1.1256\n",
      "Epoch 4153/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7835 - val_loss: 1.1504\n",
      "Epoch 4154/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7863 - val_loss: 1.1275\n",
      "Epoch 4155/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7689 - val_loss: 1.1318\n",
      "Epoch 4156/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7776 - val_loss: 1.1101\n",
      "Epoch 4157/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7742 - val_loss: 1.1344\n",
      "Epoch 4158/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7862 - val_loss: 1.1562\n",
      "Epoch 4159/5000\n",
      "572/572 [==============================] - 0s 618us/step - loss: 0.7704 - val_loss: 1.1353\n",
      "Epoch 4160/5000\n",
      "572/572 [==============================] - 0s 695us/step - loss: 0.7837 - val_loss: 1.1253\n",
      "Epoch 4161/5000\n",
      "572/572 [==============================] - 0s 709us/step - loss: 0.7855 - val_loss: 1.1248\n",
      "Epoch 4162/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7745 - val_loss: 1.1394\n",
      "Epoch 4163/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7827 - val_loss: 1.2013\n",
      "Epoch 4164/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7743 - val_loss: 1.1521\n",
      "Epoch 4165/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7832 - val_loss: 1.1588\n",
      "Epoch 4166/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7747 - val_loss: 1.1569\n",
      "Epoch 4167/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7806 - val_loss: 1.1129\n",
      "Epoch 4168/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.7721 - val_loss: 1.1472\n",
      "Epoch 4169/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7798 - val_loss: 1.1319\n",
      "Epoch 4170/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.7691 - val_loss: 1.1315\n",
      "Epoch 4171/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7966 - val_loss: 1.1333\n",
      "Epoch 4172/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7841 - val_loss: 1.1402\n",
      "Epoch 4173/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.7932 - val_loss: 1.1490\n",
      "Epoch 4174/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7654 - val_loss: 1.1325\n",
      "Epoch 4175/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7813 - val_loss: 1.1379\n",
      "Epoch 4176/5000\n",
      "572/572 [==============================] - 0s 715us/step - loss: 0.7784 - val_loss: 1.1295\n",
      "Epoch 4177/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7803 - val_loss: 1.1083\n",
      "Epoch 4178/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7760 - val_loss: 1.1149\n",
      "Epoch 4179/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7606 - val_loss: 1.1389\n",
      "Epoch 4180/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7661 - val_loss: 1.1279\n",
      "Epoch 4181/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7737 - val_loss: 1.0970\n",
      "Epoch 4182/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.7701 - val_loss: 1.0921\n",
      "Epoch 4183/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7904 - val_loss: 1.1303\n",
      "Epoch 4184/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7920 - val_loss: 1.0813\n",
      "Epoch 4185/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7744 - val_loss: 1.1014\n",
      "Epoch 4186/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7732 - val_loss: 1.0878\n",
      "Epoch 4187/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7677 - val_loss: 1.1030\n",
      "Epoch 4188/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7614 - val_loss: 1.0896\n",
      "Epoch 4189/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7695 - val_loss: 1.1050\n",
      "Epoch 4190/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7732 - val_loss: 1.0962\n",
      "Epoch 4191/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7860 - val_loss: 1.0944\n",
      "Epoch 4192/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7906 - val_loss: 1.0608\n",
      "Epoch 4193/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7784 - val_loss: 1.0874\n",
      "Epoch 4194/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 633us/step - loss: 0.7706 - val_loss: 1.1279\n",
      "Epoch 4195/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7579 - val_loss: 1.1318\n",
      "Epoch 4196/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7975 - val_loss: 1.1678\n",
      "Epoch 4197/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7684 - val_loss: 1.1506\n",
      "Epoch 4198/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7675 - val_loss: 1.1032\n",
      "Epoch 4199/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7857 - val_loss: 1.1326\n",
      "Epoch 4200/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7881 - val_loss: 1.1278\n",
      "Epoch 4201/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7891 - val_loss: 1.1380\n",
      "Epoch 4202/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7651 - val_loss: 1.1509\n",
      "Epoch 4203/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.7779 - val_loss: 1.1447\n",
      "Epoch 4204/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7846 - val_loss: 1.1376\n",
      "Epoch 4205/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7850 - val_loss: 1.1317\n",
      "Epoch 4206/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7819 - val_loss: 1.1691\n",
      "Epoch 4207/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7805 - val_loss: 1.1405\n",
      "Epoch 4208/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7907 - val_loss: 1.1557\n",
      "Epoch 4209/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7878 - val_loss: 1.1543\n",
      "Epoch 4210/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7823 - val_loss: 1.1072\n",
      "Epoch 4211/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7765 - val_loss: 1.1191\n",
      "Epoch 4212/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7756 - val_loss: 1.1463\n",
      "Epoch 4213/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7899 - val_loss: 1.1411\n",
      "Epoch 4214/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7798 - val_loss: 1.1053\n",
      "Epoch 4215/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7919 - val_loss: 1.1116\n",
      "Epoch 4216/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.7583 - val_loss: 1.1217\n",
      "Epoch 4217/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7833 - val_loss: 1.1575\n",
      "Epoch 4218/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7845 - val_loss: 1.1360\n",
      "Epoch 4219/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7689 - val_loss: 1.1331\n",
      "Epoch 4220/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7839 - val_loss: 1.1330\n",
      "Epoch 4221/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7650 - val_loss: 1.1337\n",
      "Epoch 4222/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7678 - val_loss: 1.1324\n",
      "Epoch 4223/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7883 - val_loss: 1.1158\n",
      "Epoch 4224/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 0.7861 - val_loss: 1.1392\n",
      "Epoch 4225/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7945 - val_loss: 1.0952\n",
      "Epoch 4226/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7770 - val_loss: 1.1103\n",
      "Epoch 4227/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7779 - val_loss: 1.1182\n",
      "Epoch 4228/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7785 - val_loss: 1.1241\n",
      "Epoch 4229/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7874 - val_loss: 1.1417\n",
      "Epoch 4230/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7809 - val_loss: 1.1365\n",
      "Epoch 4231/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7743 - val_loss: 1.1122\n",
      "Epoch 4232/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.7884 - val_loss: 1.1111\n",
      "Epoch 4233/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7706 - val_loss: 1.1086\n",
      "Epoch 4234/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7838 - val_loss: 1.1187\n",
      "Epoch 4235/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7803 - val_loss: 1.1269\n",
      "Epoch 4236/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7855 - val_loss: 1.1084\n",
      "Epoch 4237/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7838 - val_loss: 1.1368\n",
      "Epoch 4238/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7666 - val_loss: 1.1331\n",
      "Epoch 4239/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7842 - val_loss: 1.1179\n",
      "Epoch 4240/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7844 - val_loss: 1.1225\n",
      "Epoch 4241/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.7782 - val_loss: 1.1207\n",
      "Epoch 4242/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7796 - val_loss: 1.1085\n",
      "Epoch 4243/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7896 - val_loss: 1.1257\n",
      "Epoch 4244/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7779 - val_loss: 1.1127\n",
      "Epoch 4245/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.7834 - val_loss: 1.1188\n",
      "Epoch 4246/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7791 - val_loss: 1.1477\n",
      "Epoch 4247/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7781 - val_loss: 1.1270\n",
      "Epoch 4248/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7820 - val_loss: 1.1282\n",
      "Epoch 4249/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7817 - val_loss: 1.1199\n",
      "Epoch 4250/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7836 - val_loss: 1.1044\n",
      "Epoch 4251/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7844 - val_loss: 1.1084\n",
      "Epoch 4252/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.7902 - val_loss: 1.0800\n",
      "Epoch 4253/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7677 - val_loss: 1.0935\n",
      "Epoch 4254/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7718 - val_loss: 1.1056\n",
      "Epoch 4255/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.7798 - val_loss: 1.0982\n",
      "Epoch 4256/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7721 - val_loss: 1.1136\n",
      "Epoch 4257/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7697 - val_loss: 1.1238\n",
      "Epoch 4258/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7752 - val_loss: 1.1122\n",
      "Epoch 4259/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 0.7720 - val_loss: 1.1214\n",
      "Epoch 4260/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7680 - val_loss: 1.1594\n",
      "Epoch 4261/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7785 - val_loss: 1.1381\n",
      "Epoch 4262/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7913 - val_loss: 1.0844\n",
      "Epoch 4263/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7738 - val_loss: 1.0735\n",
      "Epoch 4264/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7822 - val_loss: 1.1412\n",
      "Epoch 4265/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7760 - val_loss: 1.1084\n",
      "Epoch 4266/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7902 - val_loss: 1.0983\n",
      "Epoch 4267/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7814 - val_loss: 1.0943\n",
      "Epoch 4268/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7717 - val_loss: 1.0771\n",
      "Epoch 4269/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7766 - val_loss: 1.1120\n",
      "Epoch 4270/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 663us/step - loss: 0.7832 - val_loss: 1.1141\n",
      "Epoch 4271/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7934 - val_loss: 1.1504\n",
      "Epoch 4272/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7761 - val_loss: 1.1875\n",
      "Epoch 4273/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.7917 - val_loss: 1.1240\n",
      "Epoch 4274/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7823 - val_loss: 1.1102\n",
      "Epoch 4275/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7733 - val_loss: 1.0634\n",
      "Epoch 4276/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7726 - val_loss: 1.0776\n",
      "Epoch 4277/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7628 - val_loss: 1.0793\n",
      "Epoch 4278/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7844 - val_loss: 1.1021\n",
      "Epoch 4279/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7870 - val_loss: 1.1122\n",
      "Epoch 4280/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7649 - val_loss: 1.0877\n",
      "Epoch 4281/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7824 - val_loss: 1.0923\n",
      "Epoch 4282/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7818 - val_loss: 1.1137\n",
      "Epoch 4283/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 0.7797 - val_loss: 1.1476\n",
      "Epoch 4284/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7684 - val_loss: 1.1538\n",
      "Epoch 4285/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7711 - val_loss: 1.1447\n",
      "Epoch 4286/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7753 - val_loss: 1.0983\n",
      "Epoch 4287/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7761 - val_loss: 1.1058\n",
      "Epoch 4288/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7657 - val_loss: 1.1458\n",
      "Epoch 4289/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7675 - val_loss: 1.1219\n",
      "Epoch 4290/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7925 - val_loss: 1.1336\n",
      "Epoch 4291/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7690 - val_loss: 1.1483\n",
      "Epoch 4292/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7689 - val_loss: 1.0842\n",
      "Epoch 4293/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7822 - val_loss: 1.0899\n",
      "Epoch 4294/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7636 - val_loss: 1.1012\n",
      "Epoch 4295/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.7990 - val_loss: 1.1129\n",
      "Epoch 4296/5000\n",
      "572/572 [==============================] - 0s 617us/step - loss: 0.7708 - val_loss: 1.1037\n",
      "Epoch 4297/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7771 - val_loss: 1.1083\n",
      "Epoch 4298/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7817 - val_loss: 1.1086\n",
      "Epoch 4299/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7823 - val_loss: 1.1242\n",
      "Epoch 4300/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7896 - val_loss: 1.1182\n",
      "Epoch 4301/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7880 - val_loss: 1.1193\n",
      "Epoch 4302/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7673 - val_loss: 1.1634\n",
      "Epoch 4303/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 0.7759 - val_loss: 1.1294\n",
      "Epoch 4304/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7685 - val_loss: 1.1106\n",
      "Epoch 4305/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.7714 - val_loss: 1.1063\n",
      "Epoch 4306/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7816 - val_loss: 1.0959\n",
      "Epoch 4307/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7773 - val_loss: 1.1080\n",
      "Epoch 4308/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.7792 - val_loss: 1.1006\n",
      "Epoch 4309/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.7917 - val_loss: 1.0869\n",
      "Epoch 4310/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.7862 - val_loss: 1.0919\n",
      "Epoch 4311/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7915 - val_loss: 1.1081\n",
      "Epoch 4312/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7791 - val_loss: 1.0949\n",
      "Epoch 4313/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.7866 - val_loss: 1.0874\n",
      "Epoch 4314/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7795 - val_loss: 1.0738\n",
      "Epoch 4315/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7788 - val_loss: 1.1140\n",
      "Epoch 4316/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7661 - val_loss: 1.1294\n",
      "Epoch 4317/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7715 - val_loss: 1.0914\n",
      "Epoch 4318/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7822 - val_loss: 1.0926\n",
      "Epoch 4319/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7845 - val_loss: 1.0839\n",
      "Epoch 4320/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7810 - val_loss: 1.0944\n",
      "Epoch 4321/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7776 - val_loss: 1.1226\n",
      "Epoch 4322/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7742 - val_loss: 1.0765\n",
      "Epoch 4323/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7922 - val_loss: 1.0857\n",
      "Epoch 4324/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.7783 - val_loss: 1.0912\n",
      "Epoch 4325/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7647 - val_loss: 1.0804\n",
      "Epoch 4326/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7853 - val_loss: 1.0868\n",
      "Epoch 4327/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7814 - val_loss: 1.1143\n",
      "Epoch 4328/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7660 - val_loss: 1.1630\n",
      "Epoch 4329/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7589 - val_loss: 1.1262\n",
      "Epoch 4330/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7878 - val_loss: 1.1126\n",
      "Epoch 4331/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7586 - val_loss: 1.1024\n",
      "Epoch 4332/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7748 - val_loss: 1.0912\n",
      "Epoch 4333/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7957 - val_loss: 1.0699\n",
      "Epoch 4334/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7765 - val_loss: 1.1035\n",
      "Epoch 4335/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7721 - val_loss: 1.1484\n",
      "Epoch 4336/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7775 - val_loss: 1.1069\n",
      "Epoch 4337/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7759 - val_loss: 1.1072\n",
      "Epoch 4338/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7734 - val_loss: 1.0949\n",
      "Epoch 4339/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.7780 - val_loss: 1.1309\n",
      "Epoch 4340/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7732 - val_loss: 1.1132\n",
      "Epoch 4341/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7650 - val_loss: 1.0973\n",
      "Epoch 4342/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7854 - val_loss: 1.1152\n",
      "Epoch 4343/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7562 - val_loss: 1.0963\n",
      "Epoch 4344/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7779 - val_loss: 1.0476\n",
      "Epoch 4345/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7770 - val_loss: 1.0722\n",
      "Epoch 4346/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 641us/step - loss: 0.7673 - val_loss: 1.0628\n",
      "Epoch 4347/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7672 - val_loss: 1.0763\n",
      "Epoch 4348/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7820 - val_loss: 1.0715\n",
      "Epoch 4349/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7728 - val_loss: 1.0781\n",
      "Epoch 4350/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7698 - val_loss: 1.0778\n",
      "Epoch 4351/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7707 - val_loss: 1.0764\n",
      "Epoch 4352/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7681 - val_loss: 1.0497\n",
      "Epoch 4353/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7817 - val_loss: 1.0551\n",
      "Epoch 4354/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7896 - val_loss: 1.0838\n",
      "Epoch 4355/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7744 - val_loss: 1.0796\n",
      "Epoch 4356/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7687 - val_loss: 1.0825\n",
      "Epoch 4357/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.7901 - val_loss: 1.1097\n",
      "Epoch 4358/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7825 - val_loss: 1.1277\n",
      "Epoch 4359/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7949 - val_loss: 1.0600\n",
      "Epoch 4360/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7885 - val_loss: 1.0725\n",
      "Epoch 4361/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7786 - val_loss: 1.0899\n",
      "Epoch 4362/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7732 - val_loss: 1.1340\n",
      "Epoch 4363/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7694 - val_loss: 1.1343\n",
      "Epoch 4364/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7828 - val_loss: 1.1276\n",
      "Epoch 4365/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7718 - val_loss: 1.0953\n",
      "Epoch 4366/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7822 - val_loss: 1.0936\n",
      "Epoch 4367/5000\n",
      "572/572 [==============================] - 0s 621us/step - loss: 0.7836 - val_loss: 1.0946\n",
      "Epoch 4368/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.7812 - val_loss: 1.0988\n",
      "Epoch 4369/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7678 - val_loss: 1.1036\n",
      "Epoch 4370/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7844 - val_loss: 1.1394\n",
      "Epoch 4371/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7523 - val_loss: 1.1437\n",
      "Epoch 4372/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7689 - val_loss: 1.1017\n",
      "Epoch 4373/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7771 - val_loss: 1.1421\n",
      "Epoch 4374/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7644 - val_loss: 1.0968\n",
      "Epoch 4375/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7602 - val_loss: 1.0958\n",
      "Epoch 4376/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7728 - val_loss: 1.0711\n",
      "Epoch 4377/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7685 - val_loss: 1.0789\n",
      "Epoch 4378/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7730 - val_loss: 1.0767\n",
      "Epoch 4379/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7735 - val_loss: 1.0751\n",
      "Epoch 4380/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7866 - val_loss: 1.0599\n",
      "Epoch 4381/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7816 - val_loss: 1.0658\n",
      "Epoch 4382/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7633 - val_loss: 1.0658\n",
      "Epoch 4383/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7833 - val_loss: 1.0758\n",
      "Epoch 4384/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7819 - val_loss: 1.1123\n",
      "Epoch 4385/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7689 - val_loss: 1.1324\n",
      "Epoch 4386/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.7683 - val_loss: 1.1335\n",
      "Epoch 4387/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7701 - val_loss: 1.1130\n",
      "Epoch 4388/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7720 - val_loss: 1.0869\n",
      "Epoch 4389/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7811 - val_loss: 1.0771\n",
      "Epoch 4390/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7825 - val_loss: 1.1101\n",
      "Epoch 4391/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7859 - val_loss: 1.1085\n",
      "Epoch 4392/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7867 - val_loss: 1.0836\n",
      "Epoch 4393/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7730 - val_loss: 1.0989\n",
      "Epoch 4394/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7793 - val_loss: 1.1094\n",
      "Epoch 4395/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7721 - val_loss: 1.0863\n",
      "Epoch 4396/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7833 - val_loss: 1.0832\n",
      "Epoch 4397/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7721 - val_loss: 1.0550\n",
      "Epoch 4398/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7731 - val_loss: 1.1185\n",
      "Epoch 4399/5000\n",
      "572/572 [==============================] - 0s 618us/step - loss: 0.7806 - val_loss: 1.1276\n",
      "Epoch 4400/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7756 - val_loss: 1.1048\n",
      "Epoch 4401/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.7730 - val_loss: 1.0888\n",
      "Epoch 4402/5000\n",
      "572/572 [==============================] - 0s 690us/step - loss: 0.7916 - val_loss: 1.1255\n",
      "Epoch 4403/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7756 - val_loss: 1.1146\n",
      "Epoch 4404/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7888 - val_loss: 1.1063\n",
      "Epoch 4405/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7604 - val_loss: 1.0999\n",
      "Epoch 4406/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7765 - val_loss: 1.1115\n",
      "Epoch 4407/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7892 - val_loss: 1.1026\n",
      "Epoch 4408/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7809 - val_loss: 1.1179\n",
      "Epoch 4409/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7659 - val_loss: 1.1163\n",
      "Epoch 4410/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.7584 - val_loss: 1.1150\n",
      "Epoch 4411/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7711 - val_loss: 1.1069\n",
      "Epoch 4412/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7771 - val_loss: 1.1251\n",
      "Epoch 4413/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7710 - val_loss: 1.1213\n",
      "Epoch 4414/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7674 - val_loss: 1.1046\n",
      "Epoch 4415/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7797 - val_loss: 1.1005\n",
      "Epoch 4416/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.7772 - val_loss: 1.1180\n",
      "Epoch 4417/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.7671 - val_loss: 1.1188\n",
      "Epoch 4418/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7702 - val_loss: 1.1270\n",
      "Epoch 4419/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7693 - val_loss: 1.1488\n",
      "Epoch 4420/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7689 - val_loss: 1.1230\n",
      "Epoch 4421/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7767 - val_loss: 1.1008\n",
      "Epoch 4422/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 673us/step - loss: 0.7636 - val_loss: 1.1312\n",
      "Epoch 4423/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7601 - val_loss: 1.1367\n",
      "Epoch 4424/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7916 - val_loss: 1.1399\n",
      "Epoch 4425/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7704 - val_loss: 1.1166\n",
      "Epoch 4426/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7700 - val_loss: 1.1504\n",
      "Epoch 4427/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7738 - val_loss: 1.1285\n",
      "Epoch 4428/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7679 - val_loss: 1.0987\n",
      "Epoch 4429/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7732 - val_loss: 1.1017\n",
      "Epoch 4430/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7704 - val_loss: 1.1204\n",
      "Epoch 4431/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7770 - val_loss: 1.1170\n",
      "Epoch 4432/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7592 - val_loss: 1.0920\n",
      "Epoch 4433/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7842 - val_loss: 1.1378\n",
      "Epoch 4434/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7769 - val_loss: 1.1283\n",
      "Epoch 4435/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7686 - val_loss: 1.1120\n",
      "Epoch 4436/5000\n",
      "572/572 [==============================] - 0s 621us/step - loss: 0.7741 - val_loss: 1.1252\n",
      "Epoch 4437/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7722 - val_loss: 1.1047\n",
      "Epoch 4438/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.7625 - val_loss: 1.1048\n",
      "Epoch 4439/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7850 - val_loss: 1.0910\n",
      "Epoch 4440/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7733 - val_loss: 1.0987\n",
      "Epoch 4441/5000\n",
      "572/572 [==============================] - 0s 729us/step - loss: 0.7753 - val_loss: 1.1135\n",
      "Epoch 4442/5000\n",
      "572/572 [==============================] - 0s 719us/step - loss: 0.7672 - val_loss: 1.1473\n",
      "Epoch 4443/5000\n",
      "572/572 [==============================] - 0s 774us/step - loss: 0.8013 - val_loss: 1.1502\n",
      "Epoch 4444/5000\n",
      "572/572 [==============================] - 0s 727us/step - loss: 0.7795 - val_loss: 1.1425\n",
      "Epoch 4445/5000\n",
      "572/572 [==============================] - 0s 784us/step - loss: 0.7778 - val_loss: 1.1189\n",
      "Epoch 4446/5000\n",
      "572/572 [==============================] - 0s 690us/step - loss: 0.7798 - val_loss: 1.1275\n",
      "Epoch 4447/5000\n",
      "572/572 [==============================] - 0s 824us/step - loss: 0.7802 - val_loss: 1.1171\n",
      "Epoch 4448/5000\n",
      "572/572 [==============================] - 0s 802us/step - loss: 0.7779 - val_loss: 1.1001\n",
      "Epoch 4449/5000\n",
      "572/572 [==============================] - 0s 792us/step - loss: 0.7937 - val_loss: 1.0870\n",
      "Epoch 4450/5000\n",
      "572/572 [==============================] - 0s 706us/step - loss: 0.7761 - val_loss: 1.0964\n",
      "Epoch 4451/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7814 - val_loss: 1.1248\n",
      "Epoch 4452/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7589 - val_loss: 1.0825\n",
      "Epoch 4453/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7624 - val_loss: 1.0775\n",
      "Epoch 4454/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7642 - val_loss: 1.0970\n",
      "Epoch 4455/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7685 - val_loss: 1.1286\n",
      "Epoch 4456/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7767 - val_loss: 1.1035\n",
      "Epoch 4457/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7688 - val_loss: 1.1186\n",
      "Epoch 4458/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7831 - val_loss: 1.1039\n",
      "Epoch 4459/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7766 - val_loss: 1.1340\n",
      "Epoch 4460/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7675 - val_loss: 1.1363\n",
      "Epoch 4461/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7819 - val_loss: 1.1235\n",
      "Epoch 4462/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7766 - val_loss: 1.1051\n",
      "Epoch 4463/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.7803 - val_loss: 1.1168\n",
      "Epoch 4464/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7764 - val_loss: 1.1284\n",
      "Epoch 4465/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7711 - val_loss: 1.1021\n",
      "Epoch 4466/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7864 - val_loss: 1.1056\n",
      "Epoch 4467/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7876 - val_loss: 1.1225\n",
      "Epoch 4468/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7830 - val_loss: 1.1025\n",
      "Epoch 4469/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7764 - val_loss: 1.1552\n",
      "Epoch 4470/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7653 - val_loss: 1.1527\n",
      "Epoch 4471/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7633 - val_loss: 1.1516\n",
      "Epoch 4472/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7804 - val_loss: 1.1163\n",
      "Epoch 4473/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7670 - val_loss: 1.1331\n",
      "Epoch 4474/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7667 - val_loss: 1.1298\n",
      "Epoch 4475/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7722 - val_loss: 1.1207\n",
      "Epoch 4476/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.7655 - val_loss: 1.1411\n",
      "Epoch 4477/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7663 - val_loss: 1.1518\n",
      "Epoch 4478/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.7731 - val_loss: 1.1234\n",
      "Epoch 4479/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7744 - val_loss: 1.1113\n",
      "Epoch 4480/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7713 - val_loss: 1.1076\n",
      "Epoch 4481/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7801 - val_loss: 1.1092\n",
      "Epoch 4482/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7732 - val_loss: 1.0993\n",
      "Epoch 4483/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7751 - val_loss: 1.1350\n",
      "Epoch 4484/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7857 - val_loss: 1.1252\n",
      "Epoch 4485/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7815 - val_loss: 1.0821\n",
      "Epoch 4486/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7880 - val_loss: 1.1150\n",
      "Epoch 4487/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7686 - val_loss: 1.1092\n",
      "Epoch 4488/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7839 - val_loss: 1.1055\n",
      "Epoch 4489/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7733 - val_loss: 1.1113\n",
      "Epoch 4490/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7694 - val_loss: 1.0936\n",
      "Epoch 4491/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7778 - val_loss: 1.1213\n",
      "Epoch 4492/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7724 - val_loss: 1.1148\n",
      "Epoch 4493/5000\n",
      "572/572 [==============================] - 0s 759us/step - loss: 0.7765 - val_loss: 1.0952\n",
      "Epoch 4494/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7687 - val_loss: 1.1599\n",
      "Epoch 4495/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7758 - val_loss: 1.1324\n",
      "Epoch 4496/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7766 - val_loss: 1.0975\n",
      "Epoch 4497/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7903 - val_loss: 1.1200\n",
      "Epoch 4498/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 652us/step - loss: 0.7837 - val_loss: 1.1419\n",
      "Epoch 4499/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7759 - val_loss: 1.2115\n",
      "Epoch 4500/5000\n",
      "572/572 [==============================] - 0s 684us/step - loss: 0.7815 - val_loss: 1.1995\n",
      "Epoch 4501/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7659 - val_loss: 1.1896\n",
      "Epoch 4502/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7691 - val_loss: 1.1798\n",
      "Epoch 4503/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7773 - val_loss: 1.2528\n",
      "Epoch 4504/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7965 - val_loss: 1.2508\n",
      "Epoch 4505/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.7825 - val_loss: 1.1919\n",
      "Epoch 4506/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7840 - val_loss: 1.1863\n",
      "Epoch 4507/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7712 - val_loss: 1.1869\n",
      "Epoch 4508/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7732 - val_loss: 1.1275\n",
      "Epoch 4509/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7613 - val_loss: 1.1571\n",
      "Epoch 4510/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7657 - val_loss: 1.1855\n",
      "Epoch 4511/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7661 - val_loss: 1.1233\n",
      "Epoch 4512/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7785 - val_loss: 1.1601\n",
      "Epoch 4513/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7689 - val_loss: 1.1196\n",
      "Epoch 4514/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7782 - val_loss: 1.1423\n",
      "Epoch 4515/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7847 - val_loss: 1.1701\n",
      "Epoch 4516/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7899 - val_loss: 1.1382\n",
      "Epoch 4517/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7709 - val_loss: 1.1239\n",
      "Epoch 4518/5000\n",
      "572/572 [==============================] - 0s 682us/step - loss: 0.7708 - val_loss: 1.1221\n",
      "Epoch 4519/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7755 - val_loss: 1.1090\n",
      "Epoch 4520/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7641 - val_loss: 1.1139\n",
      "Epoch 4521/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.7838 - val_loss: 1.1284\n",
      "Epoch 4522/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7719 - val_loss: 1.1233\n",
      "Epoch 4523/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7855 - val_loss: 1.1135\n",
      "Epoch 4524/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7761 - val_loss: 1.1147\n",
      "Epoch 4525/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7772 - val_loss: 1.1281\n",
      "Epoch 4526/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7856 - val_loss: 1.1317\n",
      "Epoch 4527/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7821 - val_loss: 1.1469\n",
      "Epoch 4528/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7753 - val_loss: 1.1787\n",
      "Epoch 4529/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7642 - val_loss: 1.1661\n",
      "Epoch 4530/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7779 - val_loss: 1.1302\n",
      "Epoch 4531/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7730 - val_loss: 1.1340\n",
      "Epoch 4532/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.7805 - val_loss: 1.1245\n",
      "Epoch 4533/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7727 - val_loss: 1.1212\n",
      "Epoch 4534/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7739 - val_loss: 1.1337\n",
      "Epoch 4535/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7598 - val_loss: 1.1389\n",
      "Epoch 4536/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.7722 - val_loss: 1.1205\n",
      "Epoch 4537/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7650 - val_loss: 1.1079\n",
      "Epoch 4538/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7769 - val_loss: 1.1483\n",
      "Epoch 4539/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7793 - val_loss: 1.1490\n",
      "Epoch 4540/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7823 - val_loss: 1.1513\n",
      "Epoch 4541/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.7611 - val_loss: 1.1816\n",
      "Epoch 4542/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7724 - val_loss: 1.1761\n",
      "Epoch 4543/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7609 - val_loss: 1.1447\n",
      "Epoch 4544/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.7719 - val_loss: 1.1505\n",
      "Epoch 4545/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7563 - val_loss: 1.0999\n",
      "Epoch 4546/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7677 - val_loss: 1.1913\n",
      "Epoch 4547/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7803 - val_loss: 1.1073\n",
      "Epoch 4548/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7732 - val_loss: 1.1457\n",
      "Epoch 4549/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.7710 - val_loss: 1.1574\n",
      "Epoch 4550/5000\n",
      "572/572 [==============================] - 0s 612us/step - loss: 0.7734 - val_loss: 1.1560\n",
      "Epoch 4551/5000\n",
      "572/572 [==============================] - 0s 688us/step - loss: 0.7759 - val_loss: 1.1259\n",
      "Epoch 4552/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7794 - val_loss: 1.1501\n",
      "Epoch 4553/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7756 - val_loss: 1.1285\n",
      "Epoch 4554/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7876 - val_loss: 1.1107\n",
      "Epoch 4555/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7790 - val_loss: 1.1003\n",
      "Epoch 4556/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7658 - val_loss: 1.1525\n",
      "Epoch 4557/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7636 - val_loss: 1.1327\n",
      "Epoch 4558/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7858 - val_loss: 1.1677\n",
      "Epoch 4559/5000\n",
      "572/572 [==============================] - 0s 616us/step - loss: 0.7685 - val_loss: 1.1656\n",
      "Epoch 4560/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7839 - val_loss: 1.0907\n",
      "Epoch 4561/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7764 - val_loss: 1.1590\n",
      "Epoch 4562/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7645 - val_loss: 1.0969\n",
      "Epoch 4563/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7681 - val_loss: 1.0935\n",
      "Epoch 4564/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7591 - val_loss: 1.0946\n",
      "Epoch 4565/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7654 - val_loss: 1.1058\n",
      "Epoch 4566/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7590 - val_loss: 1.1049\n",
      "Epoch 4567/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7814 - val_loss: 1.0969\n",
      "Epoch 4568/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7560 - val_loss: 1.1092\n",
      "Epoch 4569/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7746 - val_loss: 1.1296\n",
      "Epoch 4570/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.7750 - val_loss: 1.1225\n",
      "Epoch 4571/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7899 - val_loss: 1.1435\n",
      "Epoch 4572/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7756 - val_loss: 1.1759\n",
      "Epoch 4573/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.8042 - val_loss: 1.2095\n",
      "Epoch 4574/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 653us/step - loss: 0.7768 - val_loss: 1.2028\n",
      "Epoch 4575/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7771 - val_loss: 1.1209\n",
      "Epoch 4576/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7809 - val_loss: 1.1033\n",
      "Epoch 4577/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.7714 - val_loss: 1.1231\n",
      "Epoch 4578/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7815 - val_loss: 1.1307\n",
      "Epoch 4579/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7845 - val_loss: 1.1038\n",
      "Epoch 4580/5000\n",
      "572/572 [==============================] - 0s 686us/step - loss: 0.7574 - val_loss: 1.1719\n",
      "Epoch 4581/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7738 - val_loss: 1.1502\n",
      "Epoch 4582/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7789 - val_loss: 1.0929\n",
      "Epoch 4583/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7726 - val_loss: 1.1615\n",
      "Epoch 4584/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7665 - val_loss: 1.1060\n",
      "Epoch 4585/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.7607 - val_loss: 1.1321\n",
      "Epoch 4586/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7693 - val_loss: 1.1413\n",
      "Epoch 4587/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7720 - val_loss: 1.1596\n",
      "Epoch 4588/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7845 - val_loss: 1.1644\n",
      "Epoch 4589/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7707 - val_loss: 1.1872\n",
      "Epoch 4590/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7710 - val_loss: 1.1401\n",
      "Epoch 4591/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7673 - val_loss: 1.1545\n",
      "Epoch 4592/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7590 - val_loss: 1.1210\n",
      "Epoch 4593/5000\n",
      "572/572 [==============================] - 0s 623us/step - loss: 0.7668 - val_loss: 1.1526\n",
      "Epoch 4594/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7644 - val_loss: 1.2214\n",
      "Epoch 4595/5000\n",
      "572/572 [==============================] - 0s 675us/step - loss: 0.7594 - val_loss: 1.1380\n",
      "Epoch 4596/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7766 - val_loss: 1.1444\n",
      "Epoch 4597/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7769 - val_loss: 1.1170\n",
      "Epoch 4598/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7874 - val_loss: 1.1346\n",
      "Epoch 4599/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7735 - val_loss: 1.1183\n",
      "Epoch 4600/5000\n",
      "572/572 [==============================] - 0s 678us/step - loss: 0.7727 - val_loss: 1.1544\n",
      "Epoch 4601/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7781 - val_loss: 1.1200\n",
      "Epoch 4602/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7650 - val_loss: 1.0958\n",
      "Epoch 4603/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7651 - val_loss: 1.1161\n",
      "Epoch 4604/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7838 - val_loss: 1.1159\n",
      "Epoch 4605/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7743 - val_loss: 1.1159\n",
      "Epoch 4606/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7706 - val_loss: 1.1469\n",
      "Epoch 4607/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.7706 - val_loss: 1.1680\n",
      "Epoch 4608/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7759 - val_loss: 1.1337\n",
      "Epoch 4609/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7842 - val_loss: 1.1555\n",
      "Epoch 4610/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7826 - val_loss: 1.1395\n",
      "Epoch 4611/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7734 - val_loss: 1.1378\n",
      "Epoch 4612/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7734 - val_loss: 1.1376\n",
      "Epoch 4613/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7766 - val_loss: 1.1319\n",
      "Epoch 4614/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7742 - val_loss: 1.0932\n",
      "Epoch 4615/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7645 - val_loss: 1.1402\n",
      "Epoch 4616/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7756 - val_loss: 1.1426\n",
      "Epoch 4617/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7742 - val_loss: 1.1887\n",
      "Epoch 4618/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.7825 - val_loss: 1.2082\n",
      "Epoch 4619/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7756 - val_loss: 1.2081\n",
      "Epoch 4620/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7893 - val_loss: 1.2212\n",
      "Epoch 4621/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7693 - val_loss: 1.1979\n",
      "Epoch 4622/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7633 - val_loss: 1.1891\n",
      "Epoch 4623/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7621 - val_loss: 1.1678\n",
      "Epoch 4624/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7705 - val_loss: 1.1498\n",
      "Epoch 4625/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7706 - val_loss: 1.2075\n",
      "Epoch 4626/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.7866 - val_loss: 1.1620\n",
      "Epoch 4627/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7724 - val_loss: 1.1323\n",
      "Epoch 4628/5000\n",
      "572/572 [==============================] - 0s 692us/step - loss: 0.7748 - val_loss: 1.1378\n",
      "Epoch 4629/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.7691 - val_loss: 1.1768\n",
      "Epoch 4630/5000\n",
      "572/572 [==============================] - 0s 685us/step - loss: 0.7865 - val_loss: 1.1721\n",
      "Epoch 4631/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7656 - val_loss: 1.1635\n",
      "Epoch 4632/5000\n",
      "572/572 [==============================] - 0s 681us/step - loss: 0.7774 - val_loss: 1.1587\n",
      "Epoch 4633/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7895 - val_loss: 1.1418\n",
      "Epoch 4634/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7747 - val_loss: 1.1111\n",
      "Epoch 4635/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7757 - val_loss: 1.1085\n",
      "Epoch 4636/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7732 - val_loss: 1.1255\n",
      "Epoch 4637/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.7835 - val_loss: 1.1337\n",
      "Epoch 4638/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.7655 - val_loss: 1.1858\n",
      "Epoch 4639/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7567 - val_loss: 1.1928\n",
      "Epoch 4640/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7823 - val_loss: 1.1190\n",
      "Epoch 4641/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7644 - val_loss: 1.1403\n",
      "Epoch 4642/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7693 - val_loss: 1.1368\n",
      "Epoch 4643/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7797 - val_loss: 1.1482\n",
      "Epoch 4644/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7797 - val_loss: 1.1507\n",
      "Epoch 4645/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.7654 - val_loss: 1.1556\n",
      "Epoch 4646/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7748 - val_loss: 1.1782\n",
      "Epoch 4647/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7796 - val_loss: 1.1900\n",
      "Epoch 4648/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.8034 - val_loss: 1.1864\n",
      "Epoch 4649/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7818 - val_loss: 1.1749\n",
      "Epoch 4650/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 661us/step - loss: 0.7746 - val_loss: 1.1371\n",
      "Epoch 4651/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7664 - val_loss: 1.1899\n",
      "Epoch 4652/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7677 - val_loss: 1.1469\n",
      "Epoch 4653/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7746 - val_loss: 1.1454\n",
      "Epoch 4654/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7708 - val_loss: 1.1246\n",
      "Epoch 4655/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7773 - val_loss: 1.1138\n",
      "Epoch 4656/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7799 - val_loss: 1.0855\n",
      "Epoch 4657/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7698 - val_loss: 1.1122\n",
      "Epoch 4658/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.7695 - val_loss: 1.1052\n",
      "Epoch 4659/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7730 - val_loss: 1.1054\n",
      "Epoch 4660/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7724 - val_loss: 1.1145\n",
      "Epoch 4661/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7814 - val_loss: 1.0917\n",
      "Epoch 4662/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7717 - val_loss: 1.1042\n",
      "Epoch 4663/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7547 - val_loss: 1.1450\n",
      "Epoch 4664/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7595 - val_loss: 1.1240\n",
      "Epoch 4665/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7822 - val_loss: 1.1117\n",
      "Epoch 4666/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7617 - val_loss: 1.0862\n",
      "Epoch 4667/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7678 - val_loss: 1.1200\n",
      "Epoch 4668/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7720 - val_loss: 1.1306\n",
      "Epoch 4669/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7859 - val_loss: 1.0887\n",
      "Epoch 4670/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7727 - val_loss: 1.1187\n",
      "Epoch 4671/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7878 - val_loss: 1.1220\n",
      "Epoch 4672/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7622 - val_loss: 1.0942\n",
      "Epoch 4673/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7778 - val_loss: 1.1140\n",
      "Epoch 4674/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7556 - val_loss: 1.1112\n",
      "Epoch 4675/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7797 - val_loss: 1.1095\n",
      "Epoch 4676/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7768 - val_loss: 1.0999\n",
      "Epoch 4677/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7728 - val_loss: 1.0966\n",
      "Epoch 4678/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7931 - val_loss: 1.1020\n",
      "Epoch 4679/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7653 - val_loss: 1.1231\n",
      "Epoch 4680/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7880 - val_loss: 1.1376\n",
      "Epoch 4681/5000\n",
      "572/572 [==============================] - 0s 695us/step - loss: 0.7908 - val_loss: 1.1485\n",
      "Epoch 4682/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7684 - val_loss: 1.1172\n",
      "Epoch 4683/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7612 - val_loss: 1.1208\n",
      "Epoch 4684/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7639 - val_loss: 1.1137\n",
      "Epoch 4685/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7656 - val_loss: 1.1503\n",
      "Epoch 4686/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7858 - val_loss: 1.1777\n",
      "Epoch 4687/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7671 - val_loss: 1.1818\n",
      "Epoch 4688/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7874 - val_loss: 1.1772\n",
      "Epoch 4689/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7958 - val_loss: 1.1487\n",
      "Epoch 4690/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7849 - val_loss: 1.1308\n",
      "Epoch 4691/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7738 - val_loss: 1.1252\n",
      "Epoch 4692/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7790 - val_loss: 1.1594\n",
      "Epoch 4693/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7708 - val_loss: 1.1470\n",
      "Epoch 4694/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7618 - val_loss: 1.1385\n",
      "Epoch 4695/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7789 - val_loss: 1.1069\n",
      "Epoch 4696/5000\n",
      "572/572 [==============================] - 0s 683us/step - loss: 0.7851 - val_loss: 1.1168\n",
      "Epoch 4697/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7707 - val_loss: 1.1263\n",
      "Epoch 4698/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7725 - val_loss: 1.1300\n",
      "Epoch 4699/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7754 - val_loss: 1.1355\n",
      "Epoch 4700/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7792 - val_loss: 1.1215\n",
      "Epoch 4701/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7717 - val_loss: 1.1256\n",
      "Epoch 4702/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7600 - val_loss: 1.1314\n",
      "Epoch 4703/5000\n",
      "572/572 [==============================] - 0s 629us/step - loss: 0.7815 - val_loss: 1.1221\n",
      "Epoch 4704/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7734 - val_loss: 1.1192\n",
      "Epoch 4705/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7747 - val_loss: 1.1056\n",
      "Epoch 4706/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7666 - val_loss: 1.1414\n",
      "Epoch 4707/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7706 - val_loss: 1.1783\n",
      "Epoch 4708/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7763 - val_loss: 1.1132\n",
      "Epoch 4709/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7838 - val_loss: 1.1152\n",
      "Epoch 4710/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7676 - val_loss: 1.1360\n",
      "Epoch 4711/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7659 - val_loss: 1.1595\n",
      "Epoch 4712/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7860 - val_loss: 1.1492\n",
      "Epoch 4713/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7794 - val_loss: 1.0982\n",
      "Epoch 4714/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7750 - val_loss: 1.1307\n",
      "Epoch 4715/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7737 - val_loss: 1.1178\n",
      "Epoch 4716/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7630 - val_loss: 1.1025\n",
      "Epoch 4717/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7802 - val_loss: 1.1371\n",
      "Epoch 4718/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7752 - val_loss: 1.1161\n",
      "Epoch 4719/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7805 - val_loss: 1.1250\n",
      "Epoch 4720/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7711 - val_loss: 1.1068\n",
      "Epoch 4721/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7854 - val_loss: 1.1051\n",
      "Epoch 4722/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7577 - val_loss: 1.1204\n",
      "Epoch 4723/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7622 - val_loss: 1.0996\n",
      "Epoch 4724/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7620 - val_loss: 1.0952\n",
      "Epoch 4725/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7689 - val_loss: 1.1144\n",
      "Epoch 4726/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 658us/step - loss: 0.7803 - val_loss: 1.1457\n",
      "Epoch 4727/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7790 - val_loss: 1.1563\n",
      "Epoch 4728/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7722 - val_loss: 1.1778\n",
      "Epoch 4729/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7723 - val_loss: 1.2057\n",
      "Epoch 4730/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7793 - val_loss: 1.1813\n",
      "Epoch 4731/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7769 - val_loss: 1.1172\n",
      "Epoch 4732/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7808 - val_loss: 1.1396\n",
      "Epoch 4733/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7738 - val_loss: 1.1276\n",
      "Epoch 4734/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7714 - val_loss: 1.1433\n",
      "Epoch 4735/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7690 - val_loss: 1.1645\n",
      "Epoch 4736/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7662 - val_loss: 1.1571\n",
      "Epoch 4737/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7681 - val_loss: 1.2223\n",
      "Epoch 4738/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7802 - val_loss: 1.2370\n",
      "Epoch 4739/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7682 - val_loss: 1.1719\n",
      "Epoch 4740/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7613 - val_loss: 1.1094\n",
      "Epoch 4741/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7822 - val_loss: 1.1140\n",
      "Epoch 4742/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7755 - val_loss: 1.1289\n",
      "Epoch 4743/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7755 - val_loss: 1.1254\n",
      "Epoch 4744/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7672 - val_loss: 1.0937\n",
      "Epoch 4745/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7639 - val_loss: 1.1527\n",
      "Epoch 4746/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7853 - val_loss: 1.1533\n",
      "Epoch 4747/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7698 - val_loss: 1.1423\n",
      "Epoch 4748/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7650 - val_loss: 1.1067\n",
      "Epoch 4749/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7605 - val_loss: 1.1487\n",
      "Epoch 4750/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7720 - val_loss: 1.1809\n",
      "Epoch 4751/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7802 - val_loss: 1.0970\n",
      "Epoch 4752/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7659 - val_loss: 1.1016\n",
      "Epoch 4753/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7692 - val_loss: 1.1090\n",
      "Epoch 4754/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7743 - val_loss: 1.1118\n",
      "Epoch 4755/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.7799 - val_loss: 1.0933\n",
      "Epoch 4756/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7672 - val_loss: 1.1213\n",
      "Epoch 4757/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7745 - val_loss: 1.1479\n",
      "Epoch 4758/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7704 - val_loss: 1.1498\n",
      "Epoch 4759/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7588 - val_loss: 1.1487\n",
      "Epoch 4760/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7748 - val_loss: 1.1699\n",
      "Epoch 4761/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7828 - val_loss: 1.1047\n",
      "Epoch 4762/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7787 - val_loss: 1.1014\n",
      "Epoch 4763/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7678 - val_loss: 1.1165\n",
      "Epoch 4764/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7613 - val_loss: 1.1455\n",
      "Epoch 4765/5000\n",
      "572/572 [==============================] - 0s 679us/step - loss: 0.7816 - val_loss: 1.1388\n",
      "Epoch 4766/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7637 - val_loss: 1.1412\n",
      "Epoch 4767/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7787 - val_loss: 1.0990\n",
      "Epoch 4768/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7767 - val_loss: 1.1142\n",
      "Epoch 4769/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7733 - val_loss: 1.1436\n",
      "Epoch 4770/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7905 - val_loss: 1.1625\n",
      "Epoch 4771/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7828 - val_loss: 1.1736\n",
      "Epoch 4772/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7563 - val_loss: 1.1415\n",
      "Epoch 4773/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7728 - val_loss: 1.1180\n",
      "Epoch 4774/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7583 - val_loss: 1.1303\n",
      "Epoch 4775/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7766 - val_loss: 1.1100\n",
      "Epoch 4776/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7718 - val_loss: 1.0885\n",
      "Epoch 4777/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7885 - val_loss: 1.1297\n",
      "Epoch 4778/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7651 - val_loss: 1.1239\n",
      "Epoch 4779/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7630 - val_loss: 1.1515\n",
      "Epoch 4780/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7794 - val_loss: 1.1414\n",
      "Epoch 4781/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7737 - val_loss: 1.1709\n",
      "Epoch 4782/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7713 - val_loss: 1.1568\n",
      "Epoch 4783/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7765 - val_loss: 1.1634\n",
      "Epoch 4784/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7778 - val_loss: 1.1426\n",
      "Epoch 4785/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7752 - val_loss: 1.1527\n",
      "Epoch 4786/5000\n",
      "572/572 [==============================] - 0s 689us/step - loss: 0.7657 - val_loss: 1.1289\n",
      "Epoch 4787/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7726 - val_loss: 1.1199\n",
      "Epoch 4788/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7694 - val_loss: 1.1117\n",
      "Epoch 4789/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7717 - val_loss: 1.1342\n",
      "Epoch 4790/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7603 - val_loss: 1.1400\n",
      "Epoch 4791/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7811 - val_loss: 1.1302\n",
      "Epoch 4792/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7631 - val_loss: 1.0968\n",
      "Epoch 4793/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7576 - val_loss: 1.1498\n",
      "Epoch 4794/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.7701 - val_loss: 1.1777\n",
      "Epoch 4795/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7759 - val_loss: 1.1293\n",
      "Epoch 4796/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7612 - val_loss: 1.1127\n",
      "Epoch 4797/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.7935 - val_loss: 1.0888\n",
      "Epoch 4798/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7709 - val_loss: 1.1428\n",
      "Epoch 4799/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7784 - val_loss: 1.1564\n",
      "Epoch 4800/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7672 - val_loss: 1.1609\n",
      "Epoch 4801/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7719 - val_loss: 1.1212\n",
      "Epoch 4802/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 663us/step - loss: 0.7691 - val_loss: 1.1286\n",
      "Epoch 4803/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7723 - val_loss: 1.1344\n",
      "Epoch 4804/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7536 - val_loss: 1.1647\n",
      "Epoch 4805/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7696 - val_loss: 1.1328\n",
      "Epoch 4806/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7696 - val_loss: 1.1243\n",
      "Epoch 4807/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7635 - val_loss: 1.1071\n",
      "Epoch 4808/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7754 - val_loss: 1.1088\n",
      "Epoch 4809/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7582 - val_loss: 1.1227\n",
      "Epoch 4810/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7749 - val_loss: 1.1135\n",
      "Epoch 4811/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7939 - val_loss: 1.0893\n",
      "Epoch 4812/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7727 - val_loss: 1.1125\n",
      "Epoch 4813/5000\n",
      "572/572 [==============================] - 0s 608us/step - loss: 0.7775 - val_loss: 1.0864\n",
      "Epoch 4814/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7783 - val_loss: 1.1161\n",
      "Epoch 4815/5000\n",
      "572/572 [==============================] - 0s 619us/step - loss: 0.7667 - val_loss: 1.1143\n",
      "Epoch 4816/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7692 - val_loss: 1.1648\n",
      "Epoch 4817/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7684 - val_loss: 1.1632\n",
      "Epoch 4818/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7604 - val_loss: 1.1163\n",
      "Epoch 4819/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7724 - val_loss: 1.1071\n",
      "Epoch 4820/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7859 - val_loss: 1.1522\n",
      "Epoch 4821/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7715 - val_loss: 1.1192\n",
      "Epoch 4822/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7671 - val_loss: 1.1204\n",
      "Epoch 4823/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7625 - val_loss: 1.1066\n",
      "Epoch 4824/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7746 - val_loss: 1.0791\n",
      "Epoch 4825/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7776 - val_loss: 1.1005\n",
      "Epoch 4826/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7721 - val_loss: 1.0754\n",
      "Epoch 4827/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7749 - val_loss: 1.0856\n",
      "Epoch 4828/5000\n",
      "572/572 [==============================] - 0s 676us/step - loss: 0.7806 - val_loss: 1.1304\n",
      "Epoch 4829/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7798 - val_loss: 1.1041\n",
      "Epoch 4830/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7620 - val_loss: 1.1203\n",
      "Epoch 4831/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7608 - val_loss: 1.1216\n",
      "Epoch 4832/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7623 - val_loss: 1.1177\n",
      "Epoch 4833/5000\n",
      "572/572 [==============================] - 0s 637us/step - loss: 0.7782 - val_loss: 1.1295\n",
      "Epoch 4834/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7852 - val_loss: 1.1047\n",
      "Epoch 4835/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7752 - val_loss: 1.1173\n",
      "Epoch 4836/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7622 - val_loss: 1.1069\n",
      "Epoch 4837/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7776 - val_loss: 1.1175\n",
      "Epoch 4838/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7827 - val_loss: 1.1286\n",
      "Epoch 4839/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7835 - val_loss: 1.1311\n",
      "Epoch 4840/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7628 - val_loss: 1.1074\n",
      "Epoch 4841/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7827 - val_loss: 1.1131\n",
      "Epoch 4842/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7717 - val_loss: 1.1161\n",
      "Epoch 4843/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7776 - val_loss: 1.1067\n",
      "Epoch 4844/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7766 - val_loss: 1.1006\n",
      "Epoch 4845/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7825 - val_loss: 1.1186\n",
      "Epoch 4846/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7775 - val_loss: 1.2059\n",
      "Epoch 4847/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7763 - val_loss: 1.1424\n",
      "Epoch 4848/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7802 - val_loss: 1.1752\n",
      "Epoch 4849/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7472 - val_loss: 1.1443\n",
      "Epoch 4850/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7706 - val_loss: 1.1213\n",
      "Epoch 4851/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7619 - val_loss: 1.1383\n",
      "Epoch 4852/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7666 - val_loss: 1.1587\n",
      "Epoch 4853/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7772 - val_loss: 1.1159\n",
      "Epoch 4854/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7874 - val_loss: 1.1397\n",
      "Epoch 4855/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7828 - val_loss: 1.1470\n",
      "Epoch 4856/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7674 - val_loss: 1.1310\n",
      "Epoch 4857/5000\n",
      "572/572 [==============================] - 0s 660us/step - loss: 0.7728 - val_loss: 1.1466\n",
      "Epoch 4858/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7594 - val_loss: 1.1329\n",
      "Epoch 4859/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.7853 - val_loss: 1.1439\n",
      "Epoch 4860/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7640 - val_loss: 1.1327\n",
      "Epoch 4861/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7658 - val_loss: 1.1177\n",
      "Epoch 4862/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.7628 - val_loss: 1.1485\n",
      "Epoch 4863/5000\n",
      "572/572 [==============================] - 0s 674us/step - loss: 0.7743 - val_loss: 1.1223\n",
      "Epoch 4864/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7844 - val_loss: 1.1753\n",
      "Epoch 4865/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7762 - val_loss: 1.1519\n",
      "Epoch 4866/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7744 - val_loss: 1.1681\n",
      "Epoch 4867/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7851 - val_loss: 1.1756\n",
      "Epoch 4868/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7661 - val_loss: 1.1439\n",
      "Epoch 4869/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7697 - val_loss: 1.1615\n",
      "Epoch 4870/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7771 - val_loss: 1.1169\n",
      "Epoch 4871/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7830 - val_loss: 1.1400\n",
      "Epoch 4872/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7723 - val_loss: 1.1356\n",
      "Epoch 4873/5000\n",
      "572/572 [==============================] - 0s 666us/step - loss: 0.7848 - val_loss: 1.1369\n",
      "Epoch 4874/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7721 - val_loss: 1.1154\n",
      "Epoch 4875/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7888 - val_loss: 1.1317\n",
      "Epoch 4876/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7914 - val_loss: 1.0993\n",
      "Epoch 4877/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7728 - val_loss: 1.1332\n",
      "Epoch 4878/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 664us/step - loss: 0.7816 - val_loss: 1.1028\n",
      "Epoch 4879/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7650 - val_loss: 1.1104\n",
      "Epoch 4880/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7589 - val_loss: 1.1075\n",
      "Epoch 4881/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7665 - val_loss: 1.1212\n",
      "Epoch 4882/5000\n",
      "572/572 [==============================] - 0s 700us/step - loss: 0.7799 - val_loss: 1.1220\n",
      "Epoch 4883/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7584 - val_loss: 1.1238\n",
      "Epoch 4884/5000\n",
      "572/572 [==============================] - 0s 663us/step - loss: 0.7650 - val_loss: 1.1273\n",
      "Epoch 4885/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7743 - val_loss: 1.2110\n",
      "Epoch 4886/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7649 - val_loss: 1.1260\n",
      "Epoch 4887/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7766 - val_loss: 1.1120\n",
      "Epoch 4888/5000\n",
      "572/572 [==============================] - 0s 638us/step - loss: 0.7763 - val_loss: 1.1084\n",
      "Epoch 4889/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7748 - val_loss: 1.1165\n",
      "Epoch 4890/5000\n",
      "572/572 [==============================] - 0s 650us/step - loss: 0.7762 - val_loss: 1.1210\n",
      "Epoch 4891/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7656 - val_loss: 1.1488\n",
      "Epoch 4892/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7756 - val_loss: 1.1638\n",
      "Epoch 4893/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7672 - val_loss: 1.1866\n",
      "Epoch 4894/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7859 - val_loss: 1.1370\n",
      "Epoch 4895/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7840 - val_loss: 1.1655\n",
      "Epoch 4896/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7754 - val_loss: 1.1807\n",
      "Epoch 4897/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7850 - val_loss: 1.1558\n",
      "Epoch 4898/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7719 - val_loss: 1.1441\n",
      "Epoch 4899/5000\n",
      "572/572 [==============================] - 0s 668us/step - loss: 0.7626 - val_loss: 1.1866\n",
      "Epoch 4900/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7724 - val_loss: 1.1562\n",
      "Epoch 4901/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7642 - val_loss: 1.1525\n",
      "Epoch 4902/5000\n",
      "572/572 [==============================] - 0s 656us/step - loss: 0.7635 - val_loss: 1.1572\n",
      "Epoch 4903/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7737 - val_loss: 1.1776\n",
      "Epoch 4904/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7737 - val_loss: 1.1487\n",
      "Epoch 4905/5000\n",
      "572/572 [==============================] - 0s 631us/step - loss: 0.7689 - val_loss: 1.1428\n",
      "Epoch 4906/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7711 - val_loss: 1.1348\n",
      "Epoch 4907/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7658 - val_loss: 1.1499\n",
      "Epoch 4908/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7681 - val_loss: 1.1393\n",
      "Epoch 4909/5000\n",
      "572/572 [==============================] - 0s 670us/step - loss: 0.7567 - val_loss: 1.1631\n",
      "Epoch 4910/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7670 - val_loss: 1.1336\n",
      "Epoch 4911/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7699 - val_loss: 1.1128\n",
      "Epoch 4912/5000\n",
      "572/572 [==============================] - 0s 630us/step - loss: 0.7691 - val_loss: 1.1093\n",
      "Epoch 4913/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7714 - val_loss: 1.1420\n",
      "Epoch 4914/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7782 - val_loss: 1.1329\n",
      "Epoch 4915/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7595 - val_loss: 1.1295\n",
      "Epoch 4916/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7692 - val_loss: 1.1152\n",
      "Epoch 4917/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7611 - val_loss: 1.1378\n",
      "Epoch 4918/5000\n",
      "572/572 [==============================] - 0s 671us/step - loss: 0.7644 - val_loss: 1.1163\n",
      "Epoch 4919/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7636 - val_loss: 1.1063\n",
      "Epoch 4920/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7638 - val_loss: 1.1444\n",
      "Epoch 4921/5000\n",
      "572/572 [==============================] - 0s 661us/step - loss: 0.7863 - val_loss: 1.2340\n",
      "Epoch 4922/5000\n",
      "572/572 [==============================] - 0s 797us/step - loss: 0.7808 - val_loss: 1.1294\n",
      "Epoch 4923/5000\n",
      "572/572 [==============================] - 0s 721us/step - loss: 0.7718 - val_loss: 1.1220\n",
      "Epoch 4924/5000\n",
      "572/572 [==============================] - 0s 765us/step - loss: 0.7605 - val_loss: 1.1105\n",
      "Epoch 4925/5000\n",
      "572/572 [==============================] - 0s 811us/step - loss: 0.7741 - val_loss: 1.1331\n",
      "Epoch 4926/5000\n",
      "572/572 [==============================] - 1s 875us/step - loss: 0.7698 - val_loss: 1.1429\n",
      "Epoch 4927/5000\n",
      "572/572 [==============================] - 0s 784us/step - loss: 0.7768 - val_loss: 1.1188\n",
      "Epoch 4928/5000\n",
      "572/572 [==============================] - 0s 719us/step - loss: 0.7705 - val_loss: 1.1220\n",
      "Epoch 4929/5000\n",
      "572/572 [==============================] - 0s 817us/step - loss: 0.7661 - val_loss: 1.1164\n",
      "Epoch 4930/5000\n",
      "572/572 [==============================] - 0s 729us/step - loss: 0.7909 - val_loss: 1.1417\n",
      "Epoch 4931/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7714 - val_loss: 1.1279\n",
      "Epoch 4932/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7577 - val_loss: 1.1642\n",
      "Epoch 4933/5000\n",
      "572/572 [==============================] - 0s 649us/step - loss: 0.7729 - val_loss: 1.1379\n",
      "Epoch 4934/5000\n",
      "572/572 [==============================] - 0s 658us/step - loss: 0.7832 - val_loss: 1.1221\n",
      "Epoch 4935/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7727 - val_loss: 1.1166\n",
      "Epoch 4936/5000\n",
      "572/572 [==============================] - 0s 654us/step - loss: 0.7636 - val_loss: 1.1259\n",
      "Epoch 4937/5000\n",
      "572/572 [==============================] - 0s 662us/step - loss: 0.7705 - val_loss: 1.1268\n",
      "Epoch 4938/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7799 - val_loss: 1.1212\n",
      "Epoch 4939/5000\n",
      "572/572 [==============================] - 0s 657us/step - loss: 0.7616 - val_loss: 1.1384\n",
      "Epoch 4940/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7637 - val_loss: 1.1538\n",
      "Epoch 4941/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7726 - val_loss: 1.1367\n",
      "Epoch 4942/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7705 - val_loss: 1.1069\n",
      "Epoch 4943/5000\n",
      "572/572 [==============================] - 0s 621us/step - loss: 0.7669 - val_loss: 1.1611\n",
      "Epoch 4944/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7679 - val_loss: 1.1306\n",
      "Epoch 4945/5000\n",
      "572/572 [==============================] - 0s 669us/step - loss: 0.7721 - val_loss: 1.1214\n",
      "Epoch 4946/5000\n",
      "572/572 [==============================] - 0s 672us/step - loss: 0.7673 - val_loss: 1.1118\n",
      "Epoch 4947/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7799 - val_loss: 1.1402\n",
      "Epoch 4948/5000\n",
      "572/572 [==============================] - 0s 653us/step - loss: 0.7765 - val_loss: 1.1446\n",
      "Epoch 4949/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7695 - val_loss: 1.1548\n",
      "Epoch 4950/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7775 - val_loss: 1.1186\n",
      "Epoch 4951/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7651 - val_loss: 1.1567\n",
      "Epoch 4952/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7729 - val_loss: 1.1973\n",
      "Epoch 4953/5000\n",
      "572/572 [==============================] - 0s 651us/step - loss: 0.7650 - val_loss: 1.1975\n",
      "Epoch 4954/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 0s 651us/step - loss: 0.7682 - val_loss: 1.1657\n",
      "Epoch 4955/5000\n",
      "572/572 [==============================] - 0s 627us/step - loss: 0.7673 - val_loss: 1.2038\n",
      "Epoch 4956/5000\n",
      "572/572 [==============================] - 0s 634us/step - loss: 0.7837 - val_loss: 1.2453\n",
      "Epoch 4957/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7891 - val_loss: 1.1624\n",
      "Epoch 4958/5000\n",
      "572/572 [==============================] - 0s 646us/step - loss: 0.7826 - val_loss: 1.1415\n",
      "Epoch 4959/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.7791 - val_loss: 1.1742\n",
      "Epoch 4960/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7730 - val_loss: 1.1811\n",
      "Epoch 4961/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.7826 - val_loss: 1.1693\n",
      "Epoch 4962/5000\n",
      "572/572 [==============================] - 0s 647us/step - loss: 0.7714 - val_loss: 1.1454\n",
      "Epoch 4963/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.7594 - val_loss: 1.1612\n",
      "Epoch 4964/5000\n",
      "572/572 [==============================] - 0s 642us/step - loss: 0.7772 - val_loss: 1.1193\n",
      "Epoch 4965/5000\n",
      "572/572 [==============================] - 0s 641us/step - loss: 0.7610 - val_loss: 1.1759\n",
      "Epoch 4966/5000\n",
      "572/572 [==============================] - 0s 715us/step - loss: 0.7693 - val_loss: 1.1535\n",
      "Epoch 4967/5000\n",
      "572/572 [==============================] - 0s 644us/step - loss: 0.7612 - val_loss: 1.1437\n",
      "Epoch 4968/5000\n",
      "572/572 [==============================] - 0s 673us/step - loss: 0.7669 - val_loss: 1.1630\n",
      "Epoch 4969/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7677 - val_loss: 1.2021\n",
      "Epoch 4970/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7668 - val_loss: 1.2383\n",
      "Epoch 4971/5000\n",
      "572/572 [==============================] - 0s 648us/step - loss: 0.7775 - val_loss: 1.1819\n",
      "Epoch 4972/5000\n",
      "572/572 [==============================] - 0s 655us/step - loss: 0.7793 - val_loss: 1.1757\n",
      "Epoch 4973/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7550 - val_loss: 1.1998\n",
      "Epoch 4974/5000\n",
      "572/572 [==============================] - 0s 628us/step - loss: 0.7660 - val_loss: 1.1266\n",
      "Epoch 4975/5000\n",
      "572/572 [==============================] - 0s 664us/step - loss: 0.7725 - val_loss: 1.1343\n",
      "Epoch 4976/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7750 - val_loss: 1.1673\n",
      "Epoch 4977/5000\n",
      "572/572 [==============================] - 0s 639us/step - loss: 0.7903 - val_loss: 1.3139\n",
      "Epoch 4978/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7587 - val_loss: 1.2183\n",
      "Epoch 4979/5000\n",
      "572/572 [==============================] - 0s 625us/step - loss: 0.7762 - val_loss: 1.1843\n",
      "Epoch 4980/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7722 - val_loss: 1.2147\n",
      "Epoch 4981/5000\n",
      "572/572 [==============================] - 0s 677us/step - loss: 0.7683 - val_loss: 1.1895\n",
      "Epoch 4982/5000\n",
      "572/572 [==============================] - 0s 640us/step - loss: 0.7807 - val_loss: 1.1745\n",
      "Epoch 4983/5000\n",
      "572/572 [==============================] - 0s 667us/step - loss: 0.7711 - val_loss: 1.1275\n",
      "Epoch 4984/5000\n",
      "572/572 [==============================] - 0s 665us/step - loss: 0.7724 - val_loss: 1.1232\n",
      "Epoch 4985/5000\n",
      "572/572 [==============================] - 0s 645us/step - loss: 0.7811 - val_loss: 1.1172\n",
      "Epoch 4986/5000\n",
      "572/572 [==============================] - 0s 624us/step - loss: 0.7647 - val_loss: 1.1233\n",
      "Epoch 4987/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7852 - val_loss: 1.1304\n",
      "Epoch 4988/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7635 - val_loss: 1.1466\n",
      "Epoch 4989/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7847 - val_loss: 1.1215\n",
      "Epoch 4990/5000\n",
      "572/572 [==============================] - 0s 633us/step - loss: 0.7652 - val_loss: 1.1532\n",
      "Epoch 4991/5000\n",
      "572/572 [==============================] - 0s 643us/step - loss: 0.7594 - val_loss: 1.1876\n",
      "Epoch 4992/5000\n",
      "572/572 [==============================] - 0s 659us/step - loss: 0.7646 - val_loss: 1.1561\n",
      "Epoch 4993/5000\n",
      "572/572 [==============================] - 0s 635us/step - loss: 0.7812 - val_loss: 1.1787\n",
      "Epoch 4994/5000\n",
      "572/572 [==============================] - 0s 632us/step - loss: 0.7807 - val_loss: 1.1500\n",
      "Epoch 4995/5000\n",
      "572/572 [==============================] - 0s 626us/step - loss: 0.7641 - val_loss: 1.2316\n",
      "Epoch 4996/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7662 - val_loss: 1.1705\n",
      "Epoch 4997/5000\n",
      "572/572 [==============================] - 0s 652us/step - loss: 0.7609 - val_loss: 1.1849\n",
      "Epoch 4998/5000\n",
      "572/572 [==============================] - 0s 636us/step - loss: 0.7780 - val_loss: 1.1727\n",
      "Epoch 4999/5000\n",
      "572/572 [==============================] - 0s 680us/step - loss: 0.7800 - val_loss: 1.1529\n",
      "Epoch 5000/5000\n",
      "572/572 [==============================] - 0s 696us/step - loss: 0.7627 - val_loss: 1.1410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ec5bf65f8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calibMMDNet.fit(source, sourceLabels, epochs=500 ,batch_size=10, validation_split=0.1, verbose=1,\n",
    "#               callbacks=[lrate, mn.monitorMMD(source, target, calibMMDNet.predict),\n",
    "#                          cb.EarlyStopping(monitor='val_loss',patience=50,mode='auto')]\n",
    "#               )\n",
    "\n",
    "calibMMDNet.fit(source, sourceLabels, epochs=5000, batch_size=20, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7eb6e1c898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAIrCAYAAADr3EO5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3Xl8VNX9//HXzUBYQiBhkyVBQBEBcYGIiht1AS32a9W2lgoqbaO1X6u2fkW/2l/6bbpCF5cuVqa2WhesS1dX1EpRLCgqiogKKjuyb4GEkOT8/jiZzCS5M5mbzHrn/Xw85jGTe+4998ydSe4nZ3WMMYiIiIj4WV66CyAiIiKSbAp4RERExPcU8IiIiIjvKeARERER31PAIyIiIr6ngEdERER8TwGPiIiI+J4CHhEREfE9BTwiIiLiewp4RERExPc6pbsAqda3b18zdOjQdBdDREQS6I033thujOmX7nJI5sq5gGfo0KEsXbo03cUQEZEEchxnbbrLIJlNTVoiIiLiewp4RERExPcU8EjKLF8OH3yQ7lKIiEguyrk+PJI+xx4LvXvDjh3pLomIiOQa1fBISjU0pLsEIiKSixTwiIiIiO8p4BERERHfU8AjIiIivqeAR0RERHxPAY+IiIj4ngIeERER8T0FPCIiIuJ7CnhERETE9xTwiIiIiO8p4BERERHfU8AjIiIivqeAR0RERHxPAY+IiIj4ngIeERER8T0FPCIiIuJ7CngkYxgDNTXpLoWIiPiRAh7JGLffDt26wZ496S6JiIj4jQIeyRibNtnn6ur0lkNERPxHAY9kthUroKoq3aUQEZEsp4BHMteePXDMMfDDH6a7JCIikuUU8Ejmqquzz+rJLCIiHaSAR0RERHxPAY+IiIj4ngIeERER8T0FPCIiIuJ7ndJdABFXTz4JvXunuxQiIuITCngkM33uc3DWWekuhYiI+ISatCRz5enrKSIiiaE7ioiIiPieAh4RERHxPQU8IiIi4ns5EfA4jnOV4zhLHcdZum3btnQXR0RERFIsJwIeY8xcY0yZMaasX79+6S6OuDlwgAv/dR1H8UG6SyIiIj6kYemSGT78kNPf+hWfYwgwMt2lERERn8mJGh5Jjfnz4fTT4cAB+/Pdd8Oll6a3TCLiLwcO2L8zzz+f7pJItlHAIwmzYAG88gqEukk98gg8+mhaiyQiPrNtm/07s2BBuksi2UYBjySM4zT/uXPn9JRDRPyv5d8bkbYo4BERERHfU8AjIiIivqeAR1Lqv2ofh1NOgdra8MZ//xtOOAGAH/Jdut3/u+gZPPwwnHYa1NcnuaQiIuInCngkpU6rWwCLF4eHcoH9uVFXDtL1qcdhxAj3xUP/9S9YtKh5wCQiItIGBTySUoboPQ0bnDw+5TDIC8CwYe47aQV1ERFpB909RERExPcU8IiIiIjvKeARERER31PAIyIiIr6ngEdERER8TwGPiIiI+J4CHhEREfE9BTwiIiLiewp4RERExPcU8IiIiIjvKeCRpHvvPbj7bvv6MLPZvti/H7DLYn20aHOrY+rqYOOHVQC8+SbceSds3JiS4uaE55+HF15IdykkW23dan8nDx1Kd0lE4tcp3QUQ/yoosM/f/jbMnw+jeI8LDz1hN157Lfz1r3zrKzt4c92drY7dtg0Gr3kVgIUvw7dfhqoquC1Vhfe5yZPtszHpLYdkp0cegRtugFNOgQkT0l0akfiohkeSxnHsjdVpXC+0kH0sDUyAf/6z6V/DHp0PsomBUfNY2mdyKooqIiI+p4BHREREfE8Bj4iIiPieAh4RERHxPQU8IiIi4nsKeCTpBu//kGN5u3VCbS2fqfoneTQ0bcqjgc7LXmu162Seo2TNK7BqVet8nn8edu9OZJFFRMRnFPBI0s1+/TO8zfGtEx55hO9v+QYD2NK0qT/byNuzm60jT2/aNoJVPMd5XPH702HBguZ5rFtnh4Ld2Xpou4iISIgCHkk6hyiTvdTXu24+dPQxVPUf3vRzAPf9muURJS8RERFQwCMiIiI5QAGPiIiI+J4CHhEREfE9BTwiIiLie1o8VNLDGHj88Wab8kyD667n8VzrjYsW2WXUP/wwGaUTERGfUQ2PpEddHTz9NN877G4u5G/w3HPc84Xnm5I3nTCVG/k5d42+p/lx111nn2+7DW6+Ge69N4WFFhGRbKWAR9KnUyf+XPQN/sGFMHkyqw4/pynpUPde/JIb2dJtKFUUhI/5znega1fo3DkNBRYRkWyVEwGP4zhXOY6z1HGcpdu2bUt3cURERCTFciLgMcbMNcaUGWPK+vXrl+7i+IYxsHIlfPIJ1NSEt7/7Lrz1Vni1h4aIrjkNDfDpp7ZFywD799vt27bBlsYJl2PNIRhtBYn9+2HHjna/layxezds2uSetncvbNhgX69e3XoVjtDn5XZ9jYG3346eN8CaNXDgQLuKLTkg9P0KfU/q6txXgnGzcqU9Huzfk+pq+3rLFti5M/pxH3zQ/O+LSCw5EfBIcvzznzB6NAwfDj/4QXj7d78LX/2qDUJmzIDIiZaNga+Xw4r37B/E0A36v/4LXn/dvt4c46Z76aXu23/5Sygr69DbyQpf+AIMHuyedsUVUFoKmzfDscfCccfZlTdCHn/cfl5f/ar9OTKff/4TTjsNTj7ZPe+aGhg2DP7f/0vM+xD/eeEF+/0aNsx2sfv1r+Goo2Dt2tjHLV5sj3v8cdi3z/49qay0aQMG2O+lmxUr4Oij4Y9/TOz7EP9SwCPtVlUVfh2qqfnhD23tzltv2QBm+nQIVard+/vw/nWHwHGa5/XYY+7nieyus2+f+z6G3Fg/NNr7h/BnUFMDhx0GJSXNa95Cn9enn9rlx/r0aZ526qnNP9NIoVqh0DlEWor87hw4EP45VFsTTeg7VVVl/wmK3AawZ4/7caHaxmjfWZGWFPBI8nWysx8c+X/TKcD7HbM+Lxzx1NHJ3sUXLYo/gx//GH7yE8/nzUVj6t6GCy6AXbtg+3aYOhXee6/5TosXw+c/r+hHOu5f/+KYyi+Rz8F0l0RygAIeSb7SUujXj64bVnMjv/B8+C+mvcFvZi7lVF5hS6fB8L3v2YT//V/Iz287g9tug1tv9XzeXHRa3QJ46inbCWjlSnj6aXj55eY7Pf88/P3v4fZIkfZ65hkOW/gYvYnRUUckQRTwSGqccAIAnzDM86E7eg1n08DxvMqpdsPYsfb5xBObt8vEEtl+JiKZQb+XkkIKeERERMT3FPCIiIiI7yngEREREd9TwCMiIiK+p4BH0mL8jvl0MnUJy6+CH3Btzc+hZ0/4/vftyDBpvwkT4B//aLV5+r+/DhUVaSiQiOXs28sBunHGp4+muyiSZRTwSNrcNeruhOW1nT58pm6+nZnvX//SkOlEeOedVpuOX/O3NBREJCxvzy66UcPwfW+nuyiSZRTwSNpUdSpKWF476Y2hcYhrIJCwfKW5urwu6S6CCED4910kTgp4RERExPcU8IiIiIjvKeARERER31PAI8lRXR1evtzjcsYBL6O3Dh0CIJ9a8qltnrZnj5ZS7ojGawtAXR1dibLsdV1d86WrYy3pLtkr3Z9rXV2rpdcdGuh0UIvYSnwU8EhyjBoF/fvD//yPHe1z9tmA7Vwcy4FBR/Ju0Wmx8x42LPx81llwwgnsopjT6xbY7XmNX+uiIigstK/79WvnG8lhy5Y1vcy/5qtU0919v+uug4ICG+AOHgwDBsDatSkqpKTE22/bKR+eeSZ9Zfja16B78+/gLfyU/765B+xX0CNtU8AjybFlC3zmM7B8OXzjGzBrFksWG3bQN+Zhi+5bxe2jg7HzHjcOjIHjj4c//xnefJNv8LtweiAA8+bByJH252XL7E1Y4nPddfb67twJV10FQN6WT6Pvv3Wrfa6utjekI46wtWviH9u32+ctW9JXBpdzH0bjtoMHU1wYyUYKeKSZ9evtAsYvvODtuO3b4cc/jl2RUtRiFPrgweHXH39s/4EEe+5rrrGvX3rJ5hnKd906W4FTUgJ33QUDB7aOZVathvJyaGiwP591Frz9jt1v1ixbjkDA/uw44Udb9+gRI+Cmm+zrqipbjj/9KfYxiTRxIrz2mn0dKvPtt8PQodCpEzz/vE0bPhzWrLGvg0Ho3BlqasL5zJ9vY5J33rHXYdAg+M9/ID8fDlTD0qXhvO+Za+PVl1+2x+4/EM7nhhvsNXn8CfvzzTfDtu2x38MXvwjnnOOetmePPe8vfmGfQ+8H7Pfh+OPjuUq554IL7CPSjTfCUUc13/ab30DXrs1bKiMddZS97r0bK2Gfesr+jsyc2RT3cvXV8J3vwPXXNz/2t7+Fiy8O/zx3Lvz0p/b1qFH2d7W01ObXt68tx4ABtkwh118f/h8F7P8yAJs22f9xGkz0a9C7T/Q0kRAFPNLMpk32eeVKb8dt22aDj/Ly6PuMHAk7dsBjjROkXnGF/XnXLhtoHX54eN/KShtUrFsHt9xiKx127rQ3TGPsjfapp+Dcc20Fzh23h4/dtQv2VUF9Y8Dzk5/Y56OPhrfesjfWhgb7c6RQl6NoVq+GhQvt6717bTmWL2/72iTKkiWwYkXzbc8+C4cdBvX1MHZs62Peece16wO/+hV8/ev2Ohx1FHz4IfToAeefZz+LUN4ABphwUuu8//Uve01CXn7ZniuWf/wDXnzRPW3XLvv83HP2OfI7+MILtlVFWnvqKfuItHAhrFrVfNuyZbYipLZFV7eQ0P6hz+G99+zvyBtvwEcf220Ha2HBgtbHhlo/zzwTfvYz+/rBB5uX8aij7H7FxbYcy5bBFVfa9GFD7XfwnXfgRz+y25Yvt8HV9u32uxD6B0akvTqluwDiH7162f8QY+ndG+jW4mcXRUW2W0hBQXhbcXG4lqhLFxtwdO9u/1PcXhjer2URioqgpvGYyD+aXdoxh16nFr8xbb3fROvr0iKYn2+fW9agQfTyBQLNr2VIt25Q7XJMl/zW2zp3hsh+4i2vjZv8/Og33BC3Mnfu3HbeEub2WeS1499bt9+RWHnn54e7zfVpUevSpYv9XQ3lOWAAUBDOM1RT26OHfXYc+x3t06d9ZRdpSV8jERER8T0FPBK/devC7R3x2rEjOWWJoWdd63MeyWpKq1ZSfPBTjmYlxezs0Dnytn7KcD7qUB7JNvjQGvrWhNcUcxrqOZMFTeUu2fw6nanl6N2LGVL1HgUH274mvQh3dDqxfjGTeIn+2E7L46oXhXd8/XXbDvFpjM7OIdu22fYM4Hjeokv9gTYOSKD6eli82FYXerV9e1O5Xb33Xrh9KAN0rd3DGN51T9y3j7G0XjvNG8Oo3f/xdi3fey9mctGuT2DTJo5s+BBn+zYA8vbZ7+CQ/bGPFWlJAY/Eb8QIGD06/v0vuMDWb0+e3Hz7scfCySfD+PEJK9rBkiN4hVNZxESqOhXxBuG8awceTjeq+f2ro/nhsgtYyWju5PoYubWtz/Tz+YgjO1rspHppzTDu+s+JTT8Pe+3P/IWLeYFz4P33uf6hCTzIdO587RSCr47hijeui5qX6doVgB7s5yD5vMKpfOXQfdzFdZzByxwkn2m7fsPDfAXef992EBo9GqZObbugM2fCyJEEPt3IW4zj4rW/7PB7j9ujj8Ipp8CiRW3v21JjuV3V1cGYMbaXfIb4/Ovf5V3Gtu7QBfCDH/AOx9GT9o+uO59nuPP1iQx59+n4Dvjgg9adj1r41u3D4fTTebtmJIFlbwJQ9PPbADht618ZzsftLq/kHgU8Er/a2vAEc/H4+tftMKuLLmq+fcgQOyxoxIiEFa2uqC+n8wqnsYibjn+B1YTzbuhZxC/5DgCdG+zw1c5EGaoSr4M1be+TAfIbwje3vEMHeZ0T6cLBpmG8kTU2ARPjmgQCrB9lA9ezeZHTeYXPFbzELdihOFdwPzMPf4n/4RfNhwHFM1y4sVOPU2ePC31GKREqX3uGNbfVGQmiD4lKg0B9Y3ndev82vv8A9e3OvwuNedTFeS0PHoSxY9lMG1NGRA4xnDIFp7aWtQxhffeRrScbFYlBAY+IiIj4ngIeERER8T0FPCIiIuJ7CnhERETE9zTxoJ+9/74d9hk553s0S5bYBfgKzmIon3DcS3+H0ye5z+dfWwt//CND3y5gFOP4lAGcv+FxduzOg4e7w5GZMXrJiehY7GCHyvavab6opUMDV3A/85lMjwf/CUf1sdM5R6qvhz/8gWkUcNQ24MEGOq9+P5y+bh385S9w+ul2atoHHrAjeCJnbVu9Gp580i6iWlpq583v1MnOqHbllXaWtffegzfftJ/DzJnhGQUbr/dlpoDAB+MoZgCX8ATPch7nbHqJf/SaQWi6xS/yKIPYxHLstMs96vZwKY+AubSpKD2ognvvBWAoa5q2D931FvtX17KTIc3e/tm8SN5Hq4FB8V34SOvWwR132JF6b7/NFw8ZerIV/tQbZsyw16RxuuqCvz8MQNn25xjGTI5f8A84YxJ89BFDDx7DNnpD8G8236lT4Z//tDNTjhtnZ63705/s93XSJLtPdTXcf7+d0rtbt9Zle+89+Pvfo5f9b3+z0wOPHg2vvmo/h9NOs9fuy18O77d6tf3OL1hgP7OJE1vnFVqbo7ra/l5eein89a92jYUzzwwviBut3I3fQQoK7HD4Sy+15Zs5k9NYQinr4cEGuOwy+10yhi/zCNyxpfk1CXnsMTjhBFvu+nq73ggwmvfoy3bg8wCM2fUKA/cbQpNRTGY+pTvymchWttKfwjcGwYRJ9N3zEWdip1Af/sZjTKOGfs/DlRzk35zJpM1LWNPrOLhjPtN3wKcAD9pp3fuxjQv2Pgx3BKBzZ7rvuZhJy/5MfZ/+9qSh6d9bKKjbzSnYtBN4i39F/yRFLGNMTj3Gjx9vcsZllxkDxtTXt71vnz7GgFm82Ji7uNbsKR5izNSpzfcBY/LyjJk/374G8yhfMNdze9PPBowZONCYrl2NOXDAc5FDWd93n3t6eblNnzLFmMmTjbn6art98eLw6T/zGfu8/b5/mm/3utcsW2bMsSwzfx56k3l0yI3mNcrMw3zZTJ5szEhWGgPmGaaYQ4cNMiYQMGb//uYnXbKk+ftrfOylh7npJmPMjTcaM2SIMeecY8xDD9n0p55qXfAhQ4y5+GJj7r47nE+vXsZ88IHd5/OfD29/4YXwsc8/37S9+oJLzHXcYQyYZ5lsDJhLytYYMObciVXmEAHzB640HzPUbO402Cw87BJTQ77Z9fFOs3DmH8z9zDC38YOm/G7nevPwsFvNh4XjjAGz+pj/Mt88+Q0D9vpOYLG5netN7XU3mj/f9rb5MbeY7lQZMKZnT2N6scv8lFmmL1vNqFE2W/PII8bceqsxN91kr81559kPrPGc87jUmMJCYz75pNU1fYrzmz6PPcVDbCHA/K3XDHMTs8P7RuRnLr7YmDvvtNf3qKPC1+2JJ2z6E0+4f5kuusj9eoeE8jbGmC5d7M8LF9rn3/0u/HmVl4f379LFvj50yP58xRXhNDBmwABbzsjyX3tt8/O6lfu118L7Rx4f8d0wYMymTcYYYyaX7TA15BszY0bTNfn30VcZA6bqk63Nyx2R97+Y1PghGjNnTrjcZ/GCOUBX8zTnGQNmDUPC5zTG/HvUVa6/I5Hf09f7TjHmvPPMn3pfb27nemOuv96YRx4xd3O13fecc4w5/HCz5ugpZkehzX9XryHG3HijWZx3ctPnfuD0yWYNQ8y8Yf/bdI7nOdsAS00G3GP0yNyHmrT8zMt87C3m7t912NFRdmyunkCbeaXLwXMv4JHuXwXgHY7j3qPmMPeon3M738a0WIDCwVB3+BHhWpU21Jw5mX1ErGfRcmEuN2779O8ffh1wuZYt5cXe5yBdqKQCgGqnO/eN+DEH6N6UXk+AH/Hdpp+/zR3cN+JHPDH0RgDenXg1q3uOa0p/jZP4Nndw6Cc/Z2fJsdzKTzhAeL2PPRRxC7PZTsSqsZdeahdEmjMHfv5zuPzyZpPR/YIbW68pMmUKAD/mVtZ3PwoH0+w72NDyT1VEfk3XLZ7PIFI81zu0j9v3wnFszVXkWhjxfH+OPrp5+b2uT9Ly+Cj2UwC33RZ9h8jzlpWxk2L33+dGrzKR+7kCgPdpea3bfg8OBi6/nNkD7+Db3GFr/i69lMdorFH9ylfs3EUYthSPAmDZ+K/Dz3/O7Z1az2e0qL+d7mJpn8nUEt/vreQ2BTwiIiLiewp4RERExPcU8IiIiIjvKeARERER38u5YelV63fy8oiZ6S5GSozcsoj+wCtHfRXTRsfI0xtXtd77hZmcw2I2bh5G4bplrIi4VqcDNDTw7pU/45jGbSezuPUCfuvWxdch1EWomG3148zLg2XLYPjw1vu/27gg9Le/bbeH0gIBOwL6TBxOZjH9Vsykit0AjGU5H388giMOObwx9mrq88K/GoU122g5OP/9DxxGsotTgjPZyGvsKDic0p3L2br8d4wEVnz9l+wseKxp/xFbF7G18EgG7V7K7pc3NS07unmLw6Zzb+FAfi/GbFpCqCvvu5fPYVf3BwEoPrCp6Xp3fnMxl/FJU5kB/nvN/zCVHgxedQiDg8GhH9ugPo8PPrQ/v/eZ/6bXznUYjmp1LQMBWLc+fOEbR4k3PYeub8vPZO/eFtekcaT+zBa/XhM+dvjy68spbvzZ4LBth8OaSf9DaGnTt1cEOK4x7eBBh7EsZ83m4+m5dhnFwNg9r1AasdL3rpfD+W1/egl7XlrL/i59GLF1M0sbv7N9q9YwClj5379i+83/bPW+R29eQp/G15HXO+T0xrxXjpjJ6fv2AfDOtB9zLLD6/91H0YFNbCoaQ7/FC1j9r5n292PfPl4eMZM808CpwJa/vMKHixrTgNptu3l/RYDSncuayr/pT8/z0TPhi+ZW7sjv4DsRx797Rfh3EeC1iTdwsFN3vvbJQQwOt/yvw/c+sdekdO2r9vhJ13EKsPkRW+7Cmm30rHHohcMxjdf45REzGRmx0Pss5jR9t6D5YIWXI/J2E/qeDt23HByn1VJeTQMIGr9kfTYtZ039CYwKbYt4fntFgNLtb2HIZ9Vqu21PVYCTWBL1/CIhjomjt3+2cxznKuCqxh9HAh+ksTip1hfYnu5CpJHev95/rr7/XHvvhxtj+rW9m+SqnAh4cpnjOEuNMWXpLke66P3r/efq+8/l9y7iRn14RERExPcU8IiIiIjvKeDxv7npLkCa6f3ntlx+/7n83kVaUR8eERER8T3V8IiIiIjvKeARERER31PAIyIiIr6ngEdERER8TwGPiIiI+F7OraXVt29fM3To0HQXQ3LR9u2waRMMGgR9+6a7NMnT3veZK9dHkuKNN97YHu/SEkWdupkj8+rdEw8din3wkCHQTytYZJJ4P/ucC3iGDh3K0qVL010MyUWlpfaPaX09ZNh3MBiEykqoqIDy8g5mFnqfe/fa9xpvphl8fSTzOY6zNt59q+uP5FD9g65pT3AJL3M622h9/3Qw3L3uGj5ZN9z12Kuvht/9Lt5SSKLE+9nnXMAjkjYVFeGoIsNUVsKGDfa5nA5GP6H3WVUVkWkc+WTw9RF/Gcu7LG1af76103iFLQzwnG9ocXfJTDk38WBZWZlRDY9Ic81qeCpLbaBSUgLr13s4sDz+NJEEcxznjXgXSx0e6Gc+Pmece+KiRbB4MRxzTCKLJ0kU72evgEdEmvMSqJR6CI5EkshLwDPOyTNvnn2We2JhIdx3H/TqlcDSSTLF+9mrSUtEmisvj79GRs1QkoXq6AwvvJDuYkiKKeARkfYLBUaVlc1/FslgnTgEn/2se2Jhoa3l7NkztYWSpNM8PCLSMaEez7Nm2SauYDDdJRKJaXdeXzsa0O3x1FOwbl26iyhJoBoeEemQhZMqOHJeJb1r99PVy6gskTTp1bCD3750tGtaFScy++QR1HoccXXgAHzrW3DHHQkooCSFanhEpE3BYPTKm8sWlDO4fj0V+bOhqAj271ctj2S8nYcKXR87DhWyd38eVVV4ejQ0wLx56X5XEotGaYlIm2INxmr3kHaRBPIySqvMcUysu8BQPmEtQz2X4eijYeVKz4dJB2mUlogkTKzBWOULZ1C+eR4snKZRW5IVDtCdrV37uKb1r1nPZ049xKYC7/l+/vMdLJgklZq0RHJQrCYqt31bTcsTmcG8ebaz57x5dof169WHRzJadw7Qv2a96wPgUKduOA6eHvv2wT33pPmNSUwKeERyUORSEu3aN3LjtGkQCNhnER/omV9D9+54egwYAF/9arpLLrGoSUsklzRW1zw0qYLLFpTH1fI0aZKtvJk0KWJjZNNVeTk88ECz/LWchGSzr3W6n/1dB3s+rnfRBCDKkhWSduq0LJJLYvQ+vvfkIJOXVDL/pAq+trg8nkOaCwbhmmts85Y6LUuKeem0fFzn7ubf+cWuaUUHNrW7DO93OZYuK99u9/HR9O8PBe3oU5Qr1GlZRFqL0al48pJKStnA5CWVgA14gkE7yryoKI5+yDffbIMdx1GnZcloneuqKaqrjpr+t0seYHfRUE957twJc/56JFuGd7BwLs48ExYsSHy+uUYBj0guaVwnKxiEylLbTLVggY1P8k6qCNfwNO5eWQm7dtkKmzZbqHKstlj86xtPnMMWBqS7GE127053CfxBAY9IDgr1OQ4NsKqshPXry4HypmAHXCqEWvbRCf08aVJ4uIox4R7O8fTnUb8fSbF3GMv4gsdc0x6tvoC78m5kZ577sPX22u704xf5t9LgBDwdt3+/hrsnjDEmpx7jx483Irls7lxjioqMKS42Zvp0Y0pK7LZ4jtsYKDEG7EHG2GcwJhCwz8XF4QxLWuwb2tbyZC33E2kHYKmJ9z5gw/KUP3qwt12HXn55uq5qdoj3s1cNj4hXWV4jUVlpq8hLSsKDq+I97rX6Cr4fqGRQRYW9DlVVUFwMU6eG28Yir0lk9VDkUPbIfTRZoaTYHnqyomCka9qY/a+zrssItuSXtkrLo557B1XwQfcTPJ/zkJPPqID3nse1tTB+vOfDxE08UZGfHqrhkQ7L8hqJaBUtbaVH1gzNnWvcr0OszNs6sUgHkKIani/zcMorh6ZOTddVzQ6DYhewAAAgAElEQVTxfvYali7iVZbX8LQl1jD0ZmkVQTsyyxiYM8dei7jHsIsklpdh6cOdvubRPu67jtn9CjecvIS1PcZ4LkOvXnYSwkRqaIDzz4cvfzmx+fqJhqWLJEvjSCc/imylcmthatb6VF7euplKzVOSBYrYxeAd7vPlrGcQf13Uj23tyHf0aFixomNlk+RRDY+In3Sw9slzBY3Pa7ske3iaeNDJN1de8Xq7zrOl7xga8lrXFRgDEyfCRRe1K1vpgHg/ewU8IuniNViIZ/8ONimFTvHQpCBnLFAgI9nDS8AzKq/QrBzbjhkCN2+G734XrrvO+7GSNAp4olDAIxnDa3ASz/4eg6ioK6G7LRERDMKsWXaundmzFQhJRvES8HTuXGaeecb7feCIe2+lvlsP1nzlVs/HdsSoUTDY+9JeOUMBTxQKeCRjJKOGx+OurjFUaGMgAHff3ZRBTfdiulY3TvnqpQZJzV6SAl4Cnt69y8y4ce73gakb5zJ290IaaD1B4Ih9b/LigMt4ZOgtrdL274fFiz0WOk4TJsCSJcnJ2w8U8EShgEdygVsg4zZJcstBVq47Ntqd15sis4sGHPLm3hN/8KKRW5ICXgKeMscxse4Ct/IjNuJepfJ3LmQPRVGPnTIlnhJ4841vaLblWDRKSySHuQ2WajmgqrISLtkV5PuBSlYvrKC0stzGOG4ZBoN07WrYXVOM07sXva66Cu69N75/aTVySzJMVZe+/KffZ1zTTtnwGDd2+y07upW4pt/G3a7b6+thzx7gOe/lyaOBy/kTH3C0a/quXQp4EkE1PCI5InLZqwUL7PPseaUMqt/ApkAJg+vX20oYXGpkQrU0RUXNVzLMsb8fkrm81PAMG1ZmbrjB/T5w7Xc6E2ioS2jZ4vGf2QvZdczprmnHHANDhqS4QFkk7s8+ntkJ/fTQTMuSy+bODS97VVJimmY//vf0ueFJkOfOtdMpFxWFZ0UOzZJcXBye/jU/3/t0zW0VTjMxSzvhYaZlGB91VuM1DIk57fF13BE1eeDAdL373BbvZ68aHpEcEqU/cts7QvPqof37bT17tH457em3o74+0gFeangcp8yA+31gOcewl57so9A1/b/5DR9xpGvazJnwhz/EWWBJGPXhEZFWIrvTxOxzXFERHppeWWm3bdhgg53165t3bG7rRJFijdhSXx9JkfG8wVKcdh376jnfY/OF33BN6z/xSGBgB0omyaQaHhGfSdgo8NAwrpoa+3PXrtHn34l20pbbVYsjSeKlhme0U2Ceo7fnc5SyIWb6ys7HMqrWfckKSR4NS49CAY/4TdJiisgJCCF2htHGwbecwFBz8kiSeAl48vLKzLnnut8HSqtWMmT/Ste0szY/SJ5p4PW+57umj/jKiXz2u+PiLLEkigKeKBTwiN+0jDUSFlMUFMCBA/Z1cXHs2ZXdThp3hyGRjvMU8DjjTTcWuqb9h1PYRj/20Ms1/UfcxpuMd03r0wfWro2zwB506QKd1AElKvXhEckRLbu+hOKKUNcbLy1QzVRX22fHgZ07YxfCbQX5uDsMiaTWON5kKT2ipg9kE5+2oy/Ojh3QI3q27XbeefDMM4nPN9eohkfEZ6IthRUprmavk0+289mfdFLy5swXSZBEzrT8pXGr2dTtCE/nX7fO/i5dfbWnw9rU0GBnb77kksTm6yeq4RHJUZWVNtgJBLwPompm48bmzyI+0YDDrhPPdU2r7TuI62Yd3q674/DhMGhQBwsnSaOAR6Q9MrjzbTwtSW4tUDEzCmk5HN3tdYZdD5GWtgQGUzxlgnviD3/IYa88AQOjNGndeadtY5KsoyYtkfbI5uHV8QRrM2bAvHkwbRo88EB4e+T7BvfX2XY9xBe8NGl16VJmDh6Mch/YvRu2bHFP++Uv4fDD4dZb21tMSYJ4P/u8VBRGxHcqKuzNPUMnyQsGbWwSDLokNq4iuumaSvf0YBAefNC2i82b1zzDSZPsiK2qKvs6dA0y/HqIRKqrs19j18ewIopPHun6+OX9ffjBD6IfO2NGut+ZxKIaHhEfilzrs0ePFpU5wSCbrqnke/UVPFtSzvqKKBP5AEyfbmt4otXsqDZHMoSXGp7x/fqbRaef7fkcnVa8Tc2XLqf6ultapS1fDt/5Dixb5jlb6SDNwxOFAh7xm5aroEd2qYm25FWzVq3KOCbyidZ3R/11JEN4CXjGOXnmJ7h3Wt5HIX/hYkyUpSeeYir76Bk17z/+MZ4SeHPiiTBmTOLz9QsFPFEo4BG/iZzfr+VQ9Lj6VsfaKYM7Z4tESuSw9CNZFXWB0HSYMMHOECHuFPBEoYBHsl6LIMSthichsUnkhD6ubWMimSORAc/6z3+Lmn4lrmmfnjOD2j6pXSB01CgNd49FAU8UCngk66VqhFhk1VHPnu5tYyIZwkvAMyqv0Lx55DDXtG6rlsc8duPNd7F92rdc0wYPhr594ymBJJImHhTxoWAQVlVVUFFcSY9kj4hqOQ9PmzMVtqDmMMlQ3cx+Fq5yr6XZx1H8lFuoJd81/b3Zo6mf7Z7vEUfA6tWJKqUkmmp4RLJIxk//ExnkNA5/z9zCip94qeEZmtfPvDTCfVXzwWsW8dC1i9k+4BjPZTjxRNu0LKmlGh4RHwrFEZMm2eDHU+VJKmpcQkFOZNCjuXkkw/Q12xn24fyo6cs29GXPDm95NjTY1dIV8GQu1fCIZKF21fSkonpIzViSJonstDyYDWxisOcylJXB6697Pkw6SDMti/hYuyY2TsVsyOXlNphSsCMZrJZ86g/WRX2sqxtMXR2eH6+9lu53JrGohkdERLKelxqeY50u5h1zMNlFkhRRHx6RXKfmJRFXnThkexi7KSyEJ56wi2OJr6hJS8SvIjsQJ0PMFUpFMtfuvD7Qu7f747XXYOPGdBdRkiDjangcx/kDcAGw1RhzTOO23sCfgaHAGuBLxphdjuM4wJ3AZ4EDwJXGmDfTUW5JMdVetC3Zo6QiAyp9BpJFejdsh/nRR2ktXt2XQ7u85zt8uJ18UDKUMSajHsAZwDjg3Yhtc4BbGl/fAsxufP1Z4BnAAU4GlrSV//jx4434QEmJMWCfc8jcufYtz52b4AM8Z9zOY0SSBFhq4rzPdOJYczifuD4+YIQZw3IDxvPj8MPT9OZzXLyffUZ2WnYcZyjwpAnX8HwATDLGbHYcZyCwwBgz0nGcexpfz2u5X7S81WnZJ3K0hsfzyPJ4D3DbL0evsWQnL52WO3UqM7/5jft94IuVx/DC1x5h12DvEw+OGxe9a5AkT9yffTxRUaof2KaryBqe3RGvndDPwJPAaRFpLwJlsfJWDY9ksw7V8MQ62C0tmbVoqh2SBMNDDU+X/HHGVFW5P0aNMmb58nS9DWmHeD/7bKnh2W2MKYpI32WMKXYc50ngp8aYVxq3vwjcbEzzOaUcx7kKuApgyJAh49euXZuaNyKSSbxWDyWzhifj18iQbNPWf/nN7gMwPtZd4IHZmzjQy/uK6KrhSQ+/1fB8AAxsfD0Q+KDx9T3ANLf9oj1UwyPZqsOVIomoVUlUzYxqeCTB8FDDM76NzjjDWd2uPjxDh6br3ee2eD/7bKnh+RmwwxjzU8dxbgF6G2NmOY4zFbgW23n5JOAuY8yEWHmrD49kq1ClSCAAd9+dpm41qpmRDOWlD884J8/M7XOua9rOLoO4fXSQhjzvg5inTYMrr/R8mHRQvJ99xgU8juPMAyYBfYEtwPeAvwGPAkOAtdhh6Tsbh6X/GjgPOyx9pjExl0hRwCNZKxiEa66B+vokxxuxmrLUkVkyVCLX0hrGx6xhmOcyjBgBH37o+TDpoKwNeJJNAY9ks5TEG6rFkSzkJeA5zsk3f316uWua6dqNukFD2lWGww6DoqK295PE0tISIj5UXp6CipVkT1gokmYGh+Hnj0x3MSTFFPCISHMpiapERFJLAY9IrlJ/HMlRedTDffe5JxYWwsUXg+OktEySfOrDI+ITnuMX9dURH0lkp+Wti1ZRP+xIz2Xo1Qu6d/d8mHSQ+vCI5BjPa3mG+upMmmSDn8hISbU/4mMNODyH+7D0fRTy2ql/iXrsA8zgU9wnJRw9GlasSEgRJQlUwyPiE+2OUdxqetqq/VFAJBnGSw3PsLx+5tnDx7umjVzzXMxj/3b2Xbw67lutthsDEyfCRRfFUwJJJA1Lj0IBj0gLbsFLWwGNmsMkwySySYvnnoMBA9zTRo+GTmocySRq0hKR2CKDmpZBS1sjtTR0Xfxs5Eg4/PB0l0ISTDU8kjvUDNOcamnER7zU8Ix38swbk9378NC7N9x7r3ofZxE1aUWhgCeH6QbfnAJA8ZGENmlt2ACDByemYJJ0atISaXlDVzNMc5pgUHLZiSe6b+/VC3r2TG1ZJCVUwyP+pRodkZyR0BqeTz+1C2NJVlANj4hqdETExSE6w/vui4fSrZuCHZ9SwCP+pSabxFO/H/GBzhyCo4+OvsPHH8OwYakrkKSEAh4RiZ/n6ZxFMk89AfjB/7knFhba5nDxHQU8IhI/NROKD9QTgO9+N93FkBTLS3cBRKR9gkH7j2gwmMKTlpfbDuCq3ZEsV1CQ+MeXv5zudyWxqIZHJEu1u3Upw/vhZHjxxAfyqeXf3aa4plUHCvn5MfdR06mHpzz37oXVqxNROkkWDUsXyVIJXSw0g2R48SRDJXJY+lO/38zB4ihracUwZoxdlUJSS8PSRXyu3YPQEtEPJ4nVMOomJCkRbSbl4mKmXtIVilJbHEk+1fCIiHeqhpEMk9CJB7duhX79ElMwSbp4P3t1WhYR7yoqbLCjahjJQrXkgzHRHwp2fElNWiLiWZByKiln0kJYkMCWLXVYllS57rp0lyC9jIELLoAp7n23fUlNWiLiWahFKxCA+vrEtWyppUzay0uT1lini3mXg8kuUsabNg0efjjdpeg4dVoWkaQJdSyeNAkWLIi/ZautGhx1WJZUOeusxOZXXw/nngvXXJPYfJOpsDDdJUgt1fCISMqoBkeSxUsNz/FOJ3M8v3dN20chf+FiwPFchokTYdEiz4dJB6mGR0Til6LOM6rBkUzQiXruY2bU9K2LVlE/7EjP+fbq1ZFSSbKphkdEElL1og7Hkk5eaniOczqbfjzjmraPQl7jpHaVYfRoWLGiXYdKB6iGR0Til4CqFy2kLtnCkMcJ/3NO1PQz2pOngVNPbX+ZJPkU8IikSyZVibR72uYwNVdJtghQx8+4yT2xsBBuuQXy81NbKEk6NWmJpEsm9uDNpCBMxAMvTVrDA/3Mx+eMc09ctAgWL4Zjjklk8SSJNNOySKbLxNmKI9ulRHyqqGGHHUfu9jj3XPvPiPiOmrRE0iUBzUgJp3YpyQF1dIYXXkh3MSTFFPCISFgmBmEiIgmgJi0RERHxPQU8IiIi4nsKeERERMT3FPCIiIiI7yngEREREd9TwCMiIiK+p2HpIrlKsypLjsqnlrpzprgn9ijk4D33QY8envPt0gU66a6asbS0hEiuysSlLaJQbCZt8bK0RJnjmFh3gQFsZgsDPJfh+OPhrbc8HyYdpNXSRSS2LJpVWSuxSyLVks/VVx2Mmn5hO/JsaIAz2rPMuqSMAh6RXJVFsypnUWwmWeKee9JdAkk1BTwikvGyKDYTkQylUVoiIiLiewp4RERExPcU8IiIiIjvKeARERER31PAIyIiIr6ngEdERER8TwGPiIiI+J4CHhEREfE9BTwiIiLiewp4RERExPeyamkJx3HWAPuAeqDOGFPmOE5v4M/AUGAN8CVjzK50lVFEREQyTzbW8HzGGHN8xFLwtwAvGmNGAC82/iwiIiLSJBsDnpYuBO5vfH0/8Pk0lkVEREQyULYFPAaY7zjOG47jXNW47TBjzObG158Ch6WnaCIiIpKpsqoPD3CaMWaj4zj9gecdx3k/MtEYYxzHMS0PagyOrgIYMmRIakoqIiIZI/I+MJhAmksj6ZBVNTzGmI2Nz1uBvwITgC2O4wwEaHze6nLcXGNMmTGmrF+/fqkssoiIZIDI+0BvBTw5KWsCHsdxChzHKQy9BiYD7wL/AK5o3O0K4O/pKaGIiIhkqmxq0joM+KvjOGDL/bAx5lnHcV4HHnUc52vAWuBLaSyjiIiIZKCsCXiMMR8Dx7ls3wGcnfoSiYiISLbImiYtERERkfZSwCMiIiK+p4BHREREfE8Bj4iIiPieAh4RERHxPQU8IiIi4nsKeERERMT3FPCIiIiI7yngEREREd/LmpmWRaSFYBAqK6GiAsrL010akawRoB5+9jP3xMJC+/sU0AKjfuMYY9JdhpQqKyszS5cuTXcxRDqutBQ2bICSEli/Pt2lEUkrx3HeMMaUxbNvmeOYmHeBjz6C4cMTUzBJung/e9XwiGSriopwDY8b1QCJuDI4MPlc98QBA+w/EeI7quER8SvVAEkOSWgNz5o1cPjhCSmXJJ9qeERyXVs1QCI56hCdYdNa98T8fOjTJ7UFkpRQwCPiV+XlasoScWFwYODAdBdDUkzD0kVERMT3FPCIiIiI7yngEREREd9TwCMiIiK+p4BHREREfE8Bj4iIiPieAh4RERHxPQU8IiIi4nsKeERERMT3FPCIiIiI7yngEREREd9TwCMiIiK+p4BHREREfE8Bj4iIiPhep3QXQMSTYBAqK6GiAsrL010aEclCnTkEX/qSe2JBAfz61/ZZfMUxxqS7DClVVlZmli5dmu5iSHuVlsKGDVBSAuvXp7s0IpIhHMd5wxhTFs++ZY5jYt4FNm6EQYMSUzBJung/ezVpSXapqLDBTkVFuksiIlmqlnwwJvpDwY4vqUlLskt5uZqyRETEM9XwiIiIiO+phkeylvovi0h7zZqV2PyMgYkT4aKLEpuvJI46LUvWUv9lEQnx0ml5rNPFvMvBhJdh9GhYsSLh2Uob4v3sVcMjmSmO6puKivAuIiLx6kwd+7800zXNdC9g73fnQPfunvPt1aujJZNkUg2PZCZV34iIBwkdlr5hAwwenJiCSdKphkeyW0eqb9S5R0RiMDgw+Vz3xF69oGfP1BZIUkKjtCQzlZfbmp3IgCUYtDU/wWDsYysr7X9olZXJLaOIZKVdeX2jJz79NKxdm7rCSMqohkeyR2QgE6vmRp17RCSGooYdMHKke2JZGYwYkdoCSUoo4JHsEW8go8kJRSSGOjrBXXeluxiSYgp4JKupu46IeJVPLThO1PTxpVvZGejnOd/zz4ff/rYjJZNk0igtyR6NI7c2BUp46u71lJdrMJeIWF5HaT3bxX29rKpOxXxnwivs71zk6fx790JNDbz1lqfDJAE0Skv8p6KCTddU8r36Cp5t7Mbj2sqlah8RaUPfg5uibr9wSg3V7ZhTZ9y4DhZKkko1PJJV4oplVO0jknM8z8Nz6qnuiUVF8Mgj0KNHIosnSaQaHvGHFhFOXP2RNUpLRGI4RGd48033xLw82L1bAY8PqYZHMluotqaoyP4BUjOViLjwUsNzVF6R+fDUse6Jb74Jy5ZpaHoWSXkNj+M444H/NsZ8NVF5ijTV1uzYYf/ruvpquz2OoEddeUTETQ+zl48+dV8rq3boeWy55s9Rj337hCvZ16vENe2kk+DcKBM4S/olrIbHcZxLgEeNMYGEZJgkquHJUr17w65d9nW0vjmREQ6EOziXlKsrT7wUJUqW8lLDM8ApNddyhWvaYWxhCOtc06YwP2a+v+JaTn7tV/EUwZPhw6FPn4Rn6xsJq+FxHOeMOM85Js79RDxbOHU2xz50M127GrpG65vTYkmJQfUb+D+nkif2lxMMNt6/dUOPLd7ZrEWyWB71FLLPNa2c37OJgWyk9eKhyziOI/jI9bgC9lNFDyZMSGhRATjlFHj11cTnm2viadJaABgg+ixNYbnVIUhS5rIF5Zxn4Pu1lbjPnkHrzsqVldxZVcElu4JMvaYSqNANvS3q8C05YACf8vmR77umrep6CSsnXIlx3JeaXHTkJOry3ZvDugN3JKqQESZOTEKmOajNJi3HcbYDzwI/aSOvycDP1aQlMbWzhiUYhKnXlDKo3g43D1asjyublsc1u6Er4BHxDS9NWsOdPuaJASe5pp3w6TMxj/3Tcb/gqZHfabW9vh7OOQe+8Y14SiCJFO9nH0/A8yRQbIyJMmlB037qwyPuIoOcUA1LvHPktOiXE3pdWlkefzZqxhLxPS8BT5FzpLmQ/+eadj9Xxjz2m/yGu/mma5qantIjkQHPN4EZxphT2thvPHCtMWamp5KmmAKeNIicCNCthiVWQBJlEsFgEFbNClLhVNJjtgIZkVzneeLBdp5nz+zfUX351a5pvXpBt27tzFjaLWEBTzZwHOc84E4gAPzeGPPTaPsq4EmDtmpYYgVEcQRDVcUljCpYz6RJsGBB466ksFYnm2qQsqmsIh54CXiKu4w253T3vlr6V6rvZWXnsdxVcGurtEOH7NISzz/vOVvpoJwJeBzHCQAfAucCG4DXgWnGmPfc9lfAk4FCN+FJk2DePNsYHk9bVeNxs6oq+NnucgIBmFkf5PuBSgYVVtl5e1KxvEQ2LWWRTWUV8cBLwFNYWGaGD/d+H/jW5ls5EOjBvf1bBzzV1dC/P7zyiudspYMSOSx9IPBrYK4x5rko+0wBrgKuMcZs9VrYDpoArDbGfNxYlkeACwHXgEcyUGi9iN69bbDjOPGNEmo87oIZQW6YV8ozZRWcv7TSdlB2isM1RonkVkOS6SObIsuc6WUVSYGDB+FPf/J+3IC7oKE7nPl19/TBrUeySyYxxsR8AL8A3qKxNijKPg7wJjC7rfwS/QC+gG3GCv08A/h1tP3Hjx9vJIXmzjWmpMQ+t6WoyBiwz17yKymxx4W2x3u+9og8V7bIxjKLeAQsNXHeN/LzY9wHrrzSmIED3R8FBcbcc0+y34p4FO9n7z7RQHMXAL9rzDRa0GSAe7A1KxnHcZyrHMdZ6jjO0m3btqW7OLmlxWSAMc2ZY2tl5swJbwsGbTNMMGgf11zTOr+KinBtTnm5bapJVv+U0LkmTQqXK9NFXh+RHBV5H6ivj3EfWLoUhg6FsWNbP0491Q7Dmjmz9eOKK+DBB1P2fsS7eEZp1QDnGmNebmO/M4D5xpiuCSxfmxzHOQX4P2PMlMaf/xfAGOM6b5D68KRYOzrJBoNw881QUwOrakoZbBr7nIANdgCmT4cHHkhSoeOgvjAiGcVLH57OncvMAw+43wcu/UoeTjv7tm4ZcxYvfffFdh3rJ6edFv6TnQqJXDy0GugZx349GvdNtdeBEY7jDAM2Al8GvpKGcoibUP8cDyor4ZJdQWYziy7UspMi3p1UwRlnYGt46uvtcKx4BIMwa5btFzR7duJqftQXRiRr1dXBtGnuaYu4k7N5kTqX2+NxvM19XMlsbnY9tmFFHiZKvrnk8svh/vvTXYrW4qnheRHbKdh94oHwfvcARxpjzk5g+eLiOM5nsTN6B4A/GGN+FG1f1fBkGJeAJBiEL1xVTDG7AdhJEf0Du7j77ojh5s3GoMcIYkI1MaDaGBEf81LDk5dXZiZP9n4fuPLDWxlW9Q5v9Jnimv5+r5P4sCjxi2lNnAjjxyc826Q58UQ7Yi1VEjnx4CXAn4GvGWNcYzbHcS4Hfg9caoz5azvKmzIKeDJMtIAkYnX0nRTTh50UFYUXTI+7SSlZNTwiklG8BDzHOF3NK7j3vqimG+spdU0by3K6URM132Ucxwksi6cInpx8MvznPwnP1jcS1qRljHnCcZw7gT86jnMtdl2tddiFQocAU4Ay4PZMD3YkA1VUhAOSyOah2bNtRx5j+P7B2VANlx8MQmkbw6tb9hlqfIQ2P7QwyBkLNPGeSC7L5xBFHHRNK2IPtQXFbOvaOuhZwRkx811zxuUsuSUhRWxm+PDE55mL4p540HGczwE3ABOBLo2bDwKLgDuMMU8mpYQJphqeNPPaiTkYpOb6WTRU19KVavIwEAhg27dizNpcXAzGNNXshNbe2hiIWEhUzVsivuGlhsdxygy43wem8Cwn8rrn8w9hHaflvcqof9/j+Vgcxy7ElRfPwGlpKaEzLTuO0w34LDAU+BR4oTFphzGmrgPlTDkFPB2QiGUJvIxuCg1Dr69v2mSwkz5RXAwFBa3LEmrC2rPHBjzQbHX1hyYFOePJJDRxackGkbTyEvB0715miosTex84tGkrD3EZwwa4j9058tNFMY///dnzWHrkl1ttb2iAKVPgkksSUkxfSmQfnuHYAGdoxOY92P468ztSyHRQwNMBHR2K3VZ/mpZBQ+h8jsN+0w2DoTN1dKaOvM6d7OI1jgP3NP5H1XJFdseBoqLW50rGkHINUxdJKy8BT35+mencObH3gdK6T3i/Nnbb06ucwj4KW22vJ8BXeJg9FLked9558MwzCSmmLyVyWPocoAE4HXgDGAb8FjvR4LCOFFKyTEeHYldWhte3ighAQnHOyv2V9Ni1wdbqAAsnVTD2oVl06+bwyNjZXLRkFj1CMx/UNVYsGsOBq26gq3OQPFPfPOiJVtuSjCHlGqYukjUOHbIdgd0ETB2dGmo951lYl8/SD88mv8G9U/Oxexcxkeg9j78z8mle6O8+o0pdHZx/vucixVRXB1deCZddlth8M1k8NTwbgRuNMY9EbDsKWAmUGGM2J7eIiaUanhRxa+KJ0uwTqhy5qSjInH3XNC0eWsp6Xt1QSimNNSf799thWo5jf0sfegiMoR6HQKy+PWpuEvG9RPXheZYpnMm/aYhrIYL4daeay7mf/RS0SjM4PMkFHCI/oedsyze/Cb/5TUpPmRSJbNJqAE42xrwWsS0AHALGG2Pe6mhhU0kBT4p4aOKJXCz9widmcHHNPPIum0bwjAdYNSvIzbWVzM6v4IILaD7CKhik6uZKnq2ZxHldF9BjdpSAJluamxSYibSbl4Cnb98yM368+33gV4vLcEwDBwOtA5P8hmr+chAnxXYAACAASURBVPi3WVF0Wqu0qiq7KOnTT0c5aUEB9O0bT/HEo0QHPCcZY16P2KaAJ5fFc2Nux/w3paU0r9FpDE6a1QD1aIyMnnzS/nXp2rXt/GOVN5OCjEwIzDLpeoh44CXgCQTKTEmJ+31gQN0GSus+cU07t/ofTK+6m115fVzTu3WDPr2jnHTdOrjpJujpsnCB49im/N7RDpZYEh3w7AZajsbq67bdGJPC+RW9U8CTAPHemOPYb+GMIEfOq2T1tAo+OKOcVbOCVDiVzWpr7j05yOQllRR3rqLHod0YHBwivrcdCRAyIcgIyYRgI5Ouh4gHXgOeESO83wfO3fcXvr39Vs/HAQyv/SBm+nWDHmd+oftQrC9+EX7wg3adNickstPy9xNQHsk2sW6+8XbQDe0XWlm8RVNUpang+j2VDDIbMA9VctmCcirmlNOjxfnOX1rJIDawu64YSkqo3rCD7lTTAOR1727rkoNB9yChrSAikzobt2PdsYTLpOshkiRjxsCjj3o/ru/tS+n5bD21pa1HYzXUG/6x9zMsKL7Ic74Ghw3dj+Jwp3Xazp2wcKH3skprcU886Beq4YlTIv/Tb5lX48/rKeHn3Sqa+ujcVV3uerrIWqAzzoCaG26mutqw/LI5tk9PKO+Wo7Mi5/FRjUXqeKmpyoRaLfEFLzU8XbuWmYIC7/eBgQ0b+Vzt465pgw6s5lv8Oubxv5mzn7r87p7PO3GiXZ9K3MX92Rtjcuoxfvx4I3GYO9eYkhL73MFsbiqaa/YVN+Y1d64xRUWmunuxualoblP2rfaLpqTEGDCmqMi+nj49XM6WaUVF9udAIL73kaD3nPNCn0NJSWL3FYkBWGrivA907jzebNliEvrY8cKb9rsc67F3rzF1de4Pabd4P/u0ByCpfijgiUMCb/yt7mctN0Sca1+xTdtXHOPmF9q/uLj1jbJlWnFx66DIU2GjnLutfHI9cPLy/kP7Tp9uA9Ti4ty9btIhXgKeQGC8ycsznh/9nG3mSuc+9wd/NP857EJjJk92f7QVDM2fn65Ll/UU8Cjgab8E/tfd6t7XckPEuR7rNt3U4Zj9dHe/6bW8OXbvbp9bBjQxzuGtsC3Em0+6ay06EnClK1gLXTPV9kg7eQl4evQYb8aMMZ4fv+73f20HLu19FBR4L1Bbj+OOM2bdunR9JCmjgEcBT/sl4qbXRh6h5H9PDwcx9U6g6Ze/qWkrsoYmVHMTegQCzZ87WjPTwfeU8PO1N7+OBFzpCtYamzpVwyPt5SXggfHtiklu4wfJC3iS9VixIl0fScrE+9mr07JYie48Gq3Tc+N5ZlVV8LPdjZ2UK8KdixuwIxb+2u0yvtD1qfDMysbYdbFCi4KGZltesCA8L09tLeTnw5w59lx+6QzrtQN5Rz5LdSKWLOWl03JhYZkZPtz7fWB4zXtctPNeDK2HU9XVQffuMG2a52zhgQdg61Y49lj39Jkz4YYb2pFxbkjoaul+ooAnivaMyop1c5wxA+bNs7/9DzzQ6jxVxSWMKlhvD6202xqcAHtMIcXspsEJkBdw7F+RTp1gwAB7nptvtkFQcbEdrxkqR+Sq6iUl9tkv88nkahDS8n3n6nWQuHgJePLyysy55yb2PmAMfOlL8PWvR9nh/vvh3XftP2stHTgAq1a5H7dlCwwdCn/7W6KK6jsKeKJQwBNFe24msYKkFmmh7B+aFGy+PETEuWdVVbBrN9zD1eRFTizYMrhpWc7evW0QBHaq065dYepUW/ujm2P2ijKdQcKDWAVSvpCotbT+wef4HE+2vyADB7pv37wZbrvNfabltpxzDowb1/4y+ZyGpUd5qA9PAsXqW9IiLZ6uIdOn2+44+/Ib++p06+Y+yioy77lzjXEcu39oOLo6vvpDy+9XsjpU6zvjC3jstHz00cb1cXefW826zsPM6vyjWz3a6i+zM9DHmI0b3R87d6br0vhevJ992gOQVD8U8CRBtBtRxPaW/Y/ddg31PX6sW2PkM326TWx5Q4r8OfTacWyH13iHoGeyXB/WnkjxXMtkXW99jinlJeAZMWK8mTfPeH68/tXfthn0HCLg+mjruLN4IWryRRel66pmh3g/ezVpScdFa2pw2d7WroEAVHXpTdcDEf10gkHbd8eY1h2SQ6937IDq6ubNX4mS6iYPrWeVOOm8lpHnbjkLuCRcSvrwGEOeqY+aXF9v/0y5eXzRAFb2PJnavK5uGTP3iDls7n5Eq5S6Opg+XV+bWBK5lpZIbNHWX2q5PRhk5f5KKosq2DypnFnFQW6ureQlM4llzgJe6jaJC5ynbLADUFMTXoMLYPduG/js3Nn8t7+83AY61dXR/9p0JGipbFy+orIyNX91tJ5V4qTzWkaeO1HfIT/2N0rDezIG5s9vz5EO7b1t1uLwjx0T2Ueha3rxtqcpjnbsFqCmXaeNbepUGN56XTC/Ug2PJF/oD9r+/bZzcUkJpazn1Q2llLKBOgJ0ot5W79S7/PcUCNjh5tXVdmh6qIOy2zmi/dHsyH/6frzJZLNUfR6JPE+i8srm2r9o16C42P4zE+13O07pHqXVlufmu4zOSrcbboDbb093KTpMo7SiUMCTGs3+tjUOO6eoCHr0gIoKgpSzala4hue8rgvoMXUSNX95iupqQy+zp/lILbDDOSdMgI0b275xRBYAYNYse/zs2Qpasl2qbvqZGFwkKnBqTz4dPXe06xkaZdnB5mgvAU9BQZkZPDix94HaWli7Nnr6VvrxLsdQS77nvD8cfh7fmndqB0oXxZgxUFCQ+HxTTAFPFAp4UmNWcZBv7a7kV0UVtttNlD+UoZXQ80oHM2D9Uh7Pn8YXqx/gsW4z+ELtPCgrg9deCzdVhSYhDP3RjPZHuDQiyNq3Tyumt1cm1m5lYw1PpmlPMNfRADDa9UzQdfYS8HTvXmYOOyyx94FNm2zQU1npnn70iifot+0917QuNXvov2W5a1rB/i10OmIofV/RPDzRKOCJQgFPalT1LqXHLjvBYI+drWdaZtIkWLCA3Rv3U2R2YbCt43UE6FdUx5w5jX/7gkG4+upwwNO5Mxx2WPiPo9tEhuW0bkYLBODuu/1340q2TKzlkI5LRw1PkiWqSeucTX9izK5XME6e5zJ07Wr/RHl14kfz6FRXw9r+J7ZONLD3whmMu+dq7xnnCAU8USjgSZHIP44LF8K8eXxYNo0eSxcwqH5D02413YrYWduDvNLB9F/zGgfoyrPdLuELfRY07+wZ0rKd322pisj7crQZnyU+6brJZfjN1VW6y5zu86eZl4DniCPKzE03ud8HvvT90fT+dGVCyxbyCqeyn9ZNSAaHB5numgZwwvEx+t2XlMCJLoFSDtHEg5qHJz3c5h5pnGCnjoD5OnNNXeOcFPVOwDzWbbqp7l5sTFGRfW7c3jTPTlsT+MQ4rTFGk8plq2z83NJd5hSevz1TDCV8WqIWGeJhHp6Y94HaWmP27fP8WDl/nXkxcI5ZXnSa6yOpC4TmuHg/+7QHIKl+KOBJsog/uqG/Rx+cZCcS/OCk6eb1TieZhsZf0se6TTfrKAn/0nbrZoOjk06KK8iJi9tfWU0Il/na+owy8TNMRZk8zG6eTO2JreI9Ju630SLDhAU87dSwanXSApp9gZ7GPP64+2PJkoS/l2yjgEcBT3pE/LWK/HsU2vz/27vzODnqOv/jr086x+QAuhMChMwkRMkDTSDLEYwoYvYhR0BWVhAlS1CJJJAVz59css7iuB6Jx/4ElWUa+ckSjuXBGmU5vRZBESVo5BCQQAiZiQQhMzHX5Jj5/v6o7kxNT1VPd0/1Vf1+Ph71SKaq69vfququ+vT37PN9iV8f1+wuS7YPKuHZmmoeOPRyIhHtTbzav8QbXbEP5qDX18M1LEcAUsxxt7d7062kUpEHQVGU8ISlUfAhlquEp0TrVv2hbAHPKs5yLS0u0uXAA5279trIT0NVFHrt1YZHysbfpCDbFGedzWC6e5m9GFcnb2BFV/8s2He9MZ95Ox/it2Pnc87OWzHcvsbMAxrnDLetQoO3dai6fA2hg65N0Ovr4RqWo8F3McedfX+oTKPzIq9J2Okp9dIW04Zn+vS5bunSaJ8D69fD79OrGcvOSNN9F49wAbewkkWB29cxg9v5p5LSvvpq+Ld/G07uaoMaLYdQwFMd2ZvYs9u93lvdlqJpLDSNdl5fzh072DN6HH/tncjE0dto2tkNwB4SJAxGnO9rdKyeQ4HqIQYA8me0XoObINXOdzpd2fGnivxeRn16opotPZ/R7OIogruPAzRPhR9F3Xv8t7+FSy/N/5oGe47nUsATQgFPZWVvarfOT3PSQ20wdSqsXt0/crJfdoydVIq+rm5G4OjFSODi8QAss1jEgbq2hanF81TlPBUT8MyZM9fdeWfxz4FJ//FlJn/7X4reryBTpsChhw5ev20bvO99sHhx8H6plDdURwNTwBNCAU9lZR/CnYkWDu3toJcECXr7gxuAkSO9gQETCW8k5swEoduuaOOBnsz8WqMzE4cG3Uhr8eZfBToNDaSWo9thfBCH8xkuJuAp+TnQ2Ql33RW4qaMTbvo+fOADwbvOav903qTXn7GM1952ZuC2KWccQ/PxU4rKaiNRwBNCAU95BU1s/sLladp2X0Hvjh7AGMtOb9oIM2+krp6e/uAn6AYeNtdO9u64bZu3vRZv/lI5cYr4hjqWWj7WPMFYVFPeBaVTkYAnjy1bvLxs2xa8/b77S59L6x7ey8oP/Dh4o1lJgyT29sKHPgTnnltytmqGxuFRL62qyPaw8PfO6kx4K7Pj6+wclxrYAwtcH+Y2W9L9clFAF46U13vLpVLBb5ZK1V4X5aHUYrfqeubv1VeOnluVvl6V7oVW6PEV8ro8rxnqsArtWBZ0S6DKvbSGNH78sHpq7WXEoCW77cP8IHBZyK0uwZ7QZC+6qPKnoRwKvfZVD0AqvSjgKa9sfJJMesPoJBLOXUS760w0u+fnLXKdiWYvqMkZUPCyZLsD5y5LZtYnkwOjpqAbaIGDEtakeuhWXU+y5zPqIQxy0/dfr3IGQbUaYA3zc9ve7n3H9w09kectsq+7LNnu3TN85yOZ9O4rr9C870dSzQc8JXr0UecO5DX37iP+MmiZf8RG99/Jxe5XE04NXLKRzZ/HHDloWTd6pvvktB+6I490kS4zZzq3cmVlz1Gh115VWlI2/l6xZl4TnY/uTbOCy0mlvJ4jaZb4p9ba14uLceNg167gKSFyy7NruT1DmHJVSdRyVUc5lfu4C+0uP9w0q6XQvESR58x525ho5t7rNwxKJrdH5waaSSTwpqTJnOt0GhYsbaEFL51D926oepUWe/fCDTcM7owxTN0/f4LkA3fwKsU3TD6ETXm3f5zv8D0+XmrWQn31q3DllZEnG0pVWjGI7IetytUm2bc3835oeNNK2L5fHS6Vcp2JZncR7f0lO9nSGn8JT67cX5mqHuqnkqPKGe7nrpauVRSDQRb62vb2wd/7kJGjB5XwZO8Pi7wpafzV4FS5hGfzQ390oXVHESxrmFP08iIz3FmsckfyZODyiflPOvdkGZbduyM/v/kUeu2rHoBUemmogKdK7QB+uah9wD1s0SIvG2+Q3Pfl7cX2BTWdiWa3c2xm29ix+aup/HVmCnAGU/BXP2rpWmXvFclkYXkKqkIsYujkbFudDvO2bU01FzZjRjat7K8oXyOeagc8r73m3HETnnNzWBPpchIPuXs4wz0+6dSil3IGYPmWdZd+PfLzm0+h115VWnFW6SJzX1H11N4N/SX96TQblrYxkc2MZwd9wO5xKZrOfq9Xj9Xa6nXt8vfACqsmqMfqq7ippaqYelcr5zKdZtsVbezt3k7SdQ35/Xr4gjTvXLnMG2Ii+1r/dzM7vHp2iu+AY2xpgS93XMD53M6qsQs5d+ctgW874Cvfmjlfb7zhVR2NHQuTJvHw/FbevfK7e5xbM7qQwy3Hc+DVV72hdEqRpItj+EPgtnfxCF/kmrz7X87y0t64TEZ9+J/48s3NFXs/dUsP0VABT6Vlbt4Pz2/l/IeW9N/fMnesbYylid24UaMZtWfn4MEEly3rH4/n+uvrrztuo1DQGZ0aOpctLbCgI80XE20cen3+71fgazNBU5trpdXavLZ4eY4rnYb3LvPG59qWauat4zcEfq0Dv/LZldu3Q1cXvSQ4hGb+6l4uqO93OZ4DXev/xv8ef7nX9rBIp2/9L/oYwVNj3zZo2949cMiITUxv7h20zZxjzxGz6brxhyXluVwmT4ZRoyr3fgp4QijgqZwLLoDbb4cb5qb5WGcbXZ3bSLluuixJqmmXN/7O+efDSSexr+Xyvff2D+KjgKY2xSXorIXjqIU8lJCVsNdm47fLkmlazQt+Zq5YEp5e9iaR2zmhmEbUmR9KcxjFk2531QKevzyyliknzYw0zXJbs/BrPPe+KyJP98QTvVi3UtRoWW14Kiaw6r7d6zJ6Ee0ukfD+3jo65d4g6W6clzMTur+Ov5ztjmqpzYRUX6mftUb6HBV5rP6XF3J6t6b62/AMSCDbacHfpigoL76Bew6Gl10VnwMdHc4l2ONGsjtwqVZ7mqGWX/GOSJffcrz70oJfRX5+80FteIKphCd6gaXymZUbaOYn81r52GrvV9gGmrku2cqKXZ/qL+GB/l952dIe/y+7qH4F11D1QU2poVKGiir1uMPaqsTx3A3jOxNWeAPsO/d3vTGfeTsf4htjW7mlaQlPdbcw1XV4o6uPH7+vyorm5v4R1f0jrvvyZx0dVe2WvnGjN1VgmNk8zWG8HLjtcNZyOvfnTX/SpOLzNPeNnxS/UwS2XH8bB1yysGLvpyqtEAp4ohd4Y/M/TNraoKMDBzwxch7H9q5mhAto7AiwaNHgou1s257hBiqN+mAfigLB4gR8tmN77oK+MwV+j3I/VgN2a8u068u03cnGNReR5hprY+oNraRZwguXe1VjE5b3d2zoGZdi5sTNtLbCEQ+nOfz2NtYubOXdK5dWdxyeTZvguOPC55bIZ8sWb5qdk04atGnvXnjxRejrKz7ZvhEjuf/4VnaMSQ3a1tEBfx03nVX3jSk+4RqjgCeEAp7oZW9syWT/nKADmuD4g5Ysf8PkdBqWLu1fv3fv4MRhcDAk0VAgWLpiz105znWZrl9YstsmegMCbks1M2Fz+FxZRzyc5s23trGiqZUjv71kYGzYOjDxdBouvti7d2QLcAbF4ZnEL9/WSlc3tNLGN8a2cu3OJTQ3Q0dHlQce7OysbMOVCNyY/ByvfOLr1c5GQZyDD34Qjjpq8DYFPCEU8EQvp8MEEPCDN6wXVrZ4qKXF2yG3/PuCC2DlypBEczKgB7bUunKUphWYZrFfk7BkL0+l+UR3m1c13bUkfB/6q7X/LrWB5cuLmw81LL/+UZY7rZm3T/V6dy1dWt2AZ9MmOPnk8AKeqXte5pDezsBt/7zlK+xlFE+POTbSPOWzZzf8545z+BOzK/aew3Xlld4ozrkU8IRQwFM+uTOlL1nCwLsW9PfGyo6/4y/5aW8ffCfM3kGzQVI2jSiH+JeBFECWT96GLSUqsYqp1GTzvd2AbaTpvLiNa1wrdyWX0NXljd+TrYI66SRK/pwNSOcWb99qTy2xZo13We+7L3j7jDfl70DWc+wJ7D5iTqR5YuRIuj79RfpSJTQAqkHNzcHd3RXwhFDAE60h77X++q4JEwa0e9iWauaBnvmcs3MlBv0NFf2J5T4ggu7aekBHSwFk+ZTh3Bb68Q8KEopOpAD+r2xuH4TuERNJui66LUVy6njo6KDLkoxKTvDa6RQ0CA+BP6QO6ehY/6pzhxWSx3I8B9avh1mzvGr9ICf1/i8z+54P3HaQ28S8vkcjzQ/Ayb3la7Tcwit00FK29IN861vwmc8MXq+AJ4QCnmEIuPkMef/O7NOzeTtNO7q8ev/lrQN6aPx27Hw+MOYer+Gec17g4xzs3u2NpupcSMtHBTdloXNcPmU4twX/Bsj3ZW0Z2Ih4qGqlfEaO7K+59jfHA+gZl6JpZzc9Y5M0fXsFG5e10dS7nYmEjO48caJXT27mTcwZVKoL0NHB0bBnjXNVG2kZYGdXD717im9dPOaTSxn1X7eW/L6/PugfA9ePcL2M6Q2ezHTrVti9xzvFxepJjGfF7JvZMfKA4ncu0Z49XpXWggWDt2kcngqOv9AwQubECZvyyr/+sqQ3Ls9lyf4XDhiDI5t2dj6t3PEiGmHME5ESBH0HA8fAWbTIG/dq0aLQRC5Ltg/YL2wsnXzD8+R7m307ZubK++UibwLRramQxJL98+8NGODHP9deZl21x+Hpe+75soyTU8jyxMU3lLR0PLo+8vNQDWgcnmAq4RmGIn7upVK+ITNW9A85P2DU1WzZ99y58OSTXmkOwOjRXjjv/2wW8jktpdGBSKlq+HNVdAlPyH7Zv+fPhyn39HcRb2lbkjepgqu6hyqWym0YmGcYgGq34fnzE1t5YO7VNNETaboARyY7eMfbBk8tgXPw05+WnvAnPwnf/nbp+9cIVWmFUMATrbAbW7YkOpWCzeNDbrT+Bsn+LuvZvu1Zo0fDQQcN/WAJGxAu7mOlNLJqBh310NYpqNNACeeqpQUe7fB6RtHcTLp1Q94eVYVWddPqjbfT1gbPbm8Jn3/LH3llOzzkHENkAc9PfgKPP15IMgP09sGqH5Y2DE8+019fzd93/wimTRu8sa/P+3F4552lJX700bD//sPLYA1QwBNCAU+0gmKM+fPhnnu8uGX5cq+3RuBNN/v/qVPhd7+DESO8L/D06d4Nb+5ctv25kz3d3hxcQz5YwgaEi/touI2smkFHDZfw7BPR+UmnGTgIYM7x5h1kMN+pSafZuKyNf+1tJZWEFRMG7pRNZ1AwFPAGkQU806fDK68UkkygBzk1cH03SdZyeNHpGY77OINfc2LJeaq0a6+FT3yicu8Xq4DHzK4BlgB/zaz6vHPuvsy2q4CPAb3AJ51zD+ZLSwFPtIJijGyBzYB7bO5gPf4eWbk7+v69fL/r6eqmoBmcQzNWqw8jGT5d5/wqdH4KKIAJlomUNiaauff6DaGjUlyWTA8MhgICuWICnkMPnevOPTf4OTC2p4v9dmwqJJkB+ta+xBcee2/e10wd18UWSxaddj3Zvt1rX54dS7YSYtVoGbgG+FzA+lnAH4ExwAzgRSCRLy01Wi6fbHvCefMCGi1mGx+OHOltHDXK+zuVGtwQcd68fY3xtqaaG2aeRpG8qj1paQHvX/R8rEOkGbo5YAMFNlz1Xnpc5G2Hj+DZoV+0fXuBJ0aKUei1r6cSnm3OuW/krL8KwDn31czfDwLXOOd+E5aWSnjKL7AUPduoJyvbTic7jnw6DZdf3r++u3vgiMxBCh2aVSQOqtxmaECX8h1dAzdmvnsPz2/l/IeWFP4VjPA7W0wJj9lcB6U8BxxG+DNz9tQtPPWHvcEb3/pWOPFEb86sYvT2wnnnwTnnFLdfA4ljCc/LwJPATUAqs/47wCLf674PfCBg/6V4n+7V06ZNiyCelHwCf5W1t3slO9Bf/OMv1fF3P02l+relUt62oF+AuT8ni/55KVJHqlzC02Up58D7N1ep370Iv7MM8Svf/xyAaSWV4izlP5wD14uFLs5CluEUH1188bDPT5wNde2zS82U8JjZz4BDAjZdDTwGvA444EvAFOfcYjP7DvCYc25lJo3vA/c75+4Kex+V8OQX2Q+uQmdZzv5qTaWgp8dbzj9/4KjKEN5zI1sqtHy5t04lPCJlUZaRmgvYr9CkiynhmTRprps7t/jnwIUvfB5w/GjapwZt27oV3uhN8tiaIktwZNhiVcLjX4DDgKcz/78KuMq37UHghHz7qw1PfpH94Cp0xDL/37n7tLfnL+EpNMPVbvsgtUufjZqX/Ypflsx/rSiiDc+IEce5gw92gcvZqV+4ayZ8PXD548hj8pbEvHDQCRU5JzJQode+6gFMQZn0SnSy//8McEfm/7MZ2Gj5JdRoeVgiu/+HJZQvQCnkzfMFTGFU1SVh9NmoDXm+x9lN2ZHZw65VMQHP6NF5ngOzZzt3wgnOnXpqccsppzh3883DOw9SkrgFPLcAT+G14bk7JwC6Gq931vPA6UOlpYCnyoJKbfIFLbnbSnlA6Ve8hNFnozZEUFIbWcDz6U87d+SRxS8zZnhBj1RcrAKeKBcFPDXAf3PzN2YOutkFVXPlzKEz5EReIlLbCvleDyGygCef225zbsqU4GXSJOfOPLO0dGVYCr32NdNouVLUaLnChmq87B90cOFCb9Qy/+hlEN5iMaybbj0M+S8iwUr8/hbTaHnMmLlu166Q58CNN8Ijj3gjv+d64gk480y49NLgfVMpGDu20CxLRGI10nKUFPCUT0kTFvonBzTzxuTJjsVj5g3ZmW8cHv/Egvl6g4lIfSjx+1tMwDNq1Fx3yy3Bz4EFlx9FcsPToft2Hnsm6995fuC2yacczcx/eEshWZAIKeAJoYCnfAJjm0JuXtkdzeCAA2DXrv6Z03MDpdz0BsxSurmsx5dLcZVI7Sgm4Dl48rHuzHf9PDgd18cIFzAzOfC+51Zw5vPfDE33haYjOXDjU4VkoSgTJsCoUZEnGxsKeEIo4CmfkidmTqdh2bL+CbhaWweOr+NPIDeqSqW8UZmzIzaXUdEzQotIxRQ1eaiZy/cU2NW0P84GV2k17ezmyRP/mfWzTh+0bfNmuOau2bzMjILzXKhTTvEmcZdghV77kZXIjDSGJUsGjyfY1lZAwJN9QW6E1NY2+LX+mc/Bq8ry/11G2eZG2WPKzYqIxMPFc3/PX8a9OfwFLwevftcFcOYB0ebFOS/gkQgU0rI5Tot6aVVG7nygoR0uShmvp5A3LkMPLXX+EqldFNFL6xhGuHwDCB7GSyXNADFzZrWOvrEVeu1VpSWRyTdzRGi1T9gLSm0go3omkYZUlIC/twAADidJREFUTJXWLBvn7uXgwG0Hs4lZ/In1HFZ0HiZNgtdfL3o3GSZVaUnF5Vb5QAHVPmEv8NePFUP1TCIyhJHs5bzJvwjctsua2J2YwpQi09y5ExYvHn7epHxUwiORCSuUKbkxc743CuqOLiINq5gSnmMs4R4heLycrezHMfyBTYFzWVfHwoVw223VzkXtUi+tEAp4Ks9fywRF1DiFRVBDzaIuIg2nmIDnzZZyq5JHBW6b3f1rPn7847wy/q2B23ePaPJ6kFbInj1ewHPJJRV7y7qjgCeEAp7KK7mEJ1/7niuugJ4eaGoa3HVdRBpOlN3S8/rBD+AjHyl1bykDBTwhFPCUR1kG4Rsq0QqOwSMita2YgOdwS7pbx8wJ3DZv1yM81LSAjYmWQdtG0MeN+3+WF0bNGrStp8drw/PVrxaZcRk2NVqWigpqsDxsQQ2X/UFQtli5gsXLIlL/9udvdO8KbsPz//goF/XcSB+J4J23h6e7bl0EmZOyUcAjkahY5yh/ZLV8uXpkiUjRRuA4jfChiy98qRVmRD9islRXwHSwIsVbssRrZlP2pjStrf3TT0T5pum012YonR5+WiJS3/r6qp0DKQMFPFJZwwgs0mloaVtCujV/kFPSW/hLjkQk1vowHuTUwOUmLmTE4TMwo2aWj3602mcsHtRoWSprGCMhF7prSW9R7qnPNbW6SFkV02j5TTbR3bb/8YHb5mz7NR+e9QSvjD0i0vyVavduuPBC+NSnqp2T2qVeWiEU8FTZMB78he5ak7GFprwQKaviBh4c6f5gIdVW++0Hzz4Lhx4aZfakjBTwhFDAU19iU/BSk1GYSHwUE/DMsTHu4JN3RZ6HzZu9Epko7drlDTr42c9Gm26cKOAJoYCnvhRaMJIvnsi3TQUvIvFQTMBz3Ogx7mv3RhvwrFsHF18caZL7XHSR+lPko4AnhAKe+lJowUi+wCXfNhW8iMRDMQHP340Y42xOtAHPzp0weTL86leRJisF0MCDEguFTpqebxygfNtKnZRdROqXc3DzD6JPNztfoNQmlfCIiEjdK7YNz5Mu+jY8Uh2FXnuNwyMiIiKxp4BHREREYk8Bj4iIiMSeGi1LzVCPKRGplOuuiz7N446Dd7wj+nQlGmq0LDVDY+KISKmKabR8lI1xTxN9o+UZM+CllyJPVoagbulSd/J1HxcRiYoBjz0WfbrTp0efpkRHAY/UDI2JIyKVMm9etXMglaaARxpOblshtR0SaTzLllU7B4Xp64PTToOzz652Tuqf2vBIw8ltK6S2QyL1rxba8JTLaafBAw9UOxe1S214RELkthVS2yGRxmLA1q3VzkXhmpqqnYN4UAmPiIjUPU0t0bhUwiOSh9rtiDQuBxx2WLRp9vTA4sXwla9Em65ERwGPNKS2Nq/dTlubAh6RRrR+ffRpvvhi9GlKdBTwSENSux2RxmVAg7XmEBTwSIPSmD8iIo1Fk4eKiIhI7KmERxqWGi6LNK7zzos2vd5eeM974JJLok1XoqNu6dKwNOCgSHzUwsCDb387/OY3kScrQyj02qtKSxpWa6sX7KjhskhjyTZajnpRsFPbVKUlDUsNl0VEGodKeERERCT2FPCIiIhI7CngERERkdhTGx5pGOqGLiJZixdHm15fH7z73XDhhdGmK9FRt3RpGOqGLhJftdAt/bjjQI+XytNs6SI5NH+WiIDXLX337ujTTSSiT1Oio4BHGoa6oYtI1qhR1c6BVJoaLYuIiEjsKeARERGR2FPAIyIiIrGngEdERERir2YCHjM718yeMbM+M5ubs+0qM1trZs+b2Wm+9Qsy69aa2ZWVz7WIiIjUg5oJeICngbOBh/0rzWwWcB4wG1gAfM/MEmaWAL4LnA7MAhZmXisiIiIyQM10S3fOPQtgZrmbzgLucM7tAtaZ2VrgbZlta51zL2X2uyPz2j9VJsciIiJSL2qphCfMVMA/Lm5HZl3YehEREZEBKlrCY2Y/Aw4J2HS1c+7HZXzfpcBSgGnTppXrbUREpEb5nwNT0ZDIjaiiAY9z7uQSdusEWnx/N2fWkWd97vu2A+3gzaVVQh5ERKSO+Z8Dc2yMngMNqB6qtO4GzjOzMWY2A5gJ/A54HJhpZjPMbDRew+a7q5hPERERqVE102jZzN4PXAdMBu41szXOudOcc8+Y2Z14jZH3Ah93zvVm9rkUeBBIADc5556pUvZFRESkhtVMwOOcWwWsCtn2ZeDLAevvA+4rc9ZERESkztVDlZaIiIjIsCjgERERkdhTwCMiIiKxp4BHREREYk8Bj4iIiMSeAh4RERGJPQU8IiIiEnsKeERERCT2FPCIiIhI7CngERERkdhTwCMiIiKxp4BHREREYk8Bj4iIiMSeAh4RERGJPQU8IiIiEnsKeERERCT2FPCIiIhI7CngERERkdhTwCMiIiKxp4BHREREYk8Bj4iIiMSeAh4RERGJPQU8IiIiEnsKeERERCT2FPCIiIhI7CngERERkdhTwCMiIiKxp4BHREREYk8Bj4iIiMSeAh4RERGJPQU8IiIiEnsKeERERCT2FPCIiIhI7CngERERkdhTwCMiIiKxp4BHREREYk8Bj4iIiMSeAh4RERGJPQU8IiIiEnsKeERERCT2FPCIiIhI7CngERERkdhTwCMiIiKxp4BHREREYk8Bj4iIiMSeAh4RERGJPQU8IiIiEnsKeERERCT2FPCIiIhI7CngERERkdhTwCMiIiKxp4BHREREYk8Bj4iIiMSeAh4RERGJPQU8IiLSUPaMHFvtLEgVmHOu2nmoKDP7K7C+2vmooAOB16udiSrS8ev4G/X4G+3YpzvnJhfyQjPbCjxf5vyUS71e13Lmu6Br33ABT6Mxs9XOubnVzke16Ph1/I16/I187EOp53NTr3mvhXyrSktERERiTwGPiIiIxJ4Cnvhrr3YGqkzH39ga+fgb+diHUs/npl7zXvV8qw2PiIiIxJ5KeERERCT2FPDEhJmda2bPmFmfmc3N2XaVma01s+fN7DTf+gWZdWvN7MrK57o8zOwaM+s0szWZ5QzftsBzETdxvbb5mNnLZvZU5pqvzqybaGY/NbMXMv+mqp3PqJjZTWb2mpk97VsXeLzmuTbzeXjSzI6tXs5FqkMBT3w8DZwNPOxfaWazgPOA2cAC4HtmljCzBPBd4HRgFrAw89q4+Hfn3NGZ5T4IPxfVzGQ5NMC1zefvM9c8G/RfCfzcOTcT+Hnm77j4Ad7n2C/seE8HZmaWpcD1FcqjSM1QwBMTzrlnnXNBA2mdBdzhnNvlnFsHrAXellnWOudecs7tBu7IvDbOws5F3DTitQ1zFnBz5v83A/9YxbxEyjn3MLA5Z3XY8Z4F/KfzPAYkzWxKZXIqUhsU8MTfVGCD7++OzLqw9XFxaabo/iZfNUbcjzmrUY4zlwN+YmZPmNnSzLqDnXN/yfz/VeDg6mStYsKOt1E/EyL7jKx2BqRwZvYz4JCATVc7535c6fxUU75zgVdc/yW8B+CXgG8CiyuXO6mSE51znWZ2EPBTM3vOv9E558ysYbqlNtrxigxFAU8dcc6dXMJunUCL7+/mzDryrK95hZ4LM0sD92T+zHcu4qRRjnMA51xn5t/XzGwVXtXeJjOb4pz7S6YK57WqZrL8wo63IT8TIn6q0oq/u4HzzGyMmc3Aa7T4O+BxYKaZzTCz0XiNee+uYj4jk9M24f14Dboh/FzETWyvbRgzG29m+2X/D5yKd93vBj6SedlHgLiXhIYd793AhzO9td4ObPFVfYk0BJXwxISZvR+4DpgM3Gtma5xzpznnnjGzO4E/AXuBjzvnejP7XAo8CCSAm5xzz1Qp+1FbYWZH41VpvQxcDJDvXMSJc25vjK9tmIOBVWYG3n3tNufcA2b2OHCnmX0MWA98sIp5jJSZ3Q7MBw40sw7gX4GvEXy89wFn4DXU3wFcWPEMi1SZRloWERGR2FOVloiIiMSeAh4RERGJPQU8IiIiEnsKeERERCT2FPCIiIhI7CngEakTmVngnW/ZaGb/bWZvznndOWb2CzPrNrNdZvZnM/uWmR3qe42Z2efNbIOZ7TSzhzNd+UVEYkkBj0h92QKckFk+BxwN/Dwz2B5m9k3gTuAl4AK8Afj+HXgP3gzqWVcCXwCWA/8AbAN+ZmZB03WIiNQ9jcMjUifM7BrgUufcgb51JwKP4A0w14M3ou7HnHM35eybAE51zt1vZk3AJuCbzrm2zPbxeIM03uCc+5cKHI6ISEWphEekvj2R+fcw4DPA73ODHQDnXK9z7v7Mn+8A9scrCcpu3w78D3B6WXMrIlIlCnhE6tthmX9fxQtkHihgn7cAvcALOeufzWwTEYkdzaUlUmfMLPu9fRPwPWAr8DNgDPBKAUmkgG0B84h1AePMbLRzbndU+RURqQUKeETqyyRgj+/vV4AP4U2Uiu9fERHxUcAjUl+2ACfjBTavAhudc87MRgG7gGkFpNEFTDCzRE4pTwrYodIdEYkjteERqS97nXOrnXNPOOc6XaabpXNuD/Br4LQC0ngOSACH56x/S2abiEjsKOARiY//C8w1s4/kbjCzEWa2IPPno8DfgHN928fhjcdzf+6+IiJxoCotkZhwzv2PmX0L+L6ZvRP4Md6Agm8BLsEbZ+cB51yPmX0N+IKZdeGV6nwW7wfQdVXJvIhImSngEYkR59z/MbNHgUuB24CxeIHO3cA3fC/9Gl6AcxVeQ+jVwCnOuU0VzbCISIVopGURERGJPbXhERERkdhTwCMiIiKxp4BHREREYk8Bj4iIiMSeAh4RERGJPQU8IiIiEnsKeERERCT2FPCIiIhI7CngERERkdj7/xWD7jY2whZ0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7eb6ee72e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "calibratedSource = calibMMDNet.predict(source)\n",
    "\n",
    "##################################### qualitative evaluation: PCA #####################################\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(target)\n",
    "\n",
    "# project data onto PCs\n",
    "target_sample_pca = pca.transform(target)\n",
    "projection_before = pca.transform(source)\n",
    "projection_after = pca.transform(calibratedSource)\n",
    "\n",
    "# choose PCs to plot\n",
    "pc1 = 0\n",
    "pc2 = 1\n",
    "axis1 = 'PC'+str(pc1)\n",
    "axis2 = 'PC'+str(pc2)\n",
    "sh.scatterHist(target_sample_pca[:,pc1], target_sample_pca[:,pc2], projection_before[:,pc1], \n",
    "               projection_before[:,pc2], axis1, axis2)\n",
    "sh.scatterHist(target_sample_pca[:,pc1], target_sample_pca[:,pc2], projection_after[:,pc1], \n",
    "               projection_after[:,pc2], axis1, axis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(calibratedSource)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibratedSourcePath = os.path.join(io.DeepLearningRoot(), 'data/calibratedBatch1-gtex-20PCs.csv')\n",
    "# df.to_csv(calibratedSourcePath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
